

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://img.enderfga.cn/img/favicon.png">
  <link rel="icon" href="https://img.enderfga.cn/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Enderfga">
  <meta name="keywords" content="">
  
    <meta name="description" content="From Twitter of Yam Peleg.">
<meta property="og:type" content="article">
<meta property="og:title" content="GPT4泄露的技术细节">
<meta property="og:url" content="http://enderfga.cn/2023/07/11/gpt4/index.html">
<meta property="og:site_name" content="Enderfga&#39;Blog">
<meta property="og:description" content="From Twitter of Yam Peleg.">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-07-11T01:12:24.000Z">
<meta property="article:modified_time" content="2023-07-11T01:50:30.920Z">
<meta property="article:author" content="Enderfga">
<meta property="article:tag" content="自然语言处理">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>GPT4泄露的技术细节 - Enderfga&#39;Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"enderfga.cn","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"oG62pOOQWEHEoerO","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"8yKzDhPjGo7c9GbBxy5UimY5-gzGzoHsz","app_key":"2ghy7HB3wrWXUD1VLNd92jeC","server_url":"https://8ykzdhpj.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?oG62pOOQWEHEoerO";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Enderfga'Blog" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Enderfga</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="https://enderfga.cn/phd">
                <i class="iconfont icon-switch-fill"></i>
                <span>游戏</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" target="_blank" rel="noopener" href="https://pan.enderfga.workers.dev/">
                <i class="iconfont icon-briefcase"></i>
                <span>网盘</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://img.enderfga.cn/img/wallhaven-vqq3m5.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="GPT4泄露的技术细节"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-07-11 09:12" pubdate>
          2023年7月11日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          51 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">GPT4泄露的技术细节</h1>
            
              <p class="note note-info">
                
                  
                    <!-- compatible with older versions-->
                    本文最后更新于：2023年7月11日 上午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>From Twitter of Yam Peleg.</p>
<span id="more"></span>
<h1 id="gpt-4s-details-are-leaked.">GPT-4's details are leaked.</h1>
<p>It is over. Everything is here:</p>
<h2 id="parameters-count">Parameters count</h2>
<p>GPT-4 is more than 10x the size of GPT-3. We believe it has a total
of ~1.8 trillion parameters across 120 layers.</p>
<h2 id="mixture-of-experts---confirmed">Mixture Of Experts -
Confirmed</h2>
<p>OpenAl was able to keep costs reasonable by utilizing a mixture of
experts(MoE) model.</p>
<p>They utilizes 16 experts within their model, each is about ~111B
parameters for MLP 2 of these experts are routed to per forward
pass.</p>
<h2 id="moe-routing">MoE Routing</h2>
<p>While the literature talks a lot about advanced routing algorithms
for choosing which experts to route each token to, OpenAl's is allegedly
quite simple, for the current GPT-4 model.</p>
<p>There roughly ~55B shared parameters for attention.</p>
<h2 id="inference">Inference</h2>
<p>Each forward pass inference (generation of 1 token) only utilizes
~280B parameters and ~560 TFLOPs. This contrasts with the ~1.8 trillion
parameters and ~3,700 TFLOP that would be required per forward pass of a
purely dense model.</p>
<h2 id="dataset">Dataset</h2>
<p>GPT-4 is trained on ~13T tokens. These are not unique tokens, they
count the epochs as more tokens as well.</p>
<p>Epoch number: 2 epochs for text-based data and 4 for code-based
data.</p>
<p>There is millions of rows of instruction fine-tuning data from
ScaleAl &amp; internally.</p>
<h2 id="gpt-4-32k">GPT-4 32K</h2>
<p>There was an 8k context length (seq len) for the pre-training phase.
The 32k seq len version of GPT-4 is based on fine-tuning of the 8k after
the pre-training.</p>
<h2 id="batch-size">Batch Size</h2>
<p>The batch size was gradually ramped up over a number of days on the
cluster, but by the end, OpenAl was using a batch size of 60 million!
This, of course, is “only” a batch size of 75 million tokens per expert
due to not every expert seeing all tokens.</p>
<h3 id="for-the-real-batch-size">For the real batch size</h3>
<p>Divide this number by the seq len to get the real batch size. Just
stop with this misleading numbers already.</p>
<h2 id="parallelism-strategies">Parallelism Strategies</h2>
<p>To parallelize across all their A100s GPUs</p>
<p>They utilized 8-way tensor parallelism as that is the limit for
NVLink. Beyond that, they are using 15-way pipeline parallelism.</p>
<p>(likely used ZeRo Stage 1.lt is possiblethey used block-level
FSDP)</p>
<h2 id="training-cost">Training Cost</h2>
<p>OpenAl's training FLOPS for GPT-4 is ~2.15e25,</p>
<p>on~25,000 A100s for 90 to 100 days at about 32% to 36% MFU.</p>
<p>Part of this extremely low utilization is due to an absurd number of
failures requiring checkpoints that needed to be restarted from.</p>
<p>If their cost in the cloud was about $1 per A100 hour, the training
costs for this run alone would be about $63 million</p>
<p>(Today, the pre-training could be done with ~8,192 H100 in ~55 days
for $21.5 million at $2 per H100 hour.)</p>
<h2 id="mixture-of-expert-tradeoffs">Mixture of Expert Tradeoffs</h2>
<p>There are multiple MoE tradeoffs taken:</p>
<p>For example, MoE is incredibly difficult to deal with on inference
because not every part of the model is utilized on every token
generation.</p>
<p>This means parts may sit dormant when other parts are being used.
When serving users, this really hurts utilization rates.</p>
<p>Researchers have shown that using 64 to 128 experts achieves better
loss than 16 experts, but that's purely research.</p>
<p>There are multiple reasons to go with fewer experts. One reason for
OpenAI choosing 16 experts is because more experts are difficult to
generalize at many tasks. More experts can also be more difficult to
achieve convergence with.</p>
<p>With such a large training run, OpenAI Instead chose to be more
conservative onthe number of experts.</p>
<h2 id="gpt-4-inference-cost">GPT-4 Inference Cost</h2>
<p>GPT-4 costs 3x that of the 175B parameter Davinchi.</p>
<p>This is largely due to the larger clusters required for GPT-4 and
much lower utilization achieved.</p>
<p>AN estimate of it's costs is $0.0049 cents per 1k tokens for 128
A100s to inference GPT-4 8k seq len and $0.0021cents per 1k tokens for
128 H100's to inference GPT-4 8k seq len. It should be noted, we assume
decent high utilization,and keeping batch sizes high.</p>
<h2 id="multi-query-attention">Multi-Query Attention</h2>
<p>OpenAl are using MQA just like everybody else.</p>
<p>Because of that only 1 head is needed and memory capacity can be
significantly reduced for the KV cache. Even then, the 32k seq len GPT-4
definitely cannot run on 40GB A10Os, and the 8k is capped onmax bsz.</p>
<h2 id="continuous-batching">Continuous batching</h2>
<p>OpenAl implements both variable batch sizes and continuous batching.
This is so as to allow some level of maximum latency as well optimizing
the inference costs.</p>
<h2 id="vision-multi-modal">Vision Multi-Modal</h2>
<p>It is a separate vision encoder from the text encoder, with
cross-attention. The architecture is similar to Flamingo. This adds more
parameters on top of the 1.8T of GPT-4. lt is fine-tuned with another ~2
trillion tokens, after the text only pre-training.</p>
<p>On the vision model, OpenAl wanted to train it from scratch, but it
wasn't mature enough, so they wanted to derisk it by starting with
text.</p>
<p>One of the primary purposes of this vision capability is for
autonomous agents able to read web pages and transcribe what's in images
and video.</p>
<p>Some of the data they train on is joint data (rendered LaTeX/text),
screen shots of web page, youtube videos: samplingframes, and run
Whisper around it to get transcript.</p>
<h2 id="speculative-decoding">Speculative Decoding</h2>
<p>OpenAl might be using speculative decoding on GPT-4's inference. (not
sure100%)</p>
<p>The idea is to use a smaller faster model to decode several tokens in
advance, and then feeds them into a large oracle model as a single
batch.</p>
<p>lf the small model was right about its predictions-the larger model
agrees and we can decode several tokens in a single batch.</p>
<p>But if the larger model rejects the tokens predicted by the draft
model then the rest of the batch is discarded. And wecontinue with the
larger model.</p>
<p>The conspiracy theory that the new GPT-4 quality had been
deteriorated might be simply because they are letting the oracle model
accept lower probability sequences from the speculative decoding
model.</p>
<h2 id="inference-architecture">Inference Architecture</h2>
<p>The inference runs on a cluster of 128 GPUs.</p>
<p>There are multiple of these clusters in multiple datacenters in
different locations.</p>
<p>It is done in 8-way tensor parallelism and 16-way pipeline
parallelism.</p>
<p>Each node of 8 GPUs has only ~130B parameters, or less than 30GB per
GPU at FP16 and less than 15GB at FP8/int8.</p>
<p>The model has 120, so it fits in 15 different nodes. [Possibly the
there are less layers on the first node since it needs to also compute
the embeddings]</p>
<p>According to these numbers: OpenAl should have trained on 2x the
tokens if they were trying to go by chinchilla'soptimal.</p>
<p>[let alone surpass it like we do]</p>
<p>This goes to show that they are strugglingto get high quality
data.</p>
<h2 id="why-no-fsdp">Why no FSDP?</h2>
<p>A possible reason for this could be that some of the hardware infra
they secured is of an older generation.</p>
<p>This is pretty common at local compute clusters as the
organisationusually upgrade the infra in several "waves" to avoid a
complete pause ofoperation.</p>
<p>With such a high amount of pipeline parallelism it is very likely
that just like the rest of us they suffer from the "batch bubble":
slight idle timebetween batches.</p>
<p>Again: There is no magic.</p>
<p>They know what they are doing but it is not magic.</p>
<hr />
<p>OpenAI是将GPT-4的架构保密，这并不是因为对人类存在着某种潜在风险，而是因为他们所构建的东西是可复制的。实际上，我们预计在不久的将来，谷歌、Meta、Anthropic、Inflection、Character、腾讯、字节跳动、百度等公司都将拥有与GPT-4同等甚至更强大的模型能力。</p>
<p>不要误会，OpenAI的工程能力非常出色，他们所构建的东西令人难以置信，但是他们所采取的解决方案并非神奇。这是一个优雅的解决方案，需要考虑许多复杂的权衡。扩大规模只是战斗的一部分。OpenAI最持久的优势在于他们在实际应用中拥有最多的用户、领先的工程人才，并且可以通过未来的模型继续超越其他竞争对手。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">#自然语言处理</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>GPT4泄露的技术细节</div>
      <div>http://enderfga.cn/2023/07/11/gpt4/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Enderfga</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年7月11日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/06/27/GILL/" title="Generating Images with Multimodal Language Models">
                        <span class="hidden-mobile">Generating Images with Multimodal Language Models</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Enderfga/commit-utterances');
      s.setAttribute('issue-term', 'title');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.13.10/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.events.registerRefreshCallback(function() {
      if ('mermaid' in window) {
        mermaid.init();
      }
    });
  });
</script>





  <!-- Custom -->
  <div class="col-lg-7 mx-auto nopadding-x-md">
    <div class="container custom post-custom mx-auto">
      <img src="https://img.enderfga.cn/img/20220420162434.png" srcset="/img/loading.gif" lazyload class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <p id="jinrishici-sentence">愿我如星君如月，夜夜流光相皎洁</p> <a href="https://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener"><span> 粤ICP备2021112653号-1</span></a> <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js">
</script>
</body>
</html>
