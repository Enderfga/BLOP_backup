<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Enderfga&#39;Blog</title>
  
  
  <link href="http://enderfga.cn/atom.xml" rel="self"/>
  
  <link href="http://enderfga.cn/"/>
  <updated>2022-07-18T08:57:45.238Z</updated>
  <id>http://enderfga.cn/</id>
  
  <author>
    <name>Enderfga</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>自动驾驶技术基础之规划与仿真</title>
    <link href="http://enderfga.cn/2022/07/18/auto2/"/>
    <id>http://enderfga.cn/2022/07/18/auto2/</id>
    <published>2022-07-18T08:53:04.000Z</published>
    <updated>2022-07-18T08:57:45.238Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动驾驶技术基础的规划与仿真作业</p><span id="more"></span><embed src="./report.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动驾驶技术基础的规划与仿真作业&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动驾驶" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>深度可分离卷积简介</title>
    <link href="http://enderfga.cn/2022/06/22/dsc/"/>
    <id>http://enderfga.cn/2022/06/22/dsc/</id>
    <published>2022-06-22T09:00:41.000Z</published>
    <updated>2022-07-08T09:02:53.862Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>深度学习理论平时作业</p><span id="more"></span><embed src="./dsc.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习理论平时作业&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>cifar10-horse生成任务</title>
    <link href="http://enderfga.cn/2022/06/20/horse/"/>
    <id>http://enderfga.cn/2022/06/20/horse/</id>
    <published>2022-06-20T00:46:42.000Z</published>
    <updated>2022-07-08T09:02:29.293Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>人工智能综合实验期末大作业horse生成（VAE,AAE,GAN...)</p><span id="more"></span><h1 align="center">Horse Generation</h1><h4 align="center">Comprehensive experiment of artificial intelligence</h4><h3 id="requirements">Requirements</h3><ol type="1"><li>64x,python3.8/3.9.</li><li>CUDA toolkit 11.1.</li><li>GCC 7.</li><li>sh setup.sh/pip install -r requirements.txt</li></ol><h3 id="文件目录">文件目录</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">├─Intro<span class="token punctuation">.</span>pptx  <span class="token comment">#介绍与展示的PowerPoint</span>├─tf_aae                      <span class="token comment">#AAE的tensorflow实现</span>├─VAE                         <span class="token comment">#VAE的pytorch实现</span>├─GAN<span class="token punctuation">.</span>ipynb                   <span class="token comment">#所有GAN的pytorch实现与运行结果</span>├─requirements<span class="token punctuation">.</span>txt  <span class="token comment">#本次任务运行环境中的包</span>├─setup<span class="token punctuation">.</span>sh  <span class="token comment">#配置环境的安装脚本</span>│├─result                      <span class="token comment">#存放用于展示的结果</span>├─apps│    └─interpolate_sample<span class="token punctuation">.</span>py  <span class="token comment">#用于生成视频</span>│├─fake_horse                  <span class="token comment">#一千张生成所得马的图片</span>├─mmgen                       <span class="token comment">#一个基于 PyTorch 和MMCV的强有力的生成模型工具箱</span>│  ├─apis│  ├─core│  ├─datasets│  ├─models│  ├─ops│  └─utils├─configs                     <span class="token comment">#运行stylegan3的配置文件</span>│  ├─styleganv3│  │    └─stylegan3<span class="token punctuation">.</span>py│  ││  └─_base_│      ├─ default_runtime<span class="token punctuation">.</span>py      <span class="token comment">#训练配置</span>│      ││      ├─datasets│      │    └─horse<span class="token punctuation">.</span>py                <span class="token comment">#数据处理</span>│      ││      └─models│          └─stylegan│                └─stylegan3_base<span class="token punctuation">.</span>py  <span class="token comment">#模型搭建</span>│└─tools    ├─ dist_train<span class="token punctuation">.</span>sh   <span class="token comment">#训练模型的脚本</span>    ├─ train<span class="token punctuation">.</span>py  <span class="token comment">#训练模型的代码</span>    │    └─utils          └─inception_stat<span class="token punctuation">.</span>py         <span class="token comment">#生成用于计算fid的inception模型</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="结果展示">结果展示</h3><h4 id="部分fake马">部分fake马</h4><p><img align="center" src="https://img.enderfga.cn/img/625.png"/></p><h4 id="生成训练可视化">生成训练可视化</h4><p><img align="center" src="https://img.enderfga.cn/img/GAN_generate_animation.gif"/></p><h4 id="动态结果展示">动态结果展示</h4><p><img align="center" src="https://img.enderfga.cn/img/lerp.gif"/></p><h3 id="fid一览">FID一览</h3><p><imgsrc="https://img.enderfga.cn/img/image-20220618194023873.png" /></p><h3 id="代码说明">代码说明</h3><ol type="1"><li><p>VAE/</p></li><li><p>tf_aae/</p></li><li><p>GAN.ipynb</p><p>前两者为文件夹，存放了模型，配置，数据集，辅助函数等相关py文件，主体为main.py;</p><p>后者为ipynb文件，记录了所有GAN模型的运行结果，并用于计算FID分数。</p><p>上述代码均可以通过修改数据路径来训练或测试。</p><embed src="./horse.pdf" width="100%" height="750" type="application/pdf"></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能综合实验期末大作业horse生成（VAE,AAE,GAN...)&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>呼吸运动伪影的图像质量评估</title>
    <link href="http://enderfga.cn/2022/06/20/cmr/"/>
    <id>http://enderfga.cn/2022/06/20/cmr/</id>
    <published>2022-06-20T00:42:42.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>基于深度学习分类网络的病变诊断之呼吸运动伪影的图像质量评估</strong></p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/image-20220620084604845.png" /></p><embed src="./cmr.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;基于深度学习分类网络的病变诊断之呼吸运动伪影的图像质量评估&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习在遥感图像分类中的应用</title>
    <link href="http://enderfga.cn/2022/05/30/dl/"/>
    <id>http://enderfga.cn/2022/05/30/dl/</id>
    <published>2022-05-30T07:13:14.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>深度学习期中应用调研报告</p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/what-is-deep-learning.jpg" /></p><embed src="./dl.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习期中应用调研报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Thinking Deeper about Cifar10</title>
    <link href="http://enderfga.cn/2022/05/30/cifar/"/>
    <id>http://enderfga.cn/2022/05/30/cifar/</id>
    <published>2022-05-30T07:07:15.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>人工智能综合实验期中大作业cifar10分类</p><span id="more"></span><p><img src="https://img.enderfga.cn/img/20220530151047.png" /></p><embed src="./cifar.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能综合实验期中大作业cifar10分类&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Docker 常用命令与操作</title>
    <link href="http://enderfga.cn/2022/05/29/docker/"/>
    <id>http://enderfga.cn/2022/05/29/docker/</id>
    <published>2022-05-29T01:13:27.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一张图整理Docker常用命令</p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/image-20220529091219215.png" /></p><h2 id="docker基本概念">Docker基本概念</h2><p>Docker 包括三个基本概念：</p><ul><li>镜像（<code>Image</code>）：Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。</li><li>容器（<code>Container</code>）：镜像（<code>Image</code>）和容器（<code>Container</code>）的关系，就像是面向对象程序设计中的<code>类</code> 和 <code>实例</code>一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li><li>仓库（<code>Repository</code>）：仓库（<code>Repository</code>）类似Git的远程仓库，集中存放镜像文件。</li></ul><p>三者关系可以用下图表示：</p><p><imgsrc="https://img.enderfga.cn/img/image-20220529091304514.png" /></p><p>接下来看一看Docker的常用命令。</p><h2 id="服务">服务</h2><ul><li>查看Docker版本信息</li></ul><p>docker version</p><ul><li>查看docker简要信息</li></ul><p>docker -v</p><ul><li>启动Docker</li></ul><p>systemctl start docker</p><ul><li>关闭docker</li></ul><p>systemctl stop docker</p><ul><li>设置开机启动</li></ul><p>systemctl enable docker</p><ul><li>重启docker服务</li></ul><p>service docker restart</p><ul><li>关闭docker服务</li></ul><p>service docker stop</p><h2 id="镜像">镜像</h2><h3 id="镜像仓库">镜像仓库</h3><p><ahref="https://link.segmentfault.com/?enc=eCypHIByefaQ8WlX8AJqSg%3D%3D.IV619qtOOjR2McoljdjR%2FNJXcHjWaOrxy0NrT1051R7Ot%2BYs5eUPDK5lfZoTudgL">DockerHub</a> 等镜像仓库上有大量的高质量的镜像可以用，可以从仓库获取镜像。</p><ul><li>检索镜像</li></ul><p>docker search 关键字</p><ul><li>拉取镜像</li></ul><p>docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]</p><h3 id="镜像管理">镜像管理</h3><ul><li>列出镜像</li></ul><p>docker image ls docker images</p><ul><li>删除镜像</li></ul><p># 删除指定镜像 docker rmi <镜像Id></p><ul><li>导出镜像</li></ul><p># 将镜像保存为归档文件 docker save</p><ul><li>导入镜像</li></ul><p>docker load</p><h3 id="dockerfile构建镜像">Dockerfile构建镜像</h3><p>Dockerfile 是一个文本格式的配 文件，用户可以使用 Dockerfile来快速创建自定义的镜像。</p><p>Dockerfile 由一行行行命令语句组成，并且支持以＃开头的注释行.</p><h4 id="dockerfile常见指令">Dockerfile常见指令</h4><p>下面是Dockerfile中一些常见的指令：</p><ul><li>FROM：指定基础镜像</li><li>RUN：执行命令</li><li>COPY：复制文件</li><li>ADD：更高级的复制文件</li><li>CMD：容器启动命令</li><li>ENV：设置环境变量</li><li>EXPOSE：暴露端口</li></ul><p>其它的指令还有ENTRYPOINT、ARG、VOLUME、WORKDIR、USER、HEALTHCHECK、ONBUILD、LABEL等等。</p><h4 id="镜像构建">镜像构建</h4><p>docker build</p><h4 id="镜像运行">镜像运行</h4><p>镜像运行，就是新建并运行一个容器。</p><p>docker run [镜像ID]</p><h2 id="容器">容器</h2><h3 id="容器生命周期">容器生命周期</h3><ul><li>启动：启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动。</li></ul><p># 新建并启动</p><p>docker run [镜像名/镜像ID]</p><p># 启动已终止容器</p><p>docker start [容器ID]</p><ul><li>查看容器</li></ul><p># 列出本机运行的容器</p><p>docker ps</p><p># 列出本机所有的容器（包括停止和运行）</p><p>docker ps -a</p><ul><li>停止容器</li></ul><p># 停止运行的容器</p><p>docker stop [容器ID]</p><p># 杀死容器进程</p><p>docker kill [容器ID]</p><ul><li>重启容器</li></ul><p>docker restart [容器ID]</p><ul><li>删除容器</li></ul><p>docker rm [容器ID]</p><h3 id="进入容器">进入容器</h3><p>进入容器有两种方式：</p><p># 如果从这个 stdin 中 exit，会导致容器的停止</p><p>docker attach [容器ID]</p><p># 交互式进入容器</p><p>docker exec [容器ID]</p><p>进入容器通常使用第二种方式，<code>docker exec</code>后面跟的常见参数如下：</p><p>－ d, --detach 在容器中后台执行命令；</p><p>－ i, --interactive=true I false ：打开标准输入接受用户输入命令</p><h3 id="导出和导入">导出和导入</h3><ul><li>导出容器</li></ul><p>#导出一个已经创建的容器到一个文件</p><p>docker export [容器ID]</p><ul><li>导入容器</li></ul><p># 导出的容器快照文件可以再导入为镜像</p><p>docker import [路径]</p><h3 id="其它">其它</h3><ul><li>查看日志</li></ul><p># 导出的容器快照文件可以再导入为镜像</p><p>docker logs [容器ID]</p><p>这个命令有以下常用参数</p><p>-f : 跟踪日志输出</p><p>--since :显示某个开始时间的所有日志</p><p>-t : 显示时间戳</p><p>--tail :仅列出最新N条容器日志</p><ul><li>复制文件</li></ul><p># 从主机复制到容器</p><p>sudo docker cp host_path containerID:container_path</p><p># 从容器复制到主机</p><p>sudo docker cp containerID:container_path host_path</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一张图整理Docker常用命令&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>安の推荐</title>
    <link href="http://enderfga.cn/2022/05/28/suggest/"/>
    <id>http://enderfga.cn/2022/05/28/suggest/</id>
    <published>2022-05-28T13:33:51.000Z</published>
    <updated>2022-07-03T03:08:13.368Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><imgsrc="https://img.enderfga.cn/img/image-20220528213455416.png" /></p><p>一时兴起，乱七八糟的推荐；需要付费的也很多，一分钱一分货，希望大家支持正版</p><span id="more"></span><h1 id="书签">书签</h1><h2 id="杂项">杂项</h2><p><a href="https://enderfga.cn/">我的博客</a></p><p>没想到吧，我的第一个书签居然是自己的博客虽然没什么高质量文章，但拿来当知识备忘录还是挺方便的~</p><p><ahref="https://pan.baidu.com/disk/home?#/all?path=%2F&amp;vmode=list">百度云</a></p><p>上了大学之后使用频率很低，当然主要原因还是我校的网速....不过有时候还是会拿来下下电影</p><p><a href="https://translate.google.cn/">Google 翻译</a></p><p><a href="https://dict.cnki.net/index">CNKI翻译助手</a></p><p><a href="https://www.deepl.com/translator">DeepL翻译</a></p><p>那个知网的翻译助手在b站刷视频被推荐的，还没有怎么用过；一般用deepl＋google对照使用</p><p><a href="http://www.gamersky.com/">游民星空</a></p><p>使用频率最高的网站，从08年开始每天晚上19点定时打开看囧图，虽然怪傻的</p><p>现在没有盗版游戏下载了，但各种各样的资讯当新闻看还挺有趣的(评论区的游民老哥好玩)</p><p><a href="https://www.youtube.com/">YouTube</a></p><p>没啥好说的，其实我大部分时间也只用bilibili</p><p><a href="https://www.zhihu.com/">知乎</a></p><p>搜搜各种知识，看看文章还有科技产品推荐</p><p><a href="https://portal.sysu.edu.cn/#/index">中山大学统一门户</a></p><p>我校官网的新ui很不错，安卓端也适配了</p><p><a href="https://github.com/Enderfga?tab=stars">Your Stars</a></p><p>习惯了收藏stars来上GitHub，GitHub的使用就不用介绍了</p><p><a href="https://2550505.com/">毛怪俱乐部</a></p><p>毛怪居然有自己的官网了！好像刚刚起步，希望早日能买到hanser的专辑！</p><p><a href="https://www.douyin.com/">抖音-记录美好生活</a></p><p>为了防沉迷，我卸载了抖音；但还是想刷，有时候就看看网页版</p><p><a href="https://eshop-prices.com/?currency=CNY">eShop-Prices.com –The best price comparison tool for Nintendo Switch games – ChineseRenminbi Yuan</a></p><p>一个显示switch游戏最低价格的网站，不过我是大慈善家，买了也没有时间玩</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528220111823.png" /></p><h2 id="影视">影视</h2><p>由于下面的网站特殊性，他们常常跑路换域名···</p><p><a href="http://www.rrdyw.net/">人人电影网</a></p><p><ahref="http://www.btbtt15.com/">BT之家-BT电影天堂-影视资源交流社区</a></p><p><a href="http://www.kisssub.org/">爱恋动漫</a></p><p>下载电影，番剧···等等的地方，如果能打开的话，都挺好用的</p><p><a href="http://www.age.tv/">在线动画 动漫下载 - AGE动漫</a></p><p>在线看番，无弹幕，更新快</p><p><a href="https://omofun.tv/">OmoFun动漫视频网 - (￣﹃￣)~omO</a></p><p>在线看番，有弹幕</p><p><a href="http://dyxs14.com/">电影先生 -聚合全网高清影视在线观看、下载</a></p><p>在线看剧</p><p><a href="http://www.549.tv/">影视森林——观影第一站</a></p><p>一个集合导航类型的网站，不怎么用，除非上面的都打不开会试着在里面探索新的</p><h2 id="图片">图片</h2><p><a href="https://apod.nasa.gov/">Astronomy Picture of the Day</a></p><p>每天一张宇宙照片和介绍</p><p><a href="https://wallhaven.cc/">Awesome Wallpapers -wallhaven.cc</a></p><p>精美的壁纸，登录解锁全部内容</p><p><a href="https://unsplash.com/">Beautiful Free Images &amp; Pictures| Unsplash</a></p><p>好看的图片，不是壁纸类型的</p><p><a href="https://tinypng.com/">TinyPNG</a></p><p><a href="https://www.picdiet.com/zh-cn">Picdiet - 压缩图片</a></p><p>图片无损压缩</p><p><a href="https://bigjpg.com/">Bigjpg</a></p><p>图片无损放大</p><p><a href="https://wordart.com/">WordArt.com - Word Cloud ArtCreator</a></p><p>制作词云图，刚开始我用python，后来发现还是用这个拿去骗人效果好一点</p><p><a href="https://photomosh.com/">PhotoMosh</a></p><p>一个“无聊”的网站，会随机给你的图片来点图像增广，建议自己试试</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528221059628.png" /></p><h2 id="软件">软件</h2><p>这里写的是关于软件的书签，并不是推荐软件</p><p><ahref="https://amazing-apps.gitbooks.io/windows-apps-that-amaze-us/content/zh-CN/?q=">序章· 绝赞应用</a></p><p>GitHub上一个旨在介绍 Windows绝妙项目的网站，现在能用，不过好像断更了</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528221330033.png" /></p><p><a href="https://music.hwkxk.cn/">音乐助手 -简洁极速搜索解析各大平台音乐</a></p><p>穷人的最爱，不过最近无了，我也是写这个才发现的，希望能回来</p><p><a href="https://www.ghxi.com/">果核剥壳 - 互联网的净土</a></p><p><a href="https://www.rjsos.com/">软件SOS</a></p><p>两个我下载软件的地方，类似于xmind，bandicam等好用的付费软件上面可能有破解版</p><h2 id="知识">知识</h2><p>真正的干货</p><p><ahref="http://www.ucdrs.superlib.net/">全国图书馆参考咨询联盟</a></p><p><a href="http://libgen.rs/">Library Genesis</a></p><p><a href="https://www.jiumodiary.com/">Jiumo Search 鸠摩搜索</a></p><p><a href="https://zh.z-lib.org/">Z-Library</a></p><p>以上是下载电子书的地方，zlibrary使用频率最高，我还有把我有上面没有的pdf上传，第二个下载国外的书用的，鸠摩像是个百度网盘搜索网站，走投无路的时候会搜；最后这个参考咨询联盟其实本身没什么卵用，但结合油猴脚本可以简单地花1,2块钱买到pdf，比淘宝方便</p><p><ahref="https://apps.webofknowledge.com/UA_GeneralSearch_input.do?product=UA&amp;search_mode=GeneralSearch&amp;SID=D4NArRzmguT3sCmspng&amp;preferencesSaved=">Webof Science</a></p><p><a href="https://www.cnki.net/">中国知网</a></p><p><a href="https://scholar.google.com/">Google Scholar</a></p><p><a href="https://xueshu.baidu.com/">百度学术</a></p><p><a href="https://readpaper.com/">论文阅读-专业的学术讨论社区</a></p><p>基本只用webofscience和谷歌学术，百度学术用来批量引用；那个社区可以读读文献，划词翻译，不过能实现这个功能的方式实在太多了；知网大一写政治课作业的时候还用，现在我甚至点不开了。</p><p><a href="https://oi-wiki.org/">OI Wiki</a></p><p><a href="https://labuladong.gitee.io/algo/">labuladong的算法小抄</a></p><p>收藏了但就是懒得点开的算法知识</p><p><a href="https://www.runoob.com/">菜鸟教程</a></p><p><ahref="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a></p><p>高质量自学内容，但就是很难有被点开的机会</p><p><ahref="https://zh.wikipedia.org/wiki/Wikipedia:首页">维基百科</a></p><p>虽然收藏的是中文首页，但还是用的英文版搜资料（会全很多，翻译不及时）</p><p><a href="https://www.latexlive.com/">在线LaTeX公式编辑器</a></p><p>ocr公式，以前一天50次，现在一天10次，改用mathpix了</p><p><a href="https://paperswithcode.com/sota">State-of-the-Art</a></p><p>机器学习深度学习写作业的时候的灵感来源，或者说是借鉴来源；paperwithcode真的很方便</p><p><a href="https://cn.overleaf.com/latex/templates">Templates - -Overleaf</a></p><p>小组大作业会大家一起用这个在线编译，模板的话我还是习惯自己常备的那3个</p><p><ahref="https://spcqwserdvymm.com.vika.cn/share/shryNwH3HRgvzMTaZVAGx/fodkuzz5eaw0w">🔔Efficiency-follow</a></p><p>乱七八糟的好东西合集，自己探索吧</p><p><a href="https://snip.mathpix.com/">Snip Notes</a></p><p>mathpix他们的一个产品，我拿来上传老师发的pdf然后提取内容放到我的作业里</p><p><a href="https://quillbot.com/">Paraphrasing Tool | QuillBotAI</a></p><p>英文写作小帮手，写出来之后能帮忙提升流畅度、专业性等等等等，功能高级的部分要付费</p><p><a href="https://stackoverflow.com/">Stack Overflow</a></p><p>程序猿的“知乎”，一般有bug在这一搜都能搜到，我没怎么试过问答</p><p><a href="https://zs.symbolab.com/">Symbolab 数学求解器 -分步计算器</a></p><p>当你高数知识忘的一干二净，遇到问题就用这个来解吧，还有分步过程</p><p><a href="https://www.ilovepdf.com/zh-cn/unlock_pdf">解锁PDF文件</a></p><p>里面还有各种各样的pdf功能，不过学校提供的正版foxit也基本都有，主要是用来解锁deepl翻译的文档（只读）</p><h1 id="扩展">扩展</h1><h2 id="去广告">去广告</h2><p><imgsrc="https://img.enderfga.cn/img/image-20220528223252001.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220528223408102.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220528223542478.png" /></p><p><ahref="https://chrome.google.com/webstore/detail/adblock-plus-free-ad-bloc/cfhdojbkjhnklbpkdaibdccddilifddb">AdblockPlus</a></p><p><ahref="https://chrome.google.com/webstore/detail/adblock-%E2%80%94-best-ad-blocker/gighmmpiobklfepjocnamgkkbiglidom">AdBlock</a></p><p><ahref="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm">uBlockOrigin</a></p><p>这仨就没什么好解释的，对广告零容忍，也不嫌多就都装了；可以指定屏蔽内容，我把GitHub上那些*独分子都屏蔽了</p><h2 id="邮件">邮件</h2><p><imgsrc="https://img.enderfga.cn/img/image-20220528223729300.png" /></p><p>方便我查收<ahref="https://chrome.google.com/webstore/detail/checker-plus-for-gmail/oeopbcgkkoapgobdbedcemjljbihmemj">gmail</a>的邮件，会有消息提醒等</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528223816247.png" /></p><p>作为一个强迫症，我看到我的每一个盘多了几MB<ahref="https://chrome.google.com/webstore/detail/clean-master-the-best-chr/eagiakjmjnblliacokhcalebgnhellfi">垃圾</a>我都会很难受</p><h2 id="翻译写作">翻译写作</h2><p><imgsrc="https://img.enderfga.cn/img/image-20220528223919801.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220528223946957.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220528224113309.png" /></p><p>刚开始只用<ahref="https://chrome.google.com/webstore/detail/%E6%B2%99%E6%8B%89%E6%9F%A5%E8%AF%8D-%E8%81%9A%E5%90%88%E8%AF%8D%E5%85%B8%E5%88%92%E8%AF%8D%E7%BF%BB%E8%AF%91/cdonnmffkdaoajfknoeeecmchibpmkmg">沙拉查词</a>的，各种功能非常全面；后来用<ahref="https://chrome.google.com/webstore/detail/deepl-translate-beta-vers/cofdbpoegempjloogbagkncekinflcnj">deepl</a>边写边译（中译英），方便跟外国友人交流，写完的内容还可以用<ahref="https://chrome.google.com/webstore/detail/quillbot-for-chrome/iidnbdjijdkbmajdffnidomddglmieko">quillbot</a>修改润色。虽然以上内容只会显得我英语水平很捞，但我用的蛮开心</p><h2 id="使用体验">使用体验</h2><p><imgsrc="https://img.enderfga.cn/img/image-20220528224252617.png" /></p><p><ahref="https://chrome.google.com/webstore/detail/gitzip-for-github/ffabmkklhbepgcgfonabamgnfafbdlkn">gitzip</a>，打包GitHub上指定文件或者文件夹，不用全部clone下来方便很多</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528224450069.png" /></p><p><a href="https://limestart.cn/">青柠起始页</a></p><p>虽然装了扩展但主要还是使用这个网页，我的新标签页主页都是这个，简洁美观，左上角是便签可以倒计时。</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528224715406.png" /></p><p><ahref="https://extensions.redeviation.com/">书签侧边栏</a>，如图所示，我那一大堆乱七八糟的书签就是这样打理的</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528224903817.png" /></p><p><ahref="https://chrome.google.com/webstore/detail/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%8A%A9%E6%89%8B%EF%BC%9Abilibilicom-%E7%BB%BC%E5%90%88%E8%BE%85%E5%8A%A9%E6%89%A9%E5%B1%95/kpbnombpnpcffllnianjibmpadjolanh">哔哩哔哩助手</a>，这就是为什么我的书签里没有b站的原因，我都是从这里跳转的。功能非常非常丰富，包括但不限于下载各个分辨率的视频和弹幕，实现各种各样的默认跳转（自动宽屏，关弹幕，4k···），自动帮我给hanser三连</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528225202730.png" /></p><p>虽然经常说油猴脚本，但我自己用的还是暴力猴，作者是中国人，在哪些网页使用体验不好了我就搜一下</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528225352529.png" /></p><p>往往会有惊喜</p><p>本来想专门写一个栏目介绍了，但我好累</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528225516406.png" /></p><p>大家看名字识功能吧</p><p>比较推荐的有网页限制解除，很多网站不能复制就很烦；秀读图书互转，结合这个上面提到的参考咨询联盟才能轻松下载pdf；</p><p>百度网盘简易下载助手，目前还能用，校园网满速；AC-baidu，对百度谷歌等界面都优化了。（黑是因为我系统设置了暗）</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528225804605.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220528225854431.png" /></p><h1 id="软件-1">软件</h1><p>没动力写了，摆烂式推荐</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528230140552.png" /></p><p>foxit pdf：功能全面，毕竟是学校帮忙付费了的</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528230232796.png" /></p><p>vscode：啥都能写，加上copilot，一分钟上千行代码不是梦（bushi）</p><p>感觉vscode也可以写一个扩展分享，但我好懒，感兴趣地可以了解一下图里这个，根据注释自动写代码</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528230544526.png" /></p><p>格式工厂：啥都能给你转转，除了各种格式转换，我还用来简单地剪辑之类的；可以把各大软件的付费格式转换成常见格式</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528230709483.png" /></p><p>anaconda：maybe是python学习必备软件之一（吧）,搭建环境之后我更习惯写jupyternotebook（但用的是vscode）</p><p><imgsrc="https://img.enderfga.cn/img/image-20220528231002743.png" /></p><p>mathpix：上面一张图展示功能，快捷键截图之后就能ocr出来贴typora或者latex，甚至office系列软件</p><p>教育邮箱每月100次</p><p>列举剩下的一些体验良好的软件：</p><p>视频播放我用potplayer；解压缩我用bandizip；视频录制我用bandicam；思维导图我用xmind；</p><p>浏览器当然是chrome，不过edge也很不错；备忘录用microsoft to do；</p><p>备份习惯用google drive，打游戏用一个叫灵缇的小众加速器·····</p><p>暂时到这里吧，如果我又双叒叕心血来潮也许会更新。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img
src=&quot;https://img.enderfga.cn/img/image-20220528213455416.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;一时兴起，乱七八糟的推荐；需要付费的也很多，一分钱一分货，希望大家支持正版&lt;/p&gt;</summary>
    
    
    
    
    <category term="闲谈" scheme="http://enderfga.cn/tags/%E9%97%B2%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——感知</title>
    <link href="http://enderfga.cn/2022/05/27/robot7/"/>
    <id>http://enderfga.cn/2022/05/27/robot7/</id>
    <published>2022-05-27T07:53:41.000Z</published>
    <updated>2022-07-03T03:08:13.368Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/image-20220527155651383.png" /></p><embed src="./Perception.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>可靠数据传输原理</title>
    <link href="http://enderfga.cn/2022/05/17/net5/"/>
    <id>http://enderfga.cn/2022/05/17/net5/</id>
    <published>2022-05-16T23:52:24.000Z</published>
    <updated>2022-07-03T03:08:13.374Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第三章运输层之可靠数据传输原理</p><p><img src="https://img.enderfga.cn/img/20220517080217.png" /></p><span id="more"></span><embed src="./ARQ.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;第三章运输层之可靠数据传输原理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.enderfga.cn/img/20220517080217.png&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>2R机械臂五次多项式轨迹规划</title>
    <link href="http://enderfga.cn/2022/05/16/robot6/"/>
    <id>http://enderfga.cn/2022/05/16/robot6/</id>
    <published>2022-05-16T15:56:27.000Z</published>
    <updated>2022-07-03T03:08:13.369Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://img.enderfga.cn/img/20220516000042.png" /></p><p>智能机器人技术作业记录</p><span id="more"></span><embed src="./2R.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://img.enderfga.cn/img/20220516000042.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>C2TCP：一个超低延迟的灵活蜂窝式TCP</title>
    <link href="http://enderfga.cn/2022/05/16/net4/"/>
    <id>http://enderfga.cn/2022/05/16/net4/</id>
    <published>2022-05-16T00:59:15.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计算机网络前沿论文导读</p><p><imgsrc="https://img.enderfga.cn/img/2432716a34cb4571ac86e2b7f56f617.png" /></p><span id="more"></span><embed src="./C2TCP.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计算机网络前沿论文导读&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://img.enderfga.cn/img/2432716a34cb4571ac86e2b7f56f617.png&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——机器人运动学奇异分析与性能评价</title>
    <link href="http://enderfga.cn/2022/05/15/robot5/"/>
    <id>http://enderfga.cn/2022/05/15/robot5/</id>
    <published>2022-05-15T06:05:29.000Z</published>
    <updated>2022-07-03T03:08:13.368Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><h1id="智能机器人技术机器人运动学奇异分析与性能评价">智能机器人技术——机器人运动学奇异分析与性能评价</h1><p>一、给定平面2R机械臂状态参数，</p><p>状态描述：</p><ul><li>关节状态: <span class="math inline">\(\quad\left[\theta_{1},\theta_{2}\right]^{\mathrm{T}}\)</span></li><li>末端位置: <span class="math inline">\(\quad\left[x_{e},y_{e}\right]^{\mathrm{T}}\)</span></li></ul><p><imgsrc="https://img.enderfga.cn/img/image-20220508155155580.png" /></p><ol type="1"><li><p>计算逆运动学，求解关节角的表达式（已知末端位置<spanclass="math inline">\(\quad\left[x_{e},y_{e}\right]^{\mathrm{T}}\)</span>，求关节角<spanclass="math inline">\(\quad\left[\theta_{1},\theta_{2}\right]^{\mathrm{T}}\)</span>）</p><p>根据几何关系, 可推导出机械臂末端位置与机械臂关节变量的关系:</p><p><span class="math display">\[\begin{array}{l}p_{\mathrm{ex}}=l_{1} c_{1}+l_{2} c_{12} \\p_{\mathrm{ey}}=l_{1} s_{1}+l_{2} s_{12}\end{array}\]</span></p><p>其中,</p><p><span class="math display">\[\left\{\begin{array}{l}s_{1}=\sin \theta_{1}, c_{1}=\cos \theta_{1} \\s_{12}=\sin \left(\theta_{1}+\theta_{2}\right), c_{12}=\cos\left(\theta_{1}+\theta_{2}\right)\end{array}\right.\]</span></p><p>其向量形式为：</p><p><span class="math display">\[p_{\mathrm{e}}=\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{e} y}\end{array}\right]=\left[\begin{array}{l}l_{1} c_{1}+l_{2} c_{12} \\l_{1} s_{1}+l_{2} s_{12}\end{array}\right]=\left[\begin{array}{l}l_{1} \cos \theta_{1}+l_{2} \cos \left(\theta_{1}+\theta_{2}\right) \\l_{1} \sin \theta_{1}+l_{2} \sin \left(\theta_{1}+\theta_{2}\right)\end{array}\right]\]</span></p><p>将式子两边的平方相加, 有</p><p><span class="math display">\[p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}\left(c_{1}c_{12}+s_{1} s_{12}\right)\]</span></p><p><spanclass="math inline">\(p_{\mathrm{e}}^{2}=p_{\mathrm{ex}}^{2}+p_{\mathrm{ey}}^{2}\)</span>为基坐标系原点到末端坐标系原点的距离。</p><p>根据三角函数的性质, 有</p><p><span class="math display">\[c_{1} c_{12}+s_{1} s_{12}=c_{2}\]</span></p><p>故可化简为</p><p><span class="math display">\[p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}\]</span></p><p>因此，</p><p><span class="math display">\[\left\{\begin{array}{l}p_{\mathrm{e}}^{2} \leqslant l_{1}^{2}+l_{2}^{2}+2 l_{1}l_{2}=\left(l_{1}+l_{2}\right)^{2} \\p_{\mathrm{e}}^{2} \geqslant l_{1}^{2}+l_{2}^{2}-2 l_{1}l_{2}=\left(l_{1}-l_{2}\right)^{2}\end{array}\right.\\\left|l_{1}-l_{2}\right| \leqslant p_{e} \leqslant l_{1}+l_{2}\]</span></p><p>上式即表示了该 <span class="math inline">\(2 \mathrm{R}\)</span>机械臂的工作空间范围, 其最小边沿和最大边沿分别对应于 <spanclass="math inline">\(\theta_{2}=\pi\)</span> 和 <spanclass="math inline">\(\theta_{2}=0\)</span> 的情况。</p><p>进一步有，</p><p><span class="math display">\[\left|\frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1}l_{2}}\right| \leqslant 1\]</span></p><p>解得：</p><p><span class="math display">\[\theta_{2}=\pm \arccos \frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2l_{1} l_{2}}=\pm \arccos\frac{x_{\mathrm{e}}^{2}+y_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1}l_{2}}\]</span></p><p>关节角 <span class="math inline">\(\theta_{2}\)</span> 解出后,将其代入方程组中, 可进一步解出关节角 <spanclass="math inline">\(\theta_{1}\)</span> 。首先根据三角函数的性质:</p><p><span class="math display">\[\begin{aligned}&amp;c_{12}=c_{1} c_{2}-s_{1} s_{2} \\&amp;s_{12}=s_{1} c_{2}+c_{1} s_{2}\end{aligned}\]</span></p><p>有，</p><p><span class="math display">\[\left\{\begin{array}{l}\left(l_{1}+l_{2} c_{2}\right) c_{1}-l_{2} s_{2} s_{1}=p_{\mathrm{ex}}\\l_{2} s_{2} c_{1}+\left(l_{1}+l_{2} c_{2}\right) s_{1}=p_{\mathrm{e} y}\end{array}\right.\]</span></p><p>可写成如下形式:</p><p><span class="math display">\[\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right]\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{l}p_{e x} \\p_{\mathrm{ey}}\end{array}\right]\]</span></p><p>方程组的系数矩阵 <span class="math inline">\(\boldsymbol{A}\)</span>及其行列式分别为</p><p><span class="math display">\[\boldsymbol{A}=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right],\operatorname{det}(\boldsymbol{A})=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}c_{2}\]</span></p><p>若 <span class="math inline">\(\operatorname{det}(\boldsymbol{A})\neq 0\)</span>, 则矩阵 <spanclass="math inline">\(\boldsymbol{A}\)</span> 满秩, 方程组有解, 即:</p><p><span class="math display">\[\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right]^{-1}\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{ey}}\end{array}\right]=\frac{1}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}c_{2}}\left[\begin{array}{c}\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2}p_{\mathrm{ey}} \\-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ey}}\end{array}\right]\]</span></p><p><span class="math inline">\(\theta_{1}\)</span> 可根据解出的 <spanclass="math inline">\(s_{1}\)</span> 和 <spanclass="math inline">\(c_{1}\)</span> 求出, 即:</p><p><span class="math display">\[\begin{aligned}\theta_{1} &amp;=\arctan 2\left(s_{1}, c_{1}\right)=\arctan2\left(\frac{-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}},\frac{\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2}p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}}\right) \\&amp;=\arctan 2\left(-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2}c_{2}\right) p_{\mathrm{ey}},\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ex}}+l_{2} s_{2} p_{\mathrm{ey}}\right)\end{aligned}\]</span></p><p>根据基本不等式及三级函数的性质, 令 <spanclass="math inline">\(\operatorname{det}(\boldsymbol{A})=0\)</span>,则必有 <span class="math inline">\(l_{1}=l_{2}\)</span> 且 <spanclass="math inline">\(\theta_{2}=\pi\)</span>, 即:</p><p><span class="math display">\[\operatorname{det}(\boldsymbol{A})=0 \Rightarrow\left\{\begin{array} { l}{ l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } + 2 l _ { 1 } l _ { 2 } c _ { 2} = 0 } \\{ l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } \geqslant 2 l _ { 1 } l _ { 2 }} \\{ | c _ { 2 } | \leqslant 1 }\end{array} \Rightarrow \left\{\begin{array}{l}l_{1}=l_{2} \\\theta_{2}=\pi\end{array}\right.\right.\]</span></p><p>综上所述, 结果可以求出两组解, 对应于机器人的两种臂型, 分别称为高臂(肘) 和低臂 (肘), 平面 <span class="math inline">\(2 \mathrm{R}\)</span>机械臂逆运动学多解情况分析下图所示。也就是说, 对于前述的 <spanclass="math inline">\(2 \mathrm{R}\)</span> 机械臂,当给定末端点的一个位置 <spanclass="math inline">\(\boldsymbol{p}_{\mathrm{e}}\)</span> 时,有两组关节角与之对应, 即位置级逆运动学有多解。</p><p><imgsrc="https://img.enderfga.cn/img/image-20220515125458389.png" /></p></li><li><p>计算雅克比矩阵</p></li></ol><p>根据机械臂末端位置与机械臂关节变量的关系求导得：</p><p><span class="math display">\[\left\{\begin{array}{l}\dot{p}_{\mathrm{ex}}=-l_{1} s_{1} \dot{\theta}_{1}-l_{2}s_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=-\left(l_{1}s_{1}+l_{2} s_{12}\right) \dot{\theta}_{1}-l_{2} s_{12} \dot{\theta}_{2}\\\dot{p}_{\mathrm{cy}}=l_{1} c_{1} \dot{\theta}_{1}+l_{2}c_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=\left(l_{1}c_{1}+l_{2} c_{12}\right) \dot{\theta}_{1}+l_{2} c_{12} \dot{\theta}_{2}\\\end{array}\right.\]</span></p><p>即:</p><p><span class="math display">\[\left[\begin{array}{l}\dot{p}_{\mathrm{ex}} \\\dot{p}_{\mathrm{ey}}\end{array}\right]=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} &amp; -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} &amp; l_{2} c_{12}\end{array}\right]\left[\begin{array}{l}\dot{\theta}_{1} \\\dot{\theta}_{2}\end{array}\right]\]</span></p><p>其矩阵形式为：</p><p><span class="math display">\[\dot{\boldsymbol{p}}_{\mathrm{e}}=\boldsymbol{J}_{v}(\boldsymbol{\Theta})\dot{\boldsymbol{\Theta}}\]</span></p><p>此时, <span class="math inline">\(\boldsymbol{J}_{v}\)</span> 为<span class="math inline">\(2 \times 2\)</span> 的方阵:</p><p><span class="math display">\[\boldsymbol{J}_{v}=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} &amp; -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} &amp; l_{2} c_{12}\end{array}\right]\]</span></p><p>二、给定D-H坐标系，填写D-H参数表。</p><p><imgsrc="https://img.enderfga.cn/img/image-20220515131813671.png" /></p><p><span class="math display">\[\begin{array}{ccccc}\hline  \text { 连杆i } &amp; \theta_{i} &amp; \alpha_{i} &amp; a_{i}&amp; d_{i} \\\hline1 &amp; 0 &amp; -90^{\circ} &amp; 0 &amp; d_{1} \\2 &amp; 0 &amp; 0 &amp; a_{2} &amp; 0 \\  3 &amp; 0 &amp; 0 &amp; a_{3} &amp; 0\\  \hline\end{array}\]</span></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch常用代码段合集</title>
    <link href="http://enderfga.cn/2022/05/10/torch/"/>
    <id>http://enderfga.cn/2022/05/10/torch/</id>
    <published>2022-05-10T15:45:53.000Z</published>
    <updated>2022-07-03T03:08:13.368Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。</p><p><imgsrc="https://img.enderfga.cn/img/image-20220511003116457.png" /></p><span id="more"></span><h1 id="基本配置"><strong>基本配置</strong></h1><h3 id="导入包和版本查询"><strong>导入包和版本查询</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="可复现性"><strong>可复现性</strong></h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>显卡设置</p><p>如果只需要一张显卡</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Device configuration</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>如果需要指定多张显卡，比如0，1号显卡。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>也可以在命令行运行代码时设置显卡：</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> python train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>清除显存</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>也可以使用在命令行重置GPU的指令</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi --gpu-reset -i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="张量tensor处理"><strong>张量(Tensor)处理</strong></h1><h3 id="张量的数据类型"><strong>张量的数据类型</strong></h3><p>PyTorch有9种CPU张量类型和9种GPU张量类型。</p><p><img src="https://img.enderfga.cn/img/640" /></p><h3 id="张量基本信息"><strong>张量基本信息</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 数据类型</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 张量的shape，是个元组</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 维度的数量</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="命名张量"><strong>命名张量</strong></h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在PyTorch 1.3之前，需要使用注释</span><span class="token comment"># Tensor[N, C, H, W]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># PyTorch 1.3之后</span>NCHW <span class="token operator">=</span> <span class="token punctuation">[</span>‘N’<span class="token punctuation">,</span> ‘C’<span class="token punctuation">,</span> ‘H’<span class="token punctuation">,</span> ‘W’<span class="token punctuation">]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> names<span class="token operator">=</span>NCHW<span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 也可以这么设置</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 使用align_to可以对维度方便地排序</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>align_to<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="数据类型转换">数据类型转换</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span>torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token comment"># 类型转换</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="torch.tensor与np.ndarray转换"><strong>torch.Tensor与np.ndarray转换</strong></h3><p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If ndarray has negative stride.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3id="torch.tensor与pil.image转换"><strong>Torch.tensor与PIL.Image转换</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span><span class="token comment"># torch.Tensor -> PIL.Image</span>image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span><span class="token comment"># PIL.Image -> torch.Tensor</span>path <span class="token operator">=</span> <span class="token string">r'./figure.jpg'</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#Equivalently way</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="np.ndarray与pil.image的转换">np.ndarray与PIL.Image的转换</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>ndarray <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h3id="从只包含一个元素的张量中提取值"><strong>从只包含一个元素的张量中提取值</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">value <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="张量形变"><strong>张量形变</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，</span><span class="token comment"># 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="打乱顺序"><strong>打乱顺序</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 打乱第一个维度</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="水平翻转"><strong>水平翻转</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现</span><span class="token comment"># 假设张量的维度为[N, D, H, W].</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="复制张量"><strong>复制张量</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Operation                 |  New/Shared memory | Still in computation graph |</span>tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># |        New         |          Yes               |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># |      Shared        |          No                |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># |        New         |          No                | </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="张量拼接"><strong>张量拼接</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，而torch.stack的结果是3x10x5的张量。'''</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="将整数标签转为one-hot编码"><strong>将整数标签转为one-hot编码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch的标记默认从0开始</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">4</span>one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="得到非零元素"><strong>得到非零元素</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>               <span class="token comment"># index of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment"># index of zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>       <span class="token comment"># number of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># number of zero elements</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="判断两个张量相等"><strong>判断两个张量相等</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>  <span class="token comment"># float tensor</span>torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>     <span class="token comment"># int tensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h3 id="张量扩展"><strong>张量扩展</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="矩阵乘法"><strong>矩阵乘法</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Matrix multiplcation: (m*n) * (n*p) * -> (m*p).</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p)</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Element-wise multiplication.</span>result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="计算两组数据之间的两两欧式距离"><strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用broadcast机制</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> X2<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="模型定义和操作"><strong>模型定义和操作</strong></h1><h3 id="一个简单两层卷积网络的示例">一个简单两层卷积网络的示例</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># convolutional neural network (2 convolutional layers)</span><span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> outmodel <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>卷积层的计算和展示可以用这个网站辅助。</p><p>https://ezyang.github.io/convolution-visualizer/index.html</p><h3 id="双线性汇合bilinear-pooling">双线性汇合（bilinear pooling）</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">)</span>                        <span class="token comment"># Assume X has shape N*D*H*W</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W<span class="token punctuation">)</span>  <span class="token comment"># Bilinear pooling</span><span class="token keyword">assert</span> X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> D<span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e-5</span><span class="token punctuation">)</span>   <span class="token comment"># Signed-sqrt normalization</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment"># L2 normalization</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="多卡同步-bnbatch-normalization"><strong>多卡同步 BN（Batchnormalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batchsize）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>   affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3id="将已有网络的所有bn层改为同步bn层">将已有网络的所有BN层改为同步BN层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">convertBNtoSyncBN</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> process_group<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''Recursively replace all BN layers to SyncBN layer.    Args:        module[torch.nn.Module]. Network    '''</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>batchnorm<span class="token punctuation">.</span>_BatchNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>        sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>module<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> module<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> module<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span>                                          module<span class="token punctuation">.</span>affine<span class="token punctuation">,</span> module<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">,</span> process_group<span class="token punctuation">)</span>        sync_bn<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> module<span class="token punctuation">.</span>running_mean        sync_bn<span class="token punctuation">.</span>running_var <span class="token operator">=</span> module<span class="token punctuation">.</span>running_var        <span class="token keyword">if</span> module<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>            sync_bn<span class="token punctuation">.</span>weight <span class="token operator">=</span> module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>            sync_bn<span class="token punctuation">.</span>bias <span class="token operator">=</span> module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> sync_bn    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> child_module <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token builtin">setattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">=</span> convert_syncbn_model<span class="token punctuation">(</span>child_module<span class="token punctuation">,</span> process_group<span class="token operator">=</span>process_group<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> module<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="类似-bn-滑动平均"><strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward函数中要使用原地（inplace）操作给滑动平均赋值。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>running_mean <span class="token operator">+=</span> momentum <span class="token operator">*</span> <span class="token punctuation">(</span>current <span class="token operator">-</span> self<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="计算模型整体参数量"><strong>计算模型整体参数量</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="查看网络中的参数"><strong>查看网络中的参数</strong></h3><p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name2<span class="token punctuation">,</span> param2<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'----------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name1<span class="token punctuation">,</span> param1<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="模型可视化使用pytorchviz"><strong>模型可视化（使用pytorchviz）</strong></h3><p>https://github.com/szagoruyko/pytorchviz</p><h3id="类似-keras-的-model.summary-输出模型信息使用pytorch-summary"><strong>类似Keras 的 model.summary() 输出模型信息（使用pytorch-summary）</strong></h3><p>https://github.com/sksq96/pytorch-summary</p><p><strong>模型权重初始化</strong></p><p>注意 model.modules() 和 model.children() 的区别：model.modules()会迭代地遍历模型的所有子层，而 model.children()只会遍历模型下的一层。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Common practise for initialization.</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span>                                      nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token comment"># Initialization with given tensor.</span>layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取模型中的某一层"><strong>提取模型中的某一层</strong></h3><p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 取模型中的前两层</span>new_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>         conv_model<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="部分层使用预训练模型"><strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="将在-gpu-保存的模型加载到-cpu">将在 GPU 保存的模型加载到CPU</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2id="导入另一个模型的相同部分到新的模型"><strong>导入另一个模型的相同部分到新的模型</strong></h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># model_new代表新的模型</span><span class="token comment"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span>model_new_dict <span class="token operator">=</span> model_new<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>model_common_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> model_saved<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> model_new_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>model_new_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_common_dict<span class="token punctuation">)</span>model_new<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_new_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="数据处理"><strong>数据处理</strong></h1><h3 id="计算数据集的均值和标准差">计算数据集的均值和标准差</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">compute_mean_and_std</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 输入PyTorch的dataset，输出均值和标准差</span>    mean_r <span class="token operator">=</span> <span class="token number">0</span>    mean_g <span class="token operator">=</span> <span class="token number">0</span>    mean_b <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># change PIL Image to numpy array</span>        mean_r <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_g <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_b <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    mean_r <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_g <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_b <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    diff_r <span class="token operator">=</span> <span class="token number">0</span>    diff_g <span class="token operator">=</span> <span class="token number">0</span>    diff_b <span class="token operator">=</span> <span class="token number">0</span>    N <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        diff_r <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_r<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_g <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_g<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_b <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_b<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        N <span class="token operator">+=</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    std_r <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_r <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_g <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_g <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_b <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_b <span class="token operator">/</span> N<span class="token punctuation">)</span>    mean <span class="token operator">=</span> <span class="token punctuation">(</span>mean_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    std <span class="token operator">=</span> <span class="token punctuation">(</span>std_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> mean<span class="token punctuation">,</span> std<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="得到视频数据基本信息">得到视频数据基本信息</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> cv2video <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>mp4_path<span class="token punctuation">)</span>height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_HEIGHT<span class="token punctuation">)</span><span class="token punctuation">)</span>width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_WIDTH<span class="token punctuation">)</span><span class="token punctuation">)</span>num_frames <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_COUNT<span class="token punctuation">)</span><span class="token punctuation">)</span>fps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FPS<span class="token punctuation">)</span><span class="token punctuation">)</span>video<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="tsn-每段segment采样一帧视频">TSN每段（segment）采样一帧视频</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">K <span class="token operator">=</span> self<span class="token punctuation">.</span>_num_segments<span class="token keyword">if</span> is_train<span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Random index for each segment.</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames <span class="token operator">//</span> K<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Middle index for each segment.</span>        frame_indices <span class="token operator">=</span> num_frames <span class="token operator">/</span> K <span class="token operator">//</span> <span class="token number">2</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>                                        torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">assert</span> frame_indices<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token punctuation">[</span>frame_indices<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="常用训练和验证数据预处理"><strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255]的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的torch.Tensor。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span>                                             scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span><span class="token punctuation">)</span> val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="模型训练和测试"><strong>模型训练和测试</strong></h1><h3 id="分类模型训练代码"><strong>分类模型训练代码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Loss and optimizer</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># Train the model</span>total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token punctuation">,</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>              <span class="token comment"># Forward pass</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>              <span class="token comment"># Backward and optimizer</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: [&#123;&#125;/&#123;&#125;], Step: [&#123;&#125;/&#123;&#125;], Loss: &#123;&#125;'</span>                  <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="分类模型测试代码"><strong>分类模型测试代码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Test the model</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># eval mode(batch norm uses moving mean/variance </span>              <span class="token comment">#instead of mini-batch mean/variance)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy of the model on the 10000 test images: &#123;&#125; %'</span>          <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="自定义loss"><strong>自定义loss</strong></h3><p>继承torch.nn.Module类写自己的loss。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLoss</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Moudle<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="标签平滑label-smoothing"><strong>标签平滑（labelsmoothing）</strong></h3><p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log_softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>e <span class="token operator">=</span> e        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction      <span class="token keyword">def</span> <span class="token function">_one_hot</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> classes<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""            Convert labels to one hot vectors              Args:            labels: torch tensor in format [label1, label2, label3, ...]            classes: int, number of classes            value: label value in one hot vector, default to 1              Returns:            return one hot format labels in shape [batchsize, classes]        """</span>        one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span>        <span class="token comment">#labels and value_added  size must match</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        value_added <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>value<span class="token punctuation">)</span>        value_added <span class="token operator">=</span> value_added<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot <span class="token operator">=</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> value_added<span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot    <span class="token keyword">def</span> <span class="token function">_smooth_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> smooth_factor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""convert targets to one-hot format, and smooth        them.        Args:            target: target in form with [label1, label2, label_batchsize]            length: length of one-hot format(number of classes)            smooth_factor: smooth factor for label smooth              Returns:            smoothed labels in one hot format        """</span>        one_hot <span class="token operator">=</span> self<span class="token punctuation">.</span>_one_hot<span class="token punctuation">(</span>target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> smooth_factor<span class="token punctuation">)</span>        one_hot <span class="token operator">+=</span> smooth_factor <span class="token operator">/</span> <span class="token punctuation">(</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>target<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">!=</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input tensor to have least 2 dimensions(got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Only 2 dimension tensor are implemented, (got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        smoothed_target <span class="token operator">=</span> self<span class="token punctuation">.</span>_smooth_label<span class="token punctuation">(</span>target<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>e<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span> x <span class="token operator">*</span> smoothed_target<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'none'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> loss              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'sum'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'mean'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'unrecognized option, expect reduction to be one of none, mean, sum'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>或者直接在训练文件里做label smoothing</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    N <span class="token operator">=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># C is the number of classes.</span>    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="mixup训练"><strong>Mixup训练</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">beta_distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>distributions<span class="token punctuation">.</span>beta<span class="token punctuation">.</span>Beta<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Mixup images and labels.</span>    lambda_ <span class="token operator">=</span> beta_distribution<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    mixed_images <span class="token operator">=</span> lambda_ <span class="token operator">*</span> images <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> images<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    label_a<span class="token punctuation">,</span> label_b <span class="token operator">=</span> labels<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token comment"># Mixup loss.</span>    scores <span class="token operator">=</span> model<span class="token punctuation">(</span>mixed_images<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>lambda_ <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_a<span class="token punctuation">)</span>            <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_b<span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="l1-正则化">L1 正则化</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">l1_regularization <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment"># Standard cross-entropy loss</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    loss <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="不对偏置项进行权重衰减weight-decay"><strong>不对偏置项进行权重衰减（weightdecay）</strong></h3><p>pytorch里的weight decay相当于l2正则</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">bias_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>others_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> bias_list<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            <span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> others_list<span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="梯度裁剪gradient-clipping"><strong>梯度裁剪（gradientclipping）</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="得到当前学习率"><strong>得到当前学习率</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># If there is one global learning rate (which is the common case).</span>lr <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token comment"># If there are multiple learning rates for different layers.</span>all_lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>    all_lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>另一种方法，在一个batch训练代码里，当前的lr是optimizer.param_groups[0]['lr']</p><h3 id="学习率衰减">学习率衰减</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Reduce learning rate when validation accuarcy plateau.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span class="token comment"># Cosine annealing learning rate.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token comment"># Reduce learning rate by 10 at given epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># Learning rate warmup by 10 epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t <span class="token operator">/</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="优化器链式更新"><strong>优化器链式更新</strong></h3><p>从1.4版本开始，torch.optim.lr_scheduler支持链式更新（chaining），即用户可以定义两个schedulers，并交替在训练中使用。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> ExponentialLR<span class="token punctuation">,</span> StepLRmodel <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> SGD<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>scheduler1 <span class="token operator">=</span> ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>scheduler2 <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> scheduler2<span class="token punctuation">.</span>get_last_lr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler2<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="模型训练可视化"><strong>模型训练可视化</strong></h3><p>PyTorch可以使用tensorboard来可视化训练过程。</p><p>安装和运行TensorBoard。</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> tensorboardtensorboard --logdir<span class="token operator">=</span>runs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如'Loss/train'和'Loss/test'。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> n_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="保存与加载断点"><strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">start_epoch <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># Load checkpoint.</span><span class="token keyword">if</span> resume<span class="token punctuation">:</span> <span class="token comment"># resume为参数，第一次训练时设为0，中断再训练时设为1</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    best_acc <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_acc'</span><span class="token punctuation">]</span>    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load checkpoint at epoch &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best accuracy so far &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Train the model</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token comment"># Test the model</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          <span class="token comment"># save checkpoint</span>    is_best <span class="token operator">=</span> current_acc <span class="token operator">></span> best_acc    best_acc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>current_acc<span class="token punctuation">,</span> best_acc<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">'best_acc'</span><span class="token punctuation">:</span> best_acc<span class="token punctuation">,</span>        <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token string">'model'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>    best_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>    <span class="token keyword">if</span> is_best<span class="token punctuation">:</span>        shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> best_model_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取-imagenet-预训练模型某层的卷积特征">提取 ImageNet预训练模型某层的卷积特征</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># VGG-16 pool5 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token comment"># VGG-16 fc7 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># ResNet GAP feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取-imagenet-预训练模型多层的卷积特征">提取 ImageNet预训练模型多层的卷积特征</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Helper class to extract several convolution features from the given    pre-trained model.    Attributes:        _model, torch.nn.Module.        _layers_to_extract, list&lt;str> or set&lt;str>    Example:        >>> model = torchvision.models.resnet152(pretrained=True)        >>> model = torch.nn.Sequential(collections.OrderedDict(                list(model.named_children())[:-1]))        >>> conv_representation = FeatureExtractor(                pretrained_model=model,                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            <span class="token keyword">return</span> conv_representation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="微调全连接层">微调全连接层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># Replace the last fc layer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3id="以较大学习率微调全连接层较小学习率微调卷积层">以较大学习率微调全连接层，较小学习率微调卷积层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">1e-3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>               <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="其他注意事项"><strong>其他注意事项</strong></h1><ul><li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是O(mn)的内存，线性层太大很容易超出现有显存。</li><li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。</li><li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。</li><li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li><li>model.eval() 和 torch.no_grad() 的区别在于，model.eval()是将网络切换为测试状态，例如 BN和dropout在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行loss.backward()。</li><li>model.zero_grad()会把整个模型的参数的梯度都归零,而optimizer.zero_grad()只会把传入其中的参数的梯度归零.</li><li>torch.nn.CrossEntropyLoss 的输入不需要经过Softmax。torch.nn.CrossEntropyLoss 等价于torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li><li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。</li><li>torch.utils.data.DataLoader 中尽量设置pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False反而更快一些。num_workers 的设置需要在实验中找到最快的取值。</li><li>用 del 及时删除不用的中间变量，节约 GPU 存储。</li><li>使用 inplace 操作可节约 GPU 存储，如</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><ul><li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU的传输更快。</li><li>使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU型号。需要小心数值精度过低带来的稳定性问题。</li><li>时常使用 assert tensor.size() == (N, D, H, W)作为调试手段，确保张量维度和你设想中一致。</li><li>除了标记 y 外，尽量少使用一维张量，使用 n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li><li>统计代码各部分耗时</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>enabled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">as</span> profile<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span><span class="token comment"># 或者在命令行运行</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>bottleneck main<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><ul><li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print出来每一行的执行结果的 tensor的形状、数据类型、设备、是否需要梯度的信息。</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pip install torchsnooper</span><span class="token keyword">import</span> torchsnooper<span class="token comment"># 对于函数，使用修饰器</span><span class="token decorator annotation punctuation">@torchsnooper<span class="token punctuation">.</span>snoop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。</span><span class="token keyword">with</span> torchsnooper<span class="token punctuation">.</span>snoop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><ul><li>原本的代码</li></ul><p>https://github.com/zasdfgbnm/TorchSnooper</p><ul><li>模型可解释性，使用captum库</li></ul><p>https://captum.ai/</p><p><strong>参考资料：</strong></p><p>1.https://zhuanlan.zhihu.com/p/59205847</p><p>2.<ahref="https://pytorch.org/tutorials/">PyTorch官方文档和示例</a></p><p>3.https://pytorch.org/docs/stable/notes/faq.html</p><p>4.https://github.com/szagoruyko/pytorchviz</p><p>5.https://github.com/sksq96/pytorch-summary</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://img.enderfga.cn/img/image-20220511003116457.png&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>PID 控制在医学麻醉过程血压控制中的应用</title>
    <link href="http://enderfga.cn/2022/05/04/pid/"/>
    <id>http://enderfga.cn/2022/05/04/pid/</id>
    <published>2022-05-04T13:42:55.000Z</published>
    <updated>2022-07-03T03:08:13.374Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动控制原理大作业——pid控制器</p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/image-20220504214948390.png" /></p><embed src="./PID.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动控制原理大作业——pid控制器&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动控制原理" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>网络抓包与协议分析</title>
    <link href="http://enderfga.cn/2022/05/01/net3/"/>
    <id>http://enderfga.cn/2022/05/01/net3/</id>
    <published>2022-05-01T03:07:57.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：网络抓包与协议分析实验</p><span id="more"></span><p><img src="https://img.enderfga.cn/img/wall.png" /></p><embed src="./problem.pdf" width="100%" height="750" type="application/pdf"><embed src="./wireshark.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计网作业：网络抓包与协议分析实验&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据库原理 Exercises 3&amp;4&amp;5</title>
    <link href="http://enderfga.cn/2022/04/29/data3/"/>
    <id>http://enderfga.cn/2022/04/29/data3/</id>
    <published>2022-04-28T16:33:52.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 5&amp;6&amp;8</p><span id="more"></span><p><imgsrc="https://img.enderfga.cn/img/image-20220429003143556.png" /></p><h1 id="database-system-concepts-exercises-of-chapter-56">DatabaseSystem Concepts Exercises of Chapter 5&amp;6</h1><p><strong>Exercise 5.8</strong> Consider the bank database of Figure<strong>5.25</strong>. Write an sQL trigger to carryout the followingaction: On <strong>delete</strong> of an account, for each owner oftheaccount, check if the owner has any remaining accounts, and if shedoesnot, delete her from the <em>depositor</em> relation.</p><p>branch(branch_name, branch_city, assets)</p><p>customer ( customer_name, customer_street, customer_city )</p><p>loan( loan_number, branch_name, amount)</p><p>borrower ( customer_name, loan_number )</p><p>account ( account_number, branch_name, balance )</p><p>depositor ( customer_name, account_number )</p><p><strong>Figure 5.25</strong></p><p><strong>My answer:</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">trigger</span> <span class="token keyword">check</span><span class="token operator">-</span><span class="token keyword">delete</span><span class="token operator">-</span><span class="token keyword">trigger</span> <span class="token keyword">after</span> <span class="token keyword">delete</span> <span class="token keyword">on</span> account referencing old <span class="token keyword">row</span> <span class="token keyword">as</span> orow<span class="token keyword">for each row</span><span class="token keyword">delete</span> <span class="token keyword">from</span> depositor<span class="token keyword">where</span> depositor<span class="token punctuation">.</span>customer_name <span class="token operator">not</span> <span class="token operator">in</span>   <span class="token punctuation">(</span> <span class="token keyword">select</span> customer_name <span class="token keyword">from</span> depositor     <span class="token keyword">where</span> account_number <span class="token operator">&lt;></span> orow<span class="token punctuation">.</span>account_number <span class="token punctuation">)</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><strong>Exercise</strong> <strong>5.15</strong> Consider an employeedatabase with two relations employee (<spanclass="math inline">\(\underline{employee\_name}\)</span>, street, city)works (<span class="math inline">\(\underline{employee\_name}\)</span>,company_name, salary) where the primary keys are underlined. Write aquery to find companies whose employees earn a higher salary, onaverage, than the average salary at "First Bank Corporation". a. UsingSQL functions as appropriate. b. Without using SQL functions.</p><p><strong>My answer:</strong></p><ol type="a"><li></li></ol><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> avg_salary<span class="token punctuation">(</span>cname <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token keyword">integer</span>     <span class="token keyword">declare</span> result <span class="token keyword">integer</span><span class="token punctuation">;</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token keyword">into</span> result<span class="token keyword">from</span> works<span class="token keyword">where</span> works<span class="token punctuation">.</span>company<span class="token punctuation">.</span>name <span class="token operator">=</span> cname<span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">where</span> avg_salary<span class="token punctuation">(</span>company_name<span class="token punctuation">)</span> <span class="token operator">></span> avg_salary<span class="token punctuation">(</span>“<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><ol start="2" type="a"><li></li></ol><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">group</span> <span class="token keyword">by</span> company_name<span class="token keyword">having</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span><span class="token keyword">from</span> works<span class="token keyword">where</span> company_name<span class="token operator">=</span>”<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><hr /><p><strong>Exercise 6.1</strong> Write the following queries inrelational algebra, using the university schema. <strong>a</strong>.Find the titles of courses in the Comp. Sci. department that have 3credits. <strong>b</strong>. Find the IDs of all students who weretaught by an instructor named Einstein; make sure there are noduplicates in the result. <strong>c</strong>. Find the highest salary ofany instructor. <strong>d</strong>. Find all instructors earning thehighest salary (there may be more than one with the same salary).</p><p><strong>My answer:</strong></p><p><imgsrc="https://img.enderfga.cn/img/image-20220429003507835.png" /></p><embed src="./data.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Database System Concepts Exercises of Chapter 5&amp;amp;6&amp;amp;8&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://enderfga.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>conda/linux/git/正则表达式常用命令“笔记”</title>
    <link href="http://enderfga.cn/2022/04/28/code/"/>
    <id>http://enderfga.cn/2022/04/28/code/</id>
    <published>2022-04-28T01:34:32.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一些常用的命令，每次忘了都得搜，记录一下</p><p><imgsrc="https://img.enderfga.cn/img/image-20220428094832340.png" /></p><span id="more"></span><h1 id="anacondapython">Anaconda&amp;python</h1><p><imgsrc="https://img.enderfga.cn/img/image-20220428093957780.png" /></p><p><strong>pip安装（tensorflow-gpu为例）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>conda安装</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>pip3安装（指定版本号只需在命令末尾添加==1.12.0版本号）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip3  install tensorflow-gpu&#x3D;&#x3D;1.12.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>使用清华镜像下载</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install tensorflow-gpu&#x3D;&#x3D;1.10 -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>指定目录安装</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install -t D:\ProgramData\Anaconda3\Lib\site-packages torch-1.0.1-cp36-cp36m-win_amd64.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>卸载安装（pip3只需将conda换成pip）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  uninstall tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>创建虚拟环境（conda为例）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n py36 python&#x3D;3.6  #py36虚拟环境的名字  python&#x3D;3.6  python版本<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>删除虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda remove -n py36 --all<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>激活虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda activate py36<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>退出虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看所有创建的虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda env list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>用virtualenv创建虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">VENV_DIR</span><span class="token operator">=</span>venvpip <span class="token function">install</span> virtualenvvirtualenv <span class="token variable">$VENV_DIR</span><span class="token builtin class-name">source</span> <span class="token variable">$VENV_DIR</span>/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><strong>nohup送入后台运行</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">nohup</span> python train.py <span class="token operator">></span>nohup <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>      <span class="token comment">#train.py运行的文件  nohup生成的日志文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>CUDA指定GPU</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token function">nohup</span> python train.py  <span class="token operator">></span> nohup.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>导出requirements.txt</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python3 -m pip freeze <span class="token operator">></span> requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看GPU使用情况</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看进程号</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">ps</span> aux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>根据进程号杀死进程</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">kill</span> -9 进程号<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><img src="https://img.enderfga.cn/img/200301122312741.jpg" /></p><h1 id="linux">linux</h1><p>linux不像Windows 分了盘，它根目录下有如下常用文件夹:</p><p><em>home</em> ---------- 用户的家</p><p><em>root</em> ---------- 超级管理员root的家</p><p><em>etc</em> ---------- 存放配置文件</p><p><em>usr</em> ---------- 存放共享资源</p><h2 id="cd命令">1、cd命令:</h2><p><strong>①、进入某一个目录</strong> <code>cd 目录名</code></p><p><strong>②、进入多级目录</strong> <code>cd 目录名/目录名</code></p><p><strong>③、返回上一级目录</strong> <code>cd ..</code></p><p><strong>④、返回根目录</strong> <code>cd /</code></p><p><strong>⑤、返回根目录下的某一个目录</strong><code>cd /目录名</code></p><p><strong>⑥、回家</strong> <code>cd ~</code></p><h2 id="创建删除目录">2、创建、删除目录:</h2><p><strong>①、创建目录</strong> <code>mkdir 目录名</code></p><p><strong>②、创建多级目录</strong> <code>mkdir -p a/b/c</code></p><p><strong>③、删除目录(只能删除空目录)</strong><code>rmdir 目录名</code></p><p><strong>④、删除目录(可删除非空目录，带询问)</strong><code>rm -r</code></p><p><strong>⑤、删除目录(不带询问，谨慎使用)</strong><code>rm -rf</code></p><h2 id="对文件的操作">3、对文件的操作:</h2><p><strong>①、创建空白文件</strong> <code>touch 文件名</code></p><p><strong>②、复制文件</strong></p><p><code>cp a.txt b.txt</code> <em>表示复制a文件并重命名为b。</em></p><p><code>cp a.txt dir/b.txt</code><em>表示把a复制到dir文件夹下并重命名为b。</em></p><p><strong>③、移动文件</strong> <code>mv a.txt dir/b.txt</code><em>把a.txt移动到dir目录下并重命名为b.txt。</em></p><p><strong>④、重命名文件</strong> <code>mv a.txt b.txt</code><em>把a.txt重命名为b.txt。</em></p><p><strong>⑤、删除文件</strong></p><p><code>rm 文件名</code> <em>带询问的删除</em></p><p><code>rm -f 文件名</code> <em>不带询问的删除。</em></p><p><strong>⑥、浏览文件</strong></p><p><code>cat 文件名</code> <em>显示文件所有内容</em></p><p><code>more 文件名</code><em>分页显示，空格键下一页，回车键下一行。</em></p><p><code>less 文件名</code><em>分页显示，pgup上一页，pgdn下一页。</em></p><p><code>tail -5 a.txt</code> <em>显示a.txt文件的最后5行。</em></p><p><code>tail -f 文件名</code> <em>动态的查看。</em></p><h2 id="查看目录下的文件">4、查看目录下的文件:</h2><p><strong>①、查看所有文件和目录名称</strong> <code>ls</code></p><p><strong>②、查看所有文件和目录名称(包括隐藏的)</strong><code>ls -a</code></p><p><strong>③、查看文件并显示详细信息(最常用)</strong><code>ll</code></p><p><strong>④、友好的显示</strong> <code>ll -h</code><em>比如显示的文件大小是kb而不是字节。</em></p><h2 id="tar打包命令">5、tar打包命令:</h2><p><strong>①、将当前目录所有文件打包成haha.tar</strong><code>tar -cvf haha.tar ./*</code></p><p><strong>②、将当前目录下所有文件打包并压缩成haha.tar</strong><code>tar -zcvf haha.tar.gz ./*</code></p><p><strong>③、将haha.tar解压到当前目录</strong><code>tar -xvf haha.tar</code></p><p><strong>④、将haha.tar解压到b目录</strong><code>tar -xvf haha.tar -C b</code> <em>注意C是大写的！</em></p><h2 id="其他常用命令">6、其他常用命令:</h2><p><strong>①、grep命令</strong></p><p><code>grep category a.txt</code><em>表示在a.txt中查找category字符串所在的行，前提是打开了a.txt文件。</em></p><p><code>grep category a.txt -A2</code><em>在a.txt中查找category字符串的前两行。</em></p><p><code>grep category a.txt -B2</code><em>在a.txt中查找category字符串的后两行。</em></p><p><strong>②、查看当前目录</strong> <code>pwd</code></p><p><strong>③、wget下载命令</strong> <code>wget www.baidu.com</code><em>下载百度首页</em></p><h2 id="vivim编辑器">7、vi/vim编辑器:</h2><p><strong>①、编辑器有三种模式，分别是:</strong><strong>命令行模式:</strong>此模式无法编辑文件，<code>yy</code>复制行，<code>p</code>粘贴，<code>dd</code>删除行，按如下键都可以进入插入模式:</p><p><code>i</code> 当前位置前插入;</p><p><code>I</code> 当前行行首插入;</p><p><code>a</code> 当前位置后插入;</p><p><code>A</code> 当前行行尾插入;</p><p><code>o</code> 当前行之后插入一行;</p><p><code>O</code> 当前的之前插入一行</p><p><strong>插入模式:</strong>此模式下可以对文件进行编辑。按<code>esc</code>退出插入模式，回到命令行模式。<strong>底行模式:</strong>命令行模式下按<code>:</code>，即可进入底行模式。底行模式有如下常用命令:</p><p><code>q</code> 不保存退出;</p><p><code>q！</code> 不保存强制退出;</p><p><code>wq</code> 保存退出</p><h2 id="管道">8、管道:</h2><p><strong>管道:<code>|</code>，将一个命令的输出作为另一个命令的输入。例如:</strong><strong>在 <code>ip addr</code>的输出结果中查找<code>192.168</code>字符串:</strong><code>ip addr | grep 192.168</code></p><h2 id="系统管理命令">9、系统管理命令:</h2><p><strong>①、查看系统时间</strong> <code>date</code> 查看系统时间<code>date -s "2018-05-15 22:22:22"</code>将系统时间设置为引号里面的时间</p><p><strong>②、查看磁盘信息</strong> <code>df</code> 查看磁盘信息<code>df -h</code> 友好地展示磁盘信息</p><p><strong>③、清屏</strong> <code>clear</code>或者按<code>ctr L</code></p><p><strong>④、进程</strong> <code>ps -ef</code>查看所有进程<code>ps -ef | grep ssh</code>查找ssh进程</p><p><strong>⑤、杀掉进程</strong> <code>kill 9527</code>杀掉9527号进程<code>kill -9 9527</code> 强制杀掉9527号进程</p><p><strong>⑥、查看网络端口</strong><code>netstat -an | grep 3306</code>查看3306端口占用情况</p><p><strong>⑦、ping命令</strong><code>ping xx.xx.xxx</code>测试网络连通性</p><p><img src="https://img.enderfga.cn/img/bg2015120901.png" /></p><h1 id="git">GIT</h1><p>下面是常用 Git 命令清单。几个专用名词的译名如下。</p><blockquote><ul><li>Workspace：工作区</li><li>Index / Stage：暂存区</li><li>Repository：仓库区（或本地仓库）</li><li>Remote：远程仓库</li></ul></blockquote><h2 id="一新建代码库">一、新建代码库</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在当前目录新建一个Git代码库</span>$ <span class="token function">git</span> init<span class="token comment"># 新建一个目录，将其初始化为Git代码库</span>$ <span class="token function">git</span> init <span class="token punctuation">[</span>project-name<span class="token punctuation">]</span><span class="token comment"># 下载一个项目和它的整个代码历史</span>$ <span class="token function">git</span> clone <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="二配置">二、配置</h2><p>Git的设置文件为<code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示当前的Git配置</span>$ <span class="token function">git</span> config --list<span class="token comment"># 编辑Git配置文件</span>$ <span class="token function">git</span> config -e <span class="token punctuation">[</span>--global<span class="token punctuation">]</span><span class="token comment"># 设置提交代码时的用户信息</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.name <span class="token string">"[name]"</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.email <span class="token string">"[email address]"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="三增加删除文件">三、增加/删除文件</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 添加指定文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 添加指定目录到暂存区，包括子目录</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>dir<span class="token punctuation">]</span><span class="token comment"># 添加当前目录的所有文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span><span class="token comment"># 添加每个变化前，都会要求确认</span><span class="token comment"># 对于同一个文件的多处变化，可以实现分次提交</span>$ <span class="token function">git</span> <span class="token function">add</span> -p<span class="token comment"># 删除工作区文件，并且将这次删除放入暂存区</span>$ <span class="token function">git</span> <span class="token function">rm</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 停止追踪指定文件，但该文件会保留在工作区</span>$ <span class="token function">git</span> <span class="token function">rm</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 改名文件，并且将这个改名放入暂存区</span>$ <span class="token function">git</span> <span class="token function">mv</span> <span class="token punctuation">[</span>file-original<span class="token punctuation">]</span> <span class="token punctuation">[</span>file-renamed<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="四代码提交">四、代码提交</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 提交暂存区到仓库区</span>$ <span class="token function">git</span> commit -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交暂存区的指定文件到仓库区</span>$ <span class="token function">git</span> commit <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>. -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交工作区自上次commit之后的变化，直接到仓库区</span>$ <span class="token function">git</span> commit -a<span class="token comment"># 提交时显示所有diff信息</span>$ <span class="token function">git</span> commit -v<span class="token comment"># 使用一次新的commit，替代上一次提交</span><span class="token comment"># 如果代码没有任何新变化，则用来改写上一次commit的提交信息</span>$ <span class="token function">git</span> commit --amend -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 重做上一次commit，并包括指定文件的新变化</span>$ <span class="token function">git</span> commit --amend <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="五分支">五、分支</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有本地分支</span>$ <span class="token function">git</span> branch<span class="token comment"># 列出所有远程分支</span>$ <span class="token function">git</span> branch -r<span class="token comment"># 列出所有本地分支和远程分支</span>$ <span class="token function">git</span> branch -a<span class="token comment"># 新建一个分支，但依然停留在当前分支</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，并切换到该分支</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，指向指定commit</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，与指定的远程分支建立追踪关系</span>$ <span class="token function">git</span> branch --track <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 切换到指定分支，并更新工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 切换到上一个分支</span>$ <span class="token function">git</span> checkout -<span class="token comment"># 建立追踪关系，在现有分支与指定的远程分支之间</span>$ <span class="token function">git</span> branch --set-upstream <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 合并指定分支到当前分支</span>$ <span class="token function">git</span> merge <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 选择一个commit，合并进当前分支</span>$ <span class="token function">git</span> cherry-pick <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除分支</span>$ <span class="token function">git</span> branch -d <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 删除远程分支</span>$ <span class="token function">git</span> push origin --delete <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span>$ <span class="token function">git</span> branch -dr <span class="token punctuation">[</span>remote/branch<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="六标签">六、标签</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有tag</span>$ <span class="token function">git</span> tag<span class="token comment"># 新建一个tag在当前commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 新建一个tag在指定commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除本地tag</span>$ <span class="token function">git</span> tag -d <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 删除远程tag</span>$ <span class="token function">git</span> push origin :refs/tags/<span class="token punctuation">[</span>tagName<span class="token punctuation">]</span><span class="token comment"># 查看tag信息</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交指定tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交所有tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --tags<span class="token comment"># 新建一个分支，指向某个tag</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="七查看信息">七、查看信息</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示有变更的文件</span>$ <span class="token function">git</span> status<span class="token comment"># 显示当前分支的版本历史</span>$ <span class="token function">git</span> log<span class="token comment"># 显示commit历史，以及每次commit发生变更的文件</span>$ <span class="token function">git</span> log --stat<span class="token comment"># 搜索提交历史，根据关键词</span>$ <span class="token function">git</span> log -S <span class="token punctuation">[</span>keyword<span class="token punctuation">]</span><span class="token comment"># 显示某个commit之后的所有变动，每个commit占据一行</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --pretty<span class="token operator">=</span>format:%s<span class="token comment"># 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --grep feature<span class="token comment"># 显示某个文件的版本历史，包括文件改名</span>$ <span class="token function">git</span> log --follow <span class="token punctuation">[</span>file<span class="token punctuation">]</span>$ <span class="token function">git</span> whatchanged <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示指定文件相关的每一次diff</span>$ <span class="token function">git</span> log -p <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示过去5次提交</span>$ <span class="token function">git</span> log -5 --pretty --oneline<span class="token comment"># 显示所有提交过的用户，按提交次数排序</span>$ <span class="token function">git</span> shortlog -sn<span class="token comment"># 显示指定文件是什么人在什么时间修改过</span>$ <span class="token function">git</span> blame <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示暂存区和工作区的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span><span class="token comment"># 显示暂存区和上一个commit的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示工作区与当前分支最新commit之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> HEAD<span class="token comment"># 显示两次提交之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> <span class="token punctuation">[</span>first-branch<span class="token punctuation">]</span><span class="token punctuation">..</span>.<span class="token punctuation">[</span>second-branch<span class="token punctuation">]</span><span class="token comment"># 显示今天你写了多少行代码</span>$ <span class="token function">git</span> <span class="token function">diff</span> --shortstat <span class="token string">"@&#123;0 day ago&#125;"</span><span class="token comment"># 显示某次提交的元数据和内容变化</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交发生变化的文件</span>$ <span class="token function">git</span> show --name-only <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交时，某个文件的内容</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span>:<span class="token punctuation">[</span>filename<span class="token punctuation">]</span><span class="token comment"># 显示当前分支的最近几次提交</span>$ <span class="token function">git</span> reflog<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="八远程同步">八、远程同步</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载远程仓库的所有变动</span>$ <span class="token function">git</span> fetch <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 显示所有远程仓库</span>$ <span class="token function">git</span> remote -v<span class="token comment"># 显示某个远程仓库的信息</span>$ <span class="token function">git</span> remote show <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 增加一个新的远程仓库，并命名</span>$ <span class="token function">git</span> remote <span class="token function">add</span> <span class="token punctuation">[</span>shortname<span class="token punctuation">]</span> <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span class="token comment"># 取回远程仓库的变化，并与本地分支合并</span>$ <span class="token function">git</span> pull <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 上传本地指定分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 强行推送当前分支到远程仓库，即使有冲突</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --force<span class="token comment"># 推送所有分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --all<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="九撤销">九、撤销</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 恢复暂存区的指定文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复某个commit的指定文件到暂存区和工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>commit<span class="token punctuation">]</span> <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复暂存区的所有文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token builtin class-name">.</span><span class="token comment"># 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 重置暂存区与工作区，与上一次commit保持一致</span>$ <span class="token function">git</span> reset --hard<span class="token comment"># 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致</span>$ <span class="token function">git</span> reset --hard <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前HEAD为指定commit，但保持暂存区和工作区不变</span>$ <span class="token function">git</span> reset --keep <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个commit，用来撤销指定commit</span><span class="token comment"># 后者的所有变化都将被前者抵消，并且应用到当前分支</span>$ <span class="token function">git</span> revert <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 暂时将未提交的变化移除，稍后再移入</span>$ <span class="token function">git</span> stash$ <span class="token function">git</span> stash pop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="十其他">十、其他</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 生成一个可供发布的压缩包</span>$ <span class="token function">git</span> archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></blockquote><p>一个常用的实例</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">add</span> origin xxx<span class="token punctuation">(</span>复制的SSH链接<span class="token punctuation">)</span><span class="token function">git</span> branch -m master main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span> <span class="token function">git</span> commit -m <span class="token string">"注释"</span> <span class="token function">git</span> pull --rebase origin main<span class="token function">git</span> push origin main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="正则表达式">正则表达式</h1><embed src="./code.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;一些常用的命令，每次忘了都得搜，记录一下&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://img.enderfga.cn/img/image-20220428094832340.png&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>自动驾驶技术基础之建模与控制</title>
    <link href="http://enderfga.cn/2022/04/25/auto1/"/>
    <id>http://enderfga.cn/2022/04/25/auto1/</id>
    <published>2022-04-25T08:57:56.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动驾驶技术基础的建模与控制作业</p><span id="more"></span><p>概念题（18分）</p><ol type="1"><li>自动驾驶为了出色地完成驾驶任务，可分为哪四大模块？（4分）</li><li>系统建模一般分哪两种建模方式？（2分）</li><li>请写出高速转向车辆模型的简化横向误差模型（即四个状态为误差）（4分）</li><li>二次型性能指标函数一般包含哪三项优化项？（3分）</li><li>线性二次问题三种重要形式分别是？（3分）</li><li>KalmanFilter（LQE）如何通过LQR求得，请写出matlab关键代码，即：xxx=lqr(xxx)（2分）</li></ol><p>编程实践题（12分）</p><p><img src="https://img.enderfga.cn/img/clip_image002.png" /></p><p>给定一个双质系统: m<sub>1</sub> =2, m<sub>2</sub>=1, 弹簧系数 k=5,阻尼σ=0.1, 质量块与地面的滑动阻尼 δ=0.1 (与速度有成正比)。初始时刻m<sub>1</sub> 质量块处于 x=0 的位置, 两质量块距离为 0 。现在m<sub>2</sub> 处作用一外力 F 拖动系统使 m<sub>1</sub> 与 m<sub>2</sub>质量块均处于 x=5 的位置。</p><ol type="1"><li>对系统建模（系统可以直接测量两个物体的位置）</li><li>判断系统可控性与可观</li><li>结合给定的simulink和脚本文件，设计实现上述系统的LQG控制器并绘制闭环控制性能曲线</li></ol><p><img src="https://img.enderfga.cn/img/clip_image020.jpg" /></p><embed src="./auto1.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动驾驶技术基础的建模与控制作业&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动驾驶" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>Cognitive Mapping and Planning for Visual Navigation</title>
    <link href="http://enderfga.cn/2022/04/24/CMP/"/>
    <id>http://enderfga.cn/2022/04/24/CMP/</id>
    <published>2022-04-24T14:56:51.000Z</published>
    <updated>2022-07-03T03:08:13.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>认知科学基础课程设计报告</p><span id="more"></span><p>开放性题目，结合视语言、语音识别、机器人平台，采用Webots，构建一个单/多智能体的认知导航、认知规划、认知控制仿真算例，里面可以用已有的各种传感器组件、机器人模型，基于前期所讲简单的认知智能知识点做仿真试验，算法可以从github上开源下载使用。鼓励大家选择此题目开展一些小试验，可以提问实现的方式方法。同时提交仿真实现的设计和试验研习报告。突出认知智能应用的关键要点，进行详细阐述说明。</p><embed src="./CMP.pdf" width="100%" height="750" type="application/pdf"><p><imgsrc="https://img.enderfga.cn/img/image-20220424225934056.png" /></p><p>【1】论文地址： https://arxiv.org/abs/1702.03920 【2】代码：https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning【3】论文Slide：https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1【4】作者主页： https://people.eecs.berkeley.edu/~sgupta/【5】作者主页： https://people.eecs.berkeley.edu/~svlevine/</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;认知科学基础课程设计报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="无人系统" scheme="http://enderfga.cn/tags/%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
