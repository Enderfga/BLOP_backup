<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Enderfga&#39;Blog</title>
  
  
  <link href="http://enderfga.cn/atom.xml" rel="self"/>
  
  <link href="http://enderfga.cn/"/>
  <updated>2022-05-10T16:33:16.279Z</updated>
  <id>http://enderfga.cn/</id>
  
  <author>
    <name>Enderfga</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PyTorch常用代码段合集</title>
    <link href="http://enderfga.cn/2022/05/10/torch/"/>
    <id>http://enderfga.cn/2022/05/10/torch/</id>
    <published>2022-05-10T15:45:53.000Z</published>
    <updated>2022-05-10T16:33:16.279Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220511003116457.png" alt="image-20220511003116457"></p><span id="more"></span><h1 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a><strong>基本配置</strong></h1><h3 id="导入包和版本查询"><a href="#导入包和版本查询" class="headerlink" title="导入包和版本查询"></a><strong>导入包和版本查询</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="可复现性"><a href="#可复现性" class="headerlink" title="可复现性"></a><strong>可复现性</strong></h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>显卡设置</p><p>如果只需要一张显卡</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Device configuration</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>如果需要指定多张显卡，比如0，1号显卡。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>也可以在命令行运行代码时设置显卡：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> python train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>清除显存</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>也可以使用在命令行重置GPU的指令</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi --gpu-reset -i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h1 id="张量-Tensor-处理"><a href="#张量-Tensor-处理" class="headerlink" title="张量(Tensor)处理"></a><strong>张量(Tensor)处理</strong></h1><h3 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a><strong>张量的数据类型</strong></h3><p>PyTorch有9种CPU张量类型和9种GPU张量类型。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/640" alt="图片"></p><h3 id="张量基本信息"><a href="#张量基本信息" class="headerlink" title="张量基本信息"></a><strong>张量基本信息</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 数据类型</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 张量的shape，是个元组</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 维度的数量</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="命名张量"><a href="#命名张量" class="headerlink" title="命名张量"></a><strong>命名张量</strong></h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在PyTorch 1.3之前，需要使用注释</span><span class="token comment"># Tensor[N, C, H, W]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># PyTorch 1.3之后</span>NCHW <span class="token operator">=</span> <span class="token punctuation">[</span>‘N’<span class="token punctuation">,</span> ‘C’<span class="token punctuation">,</span> ‘H’<span class="token punctuation">,</span> ‘W’<span class="token punctuation">]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> names<span class="token operator">=</span>NCHW<span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 也可以这么设置</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 使用align_to可以对维度方便地排序</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>align_to<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span>torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token comment"># 类型转换</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="torch-Tensor与np-ndarray转换"><a href="#torch-Tensor与np-ndarray转换" class="headerlink" title="torch.Tensor与np.ndarray转换"></a><strong>torch.Tensor与np.ndarray转换</strong></h3><p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If ndarray has negative stride.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3 id="Torch-tensor与PIL-Image转换"><a href="#Torch-tensor与PIL-Image转换" class="headerlink" title="Torch.tensor与PIL.Image转换"></a><strong>Torch.tensor与PIL.Image转换</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span><span class="token comment"># torch.Tensor -> PIL.Image</span>image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span><span class="token comment"># PIL.Image -> torch.Tensor</span>path <span class="token operator">=</span> <span class="token string">r'./figure.jpg'</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#Equivalently way</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="np-ndarray与PIL-Image的转换"><a href="#np-ndarray与PIL-Image的转换" class="headerlink" title="np.ndarray与PIL.Image的转换"></a>np.ndarray与PIL.Image的转换</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>ndarray <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h3 id="从只包含一个元素的张量中提取值"><a href="#从只包含一个元素的张量中提取值" class="headerlink" title="从只包含一个元素的张量中提取值"></a><strong>从只包含一个元素的张量中提取值</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">value <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="张量形变"><a href="#张量形变" class="headerlink" title="张量形变"></a><strong>张量形变</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，</span><span class="token comment"># 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="打乱顺序"><a href="#打乱顺序" class="headerlink" title="打乱顺序"></a><strong>打乱顺序</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 打乱第一个维度</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="水平翻转"><a href="#水平翻转" class="headerlink" title="水平翻转"></a><strong>水平翻转</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现</span><span class="token comment"># 假设张量的维度为[N, D, H, W].</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3 id="复制张量"><a href="#复制张量" class="headerlink" title="复制张量"></a><strong>复制张量</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Operation                 |  New/Shared memory | Still in computation graph |</span>tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># |        New         |          Yes               |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># |      Shared        |          No                |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># |        New         |          No                | </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="张量拼接"><a href="#张量拼接" class="headerlink" title="张量拼接"></a><strong>张量拼接</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，而torch.stack的结果是3x10x5的张量。'''</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="将整数标签转为one-hot编码"><a href="#将整数标签转为one-hot编码" class="headerlink" title="将整数标签转为one-hot编码"></a><strong>将整数标签转为one-hot编码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch的标记默认从0开始</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">4</span>one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="得到非零元素"><a href="#得到非零元素" class="headerlink" title="得到非零元素"></a><strong>得到非零元素</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>               <span class="token comment"># index of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment"># index of zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>       <span class="token comment"># number of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># number of zero elements</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="判断两个张量相等"><a href="#判断两个张量相等" class="headerlink" title="判断两个张量相等"></a><strong>判断两个张量相等</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>  <span class="token comment"># float tensor</span>torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>     <span class="token comment"># int tensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h3 id="张量扩展"><a href="#张量扩展" class="headerlink" title="张量扩展"></a><strong>张量扩展</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a><strong>矩阵乘法</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Matrix multiplcation: (m*n) * (n*p) * -> (m*p).</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p)</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Element-wise multiplication.</span>result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="计算两组数据之间的两两欧式距离"><a href="#计算两组数据之间的两两欧式距离" class="headerlink" title="计算两组数据之间的两两欧式距离"></a><strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用broadcast机制</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> X2<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h1 id="模型定义和操作"><a href="#模型定义和操作" class="headerlink" title="模型定义和操作"></a><strong>模型定义和操作</strong></h1><h3 id="一个简单两层卷积网络的示例"><a href="#一个简单两层卷积网络的示例" class="headerlink" title="一个简单两层卷积网络的示例"></a>一个简单两层卷积网络的示例</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># convolutional neural network (2 convolutional layers)</span><span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> outmodel <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>卷积层的计算和展示可以用这个网站辅助。</p><p><a href="https://ezyang.github.io/convolution-visualizer/index.html">https://ezyang.github.io/convolution-visualizer/index.html</a></p><h3 id="双线性汇合（bilinear-pooling）"><a href="#双线性汇合（bilinear-pooling）" class="headerlink" title="双线性汇合（bilinear pooling）"></a>双线性汇合（bilinear pooling）</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">)</span>                        <span class="token comment"># Assume X has shape N*D*H*W</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W<span class="token punctuation">)</span>  <span class="token comment"># Bilinear pooling</span><span class="token keyword">assert</span> X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> D<span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>   <span class="token comment"># Signed-sqrt normalization</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment"># L2 normalization</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="多卡同步-BN（Batch-normalization）"><a href="#多卡同步-BN（Batch-normalization）" class="headerlink" title="多卡同步 BN（Batch normalization）"></a><strong>多卡同步 BN（Batch normalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>   affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="将已有网络的所有BN层改为同步BN层"><a href="#将已有网络的所有BN层改为同步BN层" class="headerlink" title="将已有网络的所有BN层改为同步BN层"></a>将已有网络的所有BN层改为同步BN层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">convertBNtoSyncBN</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> process_group<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''Recursively replace all BN layers to SyncBN layer.    Args:        module[torch.nn.Module]. Network    '''</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>batchnorm<span class="token punctuation">.</span>_BatchNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>        sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>module<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> module<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> module<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span>                                          module<span class="token punctuation">.</span>affine<span class="token punctuation">,</span> module<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">,</span> process_group<span class="token punctuation">)</span>        sync_bn<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> module<span class="token punctuation">.</span>running_mean        sync_bn<span class="token punctuation">.</span>running_var <span class="token operator">=</span> module<span class="token punctuation">.</span>running_var        <span class="token keyword">if</span> module<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>            sync_bn<span class="token punctuation">.</span>weight <span class="token operator">=</span> module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>            sync_bn<span class="token punctuation">.</span>bias <span class="token operator">=</span> module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> sync_bn    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> child_module <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token builtin">setattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">=</span> convert_syncbn_model<span class="token punctuation">(</span>child_module<span class="token punctuation">,</span> process_group<span class="token operator">=</span>process_group<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> module<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="类似-BN-滑动平均"><a href="#类似-BN-滑动平均" class="headerlink" title="类似 BN 滑动平均"></a><strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>running_mean <span class="token operator">+=</span> momentum <span class="token operator">*</span> <span class="token punctuation">(</span>current <span class="token operator">-</span> self<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="计算模型整体参数量"><a href="#计算模型整体参数量" class="headerlink" title="计算模型整体参数量"></a><strong>计算模型整体参数量</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="查看网络中的参数"><a href="#查看网络中的参数" class="headerlink" title="查看网络中的参数"></a><strong>查看网络中的参数</strong></h3><p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name2<span class="token punctuation">,</span> param2<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'----------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name1<span class="token punctuation">,</span> param1<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="模型可视化（使用pytorchviz）"><a href="#模型可视化（使用pytorchviz）" class="headerlink" title="模型可视化（使用pytorchviz）"></a><strong>模型可视化（使用pytorchviz）</strong></h3><p><a href="https://github.com/szagoruyko/pytorchviz">https://github.com/szagoruyko/pytorchviz</a></p><h3 id="类似-Keras-的-model-summary-输出模型信息（使用pytorch-summary-）"><a href="#类似-Keras-的-model-summary-输出模型信息（使用pytorch-summary-）" class="headerlink" title="类似 Keras 的 model.summary() 输出模型信息（使用pytorch-summary ）"></a><strong>类似 Keras 的 model.summary() 输出模型信息（使用pytorch-summary ）</strong></h3><p><a href="https://github.com/sksq96/pytorch-summary">https://github.com/sksq96/pytorch-summary</a></p><p><strong>模型权重初始化</strong></p><p>注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Common practise for initialization.</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span>                                      nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token comment"># Initialization with given tensor.</span>layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取模型中的某一层"><a href="#提取模型中的某一层" class="headerlink" title="提取模型中的某一层"></a><strong>提取模型中的某一层</strong></h3><p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 取模型中的前两层</span>new_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>         conv_model<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="部分层使用预训练模型"><a href="#部分层使用预训练模型" class="headerlink" title="部分层使用预训练模型"></a><strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="将在-GPU-保存的模型加载到-CPU"><a href="#将在-GPU-保存的模型加载到-CPU" class="headerlink" title="将在 GPU 保存的模型加载到 CPU"></a>将在 GPU 保存的模型加载到 CPU</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h2 id="导入另一个模型的相同部分到新的模型"><a href="#导入另一个模型的相同部分到新的模型" class="headerlink" title="导入另一个模型的相同部分到新的模型"></a><strong>导入另一个模型的相同部分到新的模型</strong></h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># model_new代表新的模型</span><span class="token comment"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span>model_new_dict <span class="token operator">=</span> model_new<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>model_common_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> model_saved<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> model_new_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>model_new_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_common_dict<span class="token punctuation">)</span>model_new<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_new_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a><strong>数据处理</strong></h1><h3 id="计算数据集的均值和标准差"><a href="#计算数据集的均值和标准差" class="headerlink" title="计算数据集的均值和标准差"></a>计算数据集的均值和标准差</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">compute_mean_and_std</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 输入PyTorch的dataset，输出均值和标准差</span>    mean_r <span class="token operator">=</span> <span class="token number">0</span>    mean_g <span class="token operator">=</span> <span class="token number">0</span>    mean_b <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># change PIL Image to numpy array</span>        mean_r <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_g <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_b <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    mean_r <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_g <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_b <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    diff_r <span class="token operator">=</span> <span class="token number">0</span>    diff_g <span class="token operator">=</span> <span class="token number">0</span>    diff_b <span class="token operator">=</span> <span class="token number">0</span>    N <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        diff_r <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_r<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_g <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_g<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_b <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_b<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        N <span class="token operator">+=</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    std_r <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_r <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_g <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_g <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_b <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_b <span class="token operator">/</span> N<span class="token punctuation">)</span>    mean <span class="token operator">=</span> <span class="token punctuation">(</span>mean_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    std <span class="token operator">=</span> <span class="token punctuation">(</span>std_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> mean<span class="token punctuation">,</span> std<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="得到视频数据基本信息"><a href="#得到视频数据基本信息" class="headerlink" title="得到视频数据基本信息"></a>得到视频数据基本信息</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> cv2video <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>mp4_path<span class="token punctuation">)</span>height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_HEIGHT<span class="token punctuation">)</span><span class="token punctuation">)</span>width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_WIDTH<span class="token punctuation">)</span><span class="token punctuation">)</span>num_frames <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_COUNT<span class="token punctuation">)</span><span class="token punctuation">)</span>fps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FPS<span class="token punctuation">)</span><span class="token punctuation">)</span>video<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="TSN-每段（segment）采样一帧视频"><a href="#TSN-每段（segment）采样一帧视频" class="headerlink" title="TSN 每段（segment）采样一帧视频"></a>TSN 每段（segment）采样一帧视频</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">K <span class="token operator">=</span> self<span class="token punctuation">.</span>_num_segments<span class="token keyword">if</span> is_train<span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Random index for each segment.</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames <span class="token operator">//</span> K<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Middle index for each segment.</span>        frame_indices <span class="token operator">=</span> num_frames <span class="token operator">/</span> K <span class="token operator">//</span> <span class="token number">2</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>                                        torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">assert</span> frame_indices<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token punctuation">[</span>frame_indices<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="常用训练和验证数据预处理"><a href="#常用训练和验证数据预处理" class="headerlink" title="常用训练和验证数据预处理"></a><strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span>                                             scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span><span class="token punctuation">)</span> val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="模型训练和测试"><a href="#模型训练和测试" class="headerlink" title="模型训练和测试"></a><strong>模型训练和测试</strong></h1><h3 id="分类模型训练代码"><a href="#分类模型训练代码" class="headerlink" title="分类模型训练代码"></a><strong>分类模型训练代码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Loss and optimizer</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># Train the model</span>total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token punctuation">,</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>              <span class="token comment"># Forward pass</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>              <span class="token comment"># Backward and optimizer</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: [&#123;&#125;/&#123;&#125;], Step: [&#123;&#125;/&#123;&#125;], Loss: &#123;&#125;'</span>                  <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="分类模型测试代码"><a href="#分类模型测试代码" class="headerlink" title="分类模型测试代码"></a><strong>分类模型测试代码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Test the model</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># eval mode(batch norm uses moving mean/variance </span>              <span class="token comment">#instead of mini-batch mean/variance)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy of the model on the 10000 test images: &#123;&#125; %'</span>          <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="自定义loss"><a href="#自定义loss" class="headerlink" title="自定义loss"></a><strong>自定义loss</strong></h3><p>继承torch.nn.Module类写自己的loss。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLoss</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Moudle<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="标签平滑（label-smoothing）"><a href="#标签平滑（label-smoothing）" class="headerlink" title="标签平滑（label smoothing）"></a><strong>标签平滑（label smoothing）</strong></h3><p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log_softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>e <span class="token operator">=</span> e        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction      <span class="token keyword">def</span> <span class="token function">_one_hot</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> classes<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""            Convert labels to one hot vectors              Args:            labels: torch tensor in format [label1, label2, label3, ...]            classes: int, number of classes            value: label value in one hot vector, default to 1              Returns:            return one hot format labels in shape [batchsize, classes]        """</span>        one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span>        <span class="token comment">#labels and value_added  size must match</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        value_added <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>value<span class="token punctuation">)</span>        value_added <span class="token operator">=</span> value_added<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot <span class="token operator">=</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> value_added<span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot    <span class="token keyword">def</span> <span class="token function">_smooth_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> smooth_factor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""convert targets to one-hot format, and smooth        them.        Args:            target: target in form with [label1, label2, label_batchsize]            length: length of one-hot format(number of classes)            smooth_factor: smooth factor for label smooth              Returns:            smoothed labels in one hot format        """</span>        one_hot <span class="token operator">=</span> self<span class="token punctuation">.</span>_one_hot<span class="token punctuation">(</span>target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> smooth_factor<span class="token punctuation">)</span>        one_hot <span class="token operator">+=</span> smooth_factor <span class="token operator">/</span> <span class="token punctuation">(</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>target<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">!=</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input tensor to have least 2 dimensions(got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Only 2 dimension tensor are implemented, (got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        smoothed_target <span class="token operator">=</span> self<span class="token punctuation">.</span>_smooth_label<span class="token punctuation">(</span>target<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>e<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span> x <span class="token operator">*</span> smoothed_target<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'none'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> loss              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'sum'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'mean'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'unrecognized option, expect reduction to be one of none, mean, sum'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>或者直接在训练文件里做label smoothing</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    N <span class="token operator">=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># C is the number of classes.</span>    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="Mixup训练"><a href="#Mixup训练" class="headerlink" title="Mixup训练"></a><strong>Mixup训练</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">beta_distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>distributions<span class="token punctuation">.</span>beta<span class="token punctuation">.</span>Beta<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Mixup images and labels.</span>    lambda_ <span class="token operator">=</span> beta_distribution<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    mixed_images <span class="token operator">=</span> lambda_ <span class="token operator">*</span> images <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> images<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    label_a<span class="token punctuation">,</span> label_b <span class="token operator">=</span> labels<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token comment"># Mixup loss.</span>    scores <span class="token operator">=</span> model<span class="token punctuation">(</span>mixed_images<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>lambda_ <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_a<span class="token punctuation">)</span>            <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_b<span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="L1-正则化"><a href="#L1-正则化" class="headerlink" title="L1 正则化"></a>L1 正则化</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">l1_regularization <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment"># Standard cross-entropy loss</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    loss <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="不对偏置项进行权重衰减（weight-decay）"><a href="#不对偏置项进行权重衰减（weight-decay）" class="headerlink" title="不对偏置项进行权重衰减（weight decay）"></a><strong>不对偏置项进行权重衰减（weight decay）</strong></h3><p>pytorch里的weight decay相当于l2正则</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">bias_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>others_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> bias_list<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            <span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> others_list<span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="梯度裁剪（gradient-clipping）"><a href="#梯度裁剪（gradient-clipping）" class="headerlink" title="梯度裁剪（gradient clipping）"></a><strong>梯度裁剪（gradient clipping）</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="得到当前学习率"><a href="#得到当前学习率" class="headerlink" title="得到当前学习率"></a><strong>得到当前学习率</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># If there is one global learning rate (which is the common case).</span>lr <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token comment"># If there are multiple learning rates for different layers.</span>all_lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>    all_lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>另一种方法，在一个batch训练代码里，当前的lr是optimizer.param_groups[0][‘lr’]</p><h3 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Reduce learning rate when validation accuarcy plateau.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span class="token comment"># Cosine annealing learning rate.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token comment"># Reduce learning rate by 10 at given epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># Learning rate warmup by 10 epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t <span class="token operator">/</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="优化器链式更新"><a href="#优化器链式更新" class="headerlink" title="优化器链式更新"></a><strong>优化器链式更新</strong></h3><p>从1.4版本开始，torch.optim.lr_scheduler 支持链式更新（chaining），即用户可以定义两个 schedulers，并交替在训练中使用。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> ExponentialLR<span class="token punctuation">,</span> StepLRmodel <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> SGD<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>scheduler1 <span class="token operator">=</span> ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>scheduler2 <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> scheduler2<span class="token punctuation">.</span>get_last_lr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler2<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="模型训练可视化"><a href="#模型训练可视化" class="headerlink" title="模型训练可视化"></a><strong>模型训练可视化</strong></h3><p>PyTorch可以使用tensorboard来可视化训练过程。</p><p>安装和运行TensorBoard。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> tensorboardtensorboard --logdir<span class="token operator">=</span>runs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如’Loss/train’和’Loss/test’。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> n_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="保存与加载断点"><a href="#保存与加载断点" class="headerlink" title="保存与加载断点"></a><strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">start_epoch <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># Load checkpoint.</span><span class="token keyword">if</span> resume<span class="token punctuation">:</span> <span class="token comment"># resume为参数，第一次训练时设为0，中断再训练时设为1</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    best_acc <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_acc'</span><span class="token punctuation">]</span>    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load checkpoint at epoch &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best accuracy so far &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Train the model</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token comment"># Test the model</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          <span class="token comment"># save checkpoint</span>    is_best <span class="token operator">=</span> current_acc <span class="token operator">></span> best_acc    best_acc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>current_acc<span class="token punctuation">,</span> best_acc<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">'best_acc'</span><span class="token punctuation">:</span> best_acc<span class="token punctuation">,</span>        <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token string">'model'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>    best_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>    <span class="token keyword">if</span> is_best<span class="token punctuation">:</span>        shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> best_model_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取-ImageNet-预训练模型某层的卷积特征"><a href="#提取-ImageNet-预训练模型某层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型某层的卷积特征"></a>提取 ImageNet 预训练模型某层的卷积特征</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># VGG-16 pool5 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token comment"># VGG-16 fc7 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># ResNet GAP feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取-ImageNet-预训练模型多层的卷积特征"><a href="#提取-ImageNet-预训练模型多层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型多层的卷积特征"></a>提取 ImageNet 预训练模型多层的卷积特征</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Helper class to extract several convolution features from the given    pre-trained model.    Attributes:        _model, torch.nn.Module.        _layers_to_extract, list&lt;str> or set&lt;str>    Example:        >>> model = torchvision.models.resnet152(pretrained=True)        >>> model = torch.nn.Sequential(collections.OrderedDict(                list(model.named_children())[:-1]))        >>> conv_representation = FeatureExtractor(                pretrained_model=model,                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            <span class="token keyword">return</span> conv_representation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="微调全连接层"><a href="#微调全连接层" class="headerlink" title="微调全连接层"></a>微调全连接层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># Replace the last fc layer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="以较大学习率微调全连接层，较小学习率微调卷积层"><a href="#以较大学习率微调全连接层，较小学习率微调卷积层" class="headerlink" title="以较大学习率微调全连接层，较小学习率微调卷积层"></a>以较大学习率微调全连接层，较小学习率微调卷积层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>               <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a><strong>其他注意事项</strong></h1><ul><li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是O(mn)的内存，线性层太大很容易超出现有显存。</li><li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。</li><li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。</li><li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li><li>model.eval() 和 torch.no_grad() 的区别在于，model.eval() 是将网络切换为测试状态，例如 BN 和dropout在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。</li><li>model.zero_grad()会把整个模型的参数的梯度都归零, 而optimizer.zero_grad()只会把传入其中的参数的梯度归零.</li><li>torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li><li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。</li><li>torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。num_workers 的设置需要在实验中找到最快的取值。</li><li>用 del 及时删除不用的中间变量，节约 GPU 存储。</li><li>使用 inplace 操作可节约 GPU 存储，如</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><ul><li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</li><li>使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。</li><li>时常使用 assert tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。</li><li>除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li><li>统计代码各部分耗时</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>enabled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">as</span> profile<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span><span class="token comment"># 或者在命令行运行</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>bottleneck main<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ul><li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print 出来每一行的执行结果的 tensor 的形状、数据类型、设备、是否需要梯度的信息。</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pip install torchsnooper</span><span class="token keyword">import</span> torchsnooper<span class="token comment"># 对于函数，使用修饰器</span><span class="token decorator annotation punctuation">@torchsnooper<span class="token punctuation">.</span>snoop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。</span><span class="token keyword">with</span> torchsnooper<span class="token punctuation">.</span>snoop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ul><li>原本的代码</li></ul><p><a href="https://github.com/zasdfgbnm/TorchSnooper">https://github.com/zasdfgbnm/TorchSnooper</a></p><ul><li>模型可解释性，使用captum库</li></ul><p><a href="https://captum.ai/">https://captum.ai/</a></p><p><strong>参考资料：</strong></p><p>1.<a href="https://zhuanlan.zhihu.com/p/59205847">https://zhuanlan.zhihu.com/p/59205847</a></p><p>2.<a href="https://pytorch.org/tutorials/">PyTorch官方文档和示例</a></p><p>3.<a href="https://pytorch.org/docs/stable/notes/faq.html">https://pytorch.org/docs/stable/notes/faq.html</a></p><p>4.<a href="https://github.com/szagoruyko/pytorchviz">https://github.com/szagoruyko/pytorchviz</a></p><p>5.<a href="https://github.com/sksq96/pytorch-summary">https://github.com/sksq96/pytorch-summary</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220511003116457.png&quot; alt=&quot;image-20220511003116457&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>网络抓包与协议分析</title>
    <link href="http://enderfga.cn/2022/05/01/net3/"/>
    <id>http://enderfga.cn/2022/05/01/net3/</id>
    <published>2022-05-01T03:07:57.000Z</published>
    <updated>2022-05-12T16:04:08.455Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：网络抓包与协议分析实验</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/wall.png" alt="Wireshark — A Walkthrough Of The Best Packet Analyzer In The World"></p><embed src="./problem.pdf" width="100%" height="750" type="application/pdf"><embed src="./wireshark.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计网作业：网络抓包与协议分析实验&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据库原理 Exercises 3&amp;4</title>
    <link href="http://enderfga.cn/2022/04/29/data3/"/>
    <id>http://enderfga.cn/2022/04/29/data3/</id>
    <published>2022-04-28T16:33:52.000Z</published>
    <updated>2022-04-30T07:43:33.417Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 5&amp;6</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220429003143556.png" alt="image-20220429003143556"></p><h1 id="Database-System-Concepts-Exercises-of-Chapter-5-amp-6"><a href="#Database-System-Concepts-Exercises-of-Chapter-5-amp-6" class="headerlink" title="Database System Concepts Exercises of Chapter 5&amp;6"></a>Database System Concepts Exercises of Chapter 5&amp;6</h1><p><strong>Exercise 5.8</strong> Consider the bank database of Figure <strong>5.25</strong>. Write an sQL trigger to carryout the following action: On <strong>delete</strong> of an account, for each owner of theaccount, check if the owner has any remaining accounts, and if she doesnot, delete her from the <em>depositor</em> relation.</p><p>branch(branch_name, branch_city, assets)</p><p>customer ( customer_name, customer_street, customer_city )</p><p>loan( loan_number, branch_name, amount)</p><p>borrower ( customer_name, loan_number )</p><p>account ( account_number, branch_name, balance )</p><p>depositor ( customer_name, account_number )</p><p><strong>Figure 5.25</strong></p><p><strong>My answer:</strong></p><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">trigger</span> <span class="token keyword">check</span><span class="token operator">-</span><span class="token keyword">delete</span><span class="token operator">-</span><span class="token keyword">trigger</span> <span class="token keyword">after</span> <span class="token keyword">delete</span> <span class="token keyword">on</span> account referencing old <span class="token keyword">row</span> <span class="token keyword">as</span> orow<span class="token keyword">for each row</span><span class="token keyword">delete</span> <span class="token keyword">from</span> depositor<span class="token keyword">where</span> depositor<span class="token punctuation">.</span>customer_name <span class="token operator">not</span> <span class="token operator">in</span>   <span class="token punctuation">(</span> <span class="token keyword">select</span> customer_name <span class="token keyword">from</span> depositor     <span class="token keyword">where</span> account_number <span class="token operator">&lt;></span> orow<span class="token punctuation">.</span>account_number <span class="token punctuation">)</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><strong>Exercise</strong> <strong>5.15</strong> Consider an employee database with two relations<br>employee ($\underline{employee_name}$, street, city)<br>works ($\underline{employee_name}$, company_name, salary)<br>where the primary keys are underlined. Write a query to find companies whose employees earn a higher salary, on average, than the average salary at “First Bank Corporation”.<br>a. Using SQL functions as appropriate.<br>b. Without using SQL functions.</p><p><strong>My answer:</strong></p><p>a)</p><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> avg_salary<span class="token punctuation">(</span>cname <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token keyword">integer</span>     <span class="token keyword">declare</span> result <span class="token keyword">integer</span><span class="token punctuation">;</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token keyword">into</span> result<span class="token keyword">from</span> works<span class="token keyword">where</span> works<span class="token punctuation">.</span>company<span class="token punctuation">.</span>name <span class="token operator">=</span> cname<span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">where</span> avg_salary<span class="token punctuation">(</span>company_name<span class="token punctuation">)</span> <span class="token operator">></span> avg_salary<span class="token punctuation">(</span>“<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>b)</p><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">group</span> <span class="token keyword">by</span> company_name<span class="token keyword">having</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span><span class="token keyword">from</span> works<span class="token keyword">where</span> company_name<span class="token operator">=</span>”<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><hr><p><strong>Exercise 6.1</strong> Write the following queries in relational algebra, using the university schema.<br> <strong>a</strong>. Find the titles of courses in the Comp. Sci. department that have 3 credits.<br> <strong>b</strong>. Find the IDs of all students who were taught by an instructor named Einstein; make sure there are no duplicates in the result.<br> <strong>c</strong>. Find the highest salary of any instructor.<br> <strong>d</strong>. Find all instructors earning the highest salary (there may be more than one with the same salary).</p><p><strong>My answer:</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220429003507835.png" alt="image-20220429003507835"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Database System Concepts Exercises of Chapter 5&amp;amp;6&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://enderfga.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>conda/linux/git常用命令“笔记”</title>
    <link href="http://enderfga.cn/2022/04/28/code/"/>
    <id>http://enderfga.cn/2022/04/28/code/</id>
    <published>2022-04-28T01:34:32.000Z</published>
    <updated>2022-04-28T02:00:10.884Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一些常用的命令，每次忘了都得搜，记录一下</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220428094832340.png" alt="image-20220428094832340"></p><span id="more"></span><h1 id="Anaconda-amp-python"><a href="#Anaconda-amp-python" class="headerlink" title="Anaconda&amp;python"></a>Anaconda&amp;python</h1><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220428093957780.png" alt="image-20220428093957780"></p><p><strong>pip安装（tensorflow-gpu为例）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>conda安装</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>pip3安装（指定版本号只需在命令末尾添加==1.12.0版本号）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip3  install tensorflow-gpu&#x3D;&#x3D;1.12.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>使用清华镜像下载</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install tensorflow-gpu&#x3D;&#x3D;1.10 -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>指定目录安装</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install -t D:\ProgramData\Anaconda3\Lib\site-packages torch-1.0.1-cp36-cp36m-win_amd64.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>卸载安装（pip\pip3只需将conda换成pip\pip3）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  uninstall tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>创建虚拟环境（conda为例）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n py36 python&#x3D;3.6  #py36虚拟环境的名字  python&#x3D;3.6  python版本<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>删除虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda remove -n py36 --all<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>激活虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda activate py36<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>退出虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看所有创建的虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda env list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>用virtualenv创建虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">VENV_DIR</span><span class="token operator">=</span>venvpip <span class="token function">install</span> virtualenvvirtualenv <span class="token variable">$VENV_DIR</span><span class="token builtin class-name">source</span> <span class="token variable">$VENV_DIR</span>/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><strong>nohup送入后台运行</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">nohup</span> python train.py <span class="token operator">></span>nohup <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>      <span class="token comment">#train.py运行的文件  nohup生成的日志文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>CUDA指定GPU</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token function">nohup</span> python train.py  <span class="token operator">></span> nohup.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>导出requirements.txt</p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python3 -m pip freeze <span class="token operator">></span> requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看GPU使用情况</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看进程号</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">ps</span> aux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>根据进程号杀死进程</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">kill</span> -9 进程号<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/200301122312741.jpg" alt="img"></p><h1 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h1><p>linux不像Windows 分了盘，它根目录下有如下常用文件夹:</p><p><em>home</em>         —————        用户的家</p><p><em>root</em>            —————        超级管理员root的家</p><p><em>etc</em>              —————        存放配置文件</p><p><em>usr</em>              —————        存放共享资源</p><h2 id="1、cd命令"><a href="#1、cd命令" class="headerlink" title="1、cd命令:"></a>1、cd命令:</h2><p><strong>①、进入某一个目录</strong> <code>cd 目录名</code></p><p><strong>②、进入多级目录</strong>  <code>cd 目录名/目录名</code></p><p><strong>③、返回上一级目录</strong> <code>cd ..</code></p><p><strong>④、返回根目录</strong> <code>cd /</code></p><p><strong>⑤、返回根目录下的某一个目录</strong> <code>cd /目录名</code></p><p><strong>⑥、回家</strong> <code>cd ~</code></p><h2 id="2、创建、删除目录"><a href="#2、创建、删除目录" class="headerlink" title="2、创建、删除目录:"></a>2、创建、删除目录:</h2><p><strong>①、创建目录</strong> <code>mkdir 目录名</code></p><p><strong>②、创建多级目录</strong> <code>mkdir -p a/b/c</code></p><p><strong>③、删除目录(只能删除空目录)</strong> <code>rmdir 目录名</code></p><p><strong>④、删除目录(可删除非空目录，带询问)</strong> <code>rm -r</code></p><p><strong>⑤、删除目录(不带询问，谨慎使用)</strong> <code>rm -rf</code></p><h2 id="3、对文件的操作"><a href="#3、对文件的操作" class="headerlink" title="3、对文件的操作:"></a>3、对文件的操作:</h2><p><strong>①、创建空白文件</strong> <code>touch 文件名</code></p><p><strong>②、复制文件</strong></p><p> <code>cp a.txt b.txt</code> <em>表示复制a文件并重命名为b。</em></p><p><code>cp a.txt dir/b.txt</code> <em>表示把a复制到dir文件夹下并重命名为b。</em></p><p><strong>③、移动文件</strong> <code>mv a.txt dir/b.txt</code> <em>把a.txt移动到dir目录下并重命名为b.txt。</em></p><p><strong>④、重命名文件</strong> <code>mv a.txt b.txt</code> <em>把a.txt重命名为b.txt。</em></p><p><strong>⑤、删除文件</strong></p><p><code>rm 文件名</code> <em>带询问的删除</em></p><p><code>rm -f 文件名</code> <em>不带询问的删除。</em></p><p><strong>⑥、浏览文件</strong></p><p> <code>cat 文件名</code> <em>显示文件所有内容</em></p><p><code>more 文件名</code> <em>分页显示，空格键下一页，回车键下一行。</em></p><p><code>less 文件名</code> <em>分页显示，pgup上一页，pgdn下一页。</em></p><p><code>tail -5 a.txt</code> <em>显示a.txt文件的最后5行。</em></p><p><code>tail -f 文件名</code> <em>动态的查看。</em></p><h2 id="4、查看目录下的文件"><a href="#4、查看目录下的文件" class="headerlink" title="4、查看目录下的文件:"></a>4、查看目录下的文件:</h2><p><strong>①、查看所有文件和目录名称</strong> <code>ls</code></p><p><strong>②、查看所有文件和目录名称(包括隐藏的)</strong> <code>ls -a</code></p><p><strong>③、查看文件并显示详细信息(最常用)</strong> <code>ll</code></p><p><strong>④、友好的显示</strong> <code>ll -h</code> <em>比如显示的文件大小是kb而不是字节。</em></p><h2 id="5、tar打包命令"><a href="#5、tar打包命令" class="headerlink" title="5、tar打包命令:"></a>5、tar打包命令:</h2><p><strong>①、将当前目录所有文件打包成haha.tar</strong> <code>tar -cvf haha.tar ./*</code></p><p><strong>②、将当前目录下所有文件打包并压缩成haha.tar</strong> <code>tar -zcvf haha.tar.gz ./*</code></p><p><strong>③、将haha.tar解压到当前目录</strong> <code>tar -xvf haha.tar</code></p><p><strong>④、将haha.tar解压到b目录</strong> <code>tar -xvf haha.tar -C b</code> <em>注意C是大写的！</em></p><h2 id="6、其他常用命令"><a href="#6、其他常用命令" class="headerlink" title="6、其他常用命令:"></a>6、其他常用命令:</h2><p><strong>①、grep命令</strong></p><p><code>grep category a.txt</code> <em>表示在a.txt中查找category字符串所在的行，前提是打开了a.txt文件。</em></p><p><code>grep category a.txt -A2</code> <em>在a.txt中查找category字符串的前两行。</em></p><p><code>grep category a.txt -B2</code> <em>在a.txt中查找category字符串的后两行。</em></p><p><strong>②、查看当前目录</strong> <code>pwd</code></p><p><strong>③、wget下载命令</strong> <code>wget www.baidu.com</code> <em>下载百度首页</em></p><h2 id="7、vi-vim编辑器"><a href="#7、vi-vim编辑器" class="headerlink" title="7、vi/vim编辑器:"></a>7、vi/vim编辑器:</h2><p><strong>①、编辑器有三种模式，分别是:</strong> <strong>命令行模式:</strong> 此模式无法编辑文件，<code>yy</code>复制行，<code>p</code>粘贴，<code>dd</code>删除行，按如下键都可以进入插入模式:</p><p><code>i</code>       当前位置前插入;</p><p><code>I</code>        当前行行首插入;</p><p><code>a</code>       当前位置后插入;</p><p><code>A</code>      当前行行尾插入;</p><p><code>o</code>       当前行之后插入一行;</p><p> <code>O</code>      当前的之前插入一行</p><p><strong>插入模式:</strong>此模式下可以对文件进行编辑。按 <code>esc</code>退出插入模式，回到命令行模式。 <strong>底行模式:</strong>命令行模式下按 <code>:</code>，即可进入底行模式。底行模式有如下常用命令:</p><p> <code>q</code>        不保存退出;</p><p> <code>q！</code>    不保存强制退出;</p><p><code>wq</code>     保存退出</p><h2 id="8、管道"><a href="#8、管道" class="headerlink" title="8、管道:"></a>8、管道:</h2><p><strong>管道:<code>|</code>，将一个命令的输出作为另一个命令的输入。例如:</strong> <strong>在 <code>ip addr</code>的输出结果中查找 <code>192.168</code>字符串:</strong> <code>ip addr | grep 192.168</code></p><h2 id="9、系统管理命令"><a href="#9、系统管理命令" class="headerlink" title="9、系统管理命令:"></a>9、系统管理命令:</h2><p><strong>①、查看系统时间</strong> <code>date</code>  查看系统时间 <code>date -s &quot;2018-05-15 22:22:22&quot;</code>将系统时间设置为引号里面的时间</p><p><strong>②、查看磁盘信息</strong> <code>df</code> 查看磁盘信息 <code>df -h</code>  友好地展示磁盘信息</p><p><strong>③、清屏</strong> <code>clear</code>或者按 <code>ctr L</code></p><p><strong>④、进程</strong> <code>ps -ef</code>查看所有进程 <code>ps -ef | grep ssh</code>查找ssh进程</p><p><strong>⑤、杀掉进程</strong> <code>kill 9527</code>杀掉9527号进程 <code>kill -9 9527</code> 强制杀掉9527号进程</p><p><strong>⑥、查看网络端口</strong> <code>netstat -an | grep 3306</code>查看3306端口占用情况</p><p><strong>⑦、ping命令</strong> <code>ping xx.xx.xxx</code>测试网络连通性</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/bg2015120901.png" alt="img"></p><h1 id="GIT"><a href="#GIT" class="headerlink" title="GIT"></a>GIT</h1><p>下面是常用 Git 命令清单。几个专用名词的译名如下。</p><blockquote><ul><li>Workspace：工作区</li><li>Index / Stage：暂存区</li><li>Repository：仓库区（或本地仓库）</li><li>Remote：远程仓库</li></ul></blockquote><h2 id="一、新建代码库"><a href="#一、新建代码库" class="headerlink" title="一、新建代码库"></a>一、新建代码库</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在当前目录新建一个Git代码库</span>$ <span class="token function">git</span> init<span class="token comment"># 新建一个目录，将其初始化为Git代码库</span>$ <span class="token function">git</span> init <span class="token punctuation">[</span>project-name<span class="token punctuation">]</span><span class="token comment"># 下载一个项目和它的整个代码历史</span>$ <span class="token function">git</span> clone <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="二、配置"><a href="#二、配置" class="headerlink" title="二、配置"></a>二、配置</h2><p>Git的设置文件为 <code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示当前的Git配置</span>$ <span class="token function">git</span> config --list<span class="token comment"># 编辑Git配置文件</span>$ <span class="token function">git</span> config -e <span class="token punctuation">[</span>--global<span class="token punctuation">]</span><span class="token comment"># 设置提交代码时的用户信息</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.name <span class="token string">"[name]"</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.email <span class="token string">"[email address]"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="三、增加-删除文件"><a href="#三、增加-删除文件" class="headerlink" title="三、增加/删除文件"></a>三、增加/删除文件</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 添加指定文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 添加指定目录到暂存区，包括子目录</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>dir<span class="token punctuation">]</span><span class="token comment"># 添加当前目录的所有文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span><span class="token comment"># 添加每个变化前，都会要求确认</span><span class="token comment"># 对于同一个文件的多处变化，可以实现分次提交</span>$ <span class="token function">git</span> <span class="token function">add</span> -p<span class="token comment"># 删除工作区文件，并且将这次删除放入暂存区</span>$ <span class="token function">git</span> <span class="token function">rm</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 停止追踪指定文件，但该文件会保留在工作区</span>$ <span class="token function">git</span> <span class="token function">rm</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 改名文件，并且将这个改名放入暂存区</span>$ <span class="token function">git</span> <span class="token function">mv</span> <span class="token punctuation">[</span>file-original<span class="token punctuation">]</span> <span class="token punctuation">[</span>file-renamed<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="四、代码提交"><a href="#四、代码提交" class="headerlink" title="四、代码提交"></a>四、代码提交</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 提交暂存区到仓库区</span>$ <span class="token function">git</span> commit -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交暂存区的指定文件到仓库区</span>$ <span class="token function">git</span> commit <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>. -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交工作区自上次commit之后的变化，直接到仓库区</span>$ <span class="token function">git</span> commit -a<span class="token comment"># 提交时显示所有diff信息</span>$ <span class="token function">git</span> commit -v<span class="token comment"># 使用一次新的commit，替代上一次提交</span><span class="token comment"># 如果代码没有任何新变化，则用来改写上一次commit的提交信息</span>$ <span class="token function">git</span> commit --amend -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 重做上一次commit，并包括指定文件的新变化</span>$ <span class="token function">git</span> commit --amend <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="五、分支"><a href="#五、分支" class="headerlink" title="五、分支"></a>五、分支</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有本地分支</span>$ <span class="token function">git</span> branch<span class="token comment"># 列出所有远程分支</span>$ <span class="token function">git</span> branch -r<span class="token comment"># 列出所有本地分支和远程分支</span>$ <span class="token function">git</span> branch -a<span class="token comment"># 新建一个分支，但依然停留在当前分支</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，并切换到该分支</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，指向指定commit</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，与指定的远程分支建立追踪关系</span>$ <span class="token function">git</span> branch --track <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 切换到指定分支，并更新工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 切换到上一个分支</span>$ <span class="token function">git</span> checkout -<span class="token comment"># 建立追踪关系，在现有分支与指定的远程分支之间</span>$ <span class="token function">git</span> branch --set-upstream <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 合并指定分支到当前分支</span>$ <span class="token function">git</span> merge <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 选择一个commit，合并进当前分支</span>$ <span class="token function">git</span> cherry-pick <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除分支</span>$ <span class="token function">git</span> branch -d <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 删除远程分支</span>$ <span class="token function">git</span> push origin --delete <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span>$ <span class="token function">git</span> branch -dr <span class="token punctuation">[</span>remote/branch<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="六、标签"><a href="#六、标签" class="headerlink" title="六、标签"></a>六、标签</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有tag</span>$ <span class="token function">git</span> tag<span class="token comment"># 新建一个tag在当前commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 新建一个tag在指定commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除本地tag</span>$ <span class="token function">git</span> tag -d <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 删除远程tag</span>$ <span class="token function">git</span> push origin :refs/tags/<span class="token punctuation">[</span>tagName<span class="token punctuation">]</span><span class="token comment"># 查看tag信息</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交指定tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交所有tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --tags<span class="token comment"># 新建一个分支，指向某个tag</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="七、查看信息"><a href="#七、查看信息" class="headerlink" title="七、查看信息"></a>七、查看信息</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示有变更的文件</span>$ <span class="token function">git</span> status<span class="token comment"># 显示当前分支的版本历史</span>$ <span class="token function">git</span> log<span class="token comment"># 显示commit历史，以及每次commit发生变更的文件</span>$ <span class="token function">git</span> log --stat<span class="token comment"># 搜索提交历史，根据关键词</span>$ <span class="token function">git</span> log -S <span class="token punctuation">[</span>keyword<span class="token punctuation">]</span><span class="token comment"># 显示某个commit之后的所有变动，每个commit占据一行</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --pretty<span class="token operator">=</span>format:%s<span class="token comment"># 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --grep feature<span class="token comment"># 显示某个文件的版本历史，包括文件改名</span>$ <span class="token function">git</span> log --follow <span class="token punctuation">[</span>file<span class="token punctuation">]</span>$ <span class="token function">git</span> whatchanged <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示指定文件相关的每一次diff</span>$ <span class="token function">git</span> log -p <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示过去5次提交</span>$ <span class="token function">git</span> log -5 --pretty --oneline<span class="token comment"># 显示所有提交过的用户，按提交次数排序</span>$ <span class="token function">git</span> shortlog -sn<span class="token comment"># 显示指定文件是什么人在什么时间修改过</span>$ <span class="token function">git</span> blame <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示暂存区和工作区的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span><span class="token comment"># 显示暂存区和上一个commit的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示工作区与当前分支最新commit之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> HEAD<span class="token comment"># 显示两次提交之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> <span class="token punctuation">[</span>first-branch<span class="token punctuation">]</span><span class="token punctuation">..</span>.<span class="token punctuation">[</span>second-branch<span class="token punctuation">]</span><span class="token comment"># 显示今天你写了多少行代码</span>$ <span class="token function">git</span> <span class="token function">diff</span> --shortstat <span class="token string">"@&#123;0 day ago&#125;"</span><span class="token comment"># 显示某次提交的元数据和内容变化</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交发生变化的文件</span>$ <span class="token function">git</span> show --name-only <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交时，某个文件的内容</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span>:<span class="token punctuation">[</span>filename<span class="token punctuation">]</span><span class="token comment"># 显示当前分支的最近几次提交</span>$ <span class="token function">git</span> reflog<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="八、远程同步"><a href="#八、远程同步" class="headerlink" title="八、远程同步"></a>八、远程同步</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载远程仓库的所有变动</span>$ <span class="token function">git</span> fetch <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 显示所有远程仓库</span>$ <span class="token function">git</span> remote -v<span class="token comment"># 显示某个远程仓库的信息</span>$ <span class="token function">git</span> remote show <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 增加一个新的远程仓库，并命名</span>$ <span class="token function">git</span> remote <span class="token function">add</span> <span class="token punctuation">[</span>shortname<span class="token punctuation">]</span> <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span class="token comment"># 取回远程仓库的变化，并与本地分支合并</span>$ <span class="token function">git</span> pull <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 上传本地指定分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 强行推送当前分支到远程仓库，即使有冲突</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --force<span class="token comment"># 推送所有分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --all<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="九、撤销"><a href="#九、撤销" class="headerlink" title="九、撤销"></a>九、撤销</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 恢复暂存区的指定文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复某个commit的指定文件到暂存区和工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>commit<span class="token punctuation">]</span> <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复暂存区的所有文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token builtin class-name">.</span><span class="token comment"># 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 重置暂存区与工作区，与上一次commit保持一致</span>$ <span class="token function">git</span> reset --hard<span class="token comment"># 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致</span>$ <span class="token function">git</span> reset --hard <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前HEAD为指定commit，但保持暂存区和工作区不变</span>$ <span class="token function">git</span> reset --keep <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个commit，用来撤销指定commit</span><span class="token comment"># 后者的所有变化都将被前者抵消，并且应用到当前分支</span>$ <span class="token function">git</span> revert <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 暂时将未提交的变化移除，稍后再移入</span>$ <span class="token function">git</span> stash$ <span class="token function">git</span> stash pop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="十、其他"><a href="#十、其他" class="headerlink" title="十、其他"></a>十、其他</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 生成一个可供发布的压缩包</span>$ <span class="token function">git</span> archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></blockquote><p>一个常用的实例</p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">add</span> origin xxx<span class="token punctuation">(</span>复制的SSH链接<span class="token punctuation">)</span><span class="token function">git</span> branch -m master main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span> <span class="token function">git</span> commit -m <span class="token string">"注释"</span> <span class="token function">git</span> pull --rebase origin main<span class="token function">git</span> push origin main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些常用的命令，每次忘了都得搜，记录一下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220428094832340.png&quot; alt=&quot;image-20220428094832340&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="终端" scheme="http://enderfga.cn/tags/%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>自动驾驶技术基础之建模与控制</title>
    <link href="http://enderfga.cn/2022/04/25/auto1/"/>
    <id>http://enderfga.cn/2022/04/25/auto1/</id>
    <published>2022-04-25T08:57:56.000Z</published>
    <updated>2022-05-12T16:04:16.756Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动驾驶技术基础的建模与控制作业</p><span id="more"></span><p>概念题（18分）</p><ol><li>自动驾驶为了出色地完成驾驶任务，可分为哪四大模块？（4分）</li><li>系统建模一般分哪两种建模方式？（2分）</li><li>请写出高速转向车辆模型的简化横向误差模型（即四个状态为误差）（4分）</li><li>二次型性能指标函数一般包含哪三项优化项？（3分）</li><li>线性二次问题三种重要形式分别是？（3分）</li><li>Kalman Filter（LQE）如何通过LQR求得，请写出matlab关键代码，即：xxx=lqr(xxx) （2分）</li></ol><p>编程实践题（12分）</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/clip_image002.png" alt="img"></p><p>给定一个双质系统:  m~1~ =2, m~2~=1, 弹簧系数 k=5, 阻尼σ=0.1, 质量块与地面的滑动阻尼 δ=0.1 (与速度有成正比)。初始时刻 m~1~ 质量块处于 x=0 的位置, 两质量块距离为 0 。现在 m~2~ 处作用一外力 F 拖动系统使 m~1~ 与 m~2~ 质量块均处于 x=5 的位置。</p><ol><li>对系统建模（系统可以直接测量两个物体的位置）</li><li>判断系统可控性与可观</li><li>结合给定的simulink和脚本文件，设计实现上述系统的LQG控制器并绘制闭环控制性能曲线</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/clip_image020.jpg" alt="img"></p><embed src="./auto1.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动驾驶技术基础的建模与控制作业&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动驾驶" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>Cognitive Mapping and Planning for Visual Navigation</title>
    <link href="http://enderfga.cn/2022/04/24/CMP/"/>
    <id>http://enderfga.cn/2022/04/24/CMP/</id>
    <published>2022-04-24T14:56:51.000Z</published>
    <updated>2022-04-28T01:42:47.764Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>认知科学基础课程设计报告</p><span id="more"></span><p>开放性题目，结合视语言、语音识别、机器人平台，采用Webots\ROS等不同开源仿真环境，构建一个单/多智能体的认知导航、认知规划、认知控制仿真算例，里面可以用已有的各种传感器组件、机器人模型，基于前期所讲简单的认知智能知识点做仿真试验，算法可以从github上开源下载使用。鼓励大家选择此题目开展一些小试验，可以提问实现的方式方法。同时提交仿真实现的设计和试验研习报告。突出认知智能应用的关键要点，进行详细阐述说明。</p><embed src="./CMP.pdf" width="100%" height="750" type="application/pdf"><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220424225934056.png" alt="image-20220424225934056"></p><p>【1】论文地址： <a href="https://arxiv.org/abs/1702.03920">https://arxiv.org/abs/1702.03920</a><br>【2】代码： <a href="https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning">https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning</a><br>【3】论文Slide： <a href="https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1">https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1</a><br>【4】作者主页： <a href="https://people.eecs.berkeley.edu/~sgupta/">https://people.eecs.berkeley.edu/~sgupta/</a><br>【5】作者主页： <a href="https://people.eecs.berkeley.edu/~svlevine/">https://people.eecs.berkeley.edu/~svlevine/</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;认知科学基础课程设计报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="无人系统" scheme="http://enderfga.cn/tags/%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于套接字的网络程序设计</title>
    <link href="http://enderfga.cn/2022/04/19/net2/"/>
    <id>http://enderfga.cn/2022/04/19/net2/</id>
    <published>2022-04-19T11:07:49.000Z</published>
    <updated>2022-04-26T11:48:44.960Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：套接字编程实验</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220419191104235.png" alt="image-20220419191104235"></p><h1 id="套接字编程作业1：Web服务器"><a href="#套接字编程作业1：Web服务器" class="headerlink" title="套接字编程作业1：Web服务器"></a>套接字编程作业1：Web服务器</h1><p>在本实验中，您将学习Python中TCP连接的套接字编程的基础知识：如何创建套接字，将其绑定到特定的地址和端口，以及发送和接收HTTP数据包。您还将学习一些HTTP首部格式的基础知识。</p><p>您将开发一个处理一个HTTP请求的Web服务器。您的Web服务器应该接受并解析HTTP请求，然后从服务器的文件系统获取所请求的文件，创建一个由响应文件组成的HTTP响应消息，前面是首部行，然后将响应直接发送给客户端。如果请求的文件不存在于服务器中，则服务器应该向客户端发送“404 Not Found”差错报文。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>在文件下面你会找到Web服务器的代码框架。您需要填写这个代码。而且需要在标有#Fill in start 和 # Fill in end的地方填写代码。另外，每个地方都可能需要不止一行代码。</p><h3 id="运行服务器"><a href="#运行服务器" class="headerlink" title="运行服务器"></a>运行服务器</h3><p>将HTML文件（例如HelloWorld.html）放在服务器所在的目录中。运行服务器程序。确认运行服务器的主机的IP地址（例如128.238.251.26）。从另一个主机，打开浏览器并提供相应的URL。例如：</p><p><a href="http://128.238.251.26:6789/HelloWorld.html">http://128.238.251.26:6789/HelloWorld.html</a></p><p>“HelloWorld.html”是您放在服务器目录中的文件。还要注意使用冒号后的端口号。您需要使用服务器代码中使用的端口号来替换此端口号。在上面的例子中，我们使用了端口号6789. 浏览器应该显示HelloWorld.html的内容。如果省略“:6789”，浏览器将使用默认端口80，只有当您的服务器正在端口80监听时，才会从服务器获取网页。</p><p>然后用客户端尝试获取服务器上不存在的文件。你应该会得到一个“404 Not Found”消息。</p><h3 id="需要上交的内容"><a href="#需要上交的内容" class="headerlink" title="需要上交的内容"></a>需要上交的内容</h3><p>您需要上交完整的服务器代码，以及客户端浏览器的屏幕截图，用于验证您是否从服务器实际接收到HTML文件内容。</p><h3 id="Web服务器的Python代码框架"><a href="#Web服务器的Python代码框架" class="headerlink" title="Web服务器的Python代码框架"></a>Web服务器的Python代码框架</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#import socket module</span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_STREAM<span class="token punctuation">)</span> <span class="token comment">#Prepare a sever socket </span><span class="token comment">#Fill in start </span><span class="token comment">#Fill in end </span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>       <span class="token comment">#Establish the connection  </span>    <span class="token keyword">print</span> <span class="token string">'Ready to serve...'</span>       connectionSocket<span class="token punctuation">,</span> addr <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>             message <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>        filename <span class="token operator">=</span> message<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                              f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        outputdata <span class="token operator">=</span> <span class="token comment">#Fill in start  #Fill in end</span>        <span class="token comment">#Send one HTTP header line into socket     </span>        <span class="token comment">#Fill in start     </span>        <span class="token comment">#Fill in end  </span>        <span class="token comment">#Send the content of the requested file to the client</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>outputdata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            connectionSocket<span class="token punctuation">.</span>send<span class="token punctuation">(</span>outputdata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        connectionSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> IOError<span class="token punctuation">:</span>        <span class="token comment">#Send response message for file not found</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end</span>        <span class="token comment">#Close client socket</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end         </span>    serverSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="可选练习"><a href="#可选练习" class="headerlink" title="可选练习"></a>可选练习</h3><ol><li>目前，这个Web服务器一次只处理一个HTTP请求。请实现一个能够同时处理多个请求的多线程服务器。使用线程，首先创建一个主线程，在固定端口监听客户端请求。当从客户端收到TCP连接请求时，它将通过另一个端口建立TCP连接，并在另外的单独线程中为客户端请求提供服务。这样在每个请求/响应对的独立线程中将有一个独立的TCP连接。</li><li>不使用浏览器，编写自己的HTTP客户端来测试你的服务器。您的客户端将使用一个TCP连接用于连接到服务器，向服务器发送HTTP请求，并将服务器响应显示出来。您可以假定发送的HTTP请求将使用GET方法。<br>客户端应使用命令行参数指定服务器IP地址或主机名，服务器正在监听的端口，以及被请求对象在服务器上的路径。</li></ol><h1 id="套接字编程作业2：UDPping程序"><a href="#套接字编程作业2：UDPping程序" class="headerlink" title="套接字编程作业2：UDPping程序"></a>套接字编程作业2：UDPping程序</h1><p>在本实验中，您将学习使用Python进行UDP套接字编程的基础知识。您将学习如何使用UDP套接字发送和接收数据报，以及如何设置适当的套接字超时。在实验中，您将熟悉Ping应用程序及其在计算统计信息（如丢包率）中的作用。</p><p>您首先需要研究一个用Python编写的简单的ping服务器程序，并实现对应的客户端程序。这些程序提供的功能类似于现代操作系统中可用的标准ping程序功能。然而，我们的程序使用更简单的UDP协议，而不是标准互联网控制消息协议（ICMP）来进行通信。 ping协议允许客户端机器发送一个数据包到远程机器，并使远程机器将数据包返回到客户（称为回显）的操作。另外，ping协议允许主机计算它到其他机器的往返时间。</p><p>以下是Ping服务器程序的完整代码。你的任务是写出Ping客户端程序。</p><h3 id="服务器代码"><a href="#服务器代码" class="headerlink" title="服务器代码"></a>服务器代码</h3><p>以下代码完整实现了一个ping服务器。您需要在运行客户端程序之前编译并运行此代码。<em>而且您不需要修改此代码。</em></p><p>在这个服务器代码中，30％的客户端的数据包会被模拟丢失。你应该仔细研究这个代码，它将帮助你编写ping客户端。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># UDPPingerServer.py </span><span class="token comment"># We will need the following module to generate randomized lost packets import random </span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span> <span class="token keyword">import</span> random<span class="token comment"># Create a UDP socket  </span><span class="token comment"># Notice the use of SOCK_DGRAM for UDP packets </span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_DGRAM<span class="token punctuation">)</span> <span class="token comment"># Assign IP address and port number to socket </span>serverSocket<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token number">12000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>   <span class="token comment"># Generate random number in the range of 0 to 10 </span>rand <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>   <span class="token comment"># Receive the client packet along with the address it is coming from  </span>message<span class="token punctuation">,</span> address <span class="token operator">=</span> serverSocket<span class="token punctuation">.</span>recvfrom<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span> <span class="token comment"># Capitalize the message from the client   </span>message <span class="token operator">=</span> message<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If rand is less is than 4, we consider the packet lost and do not respond   </span><span class="token keyword">if</span> rand <span class="token operator">&lt;</span> <span class="token number">4</span><span class="token punctuation">:</span>     <span class="token keyword">continue</span>   <span class="token comment"># Otherwise, the server responds     </span>serverSocket<span class="token punctuation">.</span>sendto<span class="token punctuation">(</span>message<span class="token punctuation">,</span> address<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>服务器程序在一个无限循环中监听到来的UDP数据包。当数据包到达时，如果生成一个随机整数大于或等于4，则服务器将数字转为大写并将其发送回客户端。</p><h3 id="数据包丢失"><a href="#数据包丢失" class="headerlink" title="数据包丢失"></a>数据包丢失</h3><p>UDP为应用程序提供了不可靠的传输服务。消息可能因为路由器队列溢出，硬件错误或其他原因，而在网络中丢失。但由于在内网中很丢包甚至不丢包，所以在本实验室的服务器程序添加人为损失来模拟网络丢包的影响。服务器创建一个随机整数，由它确定传入的数据包是否丢失。</p><h3 id="客户端代码"><a href="#客户端代码" class="headerlink" title="客户端代码"></a>客户端代码</h3><p>您需要实现以下客户端程序。</p><p>客户端向服务器发送10次ping。因为UDP是不可靠的协议，所以从客户端发送到服务器的数据包可能在网络中丢失。因此，客户端不能无限期地等待ping消息的回复。客户等待服务器回答的时间至多为一秒，如果在一秒内没有收到回复，您的客户端程序应该假定数据包在网络传输期间丢失。您需要查找Python文档，以了解如何在数据报套接字上设置超时值。</p><p>具体来说，您的客户端程序应该</p><ol><li>使用UDP发送ping消息（注意：不同于TCP，您不需要首先建立连接，因为UDP是无连接协议。）</li><li>从服务器输出响应消息</li><li>如果从服务器受到响应，则计算并输出每个数据包的往返时延（RTT）（以秒为单位），</li><li>否则输出“请求超时”</li></ol><p>在开发过程中，您应该先在计算机上运行 <code>UDPPingerServer.py</code>，并通过向 <code>localhost</code>（或127.0.0.1）发送数据包来测试客户端。调试完成代码后，您应该能看到ping服务器和ping客户端在不同机器上通过网络进行通信。</p><h3 id="消息格式"><a href="#消息格式" class="headerlink" title="消息格式"></a>消息格式</h3><p>本实验中的ping消息格式使用最简单的方式。客户端消息只有一行，由以下格式的ASCII字符组成：</p><blockquote><p>Ping <em>sequence_number time</em></p></blockquote><p>其中<em>sequence_number</em>从1开始，一直到10，共10条消息，而<em>time</em>则是客户端发送消息时的时间。</p><h3 id="需要上交的内容-1"><a href="#需要上交的内容-1" class="headerlink" title="需要上交的内容"></a>需要上交的内容</h3><p>您需要上交完整的客户端代码和屏幕截图，以验证您的ping程序是否按需求运行。</p><h3 id="可选练习-1"><a href="#可选练习-1" class="headerlink" title="可选练习"></a>可选练习</h3><ol><li>目前，程序计算每个数据包的往返时间（RTT），并单独打印出来。请按照标准ping程序的模式修改。您需要在客户端每次ping后显示最小，最大和平均RTT。另外，还需计算丢包率（百分比）。</li><li>UDP Ping的另一个类似的应用是UDP Heartbeat。心跳可用于检查应用程序是否已启动并运行，并报告单向丢包。客户端在UDP数据包中将一个序列号和当前时间戳发送给正在监听客户端心跳的服务器。服务器收到数据包后，计算时差，报告丢包（若发生）。如果心跳数据包在指定的一段时间内丢失，我们可以假设客户端应用程序已经停止。实现UDP Heartbeat（客户端和服务器端）。您需要修改给定的UDPPingerServer.py和您自己的UDP ping客户端。</li></ol><p><strong>以上内容来自《计算机网络：自顶向下方法》官方文档，与我的作业有部分不同，详见pdf。</strong></p><p><strong>个人实验报告</strong></p><embed src="./Socket.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计网作业：套接字编程实验&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——一阶运动学与静力学</title>
    <link href="http://enderfga.cn/2022/03/30/robot4/"/>
    <id>http://enderfga.cn/2022/03/30/robot4/</id>
    <published>2022-03-29T16:34:07.000Z</published>
    <updated>2022-04-21T05:31:49.906Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/gVyodA.jpg" alt="1648571793860.png"></p><h1 id="智能机器人技术——一阶运动学与静力学"><a href="#智能机器人技术——一阶运动学与静力学" class="headerlink" title="智能机器人技术——一阶运动学与静力学"></a>智能机器人技术——一阶运动学与静力学</h1><p>一、计算/解答题, 请写出解题过程 (30 分)。</p><ol><li>如下图所示有一处于初始位形的 RRP 机器人 (即讲义例 3 ), 求 (10 分):</li></ol><p>a) 写出各关节相对空间坐标系 ${s}$ 的旋量坐标。求解当 $\theta=\left(90^{\circ}, 90^{\circ}, 1\right)$ 时的正向运动学; 手绘此时的机器人, 标注 ${s}$ 系和 ${b}$ 系, 求解此时的空间雅克比 $J_{s}$;</p><p>b) 写出各关节相对末端坐标系 ${b}$ 的旋量坐标。求解当 $\theta=\left(90^{\circ}, 90^{\circ}, 1\right)$ 时的正向运动学, 确认与 a) 中结果相同; 求解此时的物体雅克比 $J_{b}$ 。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002641939.png" alt="image-20220330002641939"></p><p>a)</p><p>此时的机器人如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002652483.png" alt="image-20220330002652483"></p><p>初始位形<strong>M</strong>：</p><script type="math/tex; mode=display">M=\left[\begin{array}{cccc}-1 & 0 & 0 & 0  \\0 & 0 & 1 & 3  \\0 & 1 & 0 & 2 \\0 & 0 & 0 & 1\end{array}\right]</script><p>相对空间坐标系 ${s}$ 的旋量坐标为：</p><script type="math/tex; mode=display">\mathcal{S}_{i}：~\begin{array}{|c||c|c|}\hline i & \omega_{i}  & v_{i} \\\hline \hline 1 & (0,0,1) & (0, 0,0) \\\hline 2 & (1,0,0) & (0, 2,0) \\\hline 3 & (0,0,0)  & (0, 1,0) \\\hline\end{array}\\</script><p>故当$\theta=\left(90^{\circ}, 90^{\circ}, 1\right)$ 时的正向运动学<strong>PoE</strong>与空间雅克比 $J_{s}$：</p><script type="math/tex; mode=display">T=\left[\begin{array}{cccc}0 & 0 & -1 & -3 \\-1 & 0 & 0 & 0\\0 & 1 & 0 & 2\\0 & 0 & 0 & 1\\\end{array}\right]\\J_{s}(\theta)=\left[\begin{array}{ccc}0 & 0 & 0 \\0 & 1 & 0 \\1 & 0 & 0 \\0 & -2 & 0 \\0 & 0 & 0 \\0 & 0 & 1\end{array}\right]</script><p>使用到的函数如下：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">FKinSpace</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> Slist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>T <span class="token operator">=</span> M<span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token function">size</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">1</span>    T <span class="token operator">=</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> T<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> Js <span class="token operator">=</span> <span class="token function">JacobianSpace</span><span class="token punctuation">(</span>Slist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>Js <span class="token operator">=</span> Slist<span class="token punctuation">;</span>T <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">:</span> <span class="token function">length</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span>    T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Js</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">Adjoint</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>b)</p><p>初始位形<strong>M</strong>：</p><script type="math/tex; mode=display">M=\left[\begin{array}{cccc}-1 & 0 & 0 & 0  \\0 & 0 & 1 & 3  \\0 & 1 & 0 & 2 \\0 & 0 & 0 & 1\end{array}\right]</script><p>相对空间坐标系 ${b}$ 的旋量坐标为：</p><script type="math/tex; mode=display">\mathcal{B}_{i}：~\begin{array}{|c||c|c|}\hline i & \omega_{i}  & v_{i} \\\hline \hline 1 & (0,1,0) & (3, 0,0) \\\hline 2 & (-1,0,0) & (0, 3,0) \\\hline 3 & (0,0,0)  & (0, 0,1) \\\hline\end{array}\\</script><p>故当$\theta=\left(90^{\circ}, 90^{\circ}, 1\right)$ 时的正向运动学<strong>PoE</strong>与物体雅克比 $J_{b}$：</p><script type="math/tex; mode=display">T=\left[\begin{array}{cccc}0 & 0 & -1 & -3 \\-1 & 0 & 0 & 0\\0 & 1 & 0 & 2\\0 & 0 & 0 & 1\\\end{array}\right]\\(与a中结果相同)\\J_{b}(\theta)=\left[\begin{array}{ccc}0 & -1 & 0 \\0 & 0 & 0 \\1 & 0 & 0 \\0 & 0 & 0 \\0 & 4 & 0 \\0 & 0 & 1\end{array}\right]</script><p>使用到的函数如下：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">FKinBody</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> Blist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>T <span class="token operator">=</span> M<span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token function">size</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span>    T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> Jb <span class="token operator">=</span> <span class="token function">JacobianBody</span><span class="token punctuation">(</span>Blist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>Jb <span class="token operator">=</span> Blist<span class="token punctuation">;</span>T <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token function">length</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">1</span>       T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> <span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Jb</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">Adjoint</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ol><li>如下图所示有一处于初始位形的 RRRP 空间开链机器人, $p$ 为${b}$ 系原点相对于 ${s}$ 系的坐标, 求 (10 分):</li></ol><p>a) 试求当 $\theta=(0,0, \pi / 2, L)$ 时的物体雅克比 $J_{b}(\theta)$;<br>b) 试求当 $\theta=(0,0, \pi / 2, L)$ 且 $\dot{\theta}=(1,1,1,1)$ 时的 $\dot{p}$。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002705450.png" alt="image-20220330002705450"></p><p>a)</p><p>相对空间坐标系 ${b}$ 的旋量坐标为：</p><script type="math/tex; mode=display">\mathcal{B}_{i}：~\begin{array}{|c||c|c|}\hline i & \omega_{i}  & v_{i} \\\hline \hline 1 & (0,0,1) & (-L, 0,0) \\\hline 2 & (1,0,0) & (0, 0,L) \\\hline 3 & (0,0,1)  & (0, 0,0) \\\hline 4 & (0,0,0)  & (0, 1,0) \\\hline\end{array}\\</script><p>使用JacobianBody(Blist, thetalist)计算得，当 $\theta=(0,0, \pi / 2, L)$ 时的物体雅克比 $J_{b}(\theta)$：</p><script type="math/tex; mode=display">J_{b}(\theta)=\left[\begin{array}{cccC}0 & 0 & 0 &0\\0 & -1 & 0 &0\\1 & 0 & 1 &0\\-L & 0 & -L&0 \\L & 0 & 0 &1\\0 & L & 0&0\end{array}\right]</script><p>b)</p><p>当 $\dot{\theta}=(1,1,1,1)$时：</p><script type="math/tex; mode=display">\mathcal{V}_{b}=J_{b}(\theta) \dot{\theta}=\left[\begin{array}{c}\omega_{b} \\v_{b}\end{array}\right] =\left[\begin{array}{c}0\\-1\\2\\-2L\\L+1\\L\end{array}\right]\\\because R_{s b}=\left[\begin{array}{rrc}0 & -1 & 0 \\1 & 0 & 0 \\0 & 0 & 1\end{array}\right] \\\therefore\dot{p}=R_{s b} v_{b}=\left[\begin{array}{c}-L-1 \\-2 L \\L\end{array}\right]</script><ol><li>如下图所示有一处于初始位形的 PRPRRR 空间开链机器人, 此时基坐标系原点与末端坐标系原点之间距离为 $L$, 求 (10 分):</li></ol><p>a) 空间雅克比 $J_{S}$ 的前三列;</p><p>b) 物体雅克比 $J_{b}$ 的后两列;</p><p>c) 初始位形时的 $J_{S}(0)$;</p><p>d) 初始位形时, 若在末端坐标系的 $-\hat{z}_{b}$ 方向产生 $100 \mathrm{~N}$ 的力, 需要关节提供多少力或力矩?<br><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002722057.png" alt="image-20220330002722057"></p><p>a)</p><p>空间雅克比 $J_{S}$ 的前三列：</p><script type="math/tex; mode=display">\begin{aligned}&\mathcal{V}_{s 1}(\theta): \quad \omega_{s 1}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 1}=\left[\begin{array}{l}0 \\0 \\1\end{array}\right] \\&\mathcal{V}_{s 2}(\theta): \quad \omega_{s 2}=\left[\begin{array}{l}0 \\0 \\1\end{array}\right], q_{2}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 2}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right] \\&\mathcal{V}_{s 3}(\theta): \quad \omega_{s 3}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 3}=e^{\hat{z} \theta_{2}}\left[\begin{array}{l}0 \\1 \\0\end{array}\right]=\left[\begin{array}{c}-\sin \theta_{2} \\\cos \theta_{2} \\0\end{array}\right]\end{aligned}</script><p>b)</p><p>物体雅克比 $J_{b}$ 的后两列：</p><script type="math/tex; mode=display">\begin{aligned}&\mathcal{V}_{b 6}(\theta): \quad \omega_{b 6}=\left[\begin{array}{l}1 \\0 \\0\end{array}\right], q_{6}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{b 6}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right] \\&\mathcal{V}_{b 5}(\theta): \quad \omega_{b 5}=e^{\hat{x}\left(-\theta_{6}\right)}\left[\begin{array}{l}0 \\0 \\1\end{array}\right]=\left[\begin{array}{c}0 \\\sin \theta_{6} \\\cos \theta_{6}\end{array}\right], q_{5}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{b 5}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right]\end{aligned}</script><p>c)</p><p>初始位形时θ=0，故$ J_{S}(0)$：</p><script type="math/tex; mode=display">\because \mathcal{S}_{i}：~\begin{array}{|c||c|c|}\hline i & \omega_{i}  & v_{i} \\\hline \hline 1 & (0,0,0) & (0, 0,1) \\\hline 2 & (0,0,1) & (0,0,0) \\\hline 3 & (0,0,0)  & (0, 1,0) \\\hline 4 & (0,1,0) & (0, 0,0) \\\hline 5 & (0,0,1)  & (L, 0,0) \\\hline 6 & (1,0,0) & (0, 0,-L) \\\hline\end{array}\\\therefore J_{s}(0)=\left[\begin{array}{cccccc}0 & 0 & 0 & 0 & 0 & 1 \\0 & 0 & 0 & 1 & 0 & 0 \\0 & 1 & 0 & 0 & 1 & 0 \\0 & 0 & 0 & 0 & L & 0 \\0 & 0 & 1 & 0 & 0 & 0 \\1 & 0 & 0 & 0 & 0 & -L\end{array}\right]</script><p>d)</p><script type="math/tex; mode=display">\begin{aligned}&\because r_{s b}=\left[\begin{array}{l}0 \\L \\0\end{array}\right], f_{b}=\left[\begin{array}{c}0 \\0 \\-100\end{array}\right]\\&\therefore\mathcal{F}_{s}=\left[\begin{array}{c}m_{s} \\f_{s}\end{array}\right]=\left[\begin{array}{c}r_{s b} \times f_{b} \\f_{b}\end{array}\right]=\left[\begin{array}{c}-100 L \\0 \\0 \\0 \\0 \\-100\end{array}\right]\\&\therefore \tau=J_{s}^{T}(0) \mathcal{F}_{s}\\&=\left[\begin{array}{cccccc}0 & 0 & 0 & 0 & 0 & 1 \\0 & 0 & 1 & 0 & 0 & 0 \\0 & 0 & 0 & 0 & 1 & 0 \\0 & 1 & 0 & 0 & 0 & 0 \\0 & 0 & 1 & L & 0 & 0 \\1 & 0 & 0 & 0 & 0 & -L\end{array}\right]\left[\begin{array}{c}-100 L \\0 \\0 \\0 \\0 \\-100\end{array}\right]=\left[\begin{array}{c}-100 \\0 \\0 \\0 \\0 \\0\end{array}\right]\end{aligned}</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>基于强化学习的无人机自主导航</title>
    <link href="http://enderfga.cn/2022/03/28/UAV/"/>
    <id>http://enderfga.cn/2022/03/28/UAV/</id>
    <published>2022-03-28T15:54:39.786Z</published>
    <updated>2022-04-21T05:32:03.088Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>无人系统导论课程设计报告</p><span id="more"></span><embed src="./UAV.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;无人系统导论课程设计报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="无人系统" scheme="http://enderfga.cn/tags/%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Visual Synthesis Pre-training for NUWA</title>
    <link href="http://enderfga.cn/2022/03/28/NUWA/"/>
    <id>http://enderfga.cn/2022/03/28/NUWA/</id>
    <published>2022-03-28T15:54:39.753Z</published>
    <updated>2022-04-21T05:30:50.883Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>基于深度生成模型的多模态视觉合成</p><span id="more"></span><embed src="./NUWA.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;基于深度生成模型的多模态视觉合成&lt;/p&gt;</summary>
    
    
    
    
    <category term="人工智能" scheme="http://enderfga.cn/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>深度学习在新冠肺炎辅助诊断中的应用</title>
    <link href="http://enderfga.cn/2022/03/28/AI/"/>
    <id>http://enderfga.cn/2022/03/28/AI/</id>
    <published>2022-03-28T15:54:39.714Z</published>
    <updated>2022-04-21T05:29:25.505Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>综述论文</p><span id="more"></span><embed src="./COVID-19.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;综述论文&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器&amp;深度学习代码速查表</title>
    <link href="http://enderfga.cn/2022/03/24/graph/"/>
    <id>http://enderfga.cn/2022/03/24/graph/</id>
    <published>2022-03-24T14:33:47.000Z</published>
    <updated>2022-04-21T05:29:46.509Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>搬运自github.com/OUCMachineLearning/OUCML</p><span id="more"></span><h1 id="机器-amp-深度学习代码速查表"><a href="#机器-amp-深度学习代码速查表" class="headerlink" title="机器&amp;深度学习代码速查表"></a>机器&amp;深度学习代码速查表</h1><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220324225648930.png" alt="image-20220324225648930"><br><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/%E7%BD%91%E7%BB%9C.png" alt="网络"></p><h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/liner.jpg" alt="liner"></p><h3 id="python基础"><a href="#python基础" class="headerlink" title="python基础"></a>python基础</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sci.jpg" alt="sci"></p><h3 id="scipy科学计算"><a href="#scipy科学计算" class="headerlink" title="scipy科学计算"></a>scipy科学计算</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sci.png" alt="sci"></p><h3 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/spark.jpeg" alt="spark"></p><h2 id="数据保存及可视化"><a href="#数据保存及可视化" class="headerlink" title="数据保存及可视化"></a>数据保存及可视化</h2><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/np.png" alt="np"></p><h3 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/pd.png" alt="pd"><br><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/df.jpeg" alt="df"><br><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/df2.jpeg" alt="df2"></p><h3 id="bokeh"><a href="#bokeh" class="headerlink" title="bokeh"></a>bokeh</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/bokeh.jpg" alt="bokeh"></p><h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><h3 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/matplot.png" alt="matplot"></p><h3 id="ggplot"><a href="#ggplot" class="headerlink" title="ggplot"></a>ggplot</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/data%20vis.jpeg" alt="data vis"></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/gg.jpeg" alt="gg"></p><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><h3 id="sklearn"><a href="#sklearn" class="headerlink" title="sklearn"></a>sklearn</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sk.jpg" alt="sk"></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/scikit.png" alt="scikit"></p><h3 id="keras"><a href="#keras" class="headerlink" title="keras"></a>keras</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/keras.jpeg" alt="keras"></p><h3 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/TF.png" alt="TF"></p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/datastruct.png" alt="datastruct"></p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/O.png" alt="O"></p><h3 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h3><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sort.png" alt="sort"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;搬运自github.com/OUCMachineLearning/OUCML&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——正向运动学</title>
    <link href="http://enderfga.cn/2022/03/24/robot3/"/>
    <id>http://enderfga.cn/2022/03/24/robot3/</id>
    <published>2022-03-24T14:33:47.000Z</published>
    <updated>2022-04-21T05:31:44.411Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220324223524468.png" alt="image-20220324223524468"></p><h1 id="智能机器人技术——正向运动学"><a href="#智能机器人技术——正向运动学" class="headerlink" title="智能机器人技术——正向运动学"></a>智能机器人技术——正向运动学</h1><ol><li>如下图所示有一处于初始位形的 PRRRRR 空间开链机器人, 试确定末端初始位形 $M$ 、在 ${0}$ 系描述的螺旋轴 Si 、$ 在 ${b} 系描述的螺旋轴 Bi （如讲义那样列表即可)。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164358687.png" alt="image-20220323164358687"></p><p><strong>解得：</strong></p><p>相对基坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M</script><p>相对末端坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{B}_{n}\right] \theta_{n}}</script><p>末端初始位形 $M$：</p><script type="math/tex; mode=display">\left[\begin{array}{cccc}1 & 0 & 0 & 0 \\0 & 1 & 0 & L_1+L_2+L_3+L_4 \\0 & 0 & 1 & h \\0 & 0 & 0 & 1\end{array}\right]</script><p>在 ${0}$ 系描述的螺旋轴 $\mathcal{S}_{i} $：</p><script type="math/tex; mode=display">[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (0,0,0) & NULL & (0, 1,0) \\\hline 2 & (0,0,1) & (0, L_1,0)& (L_1, 0,0) \\\hline 3 & (-1,0,0) & (0, L_1,h)& (0, -h,L_1) \\\hline 4 & (-1,0,0) & (0,L_1+L_2,h)& (0, -h,L_1+L_2) \\\hline 5 & (-1,0,0) & (0,L_1+L_2+L_3,h)& (0, -h,L_1+L_2+L_3) \\\hline 6 & (0,1,0) & (0,0,h) & (-h, 0,1)\\\hline\end{array}</script><p>在 ${b}$ 系描述的螺旋轴 $\mathcal{B}_{i}$：</p><script type="math/tex; mode=display">[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (0,0,0) & NULL & (0, 1,0) \\\hline 2 & (0,0,1) & (0, -L_2-L_3-L_4,0)& (-L_2-L_3-L_4, 0,0) \\\hline 3 & (-1,0,0) & (0, -L_2-L_3-L_4,0)& (0, 0,-L_2-L_3-L_4) \\\hline 4 & (-1,0,0) & (0,-L_3-L_4,0)& (0, 0,-L_3-L_4) \\\hline 5 & (-1,0,0) & (0,-L_4,0)& (0, 0,-L_4) \\\hline 6 & (0,1,0) & (0,0,0) & (0, 0,0)\\\hline\end{array}</script><ol><li><p>如下图所示有一处于初始位形的 RRRRPR 空间开链机器人, 试确定末端初始位形 $M$ 、在 ${0}$ 系描述的螺旋轴 Si 、$ 在 ${b} 系描述的螺旋轴 Bi （如讲义那样列表即可)。<br><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164443717.png" alt="image-20220323164443717"></p><p><strong>解得：</strong></p></li></ol><p>相对基坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M</script><p>相对末端坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{B}_{n}\right] \theta_{n}}</script><p>末端初始位形 $M$：</p><script type="math/tex; mode=display">\left[\begin{array}{cccc}1 & 0 & 0 & L_1 \\0 & 1 & 0 & L_3+L_4 \\0 & 0 & 1 & -L_5-L_6 \\0 & 0 & 0 & 1\end{array}\right]</script><p>在 ${0}$ 系描述的螺旋轴 $\mathcal{S}_{i} $：</p><script type="math/tex; mode=display">[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (1,0,0) & (0, 0,0)& (0, 0,0) \\\hline 2 & (0,0,-1) & (L_1,0,0)& (0, L_1,0) \\\hline 3 & (0,1,0) & (L_1,0,L_2)& (-L_2, 0,L_1) \\\hline 4 & (1,0,0) & (0,L_3,0)& (0, 0,-L_3) \\\hline 5 & (0,0,0) & NULL & (0, 1,0)\\\hline 6 & (0,1,0) & (L_1,0,-L_5) & (L_5, 0,-L_1) \\\hline\end{array}</script><p>在 ${b}$ 系描述的螺旋轴 $\mathcal{B}_{i}$：</p><script type="math/tex; mode=display">[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (1,0,0) & (0, -L_3-L_4,L_5+L_6)& (0, L_5+L_6,L_3+L_4) \\\hline 2 & (0,0,-1) & (0, -L_3-L_4,0)& (L_3+L_4, 0,0) \\\hline 3 & (0,1,0) & (0,0,L_2+L_5+L_6)& (-L_2-L_5-L_6, 0,0) \\\hline 4 & (1,0,0) & (0,-L_4,L_5+L_6)& (0, L_5+L_6,L_4) \\\hline 5 & (0,0,0) & NULL & (0, 1,0)\\\hline 6 & (0,1,0) & (0,0,L_6) & (-L_6, 0,0) \\\hline\end{array}</script><ol><li>如下图所示有一处于初始位形的 RRRPRR 空间开链机器人, 试确定末端初始位形 $M$ 、在 ${0}$ 系描述的螺旋轴 Si 、$ 在 ${b} 系描述的螺旋轴 Bi （如讲义那样列表即可)。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164454698.png" alt="image-20220323164454698"></p><p><strong>解得：</strong></p><p>相对基坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M</script><p>相对末端坐标系的$\mathrm{PoE}$ :</p><script type="math/tex; mode=display">T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdots e^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}} e^{\left[\mathcal{B}_{n}\right] \theta_{n}}</script><p>末端初始位形 $M$：</p><script type="math/tex; mode=display">\left[\begin{array}{cccc}-1 & 0 & 0 & 0 \\0 & 1 & 0 & 4 \\0 & 0 & -1 & 1 \\0 & 0 & 0 & 1\end{array}\right]</script><p>在 ${0}$ 系描述的螺旋轴 $\mathcal{S}_{i} $：</p><script type="math/tex; mode=display">[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (0,0,1) & (0, 0,0)& (0, 0,0) \\\hline 2 & (1,0,0) & (0,0,2)& (0, 2,0) \\\hline 3 & (1,0,0) & (0,1,2)& (0, 2,-1) \\\hline 4 & (0,0,0) & NULL & (0, 1,0) \\\hline 5 & (0, \frac{\sqrt{2}}{2} , \frac{\sqrt{2}}{2} ) & (0,3,2) & (\frac{\sqrt{2}}{2}, 0,0)\\\hline 6 & (0,0,-1) & (0,4,0)& (-4, 0,0) \\\hline\end{array}</script><p>在 ${b}$ 系描述的螺旋轴 $\mathcal{B}_{i}$：</p><script type="math/tex; mode=display">[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} & v \\0 & 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow \mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}</script><script type="math/tex; mode=display">\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i & \omega_{i} & q_i & v_{i} \\\hline \hline 1 & (0,0,-1) & (0, -4,0)& (4, 0,0) \\\hline 2 & (-1,0,0) & (0,-4,-1)& (0, 1,-4) \\\hline 3 & (-1,0,0) & (0,-3,-1)& (0, 1,-3) \\\hline 4 & (0,0,0) & NULL & (0, 1,0) \\\hline 5 & (0, \frac{\sqrt{2}}{2} , -\frac{\sqrt{2}}{2} ) & (0,-1,-1) & (\sqrt{2}, 0,0)\\\hline 6 & (0,0,1) & (0,0,0)& (0, 0,0) \\\hline\end{array}</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>数据库原理 Exercises 2</title>
    <link href="http://enderfga.cn/2022/03/23/data2/"/>
    <id>http://enderfga.cn/2022/03/23/data2/</id>
    <published>2022-03-23T15:07:52.000Z</published>
    <updated>2022-04-21T05:29:37.738Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 3</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323230708879.png" alt="image-20220323230708879"></p><h1 id="Database-System-Concepts-Exercises-of-Chapter-3"><a href="#Database-System-Concepts-Exercises-of-Chapter-3" class="headerlink" title="Database System Concepts Exercises of Chapter 3"></a>Database System Concepts Exercises of Chapter 3</h1><p><strong>Exercises 3.9</strong> Consider the employee database of Figure $3.20$, where the primary keys are underlined. Give an expression in SQL for each of the following queries.</p><p>a. Find the names and cities of residence of all employees who work for “First Bank Corporation”.</p><p>b. Find the names, street addresses, and cities of residence of all employees who work for “First Bank Corporation” and earn more than $$ 10,000$.</p><p>c. Find all employees in the database who do not work for “First Bank Corporation”.</p><p>d. Find all employees in the database who earn more than each employee of “Small Bank Corporation”.</p><p>e. Assume that the companies may be located in several cities. Find all companies located in every city in which “Small Bank Corporation” is located.</p><p>f. Find the company that has the most employees.</p><p>g. Find those companies whose employees earn a higher salary, on average, than the average salary at “First Bank Corporation”.</p><script type="math/tex; mode=display">employee (\underline{employee\_name}, street, city)\\works (\underline{employee\_name}, company\_name, salary)\\company (\underline{company\_name}, city)\\manages ( \underline{ employee\_name, } manager\_name )\\Figure~~3.20~~Employee~~database~~for~~Exercises~~3.9</script><p><strong>My answer：</strong></p><p>a.</p><p><strong>select</strong> e.employee_name, city<br><strong>from</strong> employee <strong>as</strong> e, works <strong>as</strong> w<br><strong>where</strong> w.company_name $=$ ‘First Bank Corporation’ <strong>and</strong> w.employee_name $=$ e.employee_name</p><p>b.</p><p><strong>select</strong> <em><br><strong>from</strong> employee<br><strong>where</strong> employee_name <strong>in</strong><br>(<strong>select</strong> employee_name<br><strong>from</strong> works<br><strong>where</strong> company_name = ‘First Bank Corporation’ <em>*and</em></em> salary $&gt;10000$ )</p><p>c.</p><p><strong>select</strong> employee_name<br><strong>from</strong> works<br><strong>where</strong> company_name $\neq$ ‘First Bank Corporation’</p><p>d.</p><p><strong>select</strong> employee_name<br><strong>from</strong> works<br><strong>where</strong> salary $&gt;$ <strong>all</strong><br>(<strong>select</strong> salary<br><strong>from</strong> works<br><strong>where</strong> company_name $=$ ‘Small Bank Corporation’)</p><p>e.</p><p><strong>select</strong> S.company_name<br><strong>from</strong> company <strong>as</strong> $S$<br><strong>where</strong> <strong>not exists</strong> ((<strong>select</strong> city<br><strong>from</strong> company<br><strong>where</strong> company_name $=$ ‘Small Bank Corporation’)<br><strong>except</strong><br>(<strong>select</strong> city<br><strong>from</strong> company <strong>as</strong> $T$<br><strong>where</strong> S.company_name $=$ T.company_name ) )</p><p>f.</p><p><strong>select</strong> company_name<br><strong>from</strong> works<br><strong>group by</strong> company_name<br><strong>having count</strong> (<strong>distinct</strong> employee_name) $&gt;=$ <strong>all</strong><br>(<strong>select</strong> <strong>count</strong> (<strong>distinct</strong> employee_name)<br><strong>from</strong> works<br><strong>group by</strong> company_name)</p><p>g.</p><p><strong>select</strong> company_name<br><strong>from</strong> works<br><strong>group by</strong> company_name<br><strong>having</strong> <strong>avg</strong> (salary) $&gt;$ (<strong>select</strong> <strong>avg</strong> (salary)<br><strong>from</strong> works<br><strong>where</strong> company_name $=$ ‘First Bank Corporation’)</p><p><strong>Exercises 3.8</strong> Consider the bank database of Figure $3.19$, where the primary keys are underlined. Construct the following SQL queries for this relational database.</p><p>a. Find all customers of the bank who have an account but not a loan.</p><p>b. Find the names of all customers who live on the same street and in the same city as “Smith”.</p><p>c. Find the names of all branches with customers who have an account in the bank and who live in “Harrison”.</p><script type="math/tex; mode=display">branch(\underline{branch\_name}, branch\_city, assets)\\customer (\underline{customer\_name}, customer\_street, customer\_city)\\ loan (\underline{loan\_numbe}r, branch\_name, amount)\\borrower (\underline{customer\_name}, \underline{loan\_number})\\account (\underline{account\_number}, branch\_name, balance)\\depositor (\underline{customer\_name}, \underline{account\_number})\\Figure~~3.19~~Banking~~database~~for~~Exercises~~3.8~~and~~3.15</script><p><strong>My answer:</strong></p><p>a.</p><p><strong>select</strong> customer_name<br><strong>from</strong> depositor<br><strong>except</strong><br>(<strong>select</strong> customer_name<br><strong>from</strong> borrower)</p><p>b.</p><p><strong>select</strong> F.customer_name<br><strong>from</strong> customer <strong>as</strong> $F$ join customer <strong>as</strong> $S$ using(customer_street, customer_city)<br><strong>where</strong> S.customer_name $=$ ‘Smith’</p><p>c.</p><p><strong>select</strong> <strong>distinct</strong> branch_name<br><strong>from</strong> account <strong>natural join</strong> depositor <strong>natural join</strong> customer<br><strong>where</strong> customer_city = ‘Harrison’</p><p><strong>Exercises 3.15</strong> Consider the bank database of Figure 3.19, where the primary keys are underlined. Construct the following SQL queries for this relational database.<br>a. Find all customers who have an account at all the branches located in “Brooklyn”.<br>b. Find out the total sum of all loan amounts in the bank.<br>c. Find the names of all branches that have assets greater than those of at least one branch located in “Brooklyn”.</p><p><strong>My answer:</strong></p><p>a.</p><p><strong>select</strong> <strong>distinct</strong> S.customer_name</p><p><strong>from</strong> depositor <strong>as</strong> S</p><p><strong>where</strong> <strong>not exists(</strong></p><p>(<strong>select</strong> branch_name</p><p><strong>from</strong> branch</p><p><strong>where</strong> branch_city = ‘Brooklyn’)</p><p><strong>except</strong></p><p>(<strong>select</strong> R.branch_name</p><p><strong>from</strong> depositor <strong>as</strong> T, account <strong>as</strong> R</p><p><strong>where</strong> T.account_number = R.account_number</p><p><strong>and</strong> S.customer_name = T.customer_name))</p><p>b.</p><p><strong>select</strong> <strong>sum</strong>(amount) <strong>as</strong> sum_loan</p><p><strong>from</strong> loan</p><p>c.</p><p><strong>select</strong> branch_name</p><p><strong>from</strong> branch</p><p><strong>where</strong> assets ＞<strong>some</strong></p><p>(<strong>select</strong> assets</p><p><strong>from</strong> branch</p><p><strong>where</strong> branch_city = ‘Brooklyn’)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Database System Concepts Exercises of Chapter 3&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://enderfga.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——刚体运动</title>
    <link href="http://enderfga.cn/2022/03/21/robot2/"/>
    <id>http://enderfga.cn/2022/03/21/robot2/</id>
    <published>2022-03-21T07:04:45.000Z</published>
    <updated>2022-04-21T05:31:39.948Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/A2.jpg" alt="image-20220321151047649"></p><h1 id="智能机器人技术第三章——刚体运动"><a href="#智能机器人技术第三章——刚体运动" class="headerlink" title="智能机器人技术第三章——刚体运动"></a>智能机器人技术第三章——刚体运动</h1><ol><li><script type="math/tex; mode=display">已知一固定的空间坐标系 \{s\} 及其 \hat{x}_{s} 、 \hat{y}_{s} 、 \hat{z}_{s}轴坐标, 坐标系 \{a\} 的 \hat{x}_{a}轴沿 (0,0,1) 方向,\\ \hat{y}_{a} 轴沿 (-1,0,0) 方向; 坐标系 \{b\} 的 \hat{x}_{b} 轴沿 (1,0,0) 方向, \hat{y}_{b} 轴沿 (0,0,-1)方向。</script></li></ol><p><strong>a)</strong> 手绘 3 个坐标系, 注意画在不同位置以便区分。</p><script type="math/tex; mode=display">由右手定则可知，坐标系 \{a\} 的 \hat{z}_{a} 轴沿 (0,-1,0) 方向，坐标系 \{b\} 的 \hat{z}_{b} 轴沿 (0,1,0) 方向。结果如图所示：</script><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220320155656111.png" alt="image-20220320155656111"></p><p><strong>b)</strong> </p><script type="math/tex; mode=display">计算旋转矩阵 R_{s a} 和 R_{s b}</script><p> 。</p><script type="math/tex; mode=display">\begin{aligned}R_{sa} &=\left[\begin{array}{lll}0 & -1 & 0 \\0 & 0 & -1 \\1 & 0 & 0\end{array}\right] \\R_{sb} &=\left[\begin{array}{ccc}1 & 0 & 0 \\0 & 0 & 1 \\0 & -1 & 0\end{array}\right]\end{aligned}</script><p><strong>c)</strong> </p><script type="math/tex; mode=display">已知 R_{s b}, 在不使用逆矩阵的情况下计算 R_{s b}^{-1}, 并验证坐标系画的是否正确。</script><p>由旋转矩阵的性质得$R^{-1}=R^T$</p><script type="math/tex; mode=display">\begin{aligned}R_{sb}^{-1}=R^T_{sb} &=\left[\begin{array}{ccc}1 & 0 & 0 \\0 & 0 & -1 \\0 & 1 & 0\end{array}\right]\end{aligned}</script><p>可知坐标系绘画正确。</p><p><strong>d)</strong> </p><script type="math/tex; mode=display">已知 R_{s a} 和 R_{s b}, 计算 R_{a b}, 并验证坐标系画的是否正确。</script><script type="math/tex; mode=display">\begin{aligned}R_{as}=R_{sa}^{-1}=R^T_{sa} &=\left[\begin{array}{ccc}0 & 0 & 1 \\-1 & 0 & 0 \\0 & -1 & 0\end{array}\right]\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}R_{ab}=R_{as}R_{sb} &=\left[\begin{array}{ccc}0 & -1 & 0 \\-1 & 0 & 0 \\0 & 0 & -1\end{array}\right]\end{aligned}</script><p>可知坐标系绘画正确。</p><p><strong>e)</strong></p><script type="math/tex; mode=display">将 R=R_{s b} 作为变换算子, 表示绕 \hat{x} 轴转动 -90^{\circ} 。计算 R_{1}=R_{s a} R 与 R_{2}=R R_{s a}, 并回答新姿态 R_{1} 与 R_{2} 分别对应的是 R_{s a} 绕哪个坐标系的 \hat{x} 轴转动得到的结果?</script><script type="math/tex; mode=display">\begin{aligned}R_{1}=R_{sa}R &=\left[\begin{array}{ccc}0 & 0 & -1 \\0 & 1 & 0 \\1 & 0 & 0\end{array}\right]\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}R_{2}=RR_{sa} &=\left[\begin{array}{ccc}0 & -1 & 0 \\1 & 0 & 0 \\0 & 0 & 1\end{array}\right]\end{aligned}</script><script type="math/tex; mode=display">R_1表示绕坐标系 \{a\} 的 \hat{x}_{a} 轴，R_2表示绕坐标系 \{s\} 的 \hat{x}_{s} 轴。</script><p><strong>f)</strong> </p><script type="math/tex; mode=display">利用 R_{s b} 将点 p_{b}=(1,2,3) 从 \{b\} 系变换到 \{s\} 系。</script><script type="math/tex; mode=display">p_{s}=R_{sb}p_{b}=(1,3,-2)</script><p><strong>g)</strong> </p><script type="math/tex; mode=display">已知 \{s\} 系中一点 p_{s}=(1,2,3), 计算 p^{\prime}=R_{s b} p_{s} 和 p^{\prime \prime}=R_{s b}^{T} p_{s} 。每一推导过程均可以解释为坐标变换 (无须移动点的位置) 或移动点的位置 (无须改变坐标系)。</script><script type="math/tex; mode=display">p^{\prime}=R_{s b} p_{s}=(1,3,-2)：其几何意义为移动点的位置，将向量p_s绕 \hat{x} 轴转动 -90^{\circ}  (无须改变坐标系)。</script><script type="math/tex; mode=display">p^{\prime \prime}=R_{s b}^{T} p_{s}=(1,-3,2)：其几何意义为坐标变换，将 \{s\} 系中一点 p_{s}变换到 \{b\} 系 (无须移动点的位置) 。</script><p><strong>h)</strong>已知 ${s}$ 系中的角速度 $\omega_{s}=(3,2,1)$, 计算其在 ${a}$ 系中的表示。</p><script type="math/tex; mode=display">\omega_{a}=R_{as}\omega_s=(1,-3,-2)</script><p><strong>i)</strong> 计算 $R_{s a}$ 的矩阵对数 $[\widehat{\omega}] \theta$, 并提取其中的元素: 单位角速度 $\widehat{\omega}$ 和转动量 $\theta$ (可以利用编程手段)。</p><p>使用到的函数：</p><p>MatrixLog3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> so3mat <span class="token operator">=</span> <span class="token function">MatrixLog3</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span>acosinput <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">trace</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token keyword">if</span> acosinput <span class="token operator">>=</span> <span class="token number">1</span>    so3mat <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">elseif</span> acosinput <span class="token operator">&lt;=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">if</span> <span class="token operator">~</span><span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">elseif</span> <span class="token operator">~</span><span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">else</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">end</span>    so3mat <span class="token operator">=</span> <span class="token function">VecToso3</span><span class="token punctuation">(</span><span class="token keyword">pi</span> <span class="token operator">*</span> omg<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">else</span>theta <span class="token operator">=</span> <span class="token function">acos</span><span class="token punctuation">(</span>acosinput<span class="token punctuation">)</span><span class="token punctuation">;</span>       so3mat <span class="token operator">=</span> theta <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>R <span class="token operator">-</span> R<span class="token operator">'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>so3ToVec：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> omg <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span>omg <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>AxisAng3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>expc3<span class="token punctuation">)</span>theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span>expc3<span class="token punctuation">)</span><span class="token punctuation">;</span>omghat <span class="token operator">=</span> expc3 <span class="token operator">/</span> theta<span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><p>解得：</p><script type="math/tex; mode=display">[\widehat{\omega}] \theta = \left[\begin{array}{ccc}0 & -1.2092 & -1.2092 \\1.2092 & 0 & -1.2092 \\1.2092 & 1.2092 & 0\end{array}\right]</script><p>单位角速度 $\widehat{\omega}=(0.5774,-0.5774,0.5774)$ 和转动量 $\theta=2.0944$</p><p><strong>j)</strong> 计算与转动 $\widehat{\omega} \theta=(1,2,0)$ 的指数坐标对应的矩阵指数。</p><p>使用到的函数：</p><p>VecToso3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> so3mat <span class="token operator">=</span> <span class="token function">VecToso3</span><span class="token punctuation">(</span>omg<span class="token punctuation">)</span>so3mat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>MatrixExp3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span>  R <span class="token operator">=</span> <span class="token function">MatrixExp3</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span>omgtheta <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token function">norm</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">)</span>    R <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">;</span>    omgmat <span class="token operator">=</span> so3mat <span class="token operator">/</span> theta<span class="token punctuation">;</span>    R <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">cos</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><script type="math/tex; mode=display">\begin{aligned}R &=\left[\begin{array}{ccc}-0.2938 & 0.6469 & 0.7037 \\0.6469 & 0.6765 & -0.3518 \\-0.7037 & 0.3518 & -0.6173\end{array}\right]\end{aligned}</script><p>2.题干如 1 , 并且 ${a}$ 系原点相对 ${s}$ 系的坐标为 $(3,0,0),{b}$ 系原点相对 ${s}$ 系的坐标为 $(0,2,0)$。</p><p><strong>a)</strong> 手绘 3 个坐标系, 注意它们之间的相对位置关系。</p><p>图中${s}$系的三个坐标轴长度均为单位长度，以此绘得结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220320160304205.png" alt="image-20220320160304205"></p><p><strong>b)</strong> </p><script type="math/tex; mode=display">计算齐次变换矩阵 T_{s a} 和 T_{s b} 。</script><script type="math/tex; mode=display">\because T=\left[\begin{array}{cc}R & p \\0 & 1\end{array}\right]\\\therefore T_{sa}=\left[\begin{array}{cccc}0 & -1 & 0 & 3 \\0 & 0 & -1 & 0 \\1 & 0 & 0 & 0 \\0 & 0 & 0 & 1\end{array}\right]\\T_{sb}=\left[\begin{array}{cccc}1 & 0 & 0 & 0 \\0 & 0 & 1 & 2 \\0 & -1 & 0 & 0 \\0 & 0 & 0 & 1\end{array}\right]</script><p><strong>c)</strong> </p><script type="math/tex; mode=display">已知 T_{s b}, 在不使用逆矩阵的情况下计算 T_{s b}^{-1}, 并验证坐标系画的是否正确。</script><script type="math/tex; mode=display">\because T^{-1}=\left[\begin{array}{cc}R & p \\0 & 1\end{array}\right]^{-1}=\left[\begin{array}{cc}R^{\mathrm{T}} & -R^{\mathrm{T}} p \\0 & 1\end{array}\right]\\\therefore T_{sb}^{-1}=\left[\begin{array}{cccc}1 & 0 & 0 & 0 \\0 & 0 & -1 & 0 \\0 & 1 & 0 & -2 \\0 & 0 & 0 & 1\end{array}\right]</script><p>可知坐标系绘画正确。</p><p><strong>d)</strong> </p><script type="math/tex; mode=display">已知 T_{s a} 和 T_{s b}, 计算 T_{a b}, 并验证坐标系画的是否正确。</script><script type="math/tex; mode=display">\because T_{as}=T_{sa}^{-1}=\left[\begin{array}{cccc}0 & 0 & 1 & 0 \\-1 & 0 & 0 & 3 \\0 & -1 & 0 & 0 \\0 & 0 & 0 & 1\end{array}\right]\\\therefore T_{ab}=T_{as}T_{sb}=\left[\begin{array}{cccc}0 & -1 & 0 & 0 \\-1 & 0 & 0 & 3 \\0 & 0 & -1 & -2 \\0 & 0 & 0 & 1\end{array}\right]</script><p>可知坐标系绘画正确。</p><p><strong>e)</strong> </p><script type="math/tex; mode=display">将 T=T_{s b} 作为变换算子, 表示绕\hat{x}轴转动-90^{\circ} 与沿 \hat{y} 移动 2 个单位。计算T_{1}= T_{s a} T 与 T_{2}=T T_{s a}, 并回答新姿态 T_{1} 与 T_{2} 分别对应的是 T_{s a} 绕哪个坐标系的变换得到的结果?</script><script type="math/tex; mode=display">T_{1}=T_{sa}T=\left[\begin{array}{cccc}0 & 0 & -1 & 1 \\0 & 1 & 0 & 0 \\1 & 0 & 0 & 0 \\0 & 0 & 0 & 1\end{array}\right]，相对 \{a\} 系变换得到的结果，表示绕\hat{x}_{a}轴转动-90^{\circ} 与沿 \hat{x} 移动 2 个单位。</script><script type="math/tex; mode=display">T_{2}=TT_{sa}=\left[\begin{array}{cccc}0 & -1 & 0 & 3 \\1 & 0 & 0 & 2 \\0 & 0 & 1 & 0 \\0 & 0 & 0 & 1\end{array}\right]，相对 \{s\} 系变换得到的结果，表示绕\hat{x}_{s}轴转动-90^{\circ} 与沿 \hat{x} 移动 3 个单位，沿 \hat{y} 移动 2 个单位。</script><p><strong>f)</strong> </p><script type="math/tex; mode=display">利用 T_{s b} 将点 p_{b}=(1,2,3) 从 \{b\} 系变换到 \{s\} 系。</script><script type="math/tex; mode=display">p_{s}=T_{sb}p_{b}=(1,5,-2)</script><p><strong>k)</strong> </p><script type="math/tex; mode=display">已知 \{s\} 系中一点 p_{s}=(1,2,3), 计算 p^{\prime}=T_{s b} p_{s} 和 p^{\prime \prime}=T_{s b}^{-1} p_{s} 。每一推导过程均可以解释为坐标变换 (无须移动点的位置) 或移动点的位置 (无须改变坐标系)。</script><script type="math/tex; mode=display">p^{\prime}=T_{s b} p_{s}=(1,5,-2)：其几何意义为移动点的位置；</script><script type="math/tex; mode=display">p^{\prime \prime}=T_{s b}^{-1} p_{s}=(1,-3,0)：其几何意义为坐标变换。</script><p><strong>g)</strong>已知 ${s}$ 系中的旋量 $\mathcal{V}=(3,2,1,-1,-2,-3)$, 计算其在 ${a}$ 系中的表示。</p><script type="math/tex; mode=display">\mathcal{V}_{a}=\left[\begin{array}{c}\omega_{a} \\v_{a}\end{array}\right]=\left[\begin{array}{cc}R^{\mathrm{T}} & 0 \\-R^{\mathrm{T}}[p] & R^{\mathrm{T}}\end{array}\right]\left[\begin{array}{c}\omega_{s} \\v_{s}\end{array}\right]=\left[\mathrm{Ad}_{T_{a s}}\right] \mathcal{V}_{s}\\\because \left[\mathrm{Ad}_{T}\right]=\left[\begin{array}{cc}R & 0 \\{[p] R} & R\end{array}\right] \in \mathbb{R}^{6 \times 6} \\\therefore \mathcal{V}_{a}=(1,-3,-2,-9,1,-1)</script><p><strong>h)</strong> 计算 $T_{s a}$ 的矩阵对数 $[\delta] \theta$, 并提取其中的元素: 单位螺旋轴 $\mathcal{S}$ 和转动量 $\theta$ 。</p><p>使用到的函数：</p><p>MatrixLog6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> expmat <span class="token operator">=</span> <span class="token function">MatrixLog6</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">[</span>R<span class="token punctuation">,</span> p<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">TransToRp</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">;</span>omgmat <span class="token operator">=</span> <span class="token function">MatrixLog3</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">isequal</span><span class="token punctuation">(</span>omgmat<span class="token punctuation">,</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    expmat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">T</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">else</span>    theta <span class="token operator">=</span> <span class="token function">acos</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">trace</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     expmat <span class="token operator">=</span> <span class="token punctuation">[</span>omgmat<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> omgmat <span class="token operator">/</span> <span class="token number">2</span> <span class="token punctuation">...</span>                      <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> theta <span class="token operator">-</span> <span class="token function">cot</span><span class="token punctuation">(</span>theta <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>                        <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat <span class="token operator">/</span> theta<span class="token punctuation">)</span> <span class="token operator">*</span> p<span class="token punctuation">;</span>              <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>se3ToVec：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> V <span class="token operator">=</span> <span class="token function">se3ToVec</span><span class="token punctuation">(</span>se3mat<span class="token punctuation">)</span>V <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>AxisAng6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> <span class="token punctuation">[</span>S<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng6</span><span class="token punctuation">(</span>expc6<span class="token punctuation">)</span>theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span><span class="token function">expc6</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span>    theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span><span class="token function">expc6</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span>S <span class="token operator">=</span> expc6 <span class="token operator">/</span> theta<span class="token punctuation">;</span>    <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>解得：</p><script type="math/tex; mode=display">[\delta] \theta=\left[\begin{array}{cccc}0 & -1.2092 & -1.2092 & 2.2092 \\1.2092 & 0 & -1.2092 & -2.2092 \\1.2092 & 1.2092 & 0 & -1.4184 \\0 & 0 & 0 & 0\end{array}\right]</script><p>单位螺旋轴   $\mathcal{S}=(0.5774,-0.5774,0.5774,1.0548,-1.0548,-0.6772)$ 和转动量 $\theta=2.0944$</p><p><strong>i)</strong> 计算与转动 $\mathcal{S} \theta=(0,1,2,3,0,0)$ 的指数坐标对应的矩阵指数。</p><p>使用到的函数：</p><p>VecTose3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> se3mat <span class="token operator">=</span> <span class="token function">VecTose3</span><span class="token punctuation">(</span>V<span class="token punctuation">)</span>se3mat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">VecToso3</span><span class="token punctuation">(</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>MatrixExp6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span>se3mat<span class="token punctuation">)</span>omgtheta <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token function">norm</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">)</span>    T <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">;</span>    omgmat <span class="token operator">=</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> theta<span class="token punctuation">;</span>     T <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">MatrixExp3</span><span class="token punctuation">(</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">...</span>         <span class="token punctuation">(</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">*</span> theta <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">cos</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token punctuation">...</span>          <span class="token operator">+</span> <span class="token punctuation">(</span>theta <span class="token operator">-</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat<span class="token punctuation">)</span> <span class="token punctuation">...</span>            <span class="token operator">*</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">/</span> theta<span class="token punctuation">;</span>         <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><script type="math/tex; mode=display">\begin{aligned}T &=\left[\begin{array}{cccc}-0.6173 & -0.7037 & 0.3518 & 1.0555 \\0.7037 & -0.2938 & 0.6469 & 1.9407 \\-0.3518 & 0.6469 & 0.6765 & -0.9704 \\0 & 0 & 0 & 1\end{array}\right]\end{aligned}</script><p>3.目前工业机器人领域经常需要定义 4 种坐标系: 参考坐标系 ${a}$, 末端或工具坐标系 ${b}$ 、图像坐标系 ${c}$ 、件坐标系 ${d}$, 如下所示。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314230530164.png" alt="image-20220314230530164"></p><p><strong>a)</strong> </p><script type="math/tex; mode=display">基于图中所给尺寸, 确定 T_{a d} 和 T_{c d} 。</script><script type="math/tex; mode=display">T_{ad}=\left[\begin{array}{cccc}1 & 0 & 0 & -1 \\0 & 1 & 0 & 1 \\0 & 0 & 1 & 0 \\0 & 0 & 0 & 1\end{array}\right]</script><script type="math/tex; mode=display">T_{cd}=\left[\begin{array}{cccc}0 & 1 & 0 & 0 \\1 & 0 & 0 & 0 \\0 & 0 & -1 & 2 \\0 & 0 & 0 & 1\end{array}\right]</script><p><strong>b)</strong> </p><script type="math/tex; mode=display">若T_{bc}=[1~~0~~0~~4；0~~1 ~~0~~0；0~~0~~1~~0；0~~0~~0~~1],求T_{ab}。</script><script type="math/tex; mode=display">T_{ab}=T_{ac}T_{cb}=T_{ad}T_{dc}T_{bc}^{-1}=T_{ad}T_{cd}^{-1}T_{bc}^{-1}\\=\left[\begin{array}{cccc}0 & 1 & 0 & -1 \\1 & 0 & 0 & -3 \\0 & 0 & -1 & 2 \\0 & 0 & 0 & 1\end{array}\right]</script><p><img src="https://cdn.mathpix.com/cropped/2022_03_20_515d600b91de346f2453g-1.jpg?height=1510&amp;width=1069&amp;top_left_y=122&amp;top_left_x=108" alt=""></p><p><img src="https://cdn.mathpix.com/cropped/2022_03_20_515d600b91de346f2453g-2.jpg?height=556&amp;width=999&amp;top_left_y=598&amp;top_left_x=116" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220322133139136.png" alt="image-20220322133139136"></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220322133103015.png" alt="image-20220322133103015"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>数据库原理 Exercises 1</title>
    <link href="http://enderfga.cn/2022/03/17/data1/"/>
    <id>http://enderfga.cn/2022/03/17/data1/</id>
    <published>2022-03-17T15:46:56.000Z</published>
    <updated>2022-04-21T05:29:31.454Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 2</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/photo-1613068687893-5e85b4638b56" alt="black flat screen computer monitor"></p><h1 id="Database-System-Concepts-Exercises-of-Chapter-2"><a href="#Database-System-Concepts-Exercises-of-Chapter-2" class="headerlink" title="Database System Concepts Exercises of Chapter 2"></a>Database System Concepts Exercises of Chapter 2</h1><p><strong>Exercise 2.1</strong> Consider the relational database of Figure 2.14,</p><p>Employee( person_name, street, city)<br>Works (person_name, company_name, salary)<br>Company(company_name, city)<br><strong>Figure 2.14</strong></p><p>What are the appropriate primary keys?</p><p><strong>My answer:</strong></p><p>$employee (\underline{person-name}, street, city)$</p><p>$works (\underline{person-name}, company-name, salary) $</p><p>$company (\underline{company-name}, city)$</p><p><strong>Exercise</strong> <strong>2.7</strong> Consider the relational database of Figure 2.14. Given an expression in the relational algebra to express each of the following queries:</p><p>a.Find the names of all employees who live in city “Miami”</p><p>b.Find the names of all employees whose salary is greater than $100,000.</p><p>c.Find the names of all employees who live in “Miami” and whose salary is greater than $100,000.</p><p><strong>My answer:</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220318132151932.png" alt="image-20220318132151932"></p><p><strong>Exercise</strong> <strong>2.9</strong> Consider the bank database of Figure 2.15.</p><p>branch(branch_name, branch_city, assets)<br>customer(customer_name, customer_street, customer_city)<br>loan(loan_number, branch_name, amount)<br>borrower(customer_name, loan_number)<br>account(account_number, loan_number)<br>depositor(customer_name, account_number)<br><strong>Figure 2.15</strong></p><p>a.  What are the appropriate primary keys?</p><p>b. Given your choice of primary keys, identify appropriate foreign keys. Assume that branch names and customer names uniquely identify branches and customers, but loans and accounts can be associated with more than one customer.</p><p><strong>My answer:</strong></p><p>The primary keys are marked with an $\underline{underline}$, and the foreign keys are marked with a $\overline{overline}$.</p><p>$branch(\underline{branch-name}, branch-city, assets)$</p><p>$customer(\underline{customer-name}, customer-street, customer-city)$</p><p>$loan(\underline{loan-number}, \overline{branch-name}, amount)$</p><p>$borrower(\overline{\underline{customer-name}}, \overline{loan-number})$</p><p>$account(\underline{account-number}, loan-number)$</p><p>$depositor(\overline{\underline{customer-name}}, \overline{account-number})$</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Database System Concepts Exercises of Chapter 2&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://enderfga.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络和因特网</title>
    <link href="http://enderfga.cn/2022/03/14/net1/"/>
    <id>http://enderfga.cn/2022/03/14/net1/</id>
    <published>2022-03-14T14:40:45.000Z</published>
    <updated>2022-04-21T05:30:26.133Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第一章计算机网络和因特网小结</p><span id="more"></span><h2 id="1-简述面向连接和无连接两种服务的特点。"><a href="#1-简述面向连接和无连接两种服务的特点。" class="headerlink" title="1.简述面向连接和无连接两种服务的特点。"></a>1.<strong>简述面向连接和无连接两种服务的特点。</strong></h2><p>面向连接服务：质量可靠，确保从发送方发出的数据最终按顺序完整地交付给接收方。</p><p>无连接服务：质量不可靠，不能对最终交付作任何保证。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220313164646441.png" alt="image-20220313164646441"></p><p><strong>面向连接服务</strong>(connection-oriented)</p><p>面向连接服务具有<strong>可靠的数据传送，流控制，拥塞控制</strong>三个特性。</p><p>特点：</p><p>1、面向连接的数据传输过程必须经过建立连接、连接维护和释放连接的3个过程；</p><p>2、数据传输过程中，各分组不需要携带目的地址。</p><p>面向连接数据传输的收发数据顺序不变，因此传输的可靠性好，但协议复杂，通信效率不高。</p><p><strong>无连接服务</strong>(connectionless)</p><p>两个实体之间的通信<strong>不需要先建立好连接</strong>。是一种不可靠的服务。这种服务常被描述为“尽最大努力交付”(best effort delivery)或“尽力而为”。</p><p>特点：</p><p>1、数据传输过程中，每个分组都携带完整的目的地址，各分组在系统中是独立传送的。因此，无连接中的数据传输过程不需要经过3个过程；</p><p>2、由于无连接发送的不同的分组，可能经历不同路径到目的主机，所以先发送的不一定先到，因此无连接的数据分组传输过程中，目的主机接收的数据分组可能出现乱序、重复与丢失的现象。</p><p>无连接的可靠性不是很好，但因其省去许多保征机制，因此通信协议相对简单，通信效率较高。</p><h2 id="2-什么是多路复用？常分为哪两种类型。"><a href="#2-什么是多路复用？常分为哪两种类型。" class="headerlink" title="2.什么是多路复用？常分为哪两种类型。"></a>2.<strong>什么是多路复用？常分为哪两种类型。</strong></h2><p>多路复用是指在一条传输链路上同时建立多条连接，分别传输数据。</p><p>常分为以下两种类型：</p><p><strong>频分多路复用FDM(frequency-division multiplexing)</strong>：链路的频谱由跨越链路创建的连接所共享，按频率划分若干频段，每个频段专用于一个连接。</p><p><strong>时分多路复用TDM (time-division multiplexing)</strong> ：时间划分为固定区间的帧，每帧再划分为固定数量的时隙，每一个时隙专用于一个连接，用于传输数据。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314223649714.png" alt="image-20220314223649714"></p><h2 id="3-简述电路交换和分组交换特点及工作过程。"><a href="#3-简述电路交换和分组交换特点及工作过程。" class="headerlink" title="3.简述电路交换和分组交换特点及工作过程。"></a>3.<strong>简述电路交换和分组交换特点及工作过程。</strong></h2><p><strong>特点：</strong></p><ol><li><strong>电路交换 (circuit switching)</strong><br>预留端到端资源：端系统之间通信路径上所需要的资源 (缓存，链路带宽)，建立连接；<br>发送方以恒定速率向接收方传送数据。<br>如，电话网络。</li><li><strong>分组交换(packet switching)</strong><br>不需要资源预留；<br>按需使用资源，可能要排队等待，同时有其它分组发送。<br>如，因特网。</li></ol><p><strong>工作过程：</strong></p><ol><li><p>电路交换：</p><p>在两台主机A、B之间创建一条专用的端到端连接，分别占用每条链路中的一条电路；</p><p>该连接获得链路带宽的1/n，进行通信。</p></li><li><p>分组交换：</p><p>源端将报文划分为较小的数据块（分组packet）；</p><p>每个分组通过一系列链路和分组交换机传送，直到目的端</p><p>目的端恢复原报文。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314220812885.png" alt="image-20220314220812885"></p><h2 id="4-什么是协议？分层的服务模型？"><a href="#4-什么是协议？分层的服务模型？" class="headerlink" title="4.什么是协议？分层的服务模型？"></a>4.<strong>什么是协议？分层的服务模型？</strong></h2><p><strong>协议</strong>：控制网络中信息的发送和接收。定义了通信实体之间交换报文的格式和次序，以及在报文传输和/或接收或其他事件所采取的动作。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314223735346.png" alt="image-20220314223735346"></p><p><strong>分层的服务模型</strong>：上层调用下层的服务，下层为上层提供服务。</p><p>通过第n层本身执行某些动作，或再使用其相邻下层（第n-1层）的服务，来完成向其上层（第n+1层）提供的服务。</p><h2 id="5-简述分层的特点和分层后数据的传递过程。"><a href="#5-简述分层的特点和分层后数据的传递过程。" class="headerlink" title="5.简述分层的特点和分层后数据的传递过程。"></a>5.<strong>简述分层的特点和分层后数据的传递过程。</strong></h2><p><strong>分层特点：</strong></p><ul><li>每层功能独立；</li><li>每两个相邻层之间有一逻辑接口，可交换信息；</li><li>上一层建立在下一层基础上，上一层可调用下一层的服务，下一层为上一层提供服务。</li></ul><p><strong>分层后数据的传递过程</strong>：主机（端系统）间数据传送实际上并不是在对等层间直接进行，而是通过相邻层间的传递合作完成。</p><p>发送方：将用户数据由高层向低层逐层传递，每经过一层，加上该层的控制信息，直到最低层（物理层），然后直接通过物理媒体传输到目的方。（逐层封装）</p><p>接收方：将收到的数据由低层向高层逐层传递，每经过一层，去掉该层的控制信息，直到最高层，恢复为用户数据。（逐层解封）</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314222653398.png" alt="image-20220314222653398"></p><h2 id="6-因特网分层模型及各层功能。"><a href="#6-因特网分层模型及各层功能。" class="headerlink" title="6.因特网分层模型及各层功能。"></a>6.<strong>因特网分层模型及各层功能。</strong></h2><p>因特网的协议栈由5个层次组成：物理层、链路层、网络层、运输层和应用层。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314222941459.png" alt="image-20220314222941459"></p><ol><li>应用层：提供各种网络应用。传输应用报文。<br>FTP、 SMTP、 HTTP</li><li>运输层：在应用程序的客户机和服务器之间提供传输应用层报文服务。传输报文段。<br>TCP、 UDP</li><li>网络层：主机和主机之间传输网络层分组（数据报）。<br>IP协议、 选路协议</li><li>链路层： 在邻近单元之间传输数据（帧 ）。<br>PPP、以太网</li><li>物理层：在节点之间传输比特流。<br>传输媒体</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;第一章计算机网络和因特网小结&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——位形空间</title>
    <link href="http://enderfga.cn/2022/03/02/robot1/"/>
    <id>http://enderfga.cn/2022/03/02/robot1/</id>
    <published>2022-03-02T13:41:13.000Z</published>
    <updated>2022-04-21T05:31:34.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220302214614790.png" alt="image-20220302214614790"></p><h1 id="智能机器人技术——位形空间"><a href="#智能机器人技术——位形空间" class="headerlink" title="智能机器人技术——位形空间"></a>智能机器人技术——位形空间</h1><p>一、选择/填空题（10 分）。</p><ol><li>机器人的自由度是 (<strong>D</strong>) ?<br>A. 机器人上点的数量<br>B. 机器人关节数量<br>C. 组成机器人的刚体的数量<br>D. 组成机器人的刚体的数量, 减去刚体间独立约束的数量</li><li>二维平面刚体的自由度为 (<strong>3</strong>) ； 三维空间刚体的自由度为 (<strong>6</strong>) 。</li><li>根据课堂上推算三维空间内刚体自由度的方法, 推算出四维空间中刚体的自由度 (<strong>10</strong>)、有关角度的自由度 (<strong>6</strong>)、有关平移位置的自由度 (<strong>4</strong>)。(如, 三维空间中分别为 $6,3,3$ )</li><li>假设你的手臂（从肩膀到手掌）, 有 7 个自由度。你如同一位服务生一样水平端着餐盘, 防止洒出酒水。你的手臂此时有几个自由度：<strong>5</strong>， 这个任务空间的自由度是：<strong>4</strong>。</li></ol><p>二、简答题, 请写出解题过程 (10 分)。</p><ol><li><p>考虑两个刚体之间的一个关节。每个刚体有 $\mathrm{m}$ 个自由度（二维空间刚体 $m=3$, 三维空间刚体 $m=6$ ), 并且没有任何约束。关节有 $f$ 个自由度（旋转关节 $\mathrm{f}=1$, 球形关节 $\mathrm{f}=3$ 等)。试问, 用这个关节关联两个刚体, 那么引入了多少个约束（一个刚体相对于另一个, 用字母表示）?</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220302212205280.png" alt="image-20220302212205280"></p><p><strong>解：$自由度f+平面约束c=平面自由度3，自由度f＋空间约束c=空间自由度6$</strong></p><p><strong>故$\pmb{c=-f+m}$</strong></p></li><li><p>考虑一个机构包含了 3 个三维空间刚体 (记住, 包括地面, 所以 $\mathrm{N}=4$ ), 和 4 个关节: 1 个转动, 1 个平移, 一个万向, 一个球形。使用 Grubler 公式, 计算机构的自由度。</p><p><strong>解：转动副$f_1=1$，移动副$f_2=1$，万向铰$f_3=2$，球形铰$f_4=3$</strong></p><p><strong>又$\because N=4$，$J=4$，$m=6$</strong></p><p><strong>$\therefore \pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(4-1-4\right)+\left(1+1+2+3\right)=1}$</strong></p></li><li>如下图的 SRS (球形-转动-球形) 机构, 正在抓取一个物体。试问, 当机构紧握物体时 (物体与机构中的机械臂最后一段没有相对运动时), 自由度是多少?</li></ol><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/2022_02_28_40f28045fe8caa2a438eg-1.jpg" alt=""></p><p><strong>解：Spherical Joint即为球形铰$f=3$，共8个；Revolute Joint即为转动副$f=1$，共4个；</strong></p><p><strong>又$\because N=14$，$J=16$，$m=6$</strong></p><p>$\therefore \pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(14-1-16\right)+\left(3\times8+1\times4\right)=10}$</p><ol><li><p>同上题, 如果现在有 $n$ 条这样的机械臂 (题 3 中 $n=4$ ), 机构的自由度是?</p><p><strong>同理：$\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(3n+2-1-4n\right)+\left(3\times2n+1\times n\right)=n+6}$</strong></p></li><li><p>同上题, 假设 $n$ 条机械臂的转动关节, 被替换成了万向关节, 机构的自由度是?</p><p><strong>同理：$\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(3n+2-1-4n\right)+\left(3\times2n+2\times n\right)=2n+6}$</strong></p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>2022’summary</title>
    <link href="http://enderfga.cn/2021/12/31/2022/"/>
    <id>http://enderfga.cn/2021/12/31/2022/</id>
    <published>2021-12-31T13:06:06.000Z</published>
    <updated>2022-04-21T05:29:08.399Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231192304439.png" alt="image-20211231192304439"></p><p>这是2021年发的第一条朋友圈配图，顺手拿来总结吧。</p><span id="more"></span><p>没想到曾经一个因为不怎么使用微信，不怎么看朋友圈而饱受困扰的人会用看朋友圈来回顾自己的一整年。</p><p>毕竟有感而发，这次就不纠结排版美不美观、结构严不严谨了。</p><h1 id="天时人事日相催，冬至阳生春又来"><a href="#天时人事日相催，冬至阳生春又来" class="headerlink" title="天时人事日相催，冬至阳生春又来"></a>天时人事日相催，冬至阳生春又来</h1><p>21的一月初我应该有在努力复习吧，因为一整个学期的怠惰，因为对一个优秀女生的追逐。大学跟高中差别真大，没有人逼我写必刷题了，没有人逼我额外补课了，没有所谓火箭班了。大一上虽然大部分都在20年这个区间，但是给我的21年真是奠定了乱七八糟的基础。</p><p>1月6号那天开始听YOASOBI的歌。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231193810905.png" alt="image-20211231193810905"></p><p>我的“好友”为我做的图，可惜这位好友不再联系了，倒是图里的内容实现了。</p><p>放假回家了，回了一趟华美，可惜看到华美帝国回忆录的共享文档的时候我还是写不出东西来。</p><h1 id="鸿雁长飞光不度，鱼龙潜跃水成文"><a href="#鸿雁长飞光不度，鱼龙潜跃水成文" class="headerlink" title="鸿雁长飞光不度，鱼龙潜跃水成文"></a>鸿雁长飞光不度，鱼龙潜跃水成文</h1><p>在二月终于和大鸟转转转酒吧的兄弟们会师了，22年的美食王国的勇者传说继续辉煌！可能这是目前我唯一期待的年度团建了吧，一群我可以无条件信任的人。</p><p>这个月里跟了好多人出去玩，多年未见的童年好友，帮我很多的同乡师兄，关系超好的高中同学···（词穷了，就这样吧）</p><p>反正过了个年，又开学了！</p><p>甚至不记得为什么留下这段感慨：</p><p>凡事都有定期。天下万物都有定时，生有时，死有时，哭有时，笑有时，寻找有时，放手有时。</p><p>好消息是1204棋牌中心初具雏形，为后来的金碧辉煌作了铺垫。</p><h1 id="空里流霜不觉飞，汀上白沙看不见"><a href="#空里流霜不觉飞，汀上白沙看不见" class="headerlink" title="空里流霜不觉飞，汀上白沙看不见"></a>空里流霜不觉飞，汀上白沙看不见</h1><p>三月里买了我的宝贝surface，那我肯定开始家教了，虽然我天天骂它玩4399都卡，但确实给我带来了极大便利，不管去哪都只带着平板可比背着游戏本的习武之人好多了。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231195659935.png" alt="image-20211231195659935"></p><p>在这个时候参加了大创，虽然可能自己完全没有做出什么东西的能力来，但那个星期还是挺震撼的，原来科研离我并不远。毕竟我也梦想成为拉格多科学院的“疯子”。</p><p>这个月里还参加了几次团建，文体组、智协、微软俱乐部（虽然改名了）···大一参加的每一个社团或组织都让我收获了好多好多，知识也好，朋友也好，不禁感慨，还好我参加了。</p><p>三月十号那天还认识了一个special的人，感谢大物，缘分真奇妙。</p><p>虽然我貌似有很多的朋友，但事实上我是一个很害怕交友的人。害怕我的所作所为会对其他人的人生轨迹造成影响（确实怪中二的）。</p><p>不过好在大部分时候都是正面影响，希望我的朋友毕业后，就业后，10年后，50年后还是我的朋友，在我的轨迹留多点痕迹。</p><h1 id="江水流春去欲尽，江潭落月复西斜"><a href="#江水流春去欲尽，江潭落月复西斜" class="headerlink" title="江水流春去欲尽，江潭落月复西斜"></a>江水流春去欲尽，江潭落月复西斜</h1><p>四月里我开始读诗了！语文老师她看了肯定很惊讶，为什么语文成绩这么差的我居然还会对这些感兴趣，感谢老师的滕王阁序。</p><p>这个月里我应该有好好在写python，matlab，c++和数据结构与算法吧，学基础的编程语言让人充满了成就感。</p><p>这个月最特殊的事应该是认识了another special people，刚好前后差了一个月。</p><p>虽然目前是我生活里最重要的人们，但是真的给我带来了许多的”痛苦“！烦死了！希望来年你们可以不要那么傻，但是请继续傻乐下去。</p><h1 id="谁家今夜扁舟子，何处相思明月楼"><a href="#谁家今夜扁舟子，何处相思明月楼" class="headerlink" title="谁家今夜扁舟子，何处相思明月楼"></a>谁家今夜扁舟子，何处相思明月楼</h1><p>五月Enderfga’s blog 建站了！虽然产生了没几篇高质量内容，但是反正是我的，我说了算！</p><p>看起来这个月里我的朋友圈大部分都是吃吃喝喝，参加了一些小比赛，</p><p>总是会产生一些，我学会了好多东西~然后过了一段时间就发现，原来的自己好傻，连时间复杂度都不知道是什么，连flag都没有听说过。</p><h1 id="玉户帘中卷不去，捣衣砧上拂还来"><a href="#玉户帘中卷不去，捣衣砧上拂还来" class="headerlink" title="玉户帘中卷不去，捣衣砧上拂还来"></a>玉户帘中卷不去，捣衣砧上拂还来</h1><p>这个月我生日了，收到了好多好多礼物呀，虽然我还是会觉得，某一天不会和它的昨天与明天有所区别，但是被大家重视的一天就另当别论了。</p><p>这个月还停止前面说的追逐，不过即使这样还是要告诉自己：人间一趟，积极向上！</p><p>学弟学妹参加了高考，他们信心满满；而我还在为不挂科努力。</p><h1 id="春江潮水连海平，海上明月共潮生"><a href="#春江潮水连海平，海上明月共潮生" class="headerlink" title="春江潮水连海平，海上明月共潮生"></a>春江潮水连海平，海上明月共潮生</h1><p>暑假没有回家，认真打工的七月。</p><p>一天12小时的家教，给我未来的体重激增奠定了经济基础。</p><p>总是会回忆一下人，即使物是人非。</p><p>b站前一段时间是不是火了随机挑战来着？我的七月十七号早知道应该拍成视频，全靠掷骰子随机出发，没想到最后还能到关山月美术馆，莲花山和深圳湾。</p><h1 id="斜月沉沉藏海雾，碣石潇湘无限路"><a href="#斜月沉沉藏海雾，碣石潇湘无限路" class="headerlink" title="斜月沉沉藏海雾，碣石潇湘无限路"></a>斜月沉沉藏海雾，碣石潇湘无限路</h1><p>整个八月估计都在为奥运热血沸腾，16年12年08年的我都没有感受到奥运的魅力。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231202939847.png" alt="image-20211231202939847"></p><p>当然还有大吃大喝跟兄弟们的沙雕你画我猜。</p><h1 id="不知江月待何人，但见长江送流水"><a href="#不知江月待何人，但见长江送流水" class="headerlink" title="不知江月待何人，但见长江送流水"></a>不知江月待何人，但见长江送流水</h1><p>又开学啦····</p><p>我变成学长了，迎新了好多学弟学妹。</p><p>这个月我估计有点想恋爱了，转了很多有的没的。</p><p>暑假赚钱的心愿：请我的好朋友们吃大餐</p><p>开始在这个月一步步实现了！（钱包肉疼）</p><h1 id="禁街箫鼓，寒轻夜永"><a href="#禁街箫鼓，寒轻夜永" class="headerlink" title="禁街箫鼓，寒轻夜永"></a>禁街箫鼓，寒轻夜永</h1><p>国庆爱hanser五周年纪念日！</p><p>第一次跟朋友们出去旅游的国庆假期，有美女美食相伴的日子比在自习室打代码快乐多了。</p><p>越来越胖了，有钱导致我吃的太好，我应该破产的。</p><p>怎么我乐于助人，你们就乐于送我吃蛋糕奶茶呀，这不好！</p><h1 id="凝霜夜下拂罗衣，浮云中断开明月"><a href="#凝霜夜下拂罗衣，浮云中断开明月" class="headerlink" title="凝霜夜下拂罗衣，浮云中断开明月"></a>凝霜夜下拂罗衣，浮云中断开明月</h1><p>十一月不就是上个月吗？我在干嘛？</p><p>我在陪重要的人吃吃喝喝还有傻乐。</p><p>希望我来年总结的时候我还是在陪重要的人吃喝傻乐，不过得多点努力学习。怎么会有这么懒的人，就知道玩动森···</p><p>十二号那天在大教室里演讲了，感觉自己从小就很有表现欲，奈何没有任何技能，每一次上台前都手抖流汗，</p><p>但是我记得那天我讲的很满意，我自己很满意，有进步就好。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231204209953.png" alt="image-20211231204209953"></p><h1 id="愿我如星君如月，夜夜流光相皎洁"><a href="#愿我如星君如月，夜夜流光相皎洁" class="headerlink" title="愿我如星君如月，夜夜流光相皎洁"></a>愿我如星君如月，夜夜流光相皎洁</h1><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231204818624.png" alt="image-20211231204818624"></p><p>12月就不单独总结了，总结全年吧！</p><p>本人2021年年度成就总结:</p><ol><li>学术方面，凭借个人努力，在核酸检测领域产出多份数据真实详尽的报告。</li><li>健康方面，保证膳食纤维摄入，具体表现为每日坚持吃瓜，吃好瓜，吃大瓜。</li><li>商业方面，与各大平台合作，全面参与投资618双11、双12等千亿级重大项目。</li><li>环保方面，股票基金一片绿，绿水青山就是金山银山。在废物利用领域更是成绩斐然:自己作为废物，常常被别人利用。</li><li>运动方面，专注于水上项目，在摸鱼、划水等小项上有突出表现。</li><li>信仰方面，全心全意坚持转发锦鲤不动摇。</li></ol><p>算了不玩梗了。</p><p>这一年有什么值得回顾的吗？</p><p>也许应该是友谊吧，从高中到大学，相识6，7年的朋友们不在了，跳出舒适圈，结识了另外一批可爱的人。</p><p>本来不想花时间写这种东西的，会觉得“你的总结关别人什么事，写出来谁会看呀”。</p><p>后来想了想，真有道理，我应该写给明年31号的自己。</p><p>喂，桂安，你有没有记得刷LeetCode，今天学习强国了吗？和朋友们的关系好不，有没有给他们带来快乐？有给学弟学妹做个好榜样没？</p><p>linux用惯没，c++/python/matlab还记得怎么用吗？绩点到5没？体重下来没？······</p><p><img src="https://v2.jinrishici.com/one.svg" alt="今日诗词"></p><p>2021最大的收获是结识了读到这里的你，谢谢~</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231192304439.png&quot; alt=&quot;image-20211231192304439&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是2021年发的第一条朋友圈配图，顺手拿来总结吧。&lt;/p&gt;</summary>
    
    
    
    
    <category term="闲谈" scheme="http://enderfga.cn/tags/%E9%97%B2%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>wsl安装与开发环境搭建</title>
    <link href="http://enderfga.cn/2021/11/26/wsl/"/>
    <id>http://enderfga.cn/2021/11/26/wsl/</id>
    <published>2021-11-26T02:45:27.000Z</published>
    <updated>2022-04-21T05:32:29.634Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>wsl2，vscode，windows terminal，zsh，docker····</p><span id="more"></span><h1 id="Windows-Subsystem-for-Linux"><a href="#Windows-Subsystem-for-Linux" class="headerlink" title="Windows Subsystem for Linux"></a>Windows Subsystem for Linux</h1><p>首先贴一个<a href="https://docs.microsoft.com/zh-cn/windows/wsl/install">官方文档</a></p><h2 id="什么是适用于-Linux-的-Windows-子系统"><a href="#什么是适用于-Linux-的-Windows-子系统" class="headerlink" title="什么是适用于 Linux 的 Windows 子系统"></a>什么是适用于 Linux 的 Windows 子系统</h2><p>适用于 Linux 的 Windows 子系统可让开发人员按原样运行 GNU/Linux 环境 - 包括大多数命令行工具、实用工具和应用程序 - 且不会产生传统虚拟机或双启动设置开销。</p><ul><li><a href="https://aka.ms/wslstore">在 Microsoft Store</a> 中选择你偏好的 GNU/Linux 分发版。</li><li>运行常用的命令行软件工具（例如 <code>grep</code>、<code>sed</code>、<code>awk</code>）或其他 ELF-64 二进制文件。</li><li>运行 Bash shell 脚本和 GNU/Linux 命令行应用程序，包括：<ul><li>工具：vim、emacs、tmux</li><li>语言：<a href="https://docs.microsoft.com/zh-cn/windows/nodejs/setup-on-wsl2">NodeJS</a>、Javascript、<a href="https://docs.microsoft.com/zh-cn/windows/python/web-frameworks">Python</a>、Ruby、C/ C++、C# 与 F#、Rust、Go 等。</li><li>服务：SSHD、<a href="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">MySQL</a>、Apache、lighttpd、<a href="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">MongoDB</a>、<a href="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">PostgreSQL</a>。</li></ul></li><li>使用自己的 GNU/Linux 分发包管理器安装其他软件。</li><li>使用类似于 Unix 的命令行 shell 调用 Windows 应用程序。</li><li>在 Windows 上调用 GNU/Linux 应用程序。</li></ul><h2 id="什么是-WSL-2？"><a href="#什么是-WSL-2？" class="headerlink" title="什么是 WSL 2？"></a>什么是 WSL 2？</h2><p>WSL 2 是适用于 Linux 的 Windows 子系统体系结构的一个新版本，它支持适用于 Linux 的 Windows 子系统在 Windows 上运行 ELF64 Linux 二进制文件。 它的主要目标是 <strong>提高文件系统性能</strong>，以及添加 <strong>完全的系统调用兼容性</strong>。</p><p>这一新的体系结构改变了这些 Linux 二进制文件与Windows 和计算机硬件进行交互的方式，但仍然提供与 WSL 1（当前广泛可用的版本）中相同的用户体验。</p><p>单个 Linux 分发版可以在 WSL 1 或 WSL 2 体系结构中运行。 每个分发版可随时升级或降级，并且你可以并行运行 WSL 1 和 WSL 2 分发版。 WSL 2 使用全新的体系结构，该体系结构受益于运行<strong>真正</strong>的 Linux 内核。</p><h2 id="WSL-2安装"><a href="#WSL-2安装" class="headerlink" title="WSL 2安装"></a>WSL 2安装</h2><p>需要CPU开启VT（Virtualization Technology），这一步根据CPU不同操作方式不同就不细说了。</p><p>需要先启用“适用于 Linux 的 Windows 子系统”可选功能，然后才能在 Windows 上安装 Linux 分发。</p><p>以管理员身份打开 PowerShell 并运行：</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">dism<span class="token punctuation">.</span>exe <span class="token operator">/</span>online <span class="token operator">/</span><span class="token function">enable-feature</span> <span class="token operator">/</span>featurename:Microsoft<span class="token operator">-</span>Windows<span class="token operator">-</span>Subsystem<span class="token operator">-</span>Linux <span class="token operator">/</span>all <span class="token operator">/</span>norestart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>若要更新到 WSL 2，需要运行 Windows 10。</p><ul><li>对于 x64 系统：<strong>版本 1903</strong> 或更高版本，采用 <strong>内部版本 18362</strong> 或更高版本。</li><li>对于 ARM64 系统：<strong>版本 2004</strong> 或更高版本，采用 <strong>内部版本 19041</strong> 或更高版本。</li><li>低于 18362 的版本不支持 WSL 2。 使用 <a href="https://www.microsoft.com/software-download/windows10">Windows Update 助手</a>更新 Windows 版本。</li></ul><p>若要检查 Windows 版本及内部版本号，选择 Windows 徽标键 + R，然后键入“winver”，选择“确定”。 更新到“设置”菜单中的<a href="ms-settings:windowsupdate">最新 Windows 版本</a>。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126110320999.png" alt="image-20211126110320999"></p><p>安装 WSL 2 之前，必须启用“虚拟机平台”可选功能。 计算机需要<a href="https://docs.microsoft.com/zh-cn/windows/wsl/troubleshooting#error-0x80370102-the-virtual-machine-could-not-be-started-because-a-required-feature-is-not-installed">虚拟化功能</a>才能使用此功能。</p><p>以管理员身份打开 PowerShell 并运行：</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">dism<span class="token punctuation">.</span>exe <span class="token operator">/</span>online <span class="token operator">/</span><span class="token function">enable-feature</span> <span class="token operator">/</span>featurename:VirtualMachinePlatform <span class="token operator">/</span>all <span class="token operator">/</span>norestart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126110900611.png" alt="image-20211126110900611"></p><p><strong>重新启动</strong> 计算机，以完成 WSL 安装并更新到 WSL 2。</p><p>重启之后<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">下载安装</a> Linux 内核更新包并将 WSL 2 设置为默认版本。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126111436728.png" alt="image-20211126111436728"></p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">wsl <span class="token operator">--</span><span class="token function">set-default</span><span class="token operator">-</span>version 2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126111557676.png" alt="image-20211126111557676"></p><p>最后，打开 <a href="https://aka.ms/wslstore">Microsoft Store</a>，并选择你偏好的 Linux 分发版。</p><p>单击以下链接会打开每个分发版的 Microsoft Store 页面：</p><ul><li><a href="https://www.microsoft.com/store/apps/9N9TNGVNDL3Q">Ubuntu 18.04 LTS</a></li><li><a href="https://www.microsoft.com/store/apps/9n6svws3rx71">Ubuntu 20.04 LTS</a></li><li><a href="https://www.microsoft.com/store/apps/9NJFZK00FGKV">openSUSE Leap 15.1</a></li><li><a href="https://www.microsoft.com/store/apps/9MZ3D1TRP8T1">SUSE Linux Enterprise Server 12 SP5</a></li><li><a href="https://www.microsoft.com/store/apps/9PN498VPMF3Z">SUSE Linux Enterprise Server 15 SP1</a></li><li><a href="https://www.microsoft.com/store/apps/9PKR34TNCV07">Kali Linux</a></li><li><a href="https://www.microsoft.com/store/apps/9MSVKQC78PK6">Debian GNU/Linux</a></li><li><a href="https://www.microsoft.com/store/apps/9n6gdm4k2hnc">Fedora Remix for WSL</a></li><li><a href="https://www.microsoft.com/store/apps/9NV1GV1PXZ6P">Pengwin</a></li><li><a href="https://www.microsoft.com/store/apps/9N8LP0X93VCP">Pengwin Enterprise</a></li><li><a href="https://www.microsoft.com/store/apps/9p804crf0395">Alpine WSL</a></li><li><a href="https://www.microsoft.com/store/apps/9msmjqd017x7">Raft（免费试用版）</a></li></ul><p>首次启动新安装的 Linux 分发版时，将打开一个控制台窗口，系统会要求你等待一分钟或两分钟，以便文件解压缩并存储到电脑上。 未来的所有启动时间应不到一秒。</p><p>然后，需要为新的 Linux 分发版创建用户帐户和密码。</p><p>另外，以上内容貌似（？）可以使用以下一行命令解决</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wsl --install -d Ubuntu-20.04<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126142919333.png" alt="image-20211126142919333"></p><p>另外我发现用户名不能用大写，并且密码是不会显示出来的。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126143140954.png" alt="image-20211126143140954"></p><h2 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h2><p>如果遇到下载速度较慢，或者下载失败等问题，我们还可以把官方源换成国内源。</p><p><strong>备份list文件</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">cd</span> /etc/apt/<span class="token function">sudo</span> <span class="token function">cp</span> sources.list sources.list.bak<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>备份了，如果下面的哪一步出错了好恢复。</p><p><strong>修改list文件</strong></p><p>管理员权限，使用 vim 进行修改：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">vim</span> sources.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>把想要更换的源复制在剪切板，这里以阿里源为例：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>我们先通过按<strong>ggdG</strong>这几个字母将里面的内容全部删除，</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">通过按下gg后发现光标移动到文件首行了。其中，gg为跳转到文件首行；dG为删除光标所在行以及其下所有行的内容。d为删除，G为跳转到文件末尾行。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>按鼠标右键会进行粘贴，然后输入    :wq!    进行退出与保存。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126135607014.png" alt="image-20211126135607014"></p><p>最后复制这两条命令进行更新镜像源列表。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h1 id="Windows-terminal-vscode"><a href="#Windows-terminal-vscode" class="headerlink" title="Windows terminal+vscode"></a>Windows terminal+vscode</h1><p><a href="https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701?rtc=1&amp;activetab=pivot:overviewtab">Windows Terminal</a> <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started">https://docs.microsoft.com/en-us/windows/terminal/get-started</a></p><p>VS Code <a href="https://code.visualstudio.com">https://code.visualstudio.com</a></p><p>这两样软件可以大幅提高效率（还很装逼很好看）</p><p>windows terminal各项设置可以实现许多使用功能，比如我设置了默认启动Ubuntu，添加了git bash，透明亚克力效果等（本次不介绍，感兴趣自行研究）</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126112846563.png" alt="image-20211126112846563"></p><p>可以在工作区文件夹内右键然后在windows终端打开</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126112958904.png" alt="image-20211126112958904"></p><p>也可以直接打开window终端，cd到对应文件夹，然后输入</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">code <span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126113402308.png" alt="image-20211126113402308"></p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126113507900.png" alt="image-20211126113507900"></p><p>至此就可以实现在windows环境下编程，在linux环境下测试。</p><h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>使用以下脚本可以实现自动安装。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># install docker</span><span class="token function">curl</span> -fsSL get.docker.com -o get-docker.sh<span class="token function">sh</span> get-docker.sh<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token operator">!</span> <span class="token variable"><span class="token variable">$(</span>getent group docker<span class="token variable">)</span></span> <span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">then</span>     <span class="token function">sudo</span> <span class="token function">groupadd</span> docker<span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token builtin class-name">echo</span> <span class="token string">"docker user group already exists"</span><span class="token keyword">fi</span><span class="token function">sudo</span> gpasswd -a <span class="token environment constant">$USER</span> docker<span class="token function">sudo</span> <span class="token function">service</span> docker restart<span class="token function">rm</span> -rf get-docker.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126133921891.png" alt="image-20211126133921891"></p><p>可以直接复制到txt中，然后修改文件类型跟文件名为install-docker.sh（后缀是sh，名字任意）</p><p>例如我在桌面放置了该脚本，右键打开终端之后输入以下命令即可完成安装。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> install-docker.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126140126640.png" alt="image-20211126140126640"></p><p>接下来输入：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">service</span> docker startdocker version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>就可以启动服务，查看版本，证明我们已经安装成功。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126140532065.png" alt="image-20211126140532065"></p><p>如果不希望每次都特地启动docker的服务可以使用以下命令设置自启动：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>关于docker的使用就大家自己研究啦。</p><h1 id="On-my-zsh"><a href="#On-my-zsh" class="headerlink" title="On-my-zsh"></a>On-my-zsh</h1><p>一个美观且功能强大的终端</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126145704636.png" alt="image-20211126145704636"></p><p>用windows terminal启动Ubuntu，输入以下命令安装：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y <span class="token function">zsh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>oh-my-zsh中整理了常用的zsh<a href="https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins">扩展</a>和<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes">主题</a>,所以先安装oh-my-zsh</p><p>使用curl安装 :</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> -c <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token function">curl</span> -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh<span class="token variable">)</span></span>"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>使用wget安装：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> -c <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token function">wget</span> https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -<span class="token variable">)</span></span>"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>虽然我列出了上面两条命令，但最好还是看看<a href="https://ohmyz.sh/#install">官网</a>的安装页面，确保命令的最新版本。</p><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126150308574.png" alt="image-20211126150308574"></p><p>接下来输入：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">cd</span>code .zshrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>就可以cd到根目录文件夹，用vscode的可视化界面编辑配置文件，添加需要的扩展与主题了。</p><p>扩展与主题根据个人需求添加，本文不再赘述。</p><h1 id="Python开发"><a href="#Python开发" class="headerlink" title="Python开发"></a>Python开发</h1><p>花里胡哨那么多东西了，讲一点实战（假的）。</p><p>默认Ubuntu已经安装了python，我们只需要安装pip，就可以进行一些简单的编程。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3-pip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126151809809.png" alt="image-20211126151809809"></p><p>当然我们不能局限于简单的编程，我们需要<strong>创建虚拟环境</strong>，确保各个环境互相隔离，互不影响。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3-venv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>创建虚拟环境：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> python3 -m venv <span class="token function">env</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>激活与退出：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">source</span> env/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126181729703.png" alt="image-20211126181729703"></p><p>接下来就可以尽情地pip install了，在工作环境下新建文件夹，再用vscode打开，即可开始编程。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;wsl2，vscode，windows terminal，zsh，docker····&lt;/p&gt;</summary>
    
    
    
    
    <category term="操作系统" scheme="http://enderfga.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
