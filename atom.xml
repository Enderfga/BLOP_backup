<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Enderfga&#39;Blog</title>
  
  
  <link href="http://enderfga.cn/atom.xml" rel="self"/>
  
  <link href="http://enderfga.cn/"/>
  <updated>2023-03-01T03:19:08.223Z</updated>
  <id>http://enderfga.cn/</id>
  
  <author>
    <name>Enderfga</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RLHF</title>
    <link href="http://enderfga.cn/2023/03/01/RLHF/"/>
    <id>http://enderfga.cn/2023/03/01/RLHF/</id>
    <published>2023-03-01T03:17:42.000Z</published>
    <updated>2023-03-01T03:19:08.223Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="rlhf">RLHF</h1><h2 id="aligning-text-to-image-models-using-human-feedback">AligningText-to-Image Models using Human Feedback</h2><ul><li><p>Google Research ,University of California</p></li><li><p>2023.2.23</p><span id="more"></span></li></ul><h2 id="motivation">Motivation</h2><p>深度生成模型在文本到图像合成方面取得了令人印象深刻的成果，但当前的文本到图像模型往往生成与文本提示不够相符的图像。</p><p>本文的动机是改进文本到图像合成模型，使其能够更好地与文本提示对齐。</p><p>作者的方法比预训练模型更准确地生成具有指定颜色、计数和背景的对象。</p><h2 id="proposal">Proposal</h2><ul><li>提出了一种简单而有效的微调方法，用于使用人类反馈对文本到图像模型进行对齐。</li><li>使用人类反馈进行微调可以显着提高文本到图像模型的图像文本对齐，在人类评估中，我们的模型在图像文本对齐方面达到了高达47％的改善，但图像保真度略有降低。</li><li>学习的奖励函数比CLIP分数更准确地预测了人类对质量的评估。</li><li>基于作者学习的奖励函数的采样也可以显着改善图像文本对齐。</li></ul><h2 id="related-work">Related Work</h2><ul><li>T2I models</li><li>Evaluating image-text alignment</li><li>Learning with human feedback</li></ul><p>与先前关注利用人类反馈改善语言模型和RL代理的工作相比，该工作探索了使用人类反馈来调整多模式文本到图像模型与人类偏好的方法。许多关于利用人类反馈学习的先前工作都包括学习一个奖励函数并最大化奖励加权可能性（通常被称为监督微调）。受其成功的启发，作者提出了一种利用人类反馈进行微调的方法来改善文本到图像模型。</p><h2 id="method">Method</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230228130311025.png" /></p><p>包括三个阶段：</p><ol type="1"><li>首先从一系列文本提示中生成一组不同的图像，这些文本提示旨在测试文本到图像模型的各种功能。</li><li>然后，人类评级者对这些图像提供二进制反馈。</li><li>接下来，训练一个奖励模型，以文本提示和图像作为输入来预测人类反馈。</li><li>最后，我们使用奖励加权对数似然度来微调文本到图像模型，以改善文本图像对齐。</li></ol><h2 id="experiment">Experiment</h2><p>实验部分旨在测试人类反馈参与模型微调的有效性。实验用到的模型为 StableDiffusion v1.5</p><p><imgsrc="https://img.enderfga.cn/img/image-20230228132659591.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230228132741226.png" /></p><p>本文方法显著提高了图像 - 文本对齐，具体来说，模型生成的图像中有 50%的样本获得至少三分之二的赞成票（投票数量为 7票或更多赞成票），然而，微调会稍微降低图像保真度（15% 比 10%）。</p><p><imgsrc="https://img.enderfga.cn/img/image-20230228132824327.png" /></p><p>本文模型生成的图像符合 prompt指定的颜色、计数和背景。值得注意的是，本文模型还能生成没有见过的文本prompt 图像，并且质量非常高</p><p><imgsrc="https://img.enderfga.cn/img/image-20230228132908052.png" /></p><p>有奖励（绿色）比 CLIP 分数（红色）更符合典型的人类意图。</p><h2 id="limitations-and-future-directions">Limitations and futuredirections</h2><ol type="1"><li><p><strong>更细致的人类反馈</strong>，存在一些较差的生成，如高饱和度的图像颜色，指示评级者寻找更多样化的失败模式（过度饱和的颜色，不切实际的动物解剖学，物理违规等）将提高这些方面的性能。</p></li><li><p><strong>多样化和大型人类数据集</strong>，为了简化问题，作者考虑了有限的文本类别（计数，颜色，背景），因此人类反馈也相对简单（好或坏）。由于这一点，人类反馈数据的多样性有限。将其扩展到更主观的文本类别（如艺术创作）和更细致的人类反馈将是未来研究的重要方向。</p></li><li><p><strong>不同的目标和算法</strong>，为了更新文本到图像模型，作者使用奖励加权的最大似然。然而，与语言领域的先前工作类似，使用RL算法将是一个有趣的方向。作者相信RLHF微调可能会产生更好的模型，因为</p><p>（a）在更新期间使用在线样本生成</p><p>（b）KL正则化可以减轻对奖励函数的过度拟合。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;rlhf&quot;&gt;RLHF&lt;/h1&gt;
&lt;h2 id=&quot;aligning-text-to-image-models-using-human-feedback&quot;&gt;Aligning
Text-to-Image Models using Human Feedback&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Google Research ,University of California&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2023.2.23&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机视觉" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Realfusion</title>
    <link href="http://enderfga.cn/2023/03/01/Realfusion/"/>
    <id>http://enderfga.cn/2023/03/01/Realfusion/</id>
    <published>2023-03-01T03:14:27.000Z</published>
    <updated>2023-03-01T03:16:21.212Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="realfusion">RealFusion：</h1><h3 id="reconstruction-of-any-object-from-a-single-image">360°Reconstruction of Any Object from a Single Image</h3><ul><li><p>Oxford University</p></li><li><p>2023.2.23</p><span id="more"></span><h2 id="demo">Demo</h2><p>https://lukemelas.github.io/realfusion/</p><figure><img src="https://img.enderfga.cn/img/splash-figure-v2.png"alt="Examples" /><figcaption aria-hidden="true">Examples</figcaption></figure></li></ul><h2 id="motivation-single-view-3d-reconstruction">Motivation:Single-View 3D Reconstruction</h2><ul><li>Reconstructing the 3D structure of an object from a single 2D viewis a fundamental challenge in computer vision.</li><li>In the case of a single view, the reconstruction problem is highlyill-posed. As a result, the task requires semantic understandingobtained by learning. Despite the difficulty of this task, humans areadept at using a range of monocular cues to infer the 3D structures ofobjects from single views.</li></ul><h2 id="background">Background</h2><h3 id="category-level-3d-reconstruction">Category-level 3DReconstruction</h3><ul><li>Most prior work tackles the problem of category-specific single-view3D reconstruction by training a category-level reconstructionmodel.</li><li>The work: Going beyond category-level 3D reconstruction<ul><li>This work aims to go beyond category-specific images to images ofarbitrary objects. This setting is highly challenging, but humansperform it effortlessly when they observe new objects.</li></ul></li></ul><h3 id="single-view-3d-reconstruction">Single-View 3DReconstruction</h3><ul><li>Arbitrary-object 3D reconstruction has been challenging because theproblem fundamentally requires the use of large-scale 3D priors overobject shapes, which have not been available.</li><li>With the recent rise of large-scale pretraining, this problem hasbecome tractable. Examples include:<ul><li>Contrastive: CLIP</li><li>Autoregressive: DALL-E / Parti</li><li>Diffusion Models: DALL-E 2 / Imagen / Stable Diffusion</li></ul></li><li>These pretrained models may be used as priors for a variety ofvision tasks, and we are particularly interested in 3D reconstruction.<ul><li>At a high level, you can think of these models as a tool foroptimizing the realism of an input image.</li></ul></li><li>In this way, they enable an elegant approach to 3D generation andreconstruction: using these large-scale pretrained models to enforcethat a differentiable scene looks realistic from random views.</li></ul><h2 id="proposal">Proposal</h2><ol type="1"><li><p>We propose <strong>RealFusion</strong>, a method that can extractfrom a single image of an object a 360◦ photographic 3D reconstructionwithout assumptions on the type of object imaged or 3D supervision ofany kind;</p></li><li><p>We do so by leveraging an existing 2D <strong>diffusion imagegenerator</strong> via a new single image variant of textualinversion;</p></li><li><p>We also introduce new regularizers and provide an efficientimplementation using <strong>InstantNGP</strong>;</p></li><li><p>We demonstrate <strong>state-of-the-art</strong> reconstructionresults on a number of in-the-wild images and images from existingdatasets when compared to alternative approaches.</p></li></ol><h2 id="related-work">Related Work</h2><ul><li>Image-based reconstruction of appearnce and geometry</li><li>Few-view reconstruction</li><li>Single-view reconstruction<br /></li><li>Extracting 3D models from 2D generators<br /></li><li>Diffusion Models</li></ul><h2 id="method">Method</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230227112154724.png" /></p><ul><li>This approach forms the backbone of our method, RealFusion.</li></ul><ol start="0" type="1"><li>[Init] We are given a single image and a function <spanclass="math inline">\(\boldsymbol{p}_{\text {prior }}(\cdot)\)</span>which computes the likelihood of an input image <spanclass="math inline">\(\boldsymbol{I}\)</span>. We choose a camera viewand represent our scene with a differentiably-renderable representation<span class="math inline">\(\boldsymbol{x}\)</span>, for example aNeRF.</li><li>[Reconstruction] We render <spanclass="math inline">\(\boldsymbol{x}\)</span> from our given view andminimize the loss with respect to the real input image <spanclass="math inline">\(\mathbf{I}\)</span>.</li><li>[Prior] We render images <spanclass="math inline">\(\boldsymbol{I}_{\text {prior }}\)</span> of <spanclass="math inline">\(\boldsymbol{x}\)</span> from randomly-chosen viewson a hemisphere surrounding the origin, and we optimize <spanclass="math inline">\(\boldsymbol{p}_{\text {prior}}\left(\boldsymbol{I}_{\text {priol }}\right)\)</span> to enforce that<span class="math inline">\(\boldsymbol{x}\)</span> looks realistic fromall directions.</li></ol><ul><li>Prior work has explored this question in the domain of 3D generation<ul><li>Dreamfields: CLIP prior</li><li>DreamFusion: Diffusion model prior</li></ul></li><li>In our work, we adopt a diffusion model prior using StableDiffusion, a text-conditional latent diffusion model.</li><li>As currently stated, our set up combines a reconstruction objectivewith a latent diffusion-based prior objective, which is conditioned on amanual text prompt (e.g. "An image of a fish.")</li><li>However, we found that these results were lacking.</li><li>In particular, the 3D shapes that are generated look like the inputobject from the input view, but do not look like the input object fromother views.</li><li>To fix this, we need to modify the prior to place a high likelihoodon our input object, rather than a generic object with the samedescription.</li><li>We do so by performing textual inversion.<ul><li>We optimize a text embedding <spanclass="math inline">\(\mathbf{e}\)</span> in the text encoder of thediffusion model to match our input image.</li><li>Usually textual inversion is performed with multiple views of anobject, but we substitute these views with heavy imageaugmentations.</li></ul></li><li>We also add other pieces of regularization:<ol type="1"><li>A regularization on rendered normals</li><li>A coarse-to-fine training setup</li></ol></li><li>However, the key piece of the puzzle is the textual inversion.</li></ul><h2 id="experiment">Experiment</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230227165614420.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230227165925713.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230227165956615.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230227170021757.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230227170047165.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230227170111552.png" /></p><h2 id="limitations">Limitations</h2><ul><li>Requires per-image optimization<ul><li>Both the textual inversion and the 3D optimization procedure must beperformed separately for each input image.</li><li>As a result, the process is relatively slow and difficult to applyto large datasets</li></ul></li><li>In some cases, reconstruction fails to produce a solid shape<ul><li>Perhaps this could be alleviated with better inductive biases orregularization terms</li></ul></li><li>In some cases, reconstruction produces two-headed objects<ul><li>This is known as the Janus Problem</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;realfusion&quot;&gt;RealFusion：&lt;/h1&gt;
&lt;h3 id=&quot;reconstruction-of-any-object-from-a-single-image&quot;&gt;360°
Reconstruction of Any Object from a Single Image&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Oxford University&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2023.2.23&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机视觉" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Outstanding Wordle</title>
    <link href="http://enderfga.cn/2023/02/22/wordle/"/>
    <id>http://enderfga.cn/2023/02/22/wordle/</id>
    <published>2023-02-22T13:38:54.000Z</published>
    <updated>2023-02-22T13:49:05.366Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>唯一一次认真参加数学建模，虽然曾经的我确实不喜欢这类赛事。假如拿到O/F奖了就考虑写写经验或者录个视频，捞了就当我没说。</p><span id="more"></span><embed src="./wordle.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;唯一一次认真参加数学建模，虽然曾经的我确实不喜欢这类赛事。假如拿到O/F奖了就考虑写写经验或者录个视频，捞了就当我没说。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数学建模" scheme="http://enderfga.cn/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
  </entry>
  
  <entry>
    <title>亚太数模论文</title>
    <link href="http://enderfga.cn/2023/02/20/apmcm/"/>
    <id>http://enderfga.cn/2023/02/20/apmcm/</id>
    <published>2023-02-20T11:02:17.000Z</published>
    <updated>2023-02-20T11:05:59.145Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这么烂的学术垃圾都能拿奖，这比赛确实没含金量</p><span id="more"></span><embed src="./apmcm.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;这么烂的学术垃圾都能拿奖，这比赛确实没含金量&lt;/p&gt;</summary>
    
    
    
    
    <category term="数学建模" scheme="http://enderfga.cn/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
  </entry>
  
  <entry>
    <title>MAV3D:Text-To-4D Dynamic Scene Generation</title>
    <link href="http://enderfga.cn/2023/02/11/mav/"/>
    <id>http://enderfga.cn/2023/02/11/mav/</id>
    <published>2023-02-11T15:42:41.000Z</published>
    <updated>2023-02-11T15:51:26.196Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文阅读笔记</p><span id="more"></span><div style="text-align:center"><iframe width="100%" height="500" src="https://player.bilibili.com/player.html?aid=479164157&amp;bvid=BV1aT411R77Z&amp;cid=1003655006&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></iframe></div><h1 id="mav3dtext-to-4d-dynamic-scene-generation">MAV3D:Text-To-4DDynamic Scene Generation</h1><ul><li><p><strong>Meta AI</strong></p></li><li><p><strong>2023.1.26</strong></p><h2 id="demo">Demo</h2><p><ahref="https://make-a-video3d.github.io/">https://make-a-video3d.github.io/</a></p><video src="./rotating_grid.mp4"></video></li></ul><h2 id="motivation">Motivation</h2><ol type="1"><li><strong>需要一个有效的、端到端可学习的动态三维场景表征；</strong></li><li><strong>需要一个有监督学习的数据源，因为目前并不存在大规模的（文本，4D）对的数据集可供学习；</strong></li><li><strong>需要在空间和时间维度上扩展输出的分辨率，因为4D输出需要大量的内存和计算能力；</strong></li></ol><h2 id="proposal">Proposal</h2><ol type="1"><li><strong>本文提出了MAV3D，利用了T2V模型和动态NeRFs，实现从自然语言描述生成动态三维时间表示；</strong></li><li><strong>提出了一个从静态到动态的多阶段优化方案，逐步纳入静态、时间和超分辨率模型的梯度信息。</strong></li></ol><h2 id="related-work">Related Work</h2><h3 id="dynamic-nerfs">dynamic NeRFs</h3><p><strong>适用于动态场景的NeRF变体</strong></p><h3 id="mav">MAV</h3><p><strong>Make AVideo，通过在未标记的视频上训练，拓展了文本到图像（T2I）模型。</strong></p><h3 id="dreamfusion">DreamFusion</h3><p><strong>以NeRF的形式从文本描述中学习3D表示，提出了一个基于概率密度蒸馏的loss（SDS）</strong></p><h2 id="method">Method</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230209142352394.png" /></p><h3 id="d-scene-representation">4D Scene Representation</h3><p><imgsrc="https://img.enderfga.cn/img/image-20230209141807225.png" /></p><p><span class="math display">\[\left(\tau, c_i\right)=f_\theta(x, y, z, t)\]</span></p><p><span class="math display">\[\left[P_{x y}^{X Y R_1}+P_{z t}^{Z T R_1} ; P_{x z}^{X Z R_2}+P_{y t}^{YT R_2} ; P_{y z}^{Y Z R_3}+P_{y z}^{X T R_3}\right]\]</span></p><h3 id="dynamic-scene-optimization">Dynamic Scene Optimization</h3><h4id="为了监督4d场景与文本提示p匹配引入sds-ttemporal-score-distillation-sampling">为了监督4D场景与文本提示p匹配，引入SDS-T（temporalScore Distillation Sampling ）</h4><p><span class="math display">\[\nabla_\theta \mathcal{L}_{S D S-T}=E_{\sigma,\epsilon}\left[w(\sigma)\left(\hat{\epsilon}\left(V_{(\bar{\theta},\sigma, \epsilon)} \mid y, \sigma\right)-\epsilon\right) \frac{\partialV_\theta}{\partial \theta}\right]\\\]</span></p><p><span class="math display">\[\nabla_\theta \mathcal{L}_{\mathrm{SDS}}(\phi, \mathbf{x}=g(\theta))\triangleq \mathbb{E}_{t,\epsilon}\left[w(t)\left(\hat{\epsilon}_\phi\left(\mathbf{z}_t ; y,t\right)-\epsilon\right) \frac{\partial \mathbf{x}}{\partial\theta}\right]\]</span></p><h4 id="从静态到动态的场景优化">从静态到动态的场景优化</h4><h4 id="动态相机">动态相机</h4><h4 id="fps-采样">FPS 采样</h4><h4 id="高斯退火">高斯退火</h4><h4 id="全变分损失">全变分损失</h4><h3 id="super-resolution-fine-tuning">Super-Resolution Fine-Tuning</h3><p><imgsrc="https://img.enderfga.cn/img/image-20230209152345831.png" /></p><h2 id="experiment">Experiment</h2><p><strong>Metrics</strong>：R-Precision and human preference</p><p><imgsrc="https://img.enderfga.cn/img/image-20230209152747908.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230209152759865.png" /></p><h2 id="limitations">Limitations</h2><ul><li><strong>将动态NeRFs转换为实时应用的不连续网格序列的效率很低，如果能直接预测顶点的轨迹，就能得到改善。</strong></li><li><strong>利用超分辨率信息提高了表示的质量，但对于更高细节的纹理还需要进一步改进。</strong></li><li><strong>文本到四维动态场景生成的表示质量取决于T2V模型从不同视角生成视频的能力。</strong></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;论文阅读笔记&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机视觉" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Test to 3d随笔</title>
    <link href="http://enderfga.cn/2023/02/09/3d/"/>
    <id>http://enderfga.cn/2023/02/09/3d/</id>
    <published>2023-02-09T08:51:10.000Z</published>
    <updated>2023-02-09T08:53:02.663Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>随便记的笔记</p><span id="more"></span><h1 id="text-to-3d">Text-to-3D</h1><h2id="nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis">NeRF:Representing Scenes as Neural Radiance Fields for View Synthesis</h2><p><imgsrc="https://img.enderfga.cn/img/ed4df06e919cae0e638015fa78d935eb_1_Figure_1.png" /></p><p><strong>输入为连续的5维坐标（xyz坐标，以及视野角度theta和phi）；输出是空间位置的体密度以及该位置的发射射线（这里射线是根据视角变化的）。</strong></p><ol type="1"><li><strong>用 network 存体素信息: </strong>(x, y, z, , ) (, )</li><li><strong>然后用体素渲染方程获得生成视角图片：光线采样+积分</strong><span class="math display">\[C(\mathbf{r})=\int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t))\mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t, \text { where } T(t)=\exp\left(-\int_{t_n}^t \sigma(\mathbf{r}(s)) d s\right)\]</span></li><li><strong>最后与原视角图片计算损失更新网络</strong></li></ol><h2 id="dreamfusion-text-to-3d-using-2d-diffusion">DreamFusion:Text-to-3D using 2D Diffusion</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230202213651008.png" /></p><p><strong>三维合成并不存在大规模的标注数据，也没有一个高效的模型架构对3D数据进行降噪</strong></p><p><strong>使用NERF的格式，使用预训练的text to2d，加上他们提出的一个基于概率密度蒸馏的loss，证明了预训练图像扩散模型作为先验模型的有效性</strong></p><h2 id="magic3d-high-resolution-text-to-3d-content-creation">Magic3D:High-Resolution Text-to-3D Content Creation</h2><p><imgsrc="https://img.enderfga.cn/img/f3fcff88aa23d692c243bda5b3dd5467_3_Figure_2_1114637308.png" /></p><p><strong>用一个两阶段的优化框架来提高速度和分辨率：利用低分辨率的扩散先验获得一个粗略的模型，并以稀疏的三维哈希网格结构加速。使用粗略表示作为初始化，进一步优化纹理三维网格模型，用高效的可微分渲染器与高分辨率的stablediffusion模型交互。</strong></p><h2id="point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts">Point-E:A System for Generating 3D Point Clouds from Complex Prompts</h2><p><imgsrc="https://img.enderfga.cn/img/v2-b0ca9d9f44550ec6ab34dfe21797ea7e_720w.webp" /></p><p><strong>不输出传统意义上的 3D 图像，它会生成点云，或空间中代表 3D形状的离散数据点集</strong></p><p><strong>点云更容易合成，但它们无法捕获对象的细粒度形状或纹理，训练了一个额外的人工智能系统来将Point-E 的点云转换为网格</strong></p><p><strong>算力和时间需求小 但质量差</strong></p><h2id="dream3d-zero-shot-text-to-3d-synthesis-using-3d-shape-prior-and-text-to-image-diffusion-models">Dream3D:Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-ImageDiffusion Models</h2><p><imgsrc="https://img.enderfga.cn/img/image-20230202234404950.png" /></p><p><strong>引入一个显式3D先验形状，来优化CLIP引导的3D优化任务。具体的讲，首先在文本到形状转换时，使用输入文本生成了一个质量的3D形状来作为先验知识。然后使用它来初始化神经辐射场，并使用完整prompt进行优化</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;随便记的笔记&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>三维手势姿态估计算法研究</title>
    <link href="http://enderfga.cn/2023/01/13/nyu/"/>
    <id>http://enderfga.cn/2023/01/13/nyu/</id>
    <published>2023-01-13T14:08:50.000Z</published>
    <updated>2023-01-13T14:19:04.839Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>人工智能原理实验期末项目</p><span id="more"></span><embed src="./nyu.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能原理实验期末项目&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Mind-Diffusion</title>
    <link href="http://enderfga.cn/2023/01/13/diff/"/>
    <id>http://enderfga.cn/2023/01/13/diff/</id>
    <published>2023-01-13T14:04:03.000Z</published>
    <updated>2023-01-13T14:19:04.833Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计算机视觉之diffusion model with mindspore</p><span id="more"></span><embed src="./diff.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计算机视觉之diffusion model with mindspore&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>基于 JMAG 软件的电机仿真分析</title>
    <link href="http://enderfga.cn/2023/01/13/mach/"/>
    <id>http://enderfga.cn/2023/01/13/mach/</id>
    <published>2023-01-13T13:59:11.000Z</published>
    <updated>2023-01-13T14:19:04.835Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>压根没上过课，不知道这写的是啥</p><span id="more"></span><embed src="./mach.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;压根没上过课，不知道这写的是啥&lt;/p&gt;</summary>
    
    
    
    
    <category term="电机与拖动技术" scheme="http://enderfga.cn/tags/%E7%94%B5%E6%9C%BA%E4%B8%8E%E6%8B%96%E5%8A%A8%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>智能车协同实验</title>
    <link href="http://enderfga.cn/2023/01/13/car/"/>
    <id>http://enderfga.cn/2023/01/13/car/</id>
    <published>2023-01-13T13:52:04.000Z</published>
    <updated>2023-01-13T14:19:04.830Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>多智能体集群控制技术智能车实验报告</p><span id="more"></span><embed src="./1.pdf" width="100%" height="750" type="application/pdf"><embed src="./2.pdf" width="100%" height="750" type="application/pdf"><embed src="./3.pdf" width="100%" height="750" type="application/pdf"><embed src="./4.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;多智能体集群控制技术智能车实验报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="多智能体集群" scheme="http://enderfga.cn/tags/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>四旋翼集群编队</title>
    <link href="http://enderfga.cn/2023/01/13/multi/"/>
    <id>http://enderfga.cn/2023/01/13/multi/</id>
    <published>2023-01-13T13:37:11.000Z</published>
    <updated>2023-01-14T12:23:24.113Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>多智能体集群控制技术期末项目报告</p><span id="more"></span><h1 id="单积分模型sysu编队设计">单积分模型SYSU编队设计</h1><p><img src="https://img.enderfga.cn/img/SI.gif" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230113213938616.png" /></p><h1id="控制四旋翼飞行器实现编队方式设计">控制四旋翼飞行器实现编队方式设计</h1><p><img src="https://img.enderfga.cn/img/test.gif" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230113214008450.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20230113214017680.png" /></p><ul><li><p>Position control</p><p><span class="math display">\[\begin{array}{ll}\text { PID: } &amp; \ddot{\boldsymbol{p}}_{i,c}=\ddot{\boldsymbol{p}}_i{ }^{d e s}+K_{d,i}\left(\dot{\boldsymbol{p}}_i{ }^{\text {des}}-\dot{\boldsymbol{p}}_i\right)+K_{p, i}\left(\boldsymbol{p}_i{}^{\text {des }}-\boldsymbol{p}_i\right) \\\text { Model: } &amp; u_1=m\left(g+\ddot{\boldsymbol{p}}_{3, c}\right)\quad \text { (Newton Equation) } \\&amp; \phi_c=\frac{1}{g}\left(\ddot{\boldsymbol{p}}_{1, c} \sin\Psi-\ddot{\boldsymbol{p}}_{2, c} \cos \psi \right) \quad\theta_c=\frac{1}{g}\left(\ddot{\boldsymbol{p}}_{1, c} \cos\Psi+\ddot{\boldsymbol{p}}_{2, c} \sin \Psi\right)\end{array}\]</span></p></li><li><p>Attitude control</p></li></ul><p><span class="math display">\[PID: \quad\left[\begin{array}{c}\ddot{\phi}_c \\ \ddot{\theta}_c \\\ddot{\psi}_c\end{array}\right]=\left[\begin{array}{c}K_{p,\phi}\left(\phi_c-\phi\right)+K_{d,\phi}\left(\dot{\phi}_c-\dot{\phi}\right) \\ K_{p,\theta}\left(\theta_c-\theta\right)+K_{d,\phi}\left(\dot{\theta}_c-\dot{\theta}\right) \\ K_{p,\psi}\left(\psi_c-\psi\right)+K_{d,\psi}\left(\dot{\psi}_c-\dot{\psi}\right)\end{array}\right]\]</span></p><p><span class="math display">\[Model: \quad \boldsymbol{u}_2=\boldsymbol{I}\cdot\left[\begin{array}{c}\ddot{\phi}_c \\ \ddot{\theta}_c \\\ddot{\psi}_c\end{array}\right]+\left[\begin{array}{c}\omega_x \\\omega_y \\ \omega_z\end{array}\right] \times \boldsymbol{I}\cdot\left[\begin{array}{c}\omega_x \\ \omega_y \\\omega_z\end{array}\right] (Euler Equation)\]</span></p><p>我使用的控制器遵循上述公式采取了PID控制，结合单积分模型的控制共同决定了结果分数。当然字母间距、运行时间等也能对误差产生一定影响。</p><p>单积分模型中控制增益kv与刚度矩阵R、距离误差z和期望速度dv相乘，起到了限制距离误差和期望速度之间的平衡作用。具体来说，当kv增加时，系统会更快地收敛到目标状态，但是可能会出现振荡。当kv减小时，系统会更缓慢地收敛到目标状态，甚至会导致无人机几乎不动的情况。</p><p>控制器的原理是输入期望控制，输出飞行器整体推力与力矩。公式整体的推导较为复杂，涉及机器人运动学与动力学，且会解欧拉牛顿方程，但对公式的直观理解可以更好理解公式；这个公式基本是外环位置，内环姿态，计算扭矩与推力，可见推力与飞行器质量与z轴加速度有关，通过计算期望角度计算扭矩。</p><p>我使用了Ziegler-Nichols整定方法来调节PID参数，首先将积分和微分增益设置为0，然后比例增益从零开始逐渐增加，直到到达极限增益<em>KU</em>，此时控制器输出值以恒定值振荡。<em>KU</em>和振荡周期<em>TU</em>根据不同的类型，按下表中的方式来设置比例、积分和微分增益。</p><p><span class="math display">\[\begin{array}{|c|c|c|c|}\hline \text { Controller } &amp; K_p &amp; K_d &amp; K_i \\\hline \text { P } &amp; 0.5 K_u &amp; - &amp; - \\\hline \text { PD } &amp; 0.8 K_u &amp; K_p T_u / 8 &amp; - \\\hline \text { PID } &amp; 0.6 K_u &amp; K_p T_u / 8 &amp; 2 K_p / T_u\\\hline\end{array}\]</span></p><p>在位置控制中，使用了三轴PID控制器来控制x, y,z轴上的运动。使用了误差积分来消除误差；在姿态控制中，通过计算出当前的欧拉角（phi,theta, psi），并使用欧拉角的导数来控制飞行器的姿态。</p><p>Kp是比例系数，它控制着系统的稳定性和响应速度。当Kp增大时，系统的响应速度会变快，但同时也会增加系统的震荡。</p><p>Ki是积分系数，它控制着系统的累计误差。当Ki增大时，系统会更快地消除误差，但同时也会增加系统的积分饱和。</p><p>Kd是微分系数，它控制着系统的响应速度。当Kd增大时，系统的响应速度会变快，但同时也会增加系统的偏差。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;多智能体集群控制技术期末项目报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="多智能体集群" scheme="http://enderfga.cn/tags/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Tiny SSD目标检测</title>
    <link href="http://enderfga.cn/2022/12/11/ssd/"/>
    <id>http://enderfga.cn/2022/12/11/ssd/</id>
    <published>2022-12-11T13:23:46.000Z</published>
    <updated>2022-12-11T13:27:07.369Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Github: https://github.com/Enderfga/TinySSD_sysu</p><span id="more"></span><h1id="tiny-ssd-a-tiny-single-shot-detection-deep-convolutional-neural-network-for-real-time-embedded-object-detection">TinySSD: A Tiny Single-shot Detection Deep Convolutional Neural Network forReal-time Embedded Object Detection</h1><p>This repo contains the code, data and trained models for the paper <ahref="https://arxiv.org/pdf/1802.06488.pdf">Tiny SSD: A Tiny Single-shotDetection Deep Convolutional Neural Network for Real-time EmbeddedObject Detection</a>.</p><h2 id="quick-links">Quick Links</h2><ul><li><a href="#Overview">Overview</a></li><li><a href="#Requirements">Requirements</a></li><li><a href="#How-to-Install">How to Install</a></li><li><a href="#Description-of-Codes">Description of Codes</a></li><li><a href="#Preprocessing">Preprocessing</a><ul><li><a href="#Preprocessed-Data">Preprocessed Data</a></li></ul></li><li><a href="#How-to-Run">How to Run</a><ul><li><a href="#Train">Train</a><ul><li><a href="#Finetuning-from-an-existing-checkpoint">Finetuning from anexisting checkpoint</a></li></ul></li><li><a href="#Evaluate">Evaluate</a></li></ul></li><li><a href="#Results-Outputs-Checkpoints">Results, Outputs,Checkpoints</a></li></ul><h2 id="overview">Overview</h2><p>Tiny SSD is a single-shot detection deep convolutional neural networkfor real-time embedded object detection. It brings together theefficieny of Fire microarchitecture introduced in<strong>SqueezeNet</strong> and object detection performance of<strong>SSD (Single Shot Object Detector)</strong>.</p><p><img src="https://img.enderfga.cn/img/ssd.svg" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20221018133431973.png" /></p><h2 id="requirements">Requirements</h2><ul><li>numpy</li><li>pandas</li><li>matplotlib</li><li>opencv-python</li><li>torch</li><li>torchvision</li></ul><h2 id="how-to-install">How to Install</h2><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda create -n env python=3.8 -y<br>conda activate env<br></code></pre></td></tr></table></figure> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install -r requirements.txt<br></code></pre></td></tr></table></figure></p><h2 id="description-of-files">Description of Files</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs stylus">│──<span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span>                 -&gt; Run models using different models<br>│──README.md<br>│──requirements.txt<br>│──test<span class="hljs-selector-class">.py</span>                 -&gt; Testing Model<br>│──train<span class="hljs-selector-class">.py</span>                -&gt; Training Model<br>│<br>├─data<br>│  │  dataloader<span class="hljs-selector-class">.py</span>         -&gt; dataloader and <span class="hljs-attribute">transform</span><br>│  │  __init__.py<br>│  │<br>│  └─detection<br>│      │  create_train<span class="hljs-selector-class">.py</span>   -&gt; data preprocessing<br>│      │<br>│      ├─<span class="hljs-attribute">background</span><br>│      ├─sysu_train<br>│      │  │  <span class="hljs-selector-tag">label</span>.csv<br>│      │  │<br>│      │  └─images<br>│      ├─target<br>│      │      <span class="hljs-number">0</span>.jpg<br>│      │      <span class="hljs-number">0</span>.png<br>│      │      <span class="hljs-number">1</span>.png<br>│      │<br>│      └─test<br>│              <span class="hljs-number">1</span>.jpg<br>│              <span class="hljs-number">2</span>.jpg<br>│<br>├─model<br>│  │  TinySSD<span class="hljs-selector-class">.py</span>             -&gt; Definition of the model<br>│  │  __init__.py<br>│  │<br>│  └─checkpoints             -&gt; Trained model weights<br>│     net_100.pkl<br>└─utils                      -&gt; utility functions<br>        anchor.py<br>        iou.py<br>        utils.py<br>        __init__.py<br></code></pre></td></tr></table></figure><h2 id="preprocessing">Preprocessing</h2><p>We use /data/detection/background to generate the target detectiondataset for our experiments.</p><p>Since the generated data is stored in the repository, there is noneed to run this step.</p><h3 id="preprocessed-data">Preprocessed Data</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd data/detection/<br>python create_train.py<br></code></pre></td></tr></table></figure><h2 id="how-to-run">How to Run</h2><h3 id="train">Train</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python main.py --mode=train --batch_size=256 --epochs=100<br></code></pre></td></tr></table></figure><p>The checkpoints will be saved in a subfolder of<code>./model/checkpoints/</code>.</p><h4 id="finetuning-from-an-existing-checkpoint">Finetuning from anexisting checkpoint</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python main.py --mode=train --batch_size=256 --epochs=100 --path=[model path]<br></code></pre></td></tr></table></figure><p>model path should be a subdirectory in the<code>./model/checkpoints/</code> directory, e.g.<code>--path=./model/checkpoints/net_100.pkl</code></p><h3 id="evaluate">Evaluate</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">python main.py --mode=test --threshold=<span class="hljs-number">0.3</span> --path=./model/checkpoints/net_100.pkl<br></code></pre></td></tr></table></figure><h2 id="results-outputs-checkpoints">Results, Outputs, Checkpoints</h2><p>the ./model/checkpoints/net_100.pkl：class err 1.54e-03, bbox mae1.90e-03</p><p>I used the following methods to improve performance：</p><ol type="1"><li><p>HD anti-white detection object to adapt to the test image</p><p><imgsrc="https://img.enderfga.cn/img/image-20221018160400682.png" /></p></li><li><p>Flip and rotate images, etc. to improve generalizationperformance</p><p><imgsrc="https://img.enderfga.cn/img/image-20221018155947834.png" /></p></li><li><p>soft_nms</p><p><imgsrc="https://img.enderfga.cn/img/42166d224f4a20a4d58841b70d795a2a730ed0e4.jpeg@f_auto" /></p></li><li><p>smooth_L1</p><p><imgsrc="https://img.enderfga.cn/img/image-20221018155842392.png" /></p></li><li><p>Focal Loss</p><p><img src="https://img.enderfga.cn/img/20221025160416.png" /></p></li></ol><p>If we have more classes, we can further improve the model in thefollowing aspects:</p><ol type="1"><li>When an object is much smaller compared with the image, the modelcould resize the input image bigger.</li><li>There are typically a vast number of negative anchor boxes. To makethe class distribution more balanced, we could downsample negativeanchor boxes.</li><li>In the loss function, assign different weight hyperparameters to theclass loss and the offset loss.</li><li>Use other methods to evaluate the object detection model, such asthose in the single shot multibox detection paper (Liu et al.,2016).</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Github: https://github.com/Enderfga/TinySSD_sysu&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>人脸检测mtcnn复现</title>
    <link href="http://enderfga.cn/2022/12/11/mtcnn/"/>
    <id>http://enderfga.cn/2022/12/11/mtcnn/</id>
    <published>2022-12-11T12:56:31.000Z</published>
    <updated>2022-12-11T13:28:02.081Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Github: https://github.com/Enderfga/mtCNN_sysu</p><span id="more"></span><h1id="joint-face-detection-and-alignment-using-multi-task-cascaded-convolutional-networks">JointFace Detection and Alignment using Multi-task Cascaded ConvolutionalNetworks</h1><p><strong>This repo contains the code, data and trained models for thepaper </strong><ahref="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf">Joint FaceDetection and Alignment using Multi-task Cascaded ConvolutionalNetworks</a>.<strong> </strong>Try out the Gradio Web Demo: <ahref="https://huggingface.co/spaces/Enderfga/mtCNN_sysu"><imgsrc="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue"alt="Hugging Face Spaces" /></a> <imgsrc="https://img.enderfga.cn/img/1faec03527783e6e8ee03d519e167aa.png" /></p><h2 id="overview">Overview</h2><p><strong>MTCNN is a popular algorithm for face detection that usesmultiple neural networks to detect faces in images. It is capable ofdetecting faces under various lighting and pose conditions and candetect multiple faces in an image.</strong></p><p><strong>We have implemented MTCNN using the pytorch framework.Pytorch is a popular deep learning framework that provides tools forbuilding and training neural networks. </strong></p><p><imgsrc="https://img.enderfga.cn/img/image-20221208152130975.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20221208152231511.png" /></p><h2 id="description-of-file">Description of file</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs vim">├── README.md                      # explanatory document<br>├── get_data.<span class="hljs-keyword">py</span>                    # Generate corresponding training data depending <span class="hljs-keyword">on</span> the <span class="hljs-built_in">input</span> “--net”<br>├── img                            # mid.png <span class="hljs-keyword">is</span> used <span class="hljs-keyword">for</span> testing visualization effects,other images are the corresponding results.<br>│   ├── mid.png<br>│   ├── onet.png<br>│   ├── pnet.png<br>│   ├── rnet.png<br>│   ├── result.png<br>│   └── result.jpg<br>├── model_store                    # Our <span class="hljs-keyword">pre</span>-trained model<br>│   ├── onet_epoch_20.<span class="hljs-keyword">pt</span><br>│   ├── pnet_epoch_20.<span class="hljs-keyword">pt</span><br>│   └── rnet_epoch_20.<span class="hljs-keyword">pt</span><br>├── requirements.txt               # Environmental <span class="hljs-keyword">version</span> requirements<br>├── test.<span class="hljs-keyword">py</span>                        # Specify different <span class="hljs-string">&quot;--net&quot;</span> <span class="hljs-keyword">to</span> <span class="hljs-built_in">get</span> the corresponding visualization results<br>├── test.<span class="hljs-keyword">sh</span>                        # Used <span class="hljs-keyword">to</span> test mid.png, which will test the output visualization of three networks<br>├── train.out                      # Our <span class="hljs-built_in">complete</span> training <span class="hljs-built_in">log</span> <span class="hljs-keyword">for</span> this experiment<br>├── train.<span class="hljs-keyword">py</span>                       # Specify different <span class="hljs-string">&quot;--net&quot;</span> <span class="hljs-keyword">for</span> the training of the corresponding network<br>├── train.<span class="hljs-keyword">sh</span>                       # Generate data from start <span class="hljs-keyword">to</span> <span class="hljs-keyword">finish</span> <span class="hljs-built_in">and</span> train<br>└── utils                          # Some common tool functions <span class="hljs-built_in">and</span> modules<br>    ├── config.<span class="hljs-keyword">py</span><br>    ├── dataloader.<span class="hljs-keyword">py</span><br>    ├── detect.<span class="hljs-keyword">py</span><br>    ├── models.<span class="hljs-keyword">py</span><br>    ├── tool.<span class="hljs-keyword">py</span><br>    └── vision.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure><h2 id="requirements">Requirements</h2><ul><li><strong>numpy==1.21.4</strong></li><li><strong>matplotlib==3.5.0</strong></li><li><strong>opencv-python==4.4.0.42</strong></li><li><strong>torch==1.13.0+cu116</strong></li></ul><h2 id="how-to-install">How to Install</h2><p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mel">conda create -n <span class="hljs-keyword">env</span> <span class="hljs-keyword">python</span>=<span class="hljs-number">3.8</span> -y<br>conda activate <span class="hljs-keyword">env</span><br></code></pre></td></tr></table></figure> <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> -r requirements.txt<br></code></pre></td></tr></table></figure></p><h2 id="preprocessing">Preprocessing</h2><ul><li><strong>download </strong><ahref="http://shuoyang1213.me/WIDERFACE/">WIDER_FACE</a> face detectiondata then store it into ./data_set/face_detection</li><li><strong>download </strong><ahref="http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm">CNN_FacePoint</a>face detection and landmark data then store it into./data_set/face_landmark</li></ul><h3 id="preprocessed-data">Preprocessed Data</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># Before training Pnet</span><br>python get_data.py <span class="hljs-attribute">--net</span>=pnet<br><span class="hljs-comment"># Before training Rnet, please use your trained model path</span><br>python get_data.py <span class="hljs-attribute">--net</span>=rnet <span class="hljs-attribute">--pnet_path</span>=./model_store/pnet_epoch_20.pt<br><span class="hljs-comment"># Before training Onet, please use your trained model path</span><br>python get_data.py <span class="hljs-attribute">--net</span>=onet <span class="hljs-attribute">--pnet_path</span>=./model_store/pnet_epoch_20.pt <span class="hljs-attribute">--rnet_path</span>=./model_store/rnet_epoch_20.pt<br></code></pre></td></tr></table></figure><h2 id="how-to-run">How to Run</h2><h3 id="train">Train</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> train.<span class="hljs-keyword">py</span> --net=pnet/rnet/onet #Specify the corresponding network <span class="hljs-keyword">to</span> start training<br>bash train.<span class="hljs-keyword">sh</span>                        #Alternatively, use the <span class="hljs-keyword">sh</span> <span class="hljs-keyword">file</span> <span class="hljs-keyword">to</span> train in order<br></code></pre></td></tr></table></figure><p><strong>The checkpoints will be saved in a subfolder of</strong><code>./model_store/*</code>.</p><h4 id="finetuning-from-an-existing-checkpoint">Finetuning from anexisting checkpoint</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">python train.py --net=pnet<span class="hljs-regexp">/rnet/</span>onet --load=[model path]<br></code></pre></td></tr></table></figure><p><strong>model path should be a subdirectory in the</strong><code>./model_store/</code> directory, e.g.<code>--load=./model_store/pnet_epoch_20.pt</code></p><h3 id="evaluate">Evaluate</h3><h4 id="use-the-sh-file-to-test-in-order">Use the sh file to test inorder</h4><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">bash <span class="hljs-keyword">test</span>.<span class="hljs-keyword">sh</span><br></code></pre></td></tr></table></figure><h4 id="to-detect-a-single-image">To detect a single image</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">python test.py <span class="hljs-attribute">--net</span>=pnet/rnet/onet  <span class="hljs-attribute">--path</span>=test.jpg<br></code></pre></td></tr></table></figure><h4 id="to-detect-a-video-stream-from-a-camera">To detect a video streamfrom a camera</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">python test.py <span class="hljs-attribute">--input_mode</span>=0<br></code></pre></td></tr></table></figure><h4 id="the-result-of---netpnet">The result of "--net=pnet"</h4><p><img src="https://img.enderfga.cn/img/20221208160900.png" /></p><h4 id="the-result-of---netrnet">The result of "--net=rnet"</h4><p><imgsrc="https://img.enderfga.cn/img/image-20221208155022083.png" /></p><h4 id="the-result-of---netonet">The result of "--net=onet"</h4><p><imgsrc="https://img.enderfga.cn/img/image-20221208155044451.png" /></p><embed src="./mtcnn.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Github: https://github.com/Enderfga/mtCNN_sysu&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>无人机飞越冰湖</title>
    <link href="http://enderfga.cn/2022/11/22/RL/"/>
    <id>http://enderfga.cn/2022/11/22/RL/</id>
    <published>2022-11-22T07:42:38.000Z</published>
    <updated>2022-12-11T13:05:23.626Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><embed src="./RL.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="强化学习" scheme="http://enderfga.cn/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Plant Pathology 2021 with MindSpore</title>
    <link href="http://enderfga.cn/2022/11/07/plant/"/>
    <id>http://enderfga.cn/2022/11/07/plant/</id>
    <published>2022-11-07T12:45:52.000Z</published>
    <updated>2022-11-07T12:49:00.716Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><embed src="./plant.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>命令行的艺术</title>
    <link href="http://enderfga.cn/2022/11/03/shell/"/>
    <id>http://enderfga.cn/2022/11/03/shell/</id>
    <published>2022-11-03T03:21:26.000Z</published>
    <updated>2022-11-03T03:29:11.731Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="命令行的艺术">命令行的艺术</h1><p><ahref="https://gitter.im/jlevy/the-art-of-command-line?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"><imgsrc="https://badges.gitter.im/Join%20Chat.svg"alt="Join the chat at https://gitter.im/jlevy/the-art-of-command-line" /></a></p><ul><li><a href="#前言">前言</a></li><li><a href="#基础">基础</a></li><li><a href="#日常使用">日常使用</a></li><li><a href="#文件及数据处理">文件及数据处理</a></li><li><a href="#系统调试">系统调试</a></li><li><a href="#单行脚本">单行脚本</a></li><li><a href="#冷门但有用">冷门但有用</a></li><li><a href="#仅限-os-x-系统">仅限 OS X 系统</a></li><li><a href="#仅限-windows-系统">仅限 Windows 系统</a></li><li><a href="#更多资源">更多资源</a></li><li><a href="#免责声明">免责声明</a></li></ul><p><imgsrc="https://img.enderfga.cn/img/image-20221103112627881.png" /></p><p>熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文是一份我在Linux上工作时，发现的一些命令行使用技巧的摘要。有些技巧非常基础，而另一些则相当复杂，甚至晦涩难懂。这篇文章并不长，但当你能够熟练掌握这里列出的所有技巧时，你就学会了很多关于命令行的东西了。</p><p>这篇文章是<a href="AUTHORS.md">许多作者和译者</a>共同的成果。这里的部分内容 <ahref="http://www.quora.com/What-are-some-lesser-known-but-useful-Unix-commands">首次</a><ahref="http://www.quora.com/What-are-the-most-useful-Swiss-army-knife-one-liners-on-Unix">出现</a>于 <ahref="http://www.quora.com/What-are-some-time-saving-tips-that-every-Linux-user-should-know">Quora</a>，但已经迁移到了 Github，并由众多高手做出了许多改进。如果你在本文中发现了错误或者存在可以改善的地方，请<ahref="/CONTRIBUTING.md"><strong>贡献你的一份力量</strong></a>。</p><h2 id="前言">前言</h2><p>涵盖范围：</p><ul><li>这篇文章不仅能帮助刚接触命令行的新手，而且对具有经验的人也大有裨益。本文致力于做到<em>覆盖面广</em>（涉及所有重要的内容），<em>具体</em>（给出具体的最常用的例子），以及<em>简洁</em>（避免冗余的内容，或是可以在其他地方轻松查到的细枝末节）。在特定应用场景下，本文的内容属于基本功或者能帮助您节约大量的时间。</li><li>本文主要为 Linux 所写，但在<a href="#仅限-os-x-系统">仅限 OS X系统</a>章节和<a href="#仅限-windows-系统">仅限 Windows系统</a>章节中也包含有对应操作系统的内容。除去这两个章节外，其它的内容大部分均可在其他类Unix 系统或 OS X，甚至 Cygwin 中得到应用。</li><li>本文主要关注于交互式 Bash，但也有很多技巧可以应用于其他 shell 和Bash 脚本当中。</li><li>除去“标准的”Unix命令，本文还包括了一些依赖于特定软件包的命令（前提是它们具有足够的价值）。</li></ul><p>注意事项：</p><ul><li>为了能在一页内展示尽量多的东西，一些具体的信息可以在引用的页面中找到。我们相信机智的你知道如何使用Google 或者其他搜索引擎来查阅到更多的详细信息。文中部分命令需要您使用<code>apt-get</code>，<code>yum</code>，<code>dnf</code>，<code>pacman</code>，<code>pip</code> 或<code>brew</code>（以及其它合适的包管理器）来安装依赖的程序。</li><li>遇到问题的话，请尝试使用 <ahref="http://explainshell.com/">Explainshell</a>去获取相关命令、参数、管道等内容的解释。</li></ul><h2 id="基础">基础</h2><ul><li>学习 Bash 的基础知识。具体地，在命令行中输入 <code>man bash</code>并至少全文浏览一遍; 它理解起来很简单并且不冗长。其他的 shell可能很好用，但 Bash 的功能已经足够强大并且到几乎总是可用的（如果你<em>只</em>学习 zsh，fish 或其他的 shell的话，在你自己的设备上会显得很方便，但过度依赖这些功能会给您带来不便，例如当你需要在服务器上工作时）。</li><li>熟悉至少一个基于文本的编辑器。通常而言 Vim （<code>vi</code>）会是你最好的选择，毕竟在终端中编辑文本时 Vim是最好用的工具（甚至大部分情况下 Vim 要比 Emacs、大型 IDE或是炫酷的编辑器更好用）。</li><li>学会如何使用 <code>man</code> 命令去阅读文档。学会使用<code>apropos</code> 去查找文档。知道有些命令并不对应可执行文件，而是在Bash 内置好的，此时可以使用 <code>help</code> 和 <code>help -d</code>命令获取帮助信息。你可以用 <code>type 命令</code>来判断这个命令到底是可执行文件、shell 内置命令还是别名。</li><li>学会使用 <code>&gt;</code> 和 <code>&lt;</code>来重定向输出和输入，学会使用 <code>|</code> 来重定向管道。明白<code>&gt;</code> 会覆盖了输出文件而 <code>&gt;&gt;</code>是在文件末添加。了解标准输出 stdout 和标准错误 stderr。</li><li>学会使用通配符 <code>*</code> （或许再算上 <code>?</code> 和<code>[</code>...<code>]</code>） 和引用以及引用中 <code>'</code> 和<code>"</code> 的区别（后文中有一些具体的例子）。</li><li>熟悉 Bash中的任务管理工具：<code>&amp;</code>，<strong>ctrl-z</strong>，<strong>ctrl-c</strong>，<code>jobs</code>，<code>fg</code>，<code>bg</code>，<code>kill</code>等。</li><li>学会使用 <code>ssh</code> 进行远程命令行登录，最好知道如何使用<code>ssh-agent</code>，<code>ssh-add</code>等命令来实现基础的无密码认证登录。</li><li>学会基本的文件管理工具：<code>ls</code> 和 <code>ls -l</code> （了解<code>ls -l</code>中每一列代表的意义），<code>less</code>，<code>head</code>，<code>tail</code>和 <code>tail -f</code> （甚至 <code>less +F</code>），<code>ln</code>和 <code>ln -s</code>（了解硬链接与软链接的区别），<code>chown</code>，<code>chmod</code>，<code>du</code>（硬盘使用情况概述：<code>du -hs *</code>）。 关于文件系统的管理，学习<code>df</code>，<code>mount</code>，<code>fdisk</code>，<code>mkfs</code>，<code>lsblk</code>。知道inode 是什么（与 <code>ls -i</code> 和 <code>df -i</code>等命令相关）。</li><li>学习基本的网络管理工具：<code>ip</code> 或<code>ifconfig</code>，<code>dig</code>。</li><li>学习并使用一种版本控制管理系统，例如 <code>git</code>。</li><li>熟悉正则表达式，学会使用<code>grep</code>／<code>egrep</code>，它们的参数中<code>-i</code>，<code>-o</code>，<code>-v</code>，<code>-A</code>，<code>-B</code>和 <code>-C</code> 这些是很常用并值得认真学习的。</li><li>学会使用 <code>apt-get</code>，<code>yum</code>，<code>dnf</code> 或<code>pacman</code> （具体使用哪个取决于你使用的 Linux发行版）来查找和安装软件包。并确保你的环境中有 <code>pip</code>来安装基于 Python 的命令行工具 （接下来提到的部分程序使用<code>pip</code> 来安装会很方便）。</li></ul><h2 id="日常使用">日常使用</h2><ul><li>在 Bash 中，可以通过按 <strong>Tab</strong> 键实现自动补全参数，使用<strong>ctrl-r</strong>搜索命令行历史记录（按下按键之后，输入关键字便可以搜索，重复按下<strong>ctrl-r</strong> 会向后查找匹配项，按下 <strong>Enter</strong>键会执行当前匹配的命令，而按下右方向键会将匹配项放入当前行中，不会直接执行，以便做出修改）。</li><li>在 Bash 中，可以按下 <strong>ctrl-w</strong>删除你键入的最后一个单词，<strong>ctrl-u</strong>可以删除行内光标所在位置之前的内容，<strong>alt-b</strong> 和<strong>alt-f</strong> 可以以单词为单位移动光标，<strong>ctrl-a</strong>可以将光标移至行首，<strong>ctrl-e</strong>可以将光标移至行尾，<strong>ctrl-k</strong>可以删除光标至行尾的所有内容，<strong>ctrl-l</strong> 可以清屏。键入<code>man readline</code> 可以查看 Bash 中的默认快捷键。内容有很多，例如<strong>alt-.</strong> 循环地移向前一个参数，而 <strong>alt-</strong>*可以展开通配符。</li><li>你喜欢的话，可以执行 <code>set -o vi</code> 来使用 vi风格的快捷键，而执行 <code>set -o emacs</code> 可以把它改回来。</li><li>为了便于编辑长命令，在设置你的默认编辑器后（例如<code>export EDITOR=vim</code>），<strong>ctrl-x</strong><strong>ctrl-e</strong> 会打开一个编辑器来编辑当前输入的命令。在 vi风格下快捷键则是 <strong>escape-v</strong>。</li><li>键入 <code>history</code> 查看命令行历史记录，再用<code>!n</code>（<code>n</code>是命令编号）就可以再次执行。其中有许多缩写，最有用的大概就是<code>!$</code>， 它用于指代上次键入的参数，而 <code>!!</code>可以指代上次键入的命令了（参考 man 页面中的“HISTORYEXPANSION”）。不过这些功能，你也可以通过快捷键 <strong>ctrl-r</strong>和 <strong>alt-.</strong> 来实现。</li><li><code>cd</code> 命令可以切换工作路径，输入 <code>cd ~</code>可以进入 home 目录。要访问你的 home 目录中的文件，可以使用前缀<code>~</code>（例如 <code>~/.bashrc</code>）。在 <code>sh</code>脚本里则用环境变量 <code>$HOME</code> 指代 home 目录的路径。</li><li>回到前一个工作路径：<code>cd -</code>。</li><li>如果你输入命令的时候中途改了主意，按下 <strong>alt-#</strong>在行首添加 <code>#</code> 把它当做注释再按下回车执行（或者依次按下<strong>ctrl-a</strong>， <strong>#</strong>，<strong>enter</strong>）。这样做的话，之后借助命令行历史记录，你可以很方便恢复你刚才输入到一半的命令。</li><li>使用 <code>xargs</code> （ 或<code>parallel</code>）。他们非常给力。注意到你可以控制每行参数个数（<code>-L</code>）和最大并行数（<code>-P</code>）。如果你不确定它们是否会按你想的那样工作，先使用<code>xargs echo</code> 查看一下。此外，使用 <code>-I&#123;&#125;</code>会很方便。例如：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">find . -name <span class="hljs-string">&#x27;*.py&#x27;</span> | xargs grep some_function<br>cat hosts | xargs -I&#123;&#125; ssh root@&#123;&#125; hostname<br></code></pre></td></tr></table></figure><ul><li><code>pstree -p</code> 以一种优雅的方式展示进程树。</li><li>使用 <code>pgrep</code> 和 <code>pkill</code>根据名字查找进程或发送信号（<code>-f</code> 参数通常有用）。</li><li>了解你可以发往进程的信号的种类。比如，使用<code>kill -STOP [pid]</code> 停止一个进程。使用<code>man 7 signal</code> 查看详细列表。</li><li>使用 <code>nohup</code> 或 <code>disown</code>使一个后台进程持续运行。</li><li>使用 <code>netstat -lntp</code> 或 <code>ss -plat</code>检查哪些进程在监听端口（默认是检查 TCP 端口; 添加参数 <code>-u</code>则检查 UDP 端口）或者 <code>lsof -iTCP -sTCP:LISTEN -P -n</code>(这也可以在 OS X 上运行)。</li><li><code>lsof</code> 来查看开启的套接字和文件。</li><li>使用 <code>uptime</code> 或 <code>w</code>来查看系统已经运行多长时间。</li><li>使用 <code>alias</code>来创建常用命令的快捷形式。例如：<code>alias ll='ls -latr'</code>创建了一个新的命令别名 <code>ll</code>。</li><li>可以把别名、shell 选项和常用函数保存在<code>~/.bashrc</code>，具体看下这篇<ahref="http://superuser.com/a/183980/7106">文章</a>。这样做的话你就可以在所有shell 会话中使用你的设定。</li><li>把环境变量的设定以及登陆时要执行的命令保存在<code>~/.bash_profile</code>。而对于从图形界面启动的 shell 和<code>cron</code> 启动的 shell，则需要单独配置文件。</li><li>要想在几台电脑中同步你的配置文件（例如 <code>.bashrc</code> 和<code>.bash_profile</code>），可以借助 Git。</li><li>当变量和文件名中包含空格的时候要格外小心。Bash变量要用引号括起来，比如 <code>"$FOO"</code>。尽量使用 <code>-0</code>或 <code>-print0</code> 选项以便用 NULL 来分隔文件名，例如<code>locate -0 pattern | xargs -0 ls -al</code> 或<code>find / -print0 -type d | xargs -0 ls -al</code>。如果 for循环中循环访问的文件名含有空字符（空格、tab 等字符），只需用<code>IFS=$'\n'</code> 把内部字段分隔符设为换行符。</li><li>在 Bash 脚本中，使用 <code>set -x</code>去调试输出（或者使用它的变体<code>set -v</code>，它会记录原始输入，包括多余的参数和注释）。尽可能地使用严格模式：使用<code>set -e</code> 令脚本在发生错误时退出而不是继续运行；使用<code>set -u</code> 来检查是否使用了未赋值的变量；试试<code>set -o pipefail</code>，它可以监测管道中的错误。当牵扯到很多脚本时，使用<code>trap</code> 来检测 ERR 和EXIT。一个好的习惯是在脚本文件开头这样写，这会使它能够检测一些错误，并在错误发生时中断程序并输出信息：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> -euo pipefail<br><span class="hljs-built_in">trap</span> <span class="hljs-string">&quot;echo &#x27;error: Script failed: see failed command above&#x27;&quot;</span> ERR<br></code></pre></td></tr></table></figure><ul><li>在 Bash 脚本中，子 shell（使用括号<code>(...)</code>）是一种组织参数的便捷方式。一个常见的例子是临时地移动工作路径，代码如下：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># do something in current dir</span><br>(<span class="hljs-built_in">cd</span> /some/other/dir &amp;&amp; other-command)<br><span class="hljs-comment"># continue in original dir</span><br></code></pre></td></tr></table></figure><ul><li>在 Bash中，变量有许多的扩展方式。<code>$&#123;name:?error message&#125;</code>用于检查变量是否存在。此外，当 Bash脚本只需要一个参数时，可以使用这样的代码<code>input_file=$&#123;1:?usage: $0 input_file&#125;</code>。在变量为空时使用默认值：<code>$&#123;name:-default&#125;</code>。如果你要在之前的例子中再加一个（可选的）参数，可以使用类似这样的代码<code>output_file=$&#123;2:-logfile&#125;</code>，如果省略了 <spanclass="math inline">\(2，它的值就为空，于是 `output_file` 就会被设为`logfile`。数学表达式：`i=\)</span>(( (i + 1) % 5))<code>。序列：</code>{1..10}<code>。截断字符串：</code><spanclass="math inline">\({var%suffix}` 和`\)</span>{var#prefix}<code>。例如，假设</code>var=foo.pdf<code>，那么</code>echo ${var%.pdf}.txt<code>将输出</code>foo.txt`。</li><li>使用括号扩展（<code>&#123;</code>...<code>&#125;</code>）来减少输入相似文本，并自动化文本组合。这在某些情况下会很有用，例如<code>mv foo.&#123;txt,pdf&#125; some-dir</code>（同时移动两个文件），<code>cp somefile&#123;,.bak&#125;</code>（会被扩展成<code>cp somefile somefile.bak</code>）或者<code>mkdir -p test-&#123;a,b,c&#125;/subtest-&#123;1,2,3&#125;</code>（会被扩展成所有可能的组合，并创建一个目录树）。</li><li>通过使用 <code>&lt;(some command)</code>可以将输出视为文件。例如，对比本地文件 <code>/etc/hosts</code>和一个远程文件：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">diff /etc/hosts &lt;(ssh somehost cat /etc/hosts)<br></code></pre></td></tr></table></figure><ul><li>编写脚本时，你可能会想要把代码都放在大括号里。缺少右括号的话，代码就会因为语法错误而无法执行。如果你的脚本是要放在网上分享供他人使用的，这样的写法就体现出它的好处了，因为这样可以防止下载不完全代码被执行。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<br>      <span class="hljs-comment"># 在这里写代码</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>了解 Bash 中的“here documents”，例如<code>cat &lt;&lt;EOF ...</code>。</li><li>在 Bash中，同时重定向标准输出和标准错误：<code>some-command &gt;logfile 2&gt;&amp;1</code>或者<code>some-command &amp;&gt;logfile</code>。通常，为了保证命令不会在标准输入里残留一个未关闭的文件句柄捆绑在你当前所在的终端上，在命令后添加<code>&lt;/dev/null</code> 是一个好习惯。</li><li>使用 <code>man ascii</code>查看具有十六进制和十进制值的ASCII表。<code>man unicode</code>，<code>man utf-8</code>，以及<code>man latin1</code> 有助于你去了解通用的编码信息。</li><li>使用 <code>screen</code> 或 <ahref="https://tmux.github.io/"><code>tmux</code></a>来使用多份屏幕，当你在使用 ssh 时（保存 session 信息）将尤为有用。而<code>byobu</code>可以为它们提供更多的信息和易用的管理工具。另一个轻量级的 session持久化解决方案是 <ahref="https://github.com/bogner/dtach"><code>dtach</code></a>。</li><li>ssh 中，了解如何使用 <code>-L</code> 或 <code>-D</code>（偶尔需要用<code>-R</code>）开启隧道是非常有用的，比如当你需要从一台远程服务器上访问web 页面。</li><li>对 ssh 设置做一些小优化可能是很有用的，例如这个<code>~/.ssh/config</code>文件包含了防止特定网络环境下连接断开、压缩数据、多通道等选项：</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">TCPKeepAlive</span>=<span class="hljs-literal">yes</span><br><span class="hljs-attribute">ServerAliveInterval</span>=15<br><span class="hljs-attribute">ServerAliveCountMax</span>=6<br><span class="hljs-attribute">Compression</span>=<span class="hljs-literal">yes</span><br>ControlMaster auto<br>ControlPath /tmp/%r@%h:%p<br>ControlPersist <span class="hljs-literal">yes</span><br></code></pre></td></tr></table></figure><ul><li>一些其他的关于 ssh的选项是与安全相关的，应当小心翼翼的使用。例如你应当只能在可信任的网络中启用<code>StrictHostKeyChecking=no</code>，<code>ForwardAgent=yes</code>。</li><li>考虑使用 <a href="https://mosh.mit.edu/"><code>mosh</code></a> 作为ssh 的替代品，它使用 UDP协议。它可以避免连接被中断并且对带宽需求更小，但它需要在服务端做相应的配置。</li><li>获取八进制形式的文件访问权限（修改系统设置时通常需要，但<code>ls</code>的功能不那么好用并且通常会搞砸），可以使用类似如下的代码：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">stat</span> -c <span class="hljs-string">&#x27;%A %a %n&#x27;</span> /etc/timezone<br></code></pre></td></tr></table></figure><ul><li>使用 <ahref="https://github.com/mooz/percol"><code>percol</code></a> 或者 <ahref="https://github.com/junegunn/fzf"><code>fzf</code></a>可以交互式地从另一个命令输出中选取值。</li><li>使用 <code>fpp</code>（<ahref="https://github.com/facebook/PathPicker">PathPicker</a>）可以与基于另一个命令(例如<code>git</code>）输出的文件交互。</li><li>将 web服务器上当前目录下所有的文件（以及子目录）暴露给你所处网络的所有用户，使用：<code>python -m SimpleHTTPServer 7777</code> （使用端口 7777 和 Python2）或 <code>python -m http.server 7777</code> （使用端口 7777 和 Python3）。</li><li>以其他用户的身份执行命令，使用 <code>sudo</code>。默认以 root用户的身份执行；使用 <code>-u</code> 来指定其他用户。使用<code>-i</code> 来以该用户登录（需要输入_你自己的_密码）。</li><li>将 shell 切换为其他用户，使用 <code>su username</code> 或者<code>su - username</code>。加入 <code>-</code>会使得切换后的环境与使用该用户登录后的环境相同。省略用户名则默认为root。切换到哪个用户，就需要输入_哪个用户的_密码。</li><li>了解命令行的 <ahref="https://wiki.debian.org/CommonErrorMessages/ArgumentListTooLong">128K限制</a>。使用通配符匹配大量文件名时，常会遇到“Argument list toolong”的错误信息。（这种情况下换用 <code>find</code> 或<code>xargs</code> 通常可以解决。）</li><li>当你需要一个基本的计算器时，可以使用 <code>python</code>解释器（当然你要用 python 的时候也是这样）。例如：</li></ul><figure class="highlight python-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python-repl"><span class="hljs-meta">&gt;&gt;&gt;</span> <span class="python"><span class="hljs-number">2</span>+<span class="hljs-number">3</span></span><br>5<br></code></pre></td></tr></table></figure><h2 id="文件及数据处理">文件及数据处理</h2><ul><li>在当前目录下通过文件名查找一个文件，使用类似于这样的命令：<code>find . -iname '*something*'</code>。在所有路径下通过文件名查找文件，使用<code>locate something</code> （但注意到 <code>updatedb</code>可能没有对最近新建的文件建立索引，所以你可能无法定位到这些未被索引的文件）。</li><li>使用 <ahref="https://github.com/ggreer/the_silver_searcher"><code>ag</code></a>在源代码或数据文件里检索（<code>grep -r</code> 同样可以做到，但相比之下<code>ag</code> 更加先进）。</li><li>将 HTML 转为文本：<code>lynx -dump -stdin</code>。</li><li>Markdown，HTML，以及所有文档格式之间的转换，试试 <ahref="http://pandoc.org/"><code>pandoc</code></a>。</li><li>当你要处理棘手的 XML 时候，<code>xmlstarlet</code>算是上古时代流传下来的神器。</li><li>使用 <a href="http://stedolan.github.io/jq/"><code>jq</code></a>处理 JSON。</li><li>使用 <a href="https://github.com/0k/shyaml"><code>shyaml</code></a>处理 YAML。</li><li>要处理 Excel 或 CSV 文件的话，<ahref="https://github.com/onyxfish/csvkit">csvkit</a> 提供了<code>in2csv</code>，<code>csvcut</code>，<code>csvjoin</code>，<code>csvgrep</code>等方便易用的工具。</li><li>当你要处理 Amazon S3 相关的工作的时候，<ahref="https://github.com/s3tools/s3cmd"><code>s3cmd</code></a>是一个很方便的工具而 <ahref="https://github.com/bloomreach/s4cmd"><code>s4cmd</code></a>的效率更高。Amazon 官方提供的 <ahref="https://github.com/aws/aws-cli"><code>aws</code></a> 以及 <ahref="https://github.com/donnemartin/saws"><code>saws</code></a> 是其他AWS 相关工作的基础，值得学习。</li><li>了解如何使用 <code>sort</code> 和 <code>uniq</code>，包括 uniq 的<code>-u</code> 参数和 <code>-d</code>参数，具体内容在后文单行脚本节中。另外可以了解一下<code>comm</code>。</li><li>了解如何使用 <code>cut</code>，<code>paste</code> 和<code>join</code> 来更改文件。很多人都会使用 <code>cut</code>，但遗忘了<code>join</code>。</li><li>了解如何运用 <code>wc</code>去计算新行数（<code>-l</code>），字符数（<code>-m</code>），单词数（<code>-w</code>）以及字节数（<code>-c</code>）。</li><li>了解如何使用 <code>tee</code> 将标准输入复制到文件甚至标准输出，例如<code>ls -al | tee file.txt</code>。</li><li>要进行一些复杂的计算，比如分组、逆序和一些其他的统计分析，可以考虑使用<ahref="https://www.gnu.org/software/datamash/"><code>datamash</code></a>。</li><li>注意到语言设置（中文或英文等）对许多命令行工具有一些微妙的影响，比如排序的顺序和性能。大多数Linux 的安装过程会将 <code>LANG</code>或其他有关的变量设置为符合本地的设置。要意识到当你改变语言设置时，排序的结果可能会改变。明白国际化可能会使sort或其他命令运行效率下降<em>许多倍</em>。某些情况下（例如集合运算）你可以放心的使用<code>export LC_ALL=C</code> 来忽略掉国际化并按照字节来判断顺序。</li><li>你可以单独指定某一条命令的环境，只需在调用时把环境变量设定放在命令的前面，例如<code>TZ=Pacific/Fiji date</code> 可以获取斐济的时间。</li><li>了解如何使用 <code>awk</code> 和 <code>sed</code>来进行简单的数据处理。 参阅 <a href="#one-liners">One-liners</a>获取示例。</li><li>替换一个或多个文件中出现的字符串：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">perl -pi.bak -e <span class="hljs-string">&#x27;s/old-string/new-string/g&#x27;</span> my-files-*.txt<br></code></pre></td></tr></table></figure><ul><li>使用 <ahref="https://github.com/jlevy/repren"><code>repren</code></a>来批量重命名文件，或是在多个文件中搜索替换内容。（有些时候<code>rename</code> 命令也可以批量重命名，但要注意，它在不同 Linux发行版中的功能并不完全一样。）</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 将文件、目录和内容全部重命名 foo -&gt; bar:</span><br>repren --full --preserve-case --from foo --to bar .<br><span class="hljs-comment"># 还原所有备份文件 whatever.bak -&gt; whatever:</span><br>repren --renames --from <span class="hljs-string">&#x27;(.*)\.bak&#x27;</span> --to <span class="hljs-string">&#x27;\1&#x27;</span> *.bak<br><span class="hljs-comment"># 用 rename 实现上述功能（若可用）:</span><br>rename <span class="hljs-string">&#x27;s/\.bak$//&#x27;</span> *.bak<br></code></pre></td></tr></table></figure><ul><li>根据 man 页面的描述，<code>rsync</code>是一个快速且非常灵活的文件复制工具。它闻名于设备之间的文件同步，但其实它在本地情况下也同样有用。在安全设置允许下，用<code>rsync</code> 代替 <code>scp</code>可以实现文件续传，而不用重新从头开始。它同时也是删除大量文件的<ahref="https://web.archive.org/web/20130929001850/http://linuxnote.net/jianingy/en/linux/a-fast-way-to-remove-huge-number-of-files.html">最快方法</a>之一：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">mkdir empty &amp;&amp; rsync -r --delete empty/ some-dir &amp;&amp; rmdir some-dir<br></code></pre></td></tr></table></figure><ul><li>若要在复制文件时获取当前进度，可使用 <code>pv</code>，<ahref="https://github.com/dmerejkowsky/pycp"><code>pycp</code></a>，<ahref="https://github.com/Xfennec/progress"><code>progress</code></a>，<code>rsync --progress</code>。若所执行的复制为block块拷贝，可以使用<code>dd status=progress</code>。</li><li>使用 <code>shuf</code>可以以行为单位来打乱文件的内容或从一个文件中随机选取多行。</li><li>了解 <code>sort</code> 的参数。显示数字时，使用 <code>-n</code> 或者<code>-h</code> 来显示更易读的数（例如 <code>du -h</code>的输出）。明白排序时关键字的工作原理（<code>-t</code> 和<code>-k</code>）。例如，注意到你需要 <code>-k1，1</code>来仅按第一个域来排序，而 <code>-k1</code>意味着按整行排序。稳定排序（<code>sort -s</code>）在某些情况下很有用。例如，以第二个域为主关键字，第一个域为次关键字进行排序，你可以使用<code>sort -k1，1 | sort -s -k2，2</code>。</li><li>如果你想在 Bash 命令行中写 tab 制表符，按下 <strong>ctrl-v</strong><strong>[Tab]</strong> 或键入 <code>$'\t'</code>（后者可能更好，因为你可以复制粘贴它）。</li><li>标准的源代码对比及合并工具是 <code>diff</code> 和<code>patch</code>。使用 <code>diffstat</code> 查看变更总览数据。注意到<code>diff -r</code> 对整个文件夹有效。使用<code>diff -r tree1 tree2 | diffstat</code>查看变更的统计数据。<code>vimdiff</code> 用于比对并编辑文件。</li><li>对于二进制文件，使用 <code>hd</code>，<code>hexdump</code> 或者<code>xxd</code> 使其以十六进制显示，使用<code>bvi</code>，<code>hexedit</code> 或者 <code>biew</code>来进行二进制编辑。</li><li>同样对于二进制文件，<code>strings</code>（包括 <code>grep</code>等工具）可以帮助在二进制文件中查找特定比特。</li><li>制作二进制差分文件（Delta 压缩），使用 <code>xdelta3</code>。</li><li>使用 <code>iconv</code> 更改文本编码。需要更高级的功能，可以使用<code>uconv</code>，它支持一些高级的 Unicode功能。例如，这条命令移除了所有重音符号：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">uconv -f utf-8 -t utf-8 -x <span class="hljs-string">&#x27;::Any-Lower; ::Any-NFD; [:Nonspacing Mark:] &gt;; ::Any-NFC; &#x27;</span> &lt; input.txt &gt; output.txt<br></code></pre></td></tr></table></figure><ul><li>拆分文件可以使用 <code>split</code>（按大小拆分）和<code>csplit</code>（按模式拆分）。</li><li>操作日期和时间表达式，可以用 <ahref="http://www.fresse.org/dateutils/"><code>dateutils</code></a> 中的<code>dateadd</code>、<code>datediff</code>、<code>strptime</code>等工具。</li><li>使用 <code>zless</code>、<code>zmore</code>、<code>zcat</code> 和<code>zgrep</code> 对压缩过的文件进行操作。</li><li>文件属性可以通过 <code>chattr</code>进行设置，它比文件权限更加底层。例如，为了保护文件不被意外删除，可以使用不可修改标记：<code>sudo chattr +i /critical/directory/or/file</code></li><li>使用 <code>getfacl</code> 和 <code>setfacl</code>以保存和恢复文件权限。例如：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">getfacl -R /some/path &gt; permissions.txt<br>setfacl --restore=permissions.txt<br></code></pre></td></tr></table></figure><ul><li>为了高效地创建空文件，请使用 <code>truncate</code>（创建<ahref="https://zh.wikipedia.org/wiki/稀疏文件">稀疏文件</a>），<code>fallocate</code>（用于ext4，xfs，btrf 和 ocfs2文件系统），<code>xfs_mkfile</code>（适用于几乎所有的文件系统，包含在xfsprogs 包中），<code>mkfile</code>（用于类 Unix 操作系统，比如 Solaris和 Mac OS）。</li></ul><h2 id="系统调试">系统调试</h2><ul><li><code>curl</code> 和 <code>curl -I</code> 可以被轻松地应用于 web调试中，它们的好兄弟 <code>wget</code> 也是如此，或者也可以试试更潮的 <ahref="https://github.com/jkbrzt/httpie"><code>httpie</code></a>。</li><li>获取 CPU 和硬盘的使用状态，通常使用使用<code>top</code>（<code>htop</code> 更佳），<code>iostat</code> 和<code>iotop</code>。而 <code>iostat -mxz 15</code> 可以让你获悉 CPU和每个硬盘分区的基本信息和性能表现。</li><li>使用 <code>netstat</code> 和 <code>ss</code>查看网络连接的细节。</li><li><code>dstat</code>在你想要对系统的现状有一个粗略的认识时是非常有用的。然而若要对系统有一个深度的总体认识，使用<ahref="https://github.com/nicolargo/glances"><code>glances</code></a>，它会在一个终端窗口中向你提供一些系统级的数据。</li><li>若要了解内存状态，运行并理解 <code>free</code> 和<code>vmstat</code> 的输出。值得留意的是“cached”的值，它指的是 Linux内核用来作为文件缓存的内存大小，而与空闲内存无关。</li><li>Java 系统调试则是一件截然不同的事，一个可以用于 Oracle 的 JVM 或其他JVM 上的调试的技巧是你可以运行 <code>kill -3 &lt;pid&gt;</code>同时一个完整的栈轨迹和堆概述（包括 GC的细节）会被保存到标准错误或是日志文件。JDK 中的<code>jps</code>，<code>jstat</code>，<code>jstack</code>，<code>jmap</code>很有用。<a href="https://github.com/aragozin/jvm-tools">SJK tools</a>更高级。</li><li>使用 <a href="http://www.bitwizard.nl/mtr/"><code>mtr</code></a>去跟踪路由，用于确定网络问题。</li><li>用 <a href="https://dev.yorhel.nl/ncdu"><code>ncdu</code></a>来查看磁盘使用情况，它比寻常的命令，如<code>du -sh *</code>，更节省时间。</li><li>查找正在使用带宽的套接字连接或进程，使用 <ahref="http://www.ex-parrot.com/~pdw/iftop/"><code>iftop</code></a> 或 <ahref="https://github.com/raboof/nethogs"><code>nethogs</code></a>。</li><li><code>ab</code> 工具（Apache 中自带）可以简单粗暴地检查 web服务器的性能。对于更复杂的负载测试，使用 <code>siege</code>。</li><li><a href="https://wireshark.org/"><code>wireshark</code></a>，<ahref="https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html"><code>tshark</code></a>和 <a href="http://ngrep.sourceforge.net/"><code>ngrep</code></a>可用于复杂的网络调试。</li><li>了解 <code>strace</code> 和<code>ltrace</code>。这俩工具在你的程序运行失败、挂起甚至崩溃，而你却不知道为什么或你想对性能有个总体的认识的时候是非常有用的。注意profile 参数（<code>-c</code>）和附加到一个运行的进程参数（<code>-p</code>）。</li><li>了解使用 <code>ldd</code> 来检查共享库。但是<ahref="http://www.catonmat.net/blog/ldd-arbitrary-code-execution/">永远不要在不信任的文件上运行</a>。</li><li>了解如何运用 <code>gdb</code>连接到一个运行着的进程并获取它的堆栈轨迹。</li><li>学会使用<code>/proc</code>。它在调试正在出现的问题的时候有时会效果惊人。比如：<code>/proc/cpuinfo</code>，<code>/proc/meminfo</code>，<code>/proc/cmdline</code>，<code>/proc/xxx/cwd</code>，<code>/proc/xxx/exe</code>，<code>/proc/xxx/fd/</code>，<code>/proc/xxx/smaps</code>（这里的<code>xxx</code> 表示进程的 id 或 pid）。</li><li>当调试一些之前出现的问题的时候，<ahref="http://sebastien.godard.pagesperso-orange.fr/"><code>sar</code></a>非常有用。它展示了 cpu、内存以及网络等的历史数据。</li><li>关于更深层次的系统分析以及性能分析，看看 <code>stap</code>（<ahref="https://sourceware.org/systemtap/wiki">SystemTap</a>），<ahref="https://en.wikipedia.org/wiki/Perf_(Linux)"><code>perf</code></a>，以及<ahref="https://github.com/draios/sysdig"><code>sysdig</code></a>。</li><li>查看你当前使用的系统，使用<code>uname</code>，<code>uname -a</code>（Unix／kernel 信息）或者<code>lsb_release -a</code>（Linux 发行版信息）。</li><li>无论什么东西工作得很欢乐（可能是硬件或驱动问题）时可以试试<code>dmesg</code>。</li><li>如果你删除了一个文件，但通过 <code>du</code>发现没有释放预期的磁盘空间，请检查文件是否被进程占用：<code>lsof | grep deleted | grep "filename-of-my-big-file"</code></li></ul><h2 id="单行脚本">单行脚本</h2><p>一些命令组合的例子：</p><ul><li>当你需要对文本文件做集合交、并、差运算时，<code>sort</code> 和<code>uniq</code> 会是你的好帮手。具体例子请参照代码后面的，此处假设<code>a</code> 与 <code>b</code>是两内容不同的文件。这种方式效率很高，并且在小文件和上 G的文件上都能运用（注意尽管在 <code>/tmp</code>在一个小的根分区上时你可能需要 <code>-T</code> 参数，但是实际上<code>sort</code> 并不被内存大小约束），参阅前文中关于<code>LC_ALL</code> 和 <code>sort</code> 的 <code>-u</code>参数的部分。</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">sort a b | uniq &gt; c   <span class="hljs-comment"># c 是 a 并 b</span><br>sort a b | uniq -d &gt; c   <span class="hljs-comment"># c 是 a 交 b</span><br>sort a b b | uniq -u &gt; c   <span class="hljs-comment"># c 是 a - b</span><br></code></pre></td></tr></table></figure><ul><li>使用 <code>grep . *</code>（每行都会附上文件名）或者<code>head -100 *</code>（每个文件有一个标题）来阅读检查目录下所有文件的内容。这在检查一个充满配置文件的目录（如<code>/sys</code>、<code>/proc</code>、<code>/etc</code>）时特别好用。</li><li>计算文本文件第三列中所有数的和（可能比同等作用的 Python代码快三倍且代码量少三倍）：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk <span class="hljs-string">&#x27;&#123; x += $3 &#125; END &#123; print x &#125;&#x27;</span> myfile<br></code></pre></td></tr></table></figure><ul><li>如果你想在文件树上查看大小/日期，这可能看起来像递归版的<code>ls -l</code> 但比 <code>ls -lR</code> 更易于理解：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">find . -<span class="hljs-built_in">type</span> f -ls<br></code></pre></td></tr></table></figure><ul><li>假设你有一个类似于 web服务器日志文件的文本文件，并且一个确定的值只会出现在某些行上，假设一个<code>acct_id</code> 参数在 URI 中。如果你想计算出每个<code>acct_id</code> 值有多少次请求，使用如下代码：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">egrep -o <span class="hljs-string">&#x27;acct_id=[0-9]+&#x27;</span> access.log | cut -d= -f2 | sort | uniq -c | sort -rn<br></code></pre></td></tr></table></figure><ul><li>要持续监测文件改动，可以使用<code>watch</code>，例如检查某个文件夹中文件的改变，可以用<code>watch -d -n 2 'ls -rtlh | tail'</code>；或者在排查 WiFi设置故障时要监测网络设置的更改，可以用<code>watch -d -n 2 ifconfig</code>。</li><li>运行这个函数从这篇文档中随机获取一条技巧（解析 Markdown文件并抽取项目）：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">taocl</span></span>() &#123;<br>  curl -s https://raw.githubusercontent.com/jlevy/the-art-of-command-line/master/README-zh.md|<br>    pandoc -f markdown -t html |<br>    iconv -f <span class="hljs-string">&#x27;utf-8&#x27;</span> -t <span class="hljs-string">&#x27;unicode&#x27;</span> |<br>    xmlstarlet fo --html --dropdtd |<br>    xmlstarlet sel -t -v <span class="hljs-string">&quot;(html/body/ul/li[count(p)&gt;0])[<span class="hljs-variable">$RANDOM</span> mod last()+1]&quot;</span> |<br>    xmlstarlet unesc | fmt -80<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="冷门但有用">冷门但有用</h2><ul><li><code>expr</code>：计算表达式或正则匹配</li><li><code>m4</code>：简单的宏处理器</li><li><code>yes</code>：多次打印字符串</li><li><code>cal</code>：漂亮的日历</li><li><code>env</code>：执行一个命令（脚本文件中很有用）</li><li><code>printenv</code>：打印环境变量（调试时或在写脚本文件时很有用）</li><li><code>look</code>：查找以特定字符串开头的单词或行</li><li><code>cut</code>，<code>paste</code> 和<code>join</code>：数据修改</li><li><code>fmt</code>：格式化文本段落</li><li><code>pr</code>：将文本格式化成页／列形式</li><li><code>fold</code>：包裹文本中的几行</li><li><code>column</code>：将文本格式化成多个对齐、定宽的列或表格</li><li><code>expand</code> 和<code>unexpand</code>：制表符与空格之间转换</li><li><code>nl</code>：添加行号</li><li><code>seq</code>：打印数字</li><li><code>bc</code>：计算器</li><li><code>factor</code>：分解因数</li><li><ahref="https://gnupg.org/"><code>gpg</code></a>：加密并签名文件</li><li><code>toe</code>：terminfo 入口列表</li><li><code>nc</code>：网络调试及数据传输</li><li><code>socat</code>：套接字代理，与 <code>netcat</code> 类似</li><li><ahref="https://github.com/mattthias/slurm"><code>slurm</code></a>：网络流量可视化</li><li><code>dd</code>：文件或设备间传输数据</li><li><code>file</code>：确定文件类型</li><li><code>tree</code>：以树的形式显示路径和文件，类似于递归的<code>ls</code></li><li><code>stat</code>：文件信息</li><li><code>time</code>：执行命令，并计算执行时间</li><li><code>timeout</code>：在指定时长范围内执行命令，并在规定时间结束后停止进程</li><li><code>lockfile</code>：使文件只能通过 <code>rm -f</code> 移除</li><li><code>logrotate</code>： 切换、压缩以及发送日志文件</li><li><code>watch</code>：重复运行同一个命令，展示结果并／或高亮有更改的部分</li><li><ahref="https://github.com/joh/when-changed"><code>when-changed</code></a>：当检测到文件更改时执行指定命令。参阅<code>inotifywait</code> 和 <code>entr</code>。</li><li><code>tac</code>：反向输出文件</li><li><code>shuf</code>：文件中随机选取几行</li><li><code>comm</code>：一行一行的比较排序过的文件</li><li><code>strings</code>：从二进制文件中抽取文本</li><li><code>tr</code>：转换字母</li><li><code>iconv</code> 或 <code>uconv</code>：文本编码转换</li><li><code>split</code> 和 <code>csplit</code>：分割文件</li><li><code>sponge</code>：在写入前读取所有输入，在读取文件后再向同一文件写入时比较有用，例如<code>grep -v something some-file | sponge some-file</code></li><li><code>units</code>：将一种计量单位转换为另一种等效的计量单位（参阅<code>/usr/share/units/definitions.units</code>）</li><li><code>apg</code>：随机生成密码</li><li><code>xz</code>：高比例的文件压缩</li><li><code>ldd</code>：动态库信息</li><li><code>nm</code>：提取 obj 文件中的符号</li><li><code>ab</code> 或 <ahref="https://github.com/wg/wrk"><code>wrk</code></a>：web服务器性能分析</li><li><code>strace</code>：调试系统调用</li><li><ahref="http://www.bitwizard.nl/mtr/"><code>mtr</code></a>：更好的网络调试跟踪工具</li><li><code>cssh</code>：可视化的并发 shell</li><li><code>rsync</code>：通过 ssh 或本地文件系统同步文件和文件夹</li><li><a href="https://wireshark.org/"><code>wireshark</code></a> 和 <ahref="https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html"><code>tshark</code></a>：抓包和网络调试工具</li><li><ahref="http://ngrep.sourceforge.net/"><code>ngrep</code></a>：网络层的grep</li><li><code>host</code> 和 <code>dig</code>：DNS 查找</li><li><code>lsof</code>：列出当前系统打开文件的工具以及查看端口信息</li><li><code>dstat</code>：系统状态查看</li><li><ahref="https://github.com/nicolargo/glances"><code>glances</code></a>：高层次的多子系统总览</li><li><code>iostat</code>：硬盘使用状态</li><li><code>mpstat</code>： CPU 使用状态</li><li><code>vmstat</code>： 内存使用状态</li><li><code>htop</code>：top 的加强版</li><li><code>last</code>：登入记录</li><li><code>w</code>：查看处于登录状态的用户</li><li><code>id</code>：用户/组 ID 信息</li><li><ahref="http://sebastien.godard.pagesperso-orange.fr/"><code>sar</code></a>：系统历史数据</li><li><ahref="http://www.ex-parrot.com/~pdw/iftop/"><code>iftop</code></a> 或 <ahref="https://github.com/raboof/nethogs"><code>nethogs</code></a>：套接字及进程的网络利用情况</li><li><code>ss</code>：套接字数据</li><li><code>dmesg</code>：引导及系统错误信息</li><li><code>sysctl</code>：在内核运行时动态地查看和修改内核的运行参数</li><li><code>hdparm</code>：SATA/ATA 磁盘更改及性能分析</li><li><code>lsblk</code>：列出块设备信息：以树形展示你的磁盘以及磁盘分区信息</li><li><code>lshw</code>，<code>lscpu</code>，<code>lspci</code>，<code>lsusb</code>和 <code>dmidecode</code>：查看硬件信息，包括CPU、BIOS、RAID、显卡、USB设备等</li><li><code>lsmod</code> 和<code>modinfo</code>：列出内核模块，并显示其细节</li><li><code>fortune</code>，<code>ddate</code> 和<code>sl</code>：额，这主要取决于你是否认为蒸汽火车和莫名其妙的名人名言是否“有用”</li></ul><h2 id="仅限-os-x-系统">仅限 OS X 系统</h2><p>以下是<em>仅限于</em> OS X 系统的技巧。</p><ul><li>用 <code>brew</code> （Homebrew）或者 <code>port</code>（MacPorts）进行包管理。这些可以用来在 OS X系统上安装以上的大多数命令。</li><li>用 <code>pbcopy</code> 复制任何命令的输出到桌面应用，用<code>pbpaste</code> 粘贴输入。</li><li>若要在 OS X 终端中将 Option 键视为 alt 键（例如在上面介绍的<strong>alt-b</strong>、<strong>alt-f</strong> 等命令中用到），打开偏好设置 -&gt; 描述文件 -&gt; 键盘 并勾选“使用 Option 键作为 Meta键”。</li><li>用 <code>open</code> 或者<code>open -a /Applications/Whatever.app</code>使用桌面应用打开文件。</li><li>Spotlight：用 <code>mdfind</code> 搜索文件，用 <code>mdls</code>列出元数据（例如照片的 EXIF 信息）。</li><li>注意 OS X 系统是基于 BSD UNIX 的，许多命令（例如<code>ps</code>，<code>ls</code>，<code>tail</code>，<code>awk</code>，<code>sed</code>）都和Linux 中有微妙的不同（ Linux 很大程度上受到了 System V-style Unix 和 GNU工具影响）。你可以通过标题为 "BSD General Commands Manual" 的 man页面发现这些不同。在有些情况下 GNU 版本的命令也可能被安装（例如<code>gawk</code> 和 <code>gsed</code> 对应 GNU 中的 awk 和 sed）。如果要写跨平台的 Bash 脚本，避免使用这些命令（例如，考虑 Python 或者<code>perl</code> ）或者经过仔细的测试。</li><li>用 <code>sw_vers</code> 获取 OS X 的版本信息。</li></ul><h2 id="仅限-windows-系统">仅限 Windows 系统</h2><p>以下是<em>仅限于</em> Windows 系统的技巧。</p><h3 id="在-winodws-下获取-unix-工具">在 Winodws 下获取 Unix 工具</h3><ul><li>可以安装 <a href="https://cygwin.com/">Cygwin</a> 允许你在 MicrosoftWindows 中体验 Unix shell的威力。这样的话，本文中介绍的大多数内容都将适用。</li><li>在 Windows 10 上，你可以使用 <ahref="https://msdn.microsoft.com/commandline/wsl/about">Bash on Ubuntuon Windows</a>，它提供了一个熟悉的 Bash 环境，包含了不少 Unix命令行工具。好处是它允许 Linux 上编写的程序在 Windows上运行，而另一方面，Windows 上编写的程序却无法在 Bash命令行中运行。</li><li>如果你在 Windows 上主要想用 GNU 开发者工具（例如 GCC），可以考虑 <ahref="http://www.mingw.org/">MinGW</a> 以及它的 <ahref="http://www.mingw.org/wiki/msys">MSYS</a> 包，这个包提供了例如bash，gawk，make 和 grep 的工具。MSYS 并不包含所有可以与 Cygwin媲美的特性。当制作 Unix 工具的原生 Windows 端口时 MinGW将特别地有用。</li><li>另一个在 Windows 下实现接近 Unix 环境外观效果的选项是 <ahref="https://github.com/dthree/cash">Cash</a>。注意在此环境下只有很少的Unix 命令和命令行可用。</li></ul><h3 id="实用-windows-命令行工具">实用 Windows 命令行工具</h3><ul><li>可以使用 <code>wmic</code> 在命令行环境下给大部分 Windows系统管理任务编写脚本以及执行这些任务。</li><li>Windows 实用的原生命令行网络工具包括<code>ping</code>，<code>ipconfig</code>，<code>tracert</code>，和<code>netstat</code>。</li><li>可以使用 <code>Rundll32</code> 命令来实现<ahref="http://www.thewindowsclub.com/rundll32-shortcut-commands-windows">许多有用的Windows 任务</a> 。</li></ul><h3 id="cygwin-技巧">Cygwin 技巧</h3><ul><li>通过 Cygwin 的包管理器来安装额外的 Unix 程序。</li><li>使用 <code>mintty</code> 作为你的命令行窗口。</li><li>要访问 Windows 剪贴板，可以通过 <code>/dev/clipboard</code>。</li><li>运行 <code>cygstart</code> 以通过默认程序打开一个文件。</li><li>要访问 Windows 注册表，可以使用 <code>regtool</code>。</li><li>注意 Windows 驱动器路径 <code>C:\</code> 在 Cygwin 中用<code>/cygdrive/c</code> 代表，而 Cygwin 的 <code>/</code> 代表 Windows中的 <code>C:\cygwin</code>。要转换 Cygwin 和 Windows 风格的路径可以用<code>cygpath</code>。这在需要调用 Windows 程序的脚本里很有用。</li><li>学会使用 <code>wmic</code>，你就可以从命令行执行大多数 Windows系统管理任务，并编成脚本。</li><li>要在 Windows 下获得 Unix 的界面和体验，另一个办法是使用 <ahref="https://github.com/dthree/cash">Cash</a>。需要注意的是，这个环境支持的Unix 命令和命令行参数非常少。</li><li>要在 Windows 上获取 GNU 开发者工具（比如 GCC）的另一个办法是使用 <ahref="http://www.mingw.org/">MinGW</a> 以及它的 <ahref="http://www.mingw.org/wiki/msys">MSYS</a> 软件包，该软件包提供了bash、gawk、make、grep 等工具。然而 MSYS 提供的功能没有 Cygwin完善。MinGW 在创建 Unix 工具的 Windows 原生移植方面非常有用。</li></ul><h2 id="更多资源">更多资源</h2><ul><li><ahref="https://github.com/alebcay/awesome-shell">awesome-shell</a>：一份精心组织的命令行工具及资源的列表。</li><li><ahref="https://github.com/herrbischoff/awesome-osx-command-line">awesome-osx-command-line</a>：一份针对OS X 命令行的更深入的指南。</li><li><ahref="http://redsymbol.net/articles/unofficial-bash-strict-mode/">Strictmode</a>：为了编写更好的脚本文件。</li><li><ahref="https://github.com/koalaman/shellcheck">shellcheck</a>：一个静态shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。</li><li><ahref="http://www.dwheeler.com/essays/filenames-in-shell.html">Filenamesand Pathnames in Shell</a>：有关如何在 shell脚本里正确处理文件名的细枝末节。</li><li><a href="http://datascienceatthecommandline.com/#tools">Data Scienceat the CommandLine</a>：用于数据科学的一些命令和工具，摘自同名书籍。</li></ul><h2 id="免责声明">免责声明</h2><p>除去特别小的工作，你编写的代码应当方便他人阅读。能力往往伴随着责任，你<em>有能力</em> 在 Bash 中玩一些奇技淫巧并不意味着你应该去做！;)</p><h2 id="授权条款">授权条款</h2><p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><imgsrc="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"alt="Creative Commons License" /></a></p><p>本文使用授权协议 <ahref="http://creativecommons.org/licenses/by-sa/4.0/">Creative CommonsAttribution-ShareAlike 4.0 International License</a>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>脑影像智能计算及其若干应用研究进展</title>
    <link href="http://enderfga.cn/2022/10/24/medical/"/>
    <id>http://enderfga.cn/2022/10/24/medical/</id>
    <published>2022-10-24T15:40:18.000Z</published>
    <updated>2022-10-24T16:08:48.511Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><embed src="./medical.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="智能医疗" scheme="http://enderfga.cn/tags/%E6%99%BA%E8%83%BD%E5%8C%BB%E7%96%97/"/>
    
  </entry>
  
  <entry>
    <title>OS实验报告：Linux、ROS安装与使用</title>
    <link href="http://enderfga.cn/2022/09/26/oslab1/"/>
    <id>http://enderfga.cn/2022/09/26/oslab1/</id>
    <published>2022-09-26T02:09:55.000Z</published>
    <updated>2022-10-24T16:08:48.531Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.001.jpeg" /></p><h1 id="实验一-linux的安装与使用"><strong>实验一Linux的安装与使用</strong></h1><h2 id="实验目的"><strong>实验目的</strong></h2><ol type="1"><li>掌握Linux环境下的命令操作，熟悉Linux操作系统的环境和使用，记录各种测试结果；</li><li>了解LINUX系统的安装过程，记录安装流程和界面；</li><li>搭建 ROS 环境，为后续实验做准备。</li></ol><h2 id="实验内容"><strong>实验内容</strong></h2><h3 id="任务描述"><strong>任务描述</strong></h3><p>1）Linux系统的安装</p><ol type="1"><li>调研、选择Linux版本</li><li>搜索、下载Linux安装所需文件</li><li>安装Linux</li></ol><p>2）Linux基本操作命令</p><p>熟悉pwd、ls、mkdir、cd、cat、man、cp等命令的使用</p><p>3）编写程序</p><ol type="1"><li>编写能输出“Helloworld!”问候语的C程序，并在终端中编译、执行。要求记录所使用的命令及结果。</li><li>编写一个程序：显示信息“Time forPlay!”，并能在后台运行一段时间（自定义）后，弹出信息提醒用户。要求记录所使用的命令及结果。（提示：使用sleep(s)函数）</li></ol><p>4）安装ROS</p><ol type="1"><li>按照官方教程或者快捷脚本安装好对应版本的ROS；</li><li>运行ROS代码例程。</li></ol><h3 id="实验说明"><strong>实验说明</strong></h3><p>本次实验中我通过VMware和WSL2两种方式安装了Linux操作系统，磁盘管理、文件管理的命令熟悉和程序编写使用WSL2完成，ROS的安装与代码例程使用有可视化界面的VMware完成。</p><h3 id="实验记录"><strong>实验记录</strong></h3><h4 id="实施步骤"><strong>实施步骤</strong></h4><h5 id="使用vmware安装">使用VMware安装：</h5><ul><li>以管理员身份运行Vmware Workstation</li><li>载入并安装ubuntu-22.04.1-desktop-amd64.iso</li></ul><h5 id="使用wsl2安装">使用WSL2安装：</h5><ul><li>启用“适用于 Linux 的 Windows 子系统”可选功能</li><li>启用“虚拟机平台”可选功能</li><li>下载安装 Linux 内核更新包并将 WSL 2 设置为默认版本</li><li>使用 Microsoft Store，选择并安装偏好的 Linux 分发版</li></ul><ol type="1"><li>在终端练习Linux的基本操作命令</li><li>编写程序</li><li>利用脚本安装ROS并运行代码例程</li></ol><h4 id="实验记录-1"><strong>实验记录</strong></h4><p>1.安装Linux</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.002.jpeg" /></p><p>图1-VM安装过程</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.003.jpeg" /></p><p>图2-安装成功</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.004.png" /></p><p>图3-WSL2安装过程</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.005.png" /></p><p>图4-WSL2安装成功</p><ol type="1"><li>熟悉操作命令</li></ol><p><strong>pwd命令：</strong></p><p>英文全拼：print work directory，该命令用于显示工作目录，</p><p>执行 pwd 指令可立刻得知您目前所在的工作目录的绝对路径名称。</p><p><strong>ls命令：</strong></p><p>英文全拼：listfiles，该命令用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。</p><p>参数说明：</p><ul><li><strong>-a</strong> 显示所有文件及目录 (.开头的隐藏文件也会列出)</li><li><strong>-l</strong>除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出</li><li><strong>-r</strong> 将文件以相反次序显示(原定依英文字母次序)</li><li><strong>-t</strong> 将文件依建立时间之先后次序列出</li><li><strong>-A</strong> 同 -a ，但不列出 "." (目前目录) 及 ".."(父目录)</li><li><strong>-F</strong> 在列出的文件名称后加一符号；例如可执行档则加"*", 目录则加 "/"</li><li><strong>-R</strong> 若目录下有文件，则以下之文件亦皆依序列出</li></ul><p><strong>mkdir命令：</strong></p><p>英文全拼：make directory，该命令用于创建目录。</p><p>参数说明：</p><ul><li><strong>-p</strong> 确保目录名称存在，不存在的就建一个。</li></ul><p><strong>cd命令：</strong></p><p>英文全拼：change directory，该命令用于切换当前工作目录。</p><p>其中 dirName表示法可为绝对路径或相对路径。若目录名称省略，则变换至使用者的 home 目录(也就是刚 login 时所在的目录)。</p><p>另外，~ 也表示为 home 目录 的意思， . 则是表示目前所在的目录， ..则表示目前目录位置的上一层目录。</p><p><strong>cat命令：</strong></p><p>英文全拼：concatenate,该命令用于连接文件并打印到标准输出设备上。</p><p>参数说明：</p><ul><li><strong>-n 或 --number</strong>：由 1开始对所有输出的行数编号。</li><li><strong>-b 或 --number-nonblank</strong>：和 -n相似，只不过对于空白行不编号。</li><li><strong>-s 或--squeeze-blank</strong>：当遇到有连续两行以上的空白行，就代换为一行的空白行。</li><li><strong>-v 或 --show-nonprinting</strong>：使用 ^ 和 M- 符号，除了LFD 和 TAB 之外。</li><li><strong>-E 或 --show-ends</strong> : 在每行结束处显示 $。</li><li><strong>-T 或 --show-tabs</strong>: 将 TAB 字符显示为 ^I。</li><li><strong>-A, --show-all</strong>：等价于 -vET。</li><li><strong>-e：</strong>等价于"-vE"选项；</li><li><strong>-t：</strong>等价于"-vT"选项；</li></ul><p><strong>cp命令：</strong></p><p>英文全拼：copy file，该命令主要用于复制文件或目录。</p><p>参数说明：</p><ul><li><strong>-a</strong>：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。</li><li><strong>-d</strong>：复制时保留链接。这里所说的链接相当于 Windows系统中的快捷方式。</li><li><strong>-f</strong>：覆盖已经存在的目标文件而不给出提示。</li><li><strong>-i</strong>：与 -f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y时目标文件将被覆盖。</li><li><strong>-p</strong>：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。</li><li><strong>-r</strong>：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。</li><li><strong>-l</strong>：不复制文件，只是生成链接文件。</li></ul><ol type="1"><li>编写程序</li></ol><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.006.png" /></p><p>图5-vim 键盘图</p><p>使用vi文书编辑器来编写要求的程序，代码如下：</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.007.png" /></p><p>图6-编写程序一</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.008.png" /></p><p>图7-编写程序二</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.009.png" /></p><p>图8-安装gcc并编译</p><ol type="1"><li>安装ROS</li></ol><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图9-使用官方教程手动安装</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图10-使用一键安装脚本</p><h2 id="实验结果"><strong>实验结果</strong></h2><ol type="1"><li>命令熟悉</li></ol><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图11-基本操作命令结果一</p><p>如图所示，打开终端之后起始目录显示为“~”，即主目录，也就是当前登录用户的用户目录，故输入pwd的结果为/home/enderfga。</p><p>ls-l会显示当前目录下文件的详细信息，图中是我编写的两个c文件以及编译产生的文件等，ls-al则会将以“.”开头的隐藏文件也展示出来。</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图12-基本操作命令结果二</p><p>直接使用不带参数的命令cd会改变目录至当前的用户目录，即“~”；</p><p>使用命令cd../..会到上一级目录的上一级目录中，在此处也就是根目录，即“/”。</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图13-文件操作命令结果</p><p>值得注意的是，输入命令ls-l后屏幕显示的第一列内容wsl2的结果和VMware的结果并不一样。</p><p>wsl2中显示的是文件大小，如果是文件，则表示该文件的大小，单位为字节；如果是目录，则表示该目录符所占的大小，并不表示该目录下所有文件的大小。</p><p>VMware的结果如图所示：</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.011.png" /></p><p>图14-ls -l命令解析</p><p>图中还记录了两个我搜索到的其他文件操作命令，分别是</p><p>“ls -l | grep "^-" | wc -l”：统计该目录下的文件个数；以及</p><p>“find . -name 'f*' -exec rm {};”：搜寻含有特定文件名的文件并删除。</p><ol type="1"><li>程序编写</li></ol><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.010.png" /></p><p>图15-C程序输出结果</p><p>根据题目要求，a.c编译的程序实现了输出“Helloworld!”问候语；b.c编译的程序会在运行时显示“Time forPlay!”，并能在后台运行，每10秒弹出信息提醒用户。</p><ol type="1"><li>ROS测试与例程</li></ol><p>值得注意的是，本次实验中我安装的是ROS2，故PPT中的命令不能生效。查阅资料之后，我使用ROS2对应的命令成功实现了用键盘控制小乌龟运动。</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.012.png" /></p><p>图16-ROS小乌龟测试</p><p>以下是我在过去的学习中使用ROS1和rviz可视化的A*轨迹规划和Turtlebot2轨迹仿真，在此处记录。</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.013.png" /><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.014.png" /></p><p>图17-轨迹规划与实机仿真</p><h2 id="总结与讨论"><strong>总结与讨论</strong></h2><p>1.在Linux中，如何设置前、后台命令和程序的执行？</p><p>在终端中如果对命令不加处理，那么命令会在前台运行；如果打算把命令放到后台运行，这个时候只需要在命令末尾加上&amp;即可，此时终端返回的是[作业号]进程号。</p><p>需要注意的是，如果程序在后台运行，那么它将无法接受用户的输入，但是其输出将显示在屏幕上（可能用户正在进行其他工作，突然冒出了错误输出），因此在后台执行的程序需是不需要人工干预的、输出被妥善处理（比如重定向）的程序。</p><p>有的时候在程序开始运行之后，想要将程序放在后台执行，这时需要按Ctrl+Z快捷键暂停程序，然后使用bg%作业号命令将其放入后台执行，也可以使用fg%作业号将程序从后台移到前台。</p><p>&amp;是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出。而nohup命令（nohangup）是不挂断的运行，故二者常常结合起来使用，这样就能使命令永久的在后台执行，例如：</p><p>CUDA_VISIBLE_DEVICES=0,1 nohup python train.py &gt; nohup.log2&gt;&amp;1 &amp;</p><p><code></code>即为使用2块GPU后台训练的常用python命令。</p><p>2.你所使用的Linux系统的内核版本是多少？用什么命令查看内核版本？目前你所了解的各发行版本的情况如何？</p><p>可以使用uname-a来查看内核版本，本次实验使用的WSL2和VMware分别输出的结果是：</p><p>Linux Enderfga-PC 5.4.72-microsoft-standard-WSL2 #1 SMP Wed Oct 2823:40:43 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</p><p>Linux enderfga-virtual-machine 5.15.0-47-generic #51-Ubuntu SMP ThuAug 11 07:51:15 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux</p><p>可以看出WSL2相较于虚拟机的差异还是挺大的，即使均为Ubuntu20.04在内核版本上也有不同。</p><p><code></code>查阅资料得知，比较流行的发行版本有10个。Ubuntu，LinuxMint和PCLinuxOS是其中最易于使用的。想快速部署使用，就可以选择这几个。尤其对于新手，已经做到了和Windows类似的易用程度了；另一方面，SlackwareLinux，ArchLinux和FreeBSD是更激进的发行版，更新比较频繁，所以需要有一定的基础；openSUSE，Fedora，DebianGNU/Linux和Mageia则是比较保守的发行版，稳定性是他们的特点，但是软件包都比较旧，很多桌面版本的新功能没法用；CentOS是一个企业级的发行版，适合那些喜欢稳定性，可靠性和软件长期支持的用户。</p><p>在学习的过程中我使用过Ubuntu和Centos。</p><p>3.你对Linux系统有什么认识？</p><p><code></code>在我心目中，Linux是一种可以和Windows相媲美的操作系统。Linux一切皆文件、完全开源免费、支持多用户和多任务、同时还支持多种架构平台、可靠的安全性、良好的稳定性、具有强大的网络功能、多样图形界面等等都展现其巨大的魅力。通过Linux我更好地了解学习了计算机网络、操作系统等的相关知识，也实践了深度学习、智能机器人技术等应用。</p><p><strong>五、CPU指令执行过程</strong></p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.015.png" /><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.016.png" /></p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.017.png" /></p><ol type="1"><li>首先，我们有一个自动计数器。这个自动计数器会随着时钟主频不断地自增，来作为我们的PC 寄存器。</li><li>在这个自动计数器的后面，我们连上一个译码器。译码器还要同时连着我们通过大量的D 触发器组成的内存。</li><li>自动计数器会随着时钟主频不断自增，从译码器当中，找到对应的计数器所表示的内存地址，然后读取出里面的CPU 指令。</li><li>读取出来的 CPU 指令会通过我们的 CPU 时钟的控制，写入到一个由 D触发器组成的寄存器，也就是指令寄存器当中。</li><li>在指令寄存器后面，我们可以再跟一个译码器。这个译码器不再是用来寻址的了，而是把我们拿到的指令，解析成opcode 和对应的操作数。</li><li>当我们拿到对应的 opcode 和操作数，对应的输出线路就要连接ALU，开始进行各种算术和逻辑运算。对应的计算结果，则会再写回到 D触发器组成的寄存器或者内存当中。</li></ol><p>模拟代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 模拟CPU指令执行过程流水线</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-comment">//取指令（Instruction Fetch，IF）阶段</span><br><span class="hljs-comment">//译码（Instruction Decode，ID）阶段</span><br><span class="hljs-comment">//执行指令（Execute，EX）阶段</span><br><span class="hljs-comment">//访存取数（Memory，MEM）阶段</span><br><span class="hljs-comment">//结果写回（Writeback，WB）阶段</span><br><span class="hljs-comment">//指令流水线</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InstructionPipeline</span></span><br><span class="hljs-class">&#123;</span><br><span class="hljs-keyword">public</span>:<br><span class="hljs-built_in">InstructionPipeline</span>()&#123;&#125;<br>~<span class="hljs-built_in">InstructionPipeline</span>()&#123;&#125;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">IF</span><span class="hljs-params">()</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">ID</span><span class="hljs-params">()</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">EX</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">MEM</span><span class="hljs-params">()</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">WB</span><span class="hljs-params">()</span></span>;<br><span class="hljs-comment">//Program Counter Register</span><br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*p) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<br><span class="hljs-comment">//Instruction Register</span><br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*i) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<br><span class="hljs-comment">//Register</span><br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*r) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<br><span class="hljs-comment">//Memory</span><br><span class="hljs-keyword">int</span> m;<br><span class="hljs-keyword">int</span> t;<br><span class="hljs-keyword">int</span> c = <span class="hljs-number">0</span>;<br>&#125;;<br><span class="hljs-comment">//加法算数指令</span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span> </span>&#123;<br><span class="hljs-keyword">return</span> a + b;<br>&#125;<br><span class="hljs-comment">//IF阶段</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">InstructionPipeline::IF</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*t) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<span class="hljs-comment">//temp</span><br>    <span class="hljs-comment">//从指令存储器中取指令</span><br>t = p;<br><span class="hljs-comment">//下一条指令地址，自动递增；</span><br><span class="hljs-comment">//p++;</span><br>    <span class="hljs-comment">//将指令存入指令寄存器</span><br>i = p;<br>&#125;<br><span class="hljs-comment">//ID阶段</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">InstructionPipeline::ID</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*t) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<span class="hljs-comment">//temp</span><br><span class="hljs-comment">//从指令寄存器中取指令</span><br>t = i;<br><span class="hljs-comment">//译码指令</span><br>i = add;<br><span class="hljs-comment">//将译码结果存入译码寄存器</span><br>r = i;<br>&#125;<br><span class="hljs-comment">//EX阶段</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">InstructionPipeline::EX</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a,<span class="hljs-keyword">int</span> b)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in"><span class="hljs-keyword">int</span></span> (*t) (<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b);<span class="hljs-comment">//temp</span><br><span class="hljs-comment">//从译码寄存器中取译码结果</span><br>t = r;<br><span class="hljs-comment">//执行指令</span><br><span class="hljs-keyword">int</span> result = (*t)(a, b);<br><span class="hljs-comment">//将执行结果存入执行寄存器</span><br>m = result;<br>&#125;<br><span class="hljs-comment">//MEM阶段</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">InstructionPipeline::MEM</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">int</span> temp = <span class="hljs-number">0</span>;<br><span class="hljs-comment">//访存取数</span><br>temp = m;<br><span class="hljs-comment">//将访存结果存入访存寄存器</span><br>t = temp;<br>&#125;<br><span class="hljs-comment">//WB阶段</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">InstructionPipeline::WB</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">int</span> temp = <span class="hljs-number">0</span>;<br><span class="hljs-comment">//从访存寄存器中取访存结果</span><br>temp = t;<br><span class="hljs-comment">//将结果写回</span><br>c = temp;<br>std::cout &lt;&lt; <span class="hljs-string">&quot;result = &quot;</span> &lt;&lt; c &lt;&lt; std::endl;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><span class="hljs-keyword">int</span> a = <span class="hljs-number">1</span>,b = <span class="hljs-number">1</span>;<br>InstructionPipeline CPU;<br>std::cout &lt;&lt; <span class="hljs-string">&quot;取指...&quot;</span> &lt;&lt; std::endl;<br>CPU.<span class="hljs-built_in">IF</span>();<br>std::cout &lt;&lt; <span class="hljs-string">&quot;译码...&quot;</span> &lt;&lt; std::endl;<br>CPU.<span class="hljs-built_in">ID</span>();<br>std::cout &lt;&lt; <span class="hljs-string">&quot;执行...&quot;</span> &lt;&lt; std::endl;<br>CPU.<span class="hljs-built_in">EX</span>(a, b);<br>std::cout &lt;&lt; <span class="hljs-string">&quot;存结果...&quot;</span> &lt;&lt; std::endl;<br>CPU.<span class="hljs-built_in">MEM</span>();<br>CPU.<span class="hljs-built_in">WB</span>();<br>std::cout &lt;&lt; <span class="hljs-string">&quot;下一条指令地址&quot;</span> &lt;&lt; std::endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>结果如下：</p><p><imgsrc="https://img.enderfga.cn/img/Aspose.Words.a6f73596-b4e5-4742-b430-3d062b8ab739.018.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://enderfga.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>how to use github?</title>
    <link href="http://enderfga.cn/2022/09/24/github/"/>
    <id>http://enderfga.cn/2022/09/24/github/</id>
    <published>2022-09-24T15:49:08.000Z</published>
    <updated>2022-10-24T16:08:48.501Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>作为全球最大的同性交友网站gayhub，应该怎么用</p><span id="more"></span><h1 id="开始之前">开始之前</h1><p>最好学会科学上网，我没办法教这个，虽然GitHub在国内是可以访问的，但有时候确实慢得难受</p><p>不过加速GitHub的方法千奇百怪，甚至可以开个游戏加速器，这里就不再赘述了</p><h1 id="介绍">介绍</h1><p>GitHub是全球最大的开源代码网站，这里充满了最前沿的学术、最沙雕的整活、最无私的分享（突然的感慨）。</p><p>科研领域的论文源码发这里，网友们的女装照片发这里，各种各样的知识整合也发在这里，相较于国内那些c**n啥的网站，软件安装包、电子书下载都要钱（发布者都不是原作者），真是天壤之别。</p><h1 id="教程">教程？</h1><p>虽然但是，每当我写一个博客想分享点什么的时候还是不禁会怀疑自己，发展到现在这个时代，无论什么内容都能在网上找到很优秀的案例，相较于bilibili这种视频媒体，写出来的文字确实略显苍白，更优质的内容比比皆是。</p><p>所以，想简单地了解一下如何使用的话，不妨从这里看起，浏览一些播放量高跟时间新的视频：</p><p>https://search.bilibili.com/all?keyword=GitHub</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925001854942.png" /></p><p>我写教程前也看了几个，蛮不错的！</p><p>（或许我也应该尝试使用视频录制来分享知识emmmm）</p><h1 id="案例">案例</h1><h2 id="任务内容">任务内容</h2><p>写都写了，总不能啥也不教吧，我决定以一个小案例来介绍一下我院学子都是怎么用GitHub炼丹的。</p><p>假设我们现在准备参与某个比赛或者完成某项作业，首先我们手里肯定先有的是数据集，以计算机视觉的第一次作业为例：</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925113333330.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220925113344247.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220925113401643.png" /></p><p>这是一个图像分类任务，评分依据是test集上的结果，所以我们肯定希望追求最好的模型，可以在paperwithcode的imageclassification对应的<ahref="https://paperswithcode.com/task/image-classification">sota</a>页面下了解目前哪些模型比较先进：</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925111228440.png" /></p><p>如果手里的数据集是cifar10/100，imagenet等经典数据，那榜单就有很高的参考价值了。鉴于我们手里的plantpathology-2021不在榜单上，我们从作业建议的模型，也是cv领域比较著名的Lenet、VGG16、ResNet50、VIT等试起。</p><h2 id="白嫖代码">白嫖代码</h2><p>我选择经典到不能再经典的ResNet50来作为本次案例的范本，作为15年提出来的里程碑级别的模型，想要跑resnet实在是太简单不过了。无论是直接百度就能查到网友们各种各样的实现，还是后续的改进优化版本，甚至是直接使用keras.applicationtorch.hub里直接调库，总之，实现目标的途径有很多。</p><p>直接在GitHub上搜索resnet，可以得到以下结果：</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925112920348.png" /></p><p>根据经验我会选择最下面蓝色框中的仓库，因为上面的内容都与我的需求不太相适配（AI不是分类，MXNet、tensorflow、keras不是熟悉的框架，Lua不是熟悉的语言）</p><p>Pytorch-cifar100这个库看标题是使用torch在cifar100数据集上的分类，所以我们只需要下载下来，修改读取数据的部分的代码便可以跑通，得到自己的分类结果。</p><p>如果是用自己的电脑在code处下载代码的zip比较方便，但如果是云服务器，一般都装有git，直接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone https://github.com/weiaicunzai/pytorch-cifar100.git<br></code></pre></td></tr></table></figure><h2 id="准备数据">准备数据</h2><p>我点开train.py阅读源码，找到读取数据的代码，一般这些工具函数都写在utils.py中，可以看到这里是利用pytorch自带的cifar100数据的</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925113534402.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220925113713799.png" /></p><p><imgsrc="https://img.enderfga.cn/img/image-20220925121714856.png" /></p><p>读到这里，只要改好我红框圈出来的代码其实就能开始在自己的数据集上训练了，我个人比较习惯使用的是Imagefolder函数，这个函数读取的数据集需要按照类别整理好数据，既train/第一类/第一类的图片，train/第二类/第二类的图片···以此类推。显然我们拿到的数据集不是这样，属于图片和对应的label分开存储的情况，所以我一般会写一个pre_data.py来整理数据，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据集路径（这是我电脑上的，使用时也需要修改）</span><br>path = <span class="hljs-string">r&#x27;C:\Users\User\Downloads\Compressed\plant_dataset\train&#x27;</span> <span class="hljs-comment">#训练集</span><br><span class="hljs-comment"># path = r&#x27;C:\Users\User\Downloads\Compressed\plant_dataset\test&#x27; #测试集</span><br><span class="hljs-comment"># path = r&#x27;C:\Users\User\Downloads\Compressed\plant_dataset\val&#x27; #验证集</span><br><span class="hljs-comment"># 读取csv中的label</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment"># 记得把train作对应修改</span><br>df = pd.read_csv(path+<span class="hljs-string">&#x27;/train&#x27;</span>+<span class="hljs-string">&#x27;_label.csv&#x27;</span>)<br><span class="hljs-comment"># 给每一种label创建文件夹，若已存在则跳过</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> df[<span class="hljs-string">&#x27;labels&#x27;</span>].unique():<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(path+<span class="hljs-string">&#x27;/&#x27;</span>+i):<br>        os.makedirs(path+<span class="hljs-string">&#x27;/&#x27;</span>+i)<br><span class="hljs-comment"># 将图片移动到对应的文件夹中</span><br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(df)):<br>    shutil.copy(path+<span class="hljs-string">&#x27;/images/&#x27;</span>+df[<span class="hljs-string">&#x27;images&#x27;</span>][i],path+<span class="hljs-string">&#x27;/&#x27;</span>+df[<span class="hljs-string">&#x27;labels&#x27;</span>][i]+<span class="hljs-string">&#x27;/&#x27;</span>+df[<span class="hljs-string">&#x27;images&#x27;</span>][i])<br><span class="hljs-comment"># 注意 这里用的是copy不是move，原来的图片还都保存在images文件夹中，训练前需要移走</span><br></code></pre></td></tr></table></figure><h2 id="配置环境">配置环境</h2><p>这一步根据打开的仓库操作，如果你的电脑上已经装好常用的torch，tensorflow等包可能也不需要</p><p>我一般的经验是使用anaconda创建一个虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda create -n myenv python=3.6 # 3.6是这个仓库Requirements里写的，注意修改<br>conda activate myenv<br></code></pre></td></tr></table></figure><p>有些readme里Requirements写完了一两个需要包，直接pip installxxx就好，有些则在仓库里准备了requirements.txt，使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install -r requirements.txt<br></code></pre></td></tr></table></figure><p>总之配置环境这步得对症下药，有时候还需要一些其他工作，具体查看readme对症下药。</p><hr /><p>注意，cv作业建议使用mindspore框架，而不是torch，所以情况会有所不同。</p><h1 id="all-in-all">all in all</h1><p>暂时想不到什么可以写的内容，有什么问题不如评论或者私信我吧，GitHub上的精品项目太多了，天天都在疯狂star。例如以上提到的模型，我推荐在这个<ahref="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing">仓库</a>里查看代码，还附带有讲解</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925130630621.png" /></p><p>希望看到这里的同学打开我的GitHub主页给我一个<ahref="https://github.com/Enderfga/Enderfga">star</a>。</p><p><imgsrc="https://img.enderfga.cn/img/image-20220925130725261.png" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为全球最大的同性交友网站gayhub，应该怎么用&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>脑电研究</title>
    <link href="http://enderfga.cn/2022/07/18/mind/"/>
    <id>http://enderfga.cn/2022/07/18/mind/</id>
    <published>2022-07-18T09:20:02.000Z</published>
    <updated>2022-10-24T16:08:48.513Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>脑电研究：通过神经活动和视觉特征的多模态学习</strong>解码大脑表征</p><span id="more"></span><embed src="./mind.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;脑电研究：通过神经活动和视觉特征的多模态学习&lt;/strong&gt;解码大脑表征&lt;/p&gt;</summary>
    
    
    
    
    <category term="无人系统" scheme="http://enderfga.cn/tags/%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
