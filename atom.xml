<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Enderfga&#39;Blog</title>
  
  
  <link href="http://enderfga.cn/atom.xml" rel="self"/>
  
  <link href="http://enderfga.cn/"/>
  <updated>2022-06-22T09:04:52.370Z</updated>
  <id>http://enderfga.cn/</id>
  
  <author>
    <name>Enderfga</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深度可分离卷积简介</title>
    <link href="http://enderfga.cn/2022/06/22/dsc/"/>
    <id>http://enderfga.cn/2022/06/22/dsc/</id>
    <published>2022-06-22T09:00:41.000Z</published>
    <updated>2022-06-22T09:04:52.370Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">  <script id="hbeData" type="hbeData" data-hmacdigest="ce095e397ce0ca13dab029258822977333d24e5336f179eb554b23ed3fca1185">786545e84501692c1080963bf451b3f69dd705f39c926779085b2f273176cdcdf451af237adf33265bd3eab4ed758400d31cfb6b400d50ebf0b1f9d7a9d05bd4ab5bd56d613d64a2a924038ffc1d9ffc2c4402136d556e2ed91b8bacc8c2cac9f218e91060bd4ee1744f4f2da80d044d0c0ccf3b45585357c66e88a8f9d31b49a1781532b2c770a33cec2065875bc35406dadc364c8fc7ef71aa25273208208dab1cbcd03fd44c92a1bf713775010608069398d2bb693110f5a72442bc02dfea0e0251264693c76aba60777ef8390949ab11b2c4d0bc57a5d6876cb072189b74822a738bf5dc05d57d5afa1df980b4fae6bd755b6f42601a9ea58a43d3d55806206a00bee09910852e23c14cc3ccaa5f3e95be2ff1f2ec4ed107337a675bc0731bdb208187785a8ef7f730c1892208665505eb516b8db843817bc7041edc7a5823abfe9b6a76f4045184e47beb86064d0f765b8d0237e95d55e57099ef5917aa</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-xray">      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">您好, 这里需要密码.</span>      </label>      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>      </svg>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">有东西被加密了, 请输入密码查看.</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>cifar10-horse生成任务</title>
    <link href="http://enderfga.cn/2022/06/20/horse/"/>
    <id>http://enderfga.cn/2022/06/20/horse/</id>
    <published>2022-06-20T00:46:42.000Z</published>
    <updated>2022-06-20T00:56:21.930Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">  <script id="hbeData" type="hbeData" data-hmacdigest="f21feef38d2c1c7a84e64e6cf6fd873694de45117fbde24518349b83585172db">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-xray">      <input class="hbe hbe-input-field hbe-input-field-xray" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-xray" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-xray">您好, 这里需要密码.</span>      </label>      <svg class="hbe hbe-graphic hbe-graphic-xray" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>        <path d="M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0"></path>      </svg>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">有东西被加密了, 请输入密码查看.</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>呼吸运动伪影的图像质量评估</title>
    <link href="http://enderfga.cn/2022/06/20/cmr/"/>
    <id>http://enderfga.cn/2022/06/20/cmr/</id>
    <published>2022-06-20T00:42:42.000Z</published>
    <updated>2022-06-20T00:46:22.854Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>基于深度学习分类网络的病变诊断之呼吸运动伪影的图像质量评估</strong></p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220620084604845.png" alt=""></p><embed src="./cmr.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;基于深度学习分类网络的病变诊断之呼吸运动伪影的图像质量评估&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习在遥感图像分类中的应用</title>
    <link href="http://enderfga.cn/2022/05/30/dl/"/>
    <id>http://enderfga.cn/2022/05/30/dl/</id>
    <published>2022-05-30T07:13:14.000Z</published>
    <updated>2022-05-30T07:16:24.561Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>深度学习期中应用调研报告</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/what-is-deep-learning.jpg" alt=""></p><embed src="./dl.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习期中应用调研报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Thinking Deeper about Cifar10</title>
    <link href="http://enderfga.cn/2022/05/30/cifar/"/>
    <id>http://enderfga.cn/2022/05/30/cifar/</id>
    <published>2022-05-30T07:07:15.000Z</published>
    <updated>2022-05-30T07:12:49.761Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>人工智能综合实验期中大作业cifar10分类</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/20220530151047.png" alt=""></p><embed src="./cifar.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;人工智能综合实验期中大作业cifar10分类&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Docker 常用命令与操作</title>
    <link href="http://enderfga.cn/2022/05/29/docker/"/>
    <id>http://enderfga.cn/2022/05/29/docker/</id>
    <published>2022-05-29T01:13:27.000Z</published>
    <updated>2022-06-26T06:41:47.893Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一张图整理Docker常用命令</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220529091219215.png" alt=""></p><h2 id="Docker基本概念"><a href="#Docker基本概念" class="headerlink" title="Docker基本概念"></a>Docker基本概念</h2><p>Docker 包括三个基本概念：</p><ul><li>镜像（<code>Image</code>）：Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。</li><li>容器（<code>Container</code>）：镜像（<code>Image</code>）和容器（<code>Container</code>）的关系，就像是面向对象程序设计中的 <code>类</code> 和 <code>实例</code> 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li><li>仓库（<code>Repository</code>）：仓库（<code>Repository</code>）类似Git的远程仓库，集中存放镜像文件。</li></ul><p>三者关系可以用下图表示：</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220529091304514.png" alt=""></p><p>接下来看一看Docker的常用命令。</p><h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><ul><li><p>查看Docker版本信息</p><p>docker version</p></li><li><p>查看docker简要信息</p><p>docker -v</p></li><li><p>启动Docker</p><p>systemctl start docker</p></li><li><p>关闭docker</p><p>systemctl stop docker</p></li><li><p>设置开机启动</p><p>systemctl enable docker</p></li><li><p>重启docker服务</p><p>service docker restart</p></li><li><p>关闭docker服务</p><p>service docker stop</p></li></ul><h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><h3 id="镜像仓库"><a href="#镜像仓库" class="headerlink" title="镜像仓库"></a>镜像仓库</h3><p><a href="https://link.segmentfault.com/?enc=eCypHIByefaQ8WlX8AJqSg%3D%3D.IV619qtOOjR2McoljdjR%2FNJXcHjWaOrxy0NrT1051R7Ot%2BYs5eUPDK5lfZoTudgL">Docker Hub</a> 等镜像仓库上有大量的高质量的镜像可以用，可以从仓库获取镜像。</p><ul><li><p>检索镜像</p><p>docker search 关键字</p></li><li><p>拉取镜像</p><p>docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]</p></li></ul><h3 id="镜像管理"><a href="#镜像管理" class="headerlink" title="镜像管理"></a>镜像管理</h3><ul><li><p>列出镜像</p><p>docker image ls<br>docker images</p></li><li><p>删除镜像</p><p># 删除指定镜像<br>docker rmi &lt;镜像Id&gt;</p></li><li><p>导出镜像</p><p># 将镜像保存为归档文件<br>docker save</p></li><li><p>导入镜像</p><p>docker load</p></li></ul><h3 id="Dockerfile构建镜像"><a href="#Dockerfile构建镜像" class="headerlink" title="Dockerfile构建镜像"></a>Dockerfile构建镜像</h3><p>Dockerfile 是一个文本格式的配 文件，用户可以使用 Dockerfile 来快速创建自定义的镜像。</p><p>Dockerfile 由一行行行命令语句组成，并且支持以＃开头的注释行.</p><h4 id="Dockerfile常见指令"><a href="#Dockerfile常见指令" class="headerlink" title="Dockerfile常见指令"></a>Dockerfile常见指令</h4><p>下面是Dockerfile中一些常见的指令：</p><ul><li>FROM：指定基础镜像</li><li>RUN：执行命令</li><li>COPY：复制文件</li><li>ADD：更高级的复制文件</li><li>CMD：容器启动命令</li><li>ENV：设置环境变量</li><li>EXPOSE：暴露端口</li></ul><p>其它的指令还有ENTRYPOINT、ARG、VOLUME、WORKDIR、USER、HEALTHCHECK、ONBUILD、LABEL等等。</p><h4 id="镜像构建"><a href="#镜像构建" class="headerlink" title="镜像构建"></a>镜像构建</h4><p> docker build</p><h4 id="镜像运行"><a href="#镜像运行" class="headerlink" title="镜像运行"></a>镜像运行</h4><p>镜像运行，就是新建并运行一个容器。</p><p> docker run [镜像ID]</p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><h3 id="容器生命周期"><a href="#容器生命周期" class="headerlink" title="容器生命周期"></a>容器生命周期</h3><ul><li><p>启动：启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动。</p><p># 新建并启动</p><p>docker run [镜像名/镜像ID]</p><p># 启动已终止容器</p><p>docker start [容器ID]</p></li><li><p>查看容器</p><p># 列出本机运行的容器</p><p>docker ps</p><p># 列出本机所有的容器（包括停止和运行）</p><p>docker ps -a</p></li><li><p>停止容器</p><p># 停止运行的容器</p><p>docker stop [容器ID]</p><p># 杀死容器进程</p><p>docker kill [容器ID]</p></li><li><p>重启容器</p><p>docker restart [容器ID]</p></li><li><p>删除容器</p><p>docker rm [容器ID]</p></li></ul><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><p>进入容器有两种方式：</p><p> # 如果从这个 stdin 中 exit，会导致容器的停止</p><p> docker attach [容器ID]</p><p> # 交互式进入容器</p><p> docker exec [容器ID]</p><p>进入容器通常使用第二种方式，<code>docker exec</code>后面跟的常见参数如下：</p><p>－ d, —detach 在容器中后台执行命令；</p><p> － i, —interactive=true I false ：打开标准输入接受用户输入命令</p><h3 id="导出和导入"><a href="#导出和导入" class="headerlink" title="导出和导入"></a>导出和导入</h3><ul><li><p>导出容器</p><p>#导出一个已经创建的容器到一个文件</p><p>docker export [容器ID]</p></li><li><p>导入容器</p><p># 导出的容器快照文件可以再导入为镜像</p><p>docker import [路径]</p></li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li><p>查看日志</p><p># 导出的容器快照文件可以再导入为镜像</p><p>docker logs [容器ID]</p></li></ul><p>这个命令有以下常用参数</p><p> -f : 跟踪日志输出</p><p>—since :显示某个开始时间的所有日志</p><p>-t : 显示时间戳</p><p>—tail :仅列出最新N条容器日志</p><ul><li><p>复制文件</p><p># 从主机复制到容器</p><p>sudo docker cp host_path containerID:container_path</p><p># 从容器复制到主机</p><p>sudo docker cp containerID:container_path host_path</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;一张图整理Docker常用命令&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>安の推荐</title>
    <link href="http://enderfga.cn/2022/05/28/suggest/"/>
    <id>http://enderfga.cn/2022/05/28/suggest/</id>
    <published>2022-05-28T13:33:51.000Z</published>
    <updated>2022-05-29T00:39:42.466Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528213455416.png" alt=""></p><p>一时兴起，乱七八糟的推荐；需要付费的也很多，一分钱一分货，希望大家支持正版</p><span id="more"></span><h1 id="书签"><a href="#书签" class="headerlink" title="书签"></a>书签</h1><h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><p><a href="https://enderfga.cn/">我的博客</a></p><p>没想到吧，我的第一个书签居然是自己的博客 虽然没什么高质量文章，但拿来当知识备忘录还是挺方便的~</p><p><a href="https://pan.baidu.com/disk/home?#/all?path=%2F&amp;vmode=list">百度云</a></p><p>上了大学之后使用频率很低，当然主要原因还是我校的网速….不过有时候还是会拿来下下电影</p><p><a href="https://translate.google.cn/">Google 翻译</a></p><p><a href="https://dict.cnki.net/index">CNKI翻译助手</a></p><p><a href="https://www.deepl.com/translator">DeepL翻译</a></p><p>那个知网的翻译助手在b站刷视频被推荐的，还没有怎么用过；一般用deepl＋google对照使用</p><p><a href="http://www.gamersky.com/">游民星空 </a></p><p>使用频率最高的网站，从08年开始每天晚上19点定时打开看囧图，虽然怪傻的</p><p>现在没有盗版游戏下载了，但各种各样的资讯当新闻看还挺有趣的(评论区的游民老哥好玩)</p><p><a href="https://www.youtube.com/">YouTube</a></p><p>没啥好说的，其实我大部分时间也只用bilibili</p><p><a href="https://www.zhihu.com/">知乎</a></p><p>搜搜各种知识，看看文章还有科技产品推荐</p><p><a href="https://portal.sysu.edu.cn/#/index">中山大学统一门户</a></p><p>我校官网的新ui很不错，安卓端也适配了</p><p><a href="https://github.com/Enderfga?tab=stars">Your Stars</a></p><p>习惯了收藏stars来上GitHub，GitHub的使用就不用介绍了</p><p><a href="https://2550505.com/">毛怪俱乐部</a></p><p>毛怪居然有自己的官网了！好像刚刚起步，希望早日能买到hanser的专辑！</p><p><a href="https://www.douyin.com/">抖音-记录美好生活</a></p><p>为了防沉迷，我卸载了抖音；但还是想刷，有时候就看看网页版</p><p><a href="https://eshop-prices.com/?currency=CNY">eShop-Prices.com – The best price comparison tool for Nintendo Switch games – Chinese Renminbi Yuan</a></p><p>一个显示switch游戏最低价格的网站，不过我是大慈善家，买了也没有时间玩</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528220111823.png" alt=""></p><h2 id="影视"><a href="#影视" class="headerlink" title="影视"></a>影视</h2><p>由于下面的网站特殊性，他们常常跑路换域名···</p><p><a href="http://www.rrdyw.net/">人人电影网</a></p><p><a href="http://www.btbtt15.com/">BT之家-BT电影天堂-影视资源交流社区</a></p><p><a href="http://www.kisssub.org/">爱恋动漫</a></p><p>下载电影，番剧···等等的地方，如果能打开的话，都挺好用的</p><p><a href="http://www.age.tv/">在线动画 动漫下载 - AGE动漫</a></p><p>在线看番，无弹幕，更新快</p><p><a href="https://omofun.tv/">OmoFun动漫视频网 - (￣﹃￣)~omO</a></p><p>在线看番，有弹幕</p><p><a href="http://dyxs14.com/">电影先生 - 聚合全网高清影视在线观看、下载</a></p><p>在线看剧</p><p><a href="http://www.549.tv/">影视森林——观影第一站</a></p><p>一个集合导航类型的网站，不怎么用，除非上面的都打不开会试着在里面探索新的</p><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p><a href="https://apod.nasa.gov/">Astronomy Picture of the Day</a></p><p>每天一张宇宙照片和介绍</p><p><a href="https://wallhaven.cc/">Awesome Wallpapers - wallhaven.cc</a></p><p>精美的壁纸，登录解锁全部内容</p><p><a href="https://unsplash.com/">Beautiful Free Images &amp; Pictures | Unsplash</a></p><p>好看的图片，不是壁纸类型的</p><p><a href="https://tinypng.com/">TinyPNG</a></p><p><a href="https://www.picdiet.com/zh-cn">Picdiet - 压缩图片</a></p><p>图片无损压缩</p><p><a href="https://bigjpg.com/">Bigjpg</a></p><p>图片无损放大</p><p><a href="https://wordart.com/">WordArt.com - Word Cloud Art Creator</a></p><p>制作词云图，刚开始我用python，后来发现还是用这个拿去骗人效果好一点</p><p><a href="https://photomosh.com/">PhotoMosh</a></p><p>一个“无聊”的网站，会随机给你的图片来点图像增广，建议自己试试</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528221059628.png" alt=""></p><h2 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h2><p>这里写的是关于软件的书签，并不是推荐软件</p><p><a href="https://amazing-apps.gitbooks.io/windows-apps-that-amaze-us/content/zh-CN/?q=">序章 · 绝赞应用</a></p><p>GitHub上一个旨在介绍 Windows 绝妙项目的网站，现在能用，不过好像断更了</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528221330033.png" alt=""></p><p><a href="https://music.hwkxk.cn/">音乐助手 - 简洁极速搜索解析各大平台音乐</a></p><p>穷人的最爱，不过最近无了，我也是写这个才发现的，希望能回来</p><p><a href="https://www.ghxi.com/">果核剥壳 - 互联网的净土</a></p><p><a href="https://www.rjsos.com/">软件SOS</a></p><p>两个我下载软件的地方，类似于xmind，bandicam等好用的付费软件上面可能有破解版</p><h2 id="知识"><a href="#知识" class="headerlink" title="知识"></a>知识</h2><p>真正的干货</p><p><a href="http://www.ucdrs.superlib.net/">全国图书馆参考咨询联盟</a></p><p><a href="http://libgen.rs/">Library Genesis</a></p><p><a href="https://www.jiumodiary.com/">Jiumo Search 鸠摩搜索</a></p><p><a href="https://zh.z-lib.org/">Z-Library</a></p><p>以上是下载电子书的地方，zlibrary使用频率最高，我还有把我有上面没有的pdf上传，第二个下载国外的书用的，鸠摩像是个百度网盘搜索网站，走投无路的时候会搜；最后这个参考咨询联盟其实本身没什么卵用，但结合油猴脚本可以简单地花1,2块钱买到pdf，比淘宝方便</p><p><a href="https://apps.webofknowledge.com/UA_GeneralSearch_input.do?product=UA&amp;search_mode=GeneralSearch&amp;SID=D4NArRzmguT3sCmspng&amp;preferencesSaved=">Web of Science</a></p><p><a href="https://www.cnki.net/">中国知网</a></p><p><a href="https://scholar.google.com/">Google Scholar</a></p><p><a href="https://xueshu.baidu.com/">百度学术</a></p><p><a href="https://readpaper.com/">论文阅读-专业的学术讨论社区</a></p><p>基本只用webofscience和谷歌学术，百度学术用来批量引用；那个社区可以读读文献，划词翻译，不过能实现这个功能的方式实在太多了；知网大一写政治课作业的时候还用，现在我甚至点不开了。</p><p><a href="https://oi-wiki.org/">OI Wiki</a></p><p><a href="https://labuladong.gitee.io/algo/">labuladong 的算法小抄 </a></p><p>收藏了但就是懒得点开的算法知识</p><p><a href="https://www.runoob.com/">菜鸟教程</a></p><p><a href="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a></p><p>高质量自学内容，但就是很难有被点开的机会</p><p><a href="https://zh.wikipedia.org/wiki/Wikipedia:首页">维基百科</a></p><p>虽然收藏的是中文首页，但还是用的英文版搜资料（会全很多，翻译不及时）</p><p><a href="https://www.latexlive.com/">在线LaTeX公式编辑器</a></p><p>ocr公式，以前一天50次，现在一天10次，改用mathpix了</p><p><a href="https://paperswithcode.com/sota">State-of-the-Art</a></p><p>机器学习深度学习写作业的时候的灵感来源，或者说是借鉴来源；paperwithcode真的很方便</p><p><a href="https://cn.overleaf.com/latex/templates">Templates - - Overleaf</a></p><p>小组大作业会大家一起用这个在线编译，模板的话我还是习惯自己常备的那3个</p><p><a href="https://spcqwserdvymm.com.vika.cn/share/shryNwH3HRgvzMTaZVAGx/fodkuzz5eaw0w">🔔 Efficiency-follow</a></p><p>乱七八糟的好东西合集，自己探索吧</p><p><a href="https://snip.mathpix.com/">Snip Notes</a></p><p>mathpix他们的一个产品，我拿来上传老师发的pdf然后提取内容放到我的作业里</p><p><a href="https://quillbot.com/">Paraphrasing Tool | QuillBot AI</a></p><p>英文写作小帮手，写出来之后能帮忙提升流畅度、专业性等等等等，功能高级的部分要付费</p><p><a href="https://stackoverflow.com/">Stack Overflow</a></p><p>程序猿的“知乎”，一般有bug在这一搜都能搜到，我没怎么试过问答</p><p><a href="https://zs.symbolab.com/">Symbolab 数学求解器 - 分步计算器</a></p><p>当你高数知识忘的一干二净，遇到问题就用这个来解吧，还有分步过程</p><p><a href="https://www.ilovepdf.com/zh-cn/unlock_pdf">解锁 PDF文件</a></p><p>里面还有各种各样的pdf功能，不过学校提供的正版foxit也基本都有，主要是用来解锁deepl翻译的文档（只读）</p><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="去广告"><a href="#去广告" class="headerlink" title="去广告"></a>去广告</h2><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223252001.png" alt=""></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223408102.png" alt=""></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223542478.png" alt=""></p><p><a href="https://chrome.google.com/webstore/detail/adblock-plus-free-ad-bloc/cfhdojbkjhnklbpkdaibdccddilifddb">Adblock Plus</a></p><p><a href="https://chrome.google.com/webstore/detail/adblock-%E2%80%94-best-ad-blocker/gighmmpiobklfepjocnamgkkbiglidom">AdBlock</a></p><p><a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm">uBlock Origin</a></p><p>这仨就没什么好解释的，对广告零容忍，也不嫌多就都装了；可以指定屏蔽内容，我把GitHub上那些*独分子都屏蔽了</p><h2 id="邮件"><a href="#邮件" class="headerlink" title="邮件"></a>邮件</h2><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223729300.png" alt=""></p><p>方便我查收<a href="https://chrome.google.com/webstore/detail/checker-plus-for-gmail/oeopbcgkkoapgobdbedcemjljbihmemj">gmail</a>的邮件，会有消息提醒等</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223816247.png" alt=""></p><p>作为一个强迫症，我看到我的每一个盘多了几MB<a href="https://chrome.google.com/webstore/detail/clean-master-the-best-chr/eagiakjmjnblliacokhcalebgnhellfi">垃圾</a>我都会很难受</p><h2 id="翻译写作"><a href="#翻译写作" class="headerlink" title="翻译写作"></a>翻译写作</h2><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223919801.png" alt=""></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528223946957.png" alt=""></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528224113309.png" alt=""></p><p>刚开始只用<a href="https://chrome.google.com/webstore/detail/%E6%B2%99%E6%8B%89%E6%9F%A5%E8%AF%8D-%E8%81%9A%E5%90%88%E8%AF%8D%E5%85%B8%E5%88%92%E8%AF%8D%E7%BF%BB%E8%AF%91/cdonnmffkdaoajfknoeeecmchibpmkmg">沙拉查词</a>的，各种功能非常全面；后来用<a href="https://chrome.google.com/webstore/detail/deepl-translate-beta-vers/cofdbpoegempjloogbagkncekinflcnj">deepl</a>边写边译（中译英），方便跟外国友人交流，写完的内容还可以用<a href="https://chrome.google.com/webstore/detail/quillbot-for-chrome/iidnbdjijdkbmajdffnidomddglmieko">quillbot</a>修改润色。虽然以上内容只会显得我英语水平很捞，但我用的蛮开心</p><h2 id="使用体验"><a href="#使用体验" class="headerlink" title="使用体验"></a>使用体验</h2><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528224252617.png" alt=""></p><p><a href="https://chrome.google.com/webstore/detail/gitzip-for-github/ffabmkklhbepgcgfonabamgnfafbdlkn">gitzip</a>，打包GitHub上指定文件或者文件夹，不用全部clone下来方便很多</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528224450069.png" alt=""></p><p><a href="https://limestart.cn/">青柠起始页</a></p><p>虽然装了扩展但主要还是使用这个网页，我的新标签页主页都是这个，简洁美观，左上角是便签可以倒计时。</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528224715406.png" alt=""></p><p><a href="https://extensions.redeviation.com/">书签侧边栏</a>，如图所示，我那一大堆乱七八糟的书签就是这样打理的</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528224903817.png" alt=""></p><p><a href="https://chrome.google.com/webstore/detail/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%8A%A9%E6%89%8B%EF%BC%9Abilibilicom-%E7%BB%BC%E5%90%88%E8%BE%85%E5%8A%A9%E6%89%A9%E5%B1%95/kpbnombpnpcffllnianjibmpadjolanh">哔哩哔哩助手</a>，这就是为什么我的书签里没有b站的原因，我都是从这里跳转的。功能非常非常丰富，包括但不限于下载各个分辨率的视频和弹幕，实现各种各样的默认跳转（自动宽屏，关弹幕，4k···），自动帮我给hanser三连</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528225202730.png" alt=""></p><p>虽然经常说油猴脚本，但我自己用的还是暴力猴，作者是中国人，在哪些网页使用体验不好了我就搜一下</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528225352529.png" alt=""></p><p>往往会有惊喜</p><p>本来想专门写一个栏目介绍了，但我好累</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528225516406.png" alt=""></p><p>大家看名字识功能吧</p><p>比较推荐的有网页限制解除，很多网站不能复制就很烦；秀读图书互转，结合这个上面提到的参考咨询联盟才能轻松下载pdf；</p><p>百度网盘简易下载助手，目前还能用，校园网满速；AC-baidu，对百度谷歌等界面都优化了。（黑是因为我系统设置了暗）</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528225804605.png" alt=""></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528225854431.png" alt=""></p><h1 id="软件-1"><a href="#软件-1" class="headerlink" title="软件"></a>软件</h1><p>没动力写了，摆烂式推荐</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528230140552.png" alt=""></p><p>foxit pdf：功能全面，毕竟是学校帮忙付费了的</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528230232796.png" alt=""></p><p>vscode：啥都能写，加上copilot，一分钟上千行代码不是梦（bushi）</p><p>感觉vscode也可以写一个扩展分享， 但我好懒，感兴趣地可以了解一下图里这个，根据注释自动写代码</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528230544526.png" alt=""></p><p>格式工厂：啥都能给你转转，除了各种格式转换，我还用来简单地剪辑之类的；可以把各大软件的付费格式转换成常见格式</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528230709483.png" alt=""></p><p>anaconda：maybe是python学习必备软件之一（吧）,搭建环境之后我更习惯写jupyter notebook（但用的是vscode）</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528231002743.png" alt=""></p><p>mathpix：上面一张图展示功能，快捷键截图之后就能ocr出来贴typora或者latex，甚至office系列软件</p><p>教育邮箱每月100次</p><p>列举剩下的一些体验良好的软件：</p><p>视频播放我用potplayer；解压缩我用bandizip；视频录制我用bandicam；思维导图我用xmind；</p><p>浏览器当然是chrome，不过edge也很不错；备忘录用microsoft to do；</p><p>备份习惯用google drive，打游戏用一个叫灵缇的小众加速器·····</p><p>暂时到这里吧，如果我又双叒叕心血来潮也许会更新。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220528213455416.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;一时兴起，乱七八糟的推荐；需要付费的也很多，一分钱一分货，希望大家支持正版&lt;/p&gt;</summary>
    
    
    
    
    <category term="闲谈" scheme="http://enderfga.cn/tags/%E9%97%B2%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——感知</title>
    <link href="http://enderfga.cn/2022/05/27/robot7/"/>
    <id>http://enderfga.cn/2022/05/27/robot7/</id>
    <published>2022-05-27T07:53:41.000Z</published>
    <updated>2022-05-28T16:35:37.060Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220527155651383.png" alt=""></p><embed src="./Perception.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>可靠数据传输原理</title>
    <link href="http://enderfga.cn/2022/05/17/net5/"/>
    <id>http://enderfga.cn/2022/05/17/net5/</id>
    <published>2022-05-16T23:52:24.000Z</published>
    <updated>2022-05-28T16:35:37.073Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第三章运输层之可靠数据传输原理</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/20220517080217.png" alt=""></p><span id="more"></span><embed src="./ARQ.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;第三章运输层之可靠数据传输原理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/20220517080217.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>2R机械臂五次多项式轨迹规划</title>
    <link href="http://enderfga.cn/2022/05/16/robot6/"/>
    <id>http://enderfga.cn/2022/05/16/robot6/</id>
    <published>2022-05-16T15:56:27.000Z</published>
    <updated>2022-06-20T00:55:56.568Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/20220516000042.png" alt=""></p><p>智能机器人技术作业记录</p><span id="more"></span><embed src="./2R.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/20220516000042.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>C2TCP：一个超低延迟的灵活蜂窝式TCP</title>
    <link href="http://enderfga.cn/2022/05/16/net4/"/>
    <id>http://enderfga.cn/2022/05/16/net4/</id>
    <published>2022-05-16T00:59:15.000Z</published>
    <updated>2022-05-28T16:35:37.075Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计算机网络前沿论文导读</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/2432716a34cb4571ac86e2b7f56f617.png" alt=""></p><span id="more"></span><embed src="./C2TCP.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计算机网络前沿论文导读&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/2432716a34cb4571ac86e2b7f56f617.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>智能机器人技术——机器人运动学奇异分析与性能评价</title>
    <link href="http://enderfga.cn/2022/05/15/robot5/"/>
    <id>http://enderfga.cn/2022/05/15/robot5/</id>
    <published>2022-05-15T06:05:29.000Z</published>
    <updated>2022-06-20T00:56:08.960Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><h1 id="智能机器人技术——机器人运动学奇异分析与性能评价"><a href="#智能机器人技术——机器人运动学奇异分析与性能评价" class="headerlink" title="智能机器人技术——机器人运动学奇异分析与性能评价"></a>智能机器人技术——机器人运动学奇异分析与性能评价</h1><p>一、给定平面2R机械臂状态参数，</p><p>状态描述：</p><ul><li>关节状态: $\quad\left[\theta_{1}, \theta_{2}\right]^{\mathrm{T}}$</li><li>末端位置: $\quad\left[x_{e}, y_{e}\right]^{\mathrm{T}}$</li></ul><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220508155155580.png" alt=""></p><ol><li><p>计算逆运动学，求解关节角的表达式（已知末端位置$\quad\left[x_{e}, y_{e}\right]^{\mathrm{T}}$，求关节角$\quad\left[\theta_{1}, \theta_{2}\right]^{\mathrm{T}}$）</p><p>根据几何关系, 可推导出机械臂末端位置与机械臂关节变量的关系:</p><script type="math/tex; mode=display">\begin{array}{l}p_{\mathrm{ex}}=l_{1} c_{1}+l_{2} c_{12} \\p_{\mathrm{ey}}=l_{1} s_{1}+l_{2} s_{12}\end{array}</script><p>其中,</p><script type="math/tex; mode=display">\left\{\begin{array}{l}s_{1}=\sin \theta_{1}, c_{1}=\cos \theta_{1} \\s_{12}=\sin \left(\theta_{1}+\theta_{2}\right), c_{12}=\cos \left(\theta_{1}+\theta_{2}\right)\end{array}\right.</script><p>其向量形式为：</p><script type="math/tex; mode=display">p_{\mathrm{e}}=\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{e} y}\end{array}\right]=\left[\begin{array}{l}l_{1} c_{1}+l_{2} c_{12} \\l_{1} s_{1}+l_{2} s_{12}\end{array}\right]=\left[\begin{array}{l}l_{1} \cos \theta_{1}+l_{2} \cos \left(\theta_{1}+\theta_{2}\right) \\l_{1} \sin \theta_{1}+l_{2} \sin \left(\theta_{1}+\theta_{2}\right)\end{array}\right]</script><p>将式子两边的平方相加, 有</p><script type="math/tex; mode=display">p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}\left(c_{1} c_{12}+s_{1} s_{12}\right)</script><p>$p_{\mathrm{e}}^{2}=p_{\mathrm{ex}}^{2}+p_{\mathrm{ey}}^{2}$ 为基坐标系原点到末端坐标系原点的距离。</p><p>根据三角函数的性质, 有</p><script type="math/tex; mode=display">c_{1} c_{12}+s_{1} s_{12}=c_{2}</script><p>故可化简为</p><script type="math/tex; mode=display">p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}</script><p>因此，</p><script type="math/tex; mode=display">\left\{\begin{array}{l}p_{\mathrm{e}}^{2} \leqslant l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}=\left(l_{1}+l_{2}\right)^{2} \\p_{\mathrm{e}}^{2} \geqslant l_{1}^{2}+l_{2}^{2}-2 l_{1} l_{2}=\left(l_{1}-l_{2}\right)^{2}\end{array}\right.\\\left|l_{1}-l_{2}\right| \leqslant p_{e} \leqslant l_{1}+l_{2}</script><p>上式即表示了该 $2 \mathrm{R}$ 机械臂的工作空间范围, 其最小边沿和最大边沿分别对应于 $\theta_{2}=\pi$ 和 $\theta_{2}=0$ 的情况。</p><p>进一步有，</p><script type="math/tex; mode=display">\left|\frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1} l_{2}}\right| \leqslant 1</script><p>解得：</p><script type="math/tex; mode=display">\theta_{2}=\pm \arccos \frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1} l_{2}}=\pm \arccos \frac{x_{\mathrm{e}}^{2}+y_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1} l_{2}}</script><p>关节角 $\theta_{2}$ 解出后, 将其代入方程组中, 可进一步解出关节角 $\theta_{1}$ 。首先根据三角函数的性质:</p><script type="math/tex; mode=display">\begin{aligned}&c_{12}=c_{1} c_{2}-s_{1} s_{2} \\&s_{12}=s_{1} c_{2}+c_{1} s_{2}\end{aligned}</script><p>有，</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\left(l_{1}+l_{2} c_{2}\right) c_{1}-l_{2} s_{2} s_{1}=p_{\mathrm{ex}} \\l_{2} s_{2} c_{1}+\left(l_{1}+l_{2} c_{2}\right) s_{1}=p_{\mathrm{e} y}\end{array}\right.</script><p>可写成如下形式:</p><script type="math/tex; mode=display">\left[\begin{array}{cc}l_{1}+l_{2} c_{2} & -l_{2} s_{2} \\l_{2} s_{2} & l_{1}+l_{2} c_{2}\end{array}\right]\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{l}p_{e x} \\p_{\mathrm{ey}}\end{array}\right]</script><p>方程组的系数矩阵 $\boldsymbol{A}$ 及其行列式分别为</p><script type="math/tex; mode=display">\boldsymbol{A}=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} & -l_{2} s_{2} \\l_{2} s_{2} & l_{1}+l_{2} c_{2}\end{array}\right], \operatorname{det}(\boldsymbol{A})=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}</script><p>若 $\operatorname{det}(\boldsymbol{A}) \neq 0$, 则矩阵 $\boldsymbol{A}$ 满秩, 方程组有解, 即:</p><script type="math/tex; mode=display">\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} & -l_{2} s_{2} \\l_{2} s_{2} & l_{1}+l_{2} c_{2}\end{array}\right]^{-1}\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{ey}}\end{array}\right]=\frac{1}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}}\left[\begin{array}{c}\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2} p_{\mathrm{ey}} \\-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ey}}\end{array}\right]</script><p>$\theta_{1}$ 可根据解出的 $s_{1}$ 和 $c_{1}$ 求出, 即:</p><script type="math/tex; mode=display">\begin{aligned}\theta_{1} &=\arctan 2\left(s_{1}, c_{1}\right)=\arctan 2\left(\frac{-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}}, \frac{\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2} p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}}\right) \\&=\arctan 2\left(-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ey}},\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2} p_{\mathrm{ey}}\right)\end{aligned}</script><p>根据基本不等式及三级函数的性质, 令 $\operatorname{det}(\boldsymbol{A})=0$, 则必有 $l_{1}=l_{2}$ 且 $\theta_{2}=\pi$, 即:</p><script type="math/tex; mode=display">\operatorname{det}(\boldsymbol{A})=0 \Rightarrow\left\{\begin{array} { l } { l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } + 2 l _ { 1 } l _ { 2 } c _ { 2 } = 0 } \\{ l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } \geqslant 2 l _ { 1 } l _ { 2 } } \\{ | c _ { 2 } | \leqslant 1 }\end{array} \Rightarrow \left\{\begin{array}{l}l_{1}=l_{2} \\\theta_{2}=\pi\end{array}\right.\right.</script><p>综上所述, 结果可以求出两组解, 对应于机器人的两种臂型, 分别称为高臂 (肘) 和低臂 (肘), 平面 $2 \mathrm{R}$ 机械臂逆运动学多解情况分析下图所示。也就是说, 对于前述的 $2 \mathrm{R}$ 机械臂, 当给定末端点的一个位置 $\boldsymbol{p}_{\mathrm{e}}$ 时, 有两组关节角与之对应, 即位置级逆运动学有多解。</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220515125458389.png" alt=""></p></li><li>计算雅克比矩阵</li></ol><p>根据机械臂末端位置与机械臂关节变量的关系求导得：</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\dot{p}_{\mathrm{ex}}=-l_{1} s_{1} \dot{\theta}_{1}-l_{2} s_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=-\left(l_{1} s_{1}+l_{2} s_{12}\right) \dot{\theta}_{1}-l_{2} s_{12} \dot{\theta}_{2} \\\dot{p}_{\mathrm{cy}}=l_{1} c_{1} \dot{\theta}_{1}+l_{2} c_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=\left(l_{1} c_{1}+l_{2} c_{12}\right) \dot{\theta}_{1}+l_{2} c_{12} \dot{\theta}_{2} \\\end{array}\right.</script><p>即:</p><script type="math/tex; mode=display">\left[\begin{array}{l}\dot{p}_{\mathrm{ex}} \\\dot{p}_{\mathrm{ey}}\end{array}\right]=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} & -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} & l_{2} c_{12}\end{array}\right]\left[\begin{array}{l}\dot{\theta}_{1} \\\dot{\theta}_{2}\end{array}\right]</script><p>其矩阵形式为：</p><script type="math/tex; mode=display">\dot{\boldsymbol{p}}_{\mathrm{e}}=\boldsymbol{J}_{v}(\boldsymbol{\Theta}) \dot{\boldsymbol{\Theta}}</script><p>此时, $\boldsymbol{J}_{v}$ 为 $2 \times 2$ 的方阵:</p><script type="math/tex; mode=display">\boldsymbol{J}_{v}=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} & -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} & l_{2} c_{12}\end{array}\right]</script><p>二、给定D-H坐标系，填写D-H参数表。</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220515131813671.png" alt=""></p><script type="math/tex; mode=display">\begin{array}{ccccc}\hline  \text { 连杆i } & \theta_{i} & \alpha_{i} & a_{i} & d_{i} \\\hline1 & 0 & -90^{\circ} & 0 & d_{1} \\2 & 0 & 0 & a_{2} & 0 \\  3 & 0 & 0 & a_{3} & 0\\  \hline\end{array}</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;智能机器人技术作业记录&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器人" scheme="http://enderfga.cn/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch常用代码段合集</title>
    <link href="http://enderfga.cn/2022/05/10/torch/"/>
    <id>http://enderfga.cn/2022/05/10/torch/</id>
    <published>2022-05-10T15:45:53.000Z</published>
    <updated>2022-05-28T16:35:37.059Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220511003116457.png" alt=""></p><span id="more"></span><h1 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a><strong>基本配置</strong></h1><h3 id="导入包和版本查询"><a href="#导入包和版本查询" class="headerlink" title="导入包和版本查询"></a><strong>导入包和版本查询</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="可复现性"><a href="#可复现性" class="headerlink" title="可复现性"></a><strong>可复现性</strong></h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>显卡设置</p><p>如果只需要一张显卡</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Device configuration</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>如果需要指定多张显卡，比如0，1号显卡。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>也可以在命令行运行代码时设置显卡：</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> python train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>清除显存</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>也可以使用在命令行重置GPU的指令</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi --gpu-reset -i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="张量-Tensor-处理"><a href="#张量-Tensor-处理" class="headerlink" title="张量(Tensor)处理"></a><strong>张量(Tensor)处理</strong></h1><h3 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a><strong>张量的数据类型</strong></h3><p>PyTorch有9种CPU张量类型和9种GPU张量类型。</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/640" alt=""></p><h3 id="张量基本信息"><a href="#张量基本信息" class="headerlink" title="张量基本信息"></a><strong>张量基本信息</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 数据类型</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 张量的shape，是个元组</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 维度的数量</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="命名张量"><a href="#命名张量" class="headerlink" title="命名张量"></a><strong>命名张量</strong></h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在PyTorch 1.3之前，需要使用注释</span><span class="token comment"># Tensor[N, C, H, W]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># PyTorch 1.3之后</span>NCHW <span class="token operator">=</span> <span class="token punctuation">[</span>‘N’<span class="token punctuation">,</span> ‘C’<span class="token punctuation">,</span> ‘H’<span class="token punctuation">,</span> ‘W’<span class="token punctuation">]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> names<span class="token operator">=</span>NCHW<span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 也可以这么设置</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 使用align_to可以对维度方便地排序</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>align_to<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span>torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token comment"># 类型转换</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="torch-Tensor与np-ndarray转换"><a href="#torch-Tensor与np-ndarray转换" class="headerlink" title="torch.Tensor与np.ndarray转换"></a><strong>torch.Tensor与np.ndarray转换</strong></h3><p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If ndarray has negative stride.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="Torch-tensor与PIL-Image转换"><a href="#Torch-tensor与PIL-Image转换" class="headerlink" title="Torch.tensor与PIL.Image转换"></a><strong>Torch.tensor与PIL.Image转换</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span><span class="token comment"># torch.Tensor -> PIL.Image</span>image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span><span class="token comment"># PIL.Image -> torch.Tensor</span>path <span class="token operator">=</span> <span class="token string">r'./figure.jpg'</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#Equivalently way</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="np-ndarray与PIL-Image的转换"><a href="#np-ndarray与PIL-Image的转换" class="headerlink" title="np.ndarray与PIL.Image的转换"></a>np.ndarray与PIL.Image的转换</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>ndarray <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h3 id="从只包含一个元素的张量中提取值"><a href="#从只包含一个元素的张量中提取值" class="headerlink" title="从只包含一个元素的张量中提取值"></a><strong>从只包含一个元素的张量中提取值</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">value <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="张量形变"><a href="#张量形变" class="headerlink" title="张量形变"></a><strong>张量形变</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，</span><span class="token comment"># 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="打乱顺序"><a href="#打乱顺序" class="headerlink" title="打乱顺序"></a><strong>打乱顺序</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 打乱第一个维度</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="水平翻转"><a href="#水平翻转" class="headerlink" title="水平翻转"></a><strong>水平翻转</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现</span><span class="token comment"># 假设张量的维度为[N, D, H, W].</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="复制张量"><a href="#复制张量" class="headerlink" title="复制张量"></a><strong>复制张量</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Operation                 |  New/Shared memory | Still in computation graph |</span>tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># |        New         |          Yes               |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># |      Shared        |          No                |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># |        New         |          No                | </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="张量拼接"><a href="#张量拼接" class="headerlink" title="张量拼接"></a><strong>张量拼接</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，而torch.stack的结果是3x10x5的张量。'''</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="将整数标签转为one-hot编码"><a href="#将整数标签转为one-hot编码" class="headerlink" title="将整数标签转为one-hot编码"></a><strong>将整数标签转为one-hot编码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch的标记默认从0开始</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">4</span>one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="得到非零元素"><a href="#得到非零元素" class="headerlink" title="得到非零元素"></a><strong>得到非零元素</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>               <span class="token comment"># index of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment"># index of zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>       <span class="token comment"># number of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># number of zero elements</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="判断两个张量相等"><a href="#判断两个张量相等" class="headerlink" title="判断两个张量相等"></a><strong>判断两个张量相等</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>  <span class="token comment"># float tensor</span>torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>     <span class="token comment"># int tensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h3 id="张量扩展"><a href="#张量扩展" class="headerlink" title="张量扩展"></a><strong>张量扩展</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a><strong>矩阵乘法</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Matrix multiplcation: (m*n) * (n*p) * -> (m*p).</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p)</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Element-wise multiplication.</span>result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="计算两组数据之间的两两欧式距离"><a href="#计算两组数据之间的两两欧式距离" class="headerlink" title="计算两组数据之间的两两欧式距离"></a><strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用broadcast机制</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> X2<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="模型定义和操作"><a href="#模型定义和操作" class="headerlink" title="模型定义和操作"></a><strong>模型定义和操作</strong></h1><h3 id="一个简单两层卷积网络的示例"><a href="#一个简单两层卷积网络的示例" class="headerlink" title="一个简单两层卷积网络的示例"></a>一个简单两层卷积网络的示例</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># convolutional neural network (2 convolutional layers)</span><span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> outmodel <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>卷积层的计算和展示可以用这个网站辅助。</p><p><a href="https://ezyang.github.io/convolution-visualizer/index.html">https://ezyang.github.io/convolution-visualizer/index.html</a></p><h3 id="双线性汇合（bilinear-pooling）"><a href="#双线性汇合（bilinear-pooling）" class="headerlink" title="双线性汇合（bilinear pooling）"></a>双线性汇合（bilinear pooling）</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">)</span>                        <span class="token comment"># Assume X has shape N*D*H*W</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W<span class="token punctuation">)</span>  <span class="token comment"># Bilinear pooling</span><span class="token keyword">assert</span> X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> D<span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e-5</span><span class="token punctuation">)</span>   <span class="token comment"># Signed-sqrt normalization</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment"># L2 normalization</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="多卡同步-BN（Batch-normalization）"><a href="#多卡同步-BN（Batch-normalization）" class="headerlink" title="多卡同步 BN（Batch normalization）"></a><strong>多卡同步 BN（Batch normalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>   affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="将已有网络的所有BN层改为同步BN层"><a href="#将已有网络的所有BN层改为同步BN层" class="headerlink" title="将已有网络的所有BN层改为同步BN层"></a>将已有网络的所有BN层改为同步BN层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">convertBNtoSyncBN</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> process_group<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''Recursively replace all BN layers to SyncBN layer.    Args:        module[torch.nn.Module]. Network    '''</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>batchnorm<span class="token punctuation">.</span>_BatchNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>        sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>module<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> module<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> module<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span>                                          module<span class="token punctuation">.</span>affine<span class="token punctuation">,</span> module<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">,</span> process_group<span class="token punctuation">)</span>        sync_bn<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> module<span class="token punctuation">.</span>running_mean        sync_bn<span class="token punctuation">.</span>running_var <span class="token operator">=</span> module<span class="token punctuation">.</span>running_var        <span class="token keyword">if</span> module<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>            sync_bn<span class="token punctuation">.</span>weight <span class="token operator">=</span> module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>            sync_bn<span class="token punctuation">.</span>bias <span class="token operator">=</span> module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> sync_bn    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> child_module <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token builtin">setattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">=</span> convert_syncbn_model<span class="token punctuation">(</span>child_module<span class="token punctuation">,</span> process_group<span class="token operator">=</span>process_group<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> module<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="类似-BN-滑动平均"><a href="#类似-BN-滑动平均" class="headerlink" title="类似 BN 滑动平均"></a><strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>running_mean <span class="token operator">+=</span> momentum <span class="token operator">*</span> <span class="token punctuation">(</span>current <span class="token operator">-</span> self<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="计算模型整体参数量"><a href="#计算模型整体参数量" class="headerlink" title="计算模型整体参数量"></a><strong>计算模型整体参数量</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="查看网络中的参数"><a href="#查看网络中的参数" class="headerlink" title="查看网络中的参数"></a><strong>查看网络中的参数</strong></h3><p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name2<span class="token punctuation">,</span> param2<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'----------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name1<span class="token punctuation">,</span> param1<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="模型可视化（使用pytorchviz）"><a href="#模型可视化（使用pytorchviz）" class="headerlink" title="模型可视化（使用pytorchviz）"></a><strong>模型可视化（使用pytorchviz）</strong></h3><p><a href="https://github.com/szagoruyko/pytorchviz">https://github.com/szagoruyko/pytorchviz</a></p><h3 id="类似-Keras-的-model-summary-输出模型信息（使用pytorch-summary-）"><a href="#类似-Keras-的-model-summary-输出模型信息（使用pytorch-summary-）" class="headerlink" title="类似 Keras 的 model.summary() 输出模型信息（使用pytorch-summary ）"></a><strong>类似 Keras 的 model.summary() 输出模型信息（使用pytorch-summary ）</strong></h3><p><a href="https://github.com/sksq96/pytorch-summary">https://github.com/sksq96/pytorch-summary</a></p><p><strong>模型权重初始化</strong></p><p>注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Common practise for initialization.</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span>                                      nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token comment"># Initialization with given tensor.</span>layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取模型中的某一层"><a href="#提取模型中的某一层" class="headerlink" title="提取模型中的某一层"></a><strong>提取模型中的某一层</strong></h3><p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 取模型中的前两层</span>new_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>         conv_model<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="部分层使用预训练模型"><a href="#部分层使用预训练模型" class="headerlink" title="部分层使用预训练模型"></a><strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="将在-GPU-保存的模型加载到-CPU"><a href="#将在-GPU-保存的模型加载到-CPU" class="headerlink" title="将在 GPU 保存的模型加载到 CPU"></a>将在 GPU 保存的模型加载到 CPU</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="导入另一个模型的相同部分到新的模型"><a href="#导入另一个模型的相同部分到新的模型" class="headerlink" title="导入另一个模型的相同部分到新的模型"></a><strong>导入另一个模型的相同部分到新的模型</strong></h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># model_new代表新的模型</span><span class="token comment"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span>model_new_dict <span class="token operator">=</span> model_new<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>model_common_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> model_saved<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> model_new_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>model_new_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_common_dict<span class="token punctuation">)</span>model_new<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_new_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a><strong>数据处理</strong></h1><h3 id="计算数据集的均值和标准差"><a href="#计算数据集的均值和标准差" class="headerlink" title="计算数据集的均值和标准差"></a>计算数据集的均值和标准差</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">compute_mean_and_std</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 输入PyTorch的dataset，输出均值和标准差</span>    mean_r <span class="token operator">=</span> <span class="token number">0</span>    mean_g <span class="token operator">=</span> <span class="token number">0</span>    mean_b <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># change PIL Image to numpy array</span>        mean_r <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_g <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_b <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    mean_r <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_g <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_b <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    diff_r <span class="token operator">=</span> <span class="token number">0</span>    diff_g <span class="token operator">=</span> <span class="token number">0</span>    diff_b <span class="token operator">=</span> <span class="token number">0</span>    N <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        diff_r <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_r<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_g <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_g<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_b <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_b<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        N <span class="token operator">+=</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    std_r <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_r <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_g <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_g <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_b <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_b <span class="token operator">/</span> N<span class="token punctuation">)</span>    mean <span class="token operator">=</span> <span class="token punctuation">(</span>mean_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    std <span class="token operator">=</span> <span class="token punctuation">(</span>std_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> mean<span class="token punctuation">,</span> std<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="得到视频数据基本信息"><a href="#得到视频数据基本信息" class="headerlink" title="得到视频数据基本信息"></a>得到视频数据基本信息</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> cv2video <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>mp4_path<span class="token punctuation">)</span>height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_HEIGHT<span class="token punctuation">)</span><span class="token punctuation">)</span>width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_WIDTH<span class="token punctuation">)</span><span class="token punctuation">)</span>num_frames <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_COUNT<span class="token punctuation">)</span><span class="token punctuation">)</span>fps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FPS<span class="token punctuation">)</span><span class="token punctuation">)</span>video<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="TSN-每段（segment）采样一帧视频"><a href="#TSN-每段（segment）采样一帧视频" class="headerlink" title="TSN 每段（segment）采样一帧视频"></a>TSN 每段（segment）采样一帧视频</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">K <span class="token operator">=</span> self<span class="token punctuation">.</span>_num_segments<span class="token keyword">if</span> is_train<span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Random index for each segment.</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames <span class="token operator">//</span> K<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Middle index for each segment.</span>        frame_indices <span class="token operator">=</span> num_frames <span class="token operator">/</span> K <span class="token operator">//</span> <span class="token number">2</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>                                        torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">assert</span> frame_indices<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token punctuation">[</span>frame_indices<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="常用训练和验证数据预处理"><a href="#常用训练和验证数据预处理" class="headerlink" title="常用训练和验证数据预处理"></a><strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span>                                             scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span><span class="token punctuation">)</span> val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="模型训练和测试"><a href="#模型训练和测试" class="headerlink" title="模型训练和测试"></a><strong>模型训练和测试</strong></h1><h3 id="分类模型训练代码"><a href="#分类模型训练代码" class="headerlink" title="分类模型训练代码"></a><strong>分类模型训练代码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Loss and optimizer</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># Train the model</span>total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token punctuation">,</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>              <span class="token comment"># Forward pass</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>              <span class="token comment"># Backward and optimizer</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: [&#123;&#125;/&#123;&#125;], Step: [&#123;&#125;/&#123;&#125;], Loss: &#123;&#125;'</span>                  <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="分类模型测试代码"><a href="#分类模型测试代码" class="headerlink" title="分类模型测试代码"></a><strong>分类模型测试代码</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Test the model</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># eval mode(batch norm uses moving mean/variance </span>              <span class="token comment">#instead of mini-batch mean/variance)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy of the model on the 10000 test images: &#123;&#125; %'</span>          <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="自定义loss"><a href="#自定义loss" class="headerlink" title="自定义loss"></a><strong>自定义loss</strong></h3><p>继承torch.nn.Module类写自己的loss。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLoss</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Moudle<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="标签平滑（label-smoothing）"><a href="#标签平滑（label-smoothing）" class="headerlink" title="标签平滑（label smoothing）"></a><strong>标签平滑（label smoothing）</strong></h3><p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log_softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>e <span class="token operator">=</span> e        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction      <span class="token keyword">def</span> <span class="token function">_one_hot</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> classes<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""            Convert labels to one hot vectors              Args:            labels: torch tensor in format [label1, label2, label3, ...]            classes: int, number of classes            value: label value in one hot vector, default to 1              Returns:            return one hot format labels in shape [batchsize, classes]        """</span>        one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span>        <span class="token comment">#labels and value_added  size must match</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        value_added <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>value<span class="token punctuation">)</span>        value_added <span class="token operator">=</span> value_added<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot <span class="token operator">=</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> value_added<span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot    <span class="token keyword">def</span> <span class="token function">_smooth_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> smooth_factor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""convert targets to one-hot format, and smooth        them.        Args:            target: target in form with [label1, label2, label_batchsize]            length: length of one-hot format(number of classes)            smooth_factor: smooth factor for label smooth              Returns:            smoothed labels in one hot format        """</span>        one_hot <span class="token operator">=</span> self<span class="token punctuation">.</span>_one_hot<span class="token punctuation">(</span>target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> smooth_factor<span class="token punctuation">)</span>        one_hot <span class="token operator">+=</span> smooth_factor <span class="token operator">/</span> <span class="token punctuation">(</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>target<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">!=</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input tensor to have least 2 dimensions(got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Only 2 dimension tensor are implemented, (got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        smoothed_target <span class="token operator">=</span> self<span class="token punctuation">.</span>_smooth_label<span class="token punctuation">(</span>target<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>e<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span> x <span class="token operator">*</span> smoothed_target<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'none'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> loss              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'sum'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'mean'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'unrecognized option, expect reduction to be one of none, mean, sum'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>或者直接在训练文件里做label smoothing</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    N <span class="token operator">=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># C is the number of classes.</span>    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="Mixup训练"><a href="#Mixup训练" class="headerlink" title="Mixup训练"></a><strong>Mixup训练</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">beta_distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>distributions<span class="token punctuation">.</span>beta<span class="token punctuation">.</span>Beta<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Mixup images and labels.</span>    lambda_ <span class="token operator">=</span> beta_distribution<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    mixed_images <span class="token operator">=</span> lambda_ <span class="token operator">*</span> images <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> images<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    label_a<span class="token punctuation">,</span> label_b <span class="token operator">=</span> labels<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token comment"># Mixup loss.</span>    scores <span class="token operator">=</span> model<span class="token punctuation">(</span>mixed_images<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>lambda_ <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_a<span class="token punctuation">)</span>            <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_b<span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="L1-正则化"><a href="#L1-正则化" class="headerlink" title="L1 正则化"></a>L1 正则化</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">l1_regularization <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment"># Standard cross-entropy loss</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    loss <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="不对偏置项进行权重衰减（weight-decay）"><a href="#不对偏置项进行权重衰减（weight-decay）" class="headerlink" title="不对偏置项进行权重衰减（weight decay）"></a><strong>不对偏置项进行权重衰减（weight decay）</strong></h3><p>pytorch里的weight decay相当于l2正则</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">bias_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>others_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> bias_list<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            <span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> others_list<span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="梯度裁剪（gradient-clipping）"><a href="#梯度裁剪（gradient-clipping）" class="headerlink" title="梯度裁剪（gradient clipping）"></a><strong>梯度裁剪（gradient clipping）</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h3 id="得到当前学习率"><a href="#得到当前学习率" class="headerlink" title="得到当前学习率"></a><strong>得到当前学习率</strong></h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># If there is one global learning rate (which is the common case).</span>lr <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token comment"># If there are multiple learning rates for different layers.</span>all_lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>    all_lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>另一种方法，在一个batch训练代码里，当前的lr是optimizer.param_groups[0][‘lr’]</p><h3 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Reduce learning rate when validation accuarcy plateau.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span class="token comment"># Cosine annealing learning rate.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token comment"># Reduce learning rate by 10 at given epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># Learning rate warmup by 10 epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t <span class="token operator">/</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="优化器链式更新"><a href="#优化器链式更新" class="headerlink" title="优化器链式更新"></a><strong>优化器链式更新</strong></h3><p>从1.4版本开始，torch.optim.lr_scheduler 支持链式更新（chaining），即用户可以定义两个 schedulers，并交替在训练中使用。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> ExponentialLR<span class="token punctuation">,</span> StepLRmodel <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> SGD<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>scheduler1 <span class="token operator">=</span> ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>scheduler2 <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> scheduler2<span class="token punctuation">.</span>get_last_lr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler2<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="模型训练可视化"><a href="#模型训练可视化" class="headerlink" title="模型训练可视化"></a><strong>模型训练可视化</strong></h3><p>PyTorch可以使用tensorboard来可视化训练过程。</p><p>安装和运行TensorBoard。</p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> tensorboardtensorboard --logdir<span class="token operator">=</span>runs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如’Loss/train’和’Loss/test’。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> n_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="保存与加载断点"><a href="#保存与加载断点" class="headerlink" title="保存与加载断点"></a><strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">start_epoch <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># Load checkpoint.</span><span class="token keyword">if</span> resume<span class="token punctuation">:</span> <span class="token comment"># resume为参数，第一次训练时设为0，中断再训练时设为1</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    best_acc <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_acc'</span><span class="token punctuation">]</span>    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load checkpoint at epoch &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best accuracy so far &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Train the model</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token comment"># Test the model</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          <span class="token comment"># save checkpoint</span>    is_best <span class="token operator">=</span> current_acc <span class="token operator">></span> best_acc    best_acc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>current_acc<span class="token punctuation">,</span> best_acc<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">'best_acc'</span><span class="token punctuation">:</span> best_acc<span class="token punctuation">,</span>        <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token string">'model'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>    best_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>    <span class="token keyword">if</span> is_best<span class="token punctuation">:</span>        shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> best_model_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取-ImageNet-预训练模型某层的卷积特征"><a href="#提取-ImageNet-预训练模型某层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型某层的卷积特征"></a>提取 ImageNet 预训练模型某层的卷积特征</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># VGG-16 pool5 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token comment"># VGG-16 fc7 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># ResNet GAP feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="提取-ImageNet-预训练模型多层的卷积特征"><a href="#提取-ImageNet-预训练模型多层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型多层的卷积特征"></a>提取 ImageNet 预训练模型多层的卷积特征</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Helper class to extract several convolution features from the given    pre-trained model.    Attributes:        _model, torch.nn.Module.        _layers_to_extract, list&lt;str> or set&lt;str>    Example:        >>> model = torchvision.models.resnet152(pretrained=True)        >>> model = torch.nn.Sequential(collections.OrderedDict(                list(model.named_children())[:-1]))        >>> conv_representation = FeatureExtractor(                pretrained_model=model,                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            <span class="token keyword">return</span> conv_representation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="微调全连接层"><a href="#微调全连接层" class="headerlink" title="微调全连接层"></a>微调全连接层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># Replace the last fc layer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="以较大学习率微调全连接层，较小学习率微调卷积层"><a href="#以较大学习率微调全连接层，较小学习率微调卷积层" class="headerlink" title="以较大学习率微调全连接层，较小学习率微调卷积层"></a>以较大学习率微调全连接层，较小学习率微调卷积层</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">1e-3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>               <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a><strong>其他注意事项</strong></h1><ul><li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是O(mn)的内存，线性层太大很容易超出现有显存。</li><li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。</li><li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。</li><li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li><li>model.eval() 和 torch.no_grad() 的区别在于，model.eval() 是将网络切换为测试状态，例如 BN 和dropout在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。</li><li>model.zero_grad()会把整个模型的参数的梯度都归零, 而optimizer.zero_grad()只会把传入其中的参数的梯度归零.</li><li>torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li><li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。</li><li>torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。num_workers 的设置需要在实验中找到最快的取值。</li><li>用 del 及时删除不用的中间变量，节约 GPU 存储。</li><li>使用 inplace 操作可节约 GPU 存储，如</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><ul><li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</li><li>使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。</li><li>时常使用 assert tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。</li><li>除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li><li>统计代码各部分耗时</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>enabled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">as</span> profile<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span><span class="token comment"># 或者在命令行运行</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>bottleneck main<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><ul><li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print 出来每一行的执行结果的 tensor 的形状、数据类型、设备、是否需要梯度的信息。</li></ul><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pip install torchsnooper</span><span class="token keyword">import</span> torchsnooper<span class="token comment"># 对于函数，使用修饰器</span><span class="token decorator annotation punctuation">@torchsnooper<span class="token punctuation">.</span>snoop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。</span><span class="token keyword">with</span> torchsnooper<span class="token punctuation">.</span>snoop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><ul><li>原本的代码</li></ul><p><a href="https://github.com/zasdfgbnm/TorchSnooper">https://github.com/zasdfgbnm/TorchSnooper</a></p><ul><li>模型可解释性，使用captum库</li></ul><p><a href="https://captum.ai/">https://captum.ai/</a></p><p><strong>参考资料：</strong></p><p>1.<a href="https://zhuanlan.zhihu.com/p/59205847">https://zhuanlan.zhihu.com/p/59205847</a></p><p>2.<a href="https://pytorch.org/tutorials/">PyTorch官方文档和示例</a></p><p>3.<a href="https://pytorch.org/docs/stable/notes/faq.html">https://pytorch.org/docs/stable/notes/faq.html</a></p><p>4.<a href="https://github.com/szagoruyko/pytorchviz">https://github.com/szagoruyko/pytorchviz</a></p><p>5.<a href="https://github.com/sksq96/pytorch-summary">https://github.com/sksq96/pytorch-summary</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220511003116457.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="深度学习" scheme="http://enderfga.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>PID 控制在医学麻醉过程血压控制中的应用</title>
    <link href="http://enderfga.cn/2022/05/04/pid/"/>
    <id>http://enderfga.cn/2022/05/04/pid/</id>
    <published>2022-05-04T13:42:55.000Z</published>
    <updated>2022-06-20T00:56:17.116Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动控制原理大作业——pid控制器</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220504214948390.png" alt=""></p><embed src="./PID.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动控制原理大作业——pid控制器&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动控制原理" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>网络抓包与协议分析</title>
    <link href="http://enderfga.cn/2022/05/01/net3/"/>
    <id>http://enderfga.cn/2022/05/01/net3/</id>
    <published>2022-05-01T03:07:57.000Z</published>
    <updated>2022-05-28T16:35:37.075Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：网络抓包与协议分析实验</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/wall.png" alt=""></p><embed src="./problem.pdf" width="100%" height="750" type="application/pdf"><embed src="./wireshark.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计网作业：网络抓包与协议分析实验&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据库原理 Exercises 3&amp;4&amp;5</title>
    <link href="http://enderfga.cn/2022/04/29/data3/"/>
    <id>http://enderfga.cn/2022/04/29/data3/</id>
    <published>2022-04-28T16:33:52.000Z</published>
    <updated>2022-06-03T16:18:04.234Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 5&amp;6&amp;8</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220429003143556.png" alt=""></p><h1 id="Database-System-Concepts-Exercises-of-Chapter-5-amp-6"><a href="#Database-System-Concepts-Exercises-of-Chapter-5-amp-6" class="headerlink" title="Database System Concepts Exercises of Chapter 5&amp;6"></a>Database System Concepts Exercises of Chapter 5&amp;6</h1><p><strong>Exercise 5.8</strong> Consider the bank database of Figure <strong>5.25</strong>. Write an sQL trigger to carryout the following action: On <strong>delete</strong> of an account, for each owner of theaccount, check if the owner has any remaining accounts, and if she doesnot, delete her from the <em>depositor</em> relation.</p><p>branch(branch_name, branch_city, assets)</p><p>customer ( customer_name, customer_street, customer_city )</p><p>loan( loan_number, branch_name, amount)</p><p>borrower ( customer_name, loan_number )</p><p>account ( account_number, branch_name, balance )</p><p>depositor ( customer_name, account_number )</p><p><strong>Figure 5.25</strong></p><p><strong>My answer:</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">trigger</span> <span class="token keyword">check</span><span class="token operator">-</span><span class="token keyword">delete</span><span class="token operator">-</span><span class="token keyword">trigger</span> <span class="token keyword">after</span> <span class="token keyword">delete</span> <span class="token keyword">on</span> account referencing old <span class="token keyword">row</span> <span class="token keyword">as</span> orow<span class="token keyword">for each row</span><span class="token keyword">delete</span> <span class="token keyword">from</span> depositor<span class="token keyword">where</span> depositor<span class="token punctuation">.</span>customer_name <span class="token operator">not</span> <span class="token operator">in</span>   <span class="token punctuation">(</span> <span class="token keyword">select</span> customer_name <span class="token keyword">from</span> depositor     <span class="token keyword">where</span> account_number <span class="token operator">&lt;></span> orow<span class="token punctuation">.</span>account_number <span class="token punctuation">)</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><strong>Exercise</strong> <strong>5.15</strong> Consider an employee database with two relations<br>employee ($\underline{employee_name}$, street, city)<br>works ($\underline{employee_name}$, company_name, salary)<br>where the primary keys are underlined. Write a query to find companies whose employees earn a higher salary, on average, than the average salary at “First Bank Corporation”.<br>a. Using SQL functions as appropriate.<br>b. Without using SQL functions.</p><p><strong>My answer:</strong></p><p>a)</p><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> avg_salary<span class="token punctuation">(</span>cname <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token keyword">integer</span>     <span class="token keyword">declare</span> result <span class="token keyword">integer</span><span class="token punctuation">;</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token keyword">into</span> result<span class="token keyword">from</span> works<span class="token keyword">where</span> works<span class="token punctuation">.</span>company<span class="token punctuation">.</span>name <span class="token operator">=</span> cname<span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">where</span> avg_salary<span class="token punctuation">(</span>company_name<span class="token punctuation">)</span> <span class="token operator">></span> avg_salary<span class="token punctuation">(</span>“<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>b)</p><figure><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">group</span> <span class="token keyword">by</span> company_name<span class="token keyword">having</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span><span class="token keyword">from</span> works<span class="token keyword">where</span> company_name<span class="token operator">=</span>”<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><hr><p><strong>Exercise 6.1</strong> Write the following queries in relational algebra, using the university schema.<br> <strong>a</strong>. Find the titles of courses in the Comp. Sci. department that have 3 credits.<br> <strong>b</strong>. Find the IDs of all students who were taught by an instructor named Einstein; make sure there are no duplicates in the result.<br> <strong>c</strong>. Find the highest salary of any instructor.<br> <strong>d</strong>. Find all instructors earning the highest salary (there may be more than one with the same salary).</p><p><strong>My answer:</strong></p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220429003507835.png" alt=""></p><embed src="./data.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Database System Concepts Exercises of Chapter 5&amp;amp;6&amp;amp;8&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据库" scheme="http://enderfga.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>conda/linux/git/正则表达式常用命令“笔记”</title>
    <link href="http://enderfga.cn/2022/04/28/code/"/>
    <id>http://enderfga.cn/2022/04/28/code/</id>
    <published>2022-04-28T01:34:32.000Z</published>
    <updated>2022-06-26T02:33:29.641Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一些常用的命令，每次忘了都得搜，记录一下</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220428094832340.png" alt=""></p><span id="more"></span><h1 id="Anaconda-amp-python"><a href="#Anaconda-amp-python" class="headerlink" title="Anaconda&amp;python"></a>Anaconda&amp;python</h1><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220428093957780.png" alt=""></p><p><strong>pip安装（tensorflow-gpu为例）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>conda安装</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>pip3安装（指定版本号只需在命令末尾添加==1.12.0版本号）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip3  install tensorflow-gpu&#x3D;&#x3D;1.12.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>使用清华镜像下载</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install tensorflow-gpu&#x3D;&#x3D;1.10 -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>指定目录安装</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install -t D:\ProgramData\Anaconda3\Lib\site-packages torch-1.0.1-cp36-cp36m-win_amd64.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>卸载安装（pip\pip3只需将conda换成pip\pip3）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  uninstall tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>创建虚拟环境（conda为例）</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n py36 python&#x3D;3.6  #py36虚拟环境的名字  python&#x3D;3.6  python版本<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>删除虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda remove -n py36 --all<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>激活虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda activate py36<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>退出虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看所有创建的虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda env list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>用virtualenv创建虚拟环境</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">VENV_DIR</span><span class="token operator">=</span>venvpip <span class="token function">install</span> virtualenvvirtualenv <span class="token variable">$VENV_DIR</span><span class="token builtin class-name">source</span> <span class="token variable">$VENV_DIR</span>/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><strong>nohup送入后台运行</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">nohup</span> python train.py <span class="token operator">></span>nohup <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>      <span class="token comment">#train.py运行的文件  nohup生成的日志文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>CUDA指定GPU</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token function">nohup</span> python train.py  <span class="token operator">></span> nohup.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>导出requirements.txt</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python3 -m pip freeze <span class="token operator">></span> requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看GPU使用情况</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>查看进程号</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">ps</span> aux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>根据进程号杀死进程</strong></p><figure><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">kill</span> -9 进程号<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/200301122312741.jpg" alt=""></p><h1 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h1><p>linux不像Windows 分了盘，它根目录下有如下常用文件夹:</p><p><em>home</em>         —————        用户的家</p><p><em>root</em>            —————        超级管理员root的家</p><p><em>etc</em>              —————        存放配置文件</p><p><em>usr</em>              —————        存放共享资源</p><h2 id="1、cd命令"><a href="#1、cd命令" class="headerlink" title="1、cd命令:"></a>1、cd命令:</h2><p><strong>①、进入某一个目录</strong> <code>cd 目录名</code></p><p><strong>②、进入多级目录</strong>  <code>cd 目录名/目录名</code></p><p><strong>③、返回上一级目录</strong> <code>cd ..</code></p><p><strong>④、返回根目录</strong> <code>cd /</code></p><p><strong>⑤、返回根目录下的某一个目录</strong> <code>cd /目录名</code></p><p><strong>⑥、回家</strong> <code>cd ~</code></p><h2 id="2、创建、删除目录"><a href="#2、创建、删除目录" class="headerlink" title="2、创建、删除目录:"></a>2、创建、删除目录:</h2><p><strong>①、创建目录</strong> <code>mkdir 目录名</code></p><p><strong>②、创建多级目录</strong> <code>mkdir -p a/b/c</code></p><p><strong>③、删除目录(只能删除空目录)</strong> <code>rmdir 目录名</code></p><p><strong>④、删除目录(可删除非空目录，带询问)</strong> <code>rm -r</code></p><p><strong>⑤、删除目录(不带询问，谨慎使用)</strong> <code>rm -rf</code></p><h2 id="3、对文件的操作"><a href="#3、对文件的操作" class="headerlink" title="3、对文件的操作:"></a>3、对文件的操作:</h2><p><strong>①、创建空白文件</strong> <code>touch 文件名</code></p><p><strong>②、复制文件</strong></p><p> <code>cp a.txt b.txt</code> <em>表示复制a文件并重命名为b。</em></p><p><code>cp a.txt dir/b.txt</code> <em>表示把a复制到dir文件夹下并重命名为b。</em></p><p><strong>③、移动文件</strong> <code>mv a.txt dir/b.txt</code> <em>把a.txt移动到dir目录下并重命名为b.txt。</em></p><p><strong>④、重命名文件</strong> <code>mv a.txt b.txt</code> <em>把a.txt重命名为b.txt。</em></p><p><strong>⑤、删除文件</strong></p><p><code>rm 文件名</code> <em>带询问的删除</em></p><p><code>rm -f 文件名</code> <em>不带询问的删除。</em></p><p><strong>⑥、浏览文件</strong></p><p> <code>cat 文件名</code> <em>显示文件所有内容</em></p><p><code>more 文件名</code> <em>分页显示，空格键下一页，回车键下一行。</em></p><p><code>less 文件名</code> <em>分页显示，pgup上一页，pgdn下一页。</em></p><p><code>tail -5 a.txt</code> <em>显示a.txt文件的最后5行。</em></p><p><code>tail -f 文件名</code> <em>动态的查看。</em></p><h2 id="4、查看目录下的文件"><a href="#4、查看目录下的文件" class="headerlink" title="4、查看目录下的文件:"></a>4、查看目录下的文件:</h2><p><strong>①、查看所有文件和目录名称</strong> <code>ls</code></p><p><strong>②、查看所有文件和目录名称(包括隐藏的)</strong> <code>ls -a</code></p><p><strong>③、查看文件并显示详细信息(最常用)</strong> <code>ll</code></p><p><strong>④、友好的显示</strong> <code>ll -h</code> <em>比如显示的文件大小是kb而不是字节。</em></p><h2 id="5、tar打包命令"><a href="#5、tar打包命令" class="headerlink" title="5、tar打包命令:"></a>5、tar打包命令:</h2><p><strong>①、将当前目录所有文件打包成haha.tar</strong> <code>tar -cvf haha.tar ./*</code></p><p><strong>②、将当前目录下所有文件打包并压缩成haha.tar</strong> <code>tar -zcvf haha.tar.gz ./*</code></p><p><strong>③、将haha.tar解压到当前目录</strong> <code>tar -xvf haha.tar</code></p><p><strong>④、将haha.tar解压到b目录</strong> <code>tar -xvf haha.tar -C b</code> <em>注意C是大写的！</em></p><h2 id="6、其他常用命令"><a href="#6、其他常用命令" class="headerlink" title="6、其他常用命令:"></a>6、其他常用命令:</h2><p><strong>①、grep命令</strong></p><p><code>grep category a.txt</code> <em>表示在a.txt中查找category字符串所在的行，前提是打开了a.txt文件。</em></p><p><code>grep category a.txt -A2</code> <em>在a.txt中查找category字符串的前两行。</em></p><p><code>grep category a.txt -B2</code> <em>在a.txt中查找category字符串的后两行。</em></p><p><strong>②、查看当前目录</strong> <code>pwd</code></p><p><strong>③、wget下载命令</strong> <code>wget www.baidu.com</code> <em>下载百度首页</em></p><h2 id="7、vi-vim编辑器"><a href="#7、vi-vim编辑器" class="headerlink" title="7、vi/vim编辑器:"></a>7、vi/vim编辑器:</h2><p><strong>①、编辑器有三种模式，分别是:</strong> <strong>命令行模式:</strong> 此模式无法编辑文件，<code>yy</code>复制行，<code>p</code>粘贴，<code>dd</code>删除行，按如下键都可以进入插入模式:</p><p><code>i</code>       当前位置前插入;</p><p><code>I</code>        当前行行首插入;</p><p><code>a</code>       当前位置后插入;</p><p><code>A</code>      当前行行尾插入;</p><p><code>o</code>       当前行之后插入一行;</p><p> <code>O</code>      当前的之前插入一行</p><p><strong>插入模式:</strong>此模式下可以对文件进行编辑。按 <code>esc</code>退出插入模式，回到命令行模式。 <strong>底行模式:</strong>命令行模式下按 <code>:</code>，即可进入底行模式。底行模式有如下常用命令:</p><p> <code>q</code>        不保存退出;</p><p> <code>q！</code>    不保存强制退出;</p><p><code>wq</code>     保存退出</p><h2 id="8、管道"><a href="#8、管道" class="headerlink" title="8、管道:"></a>8、管道:</h2><p><strong>管道:<code>|</code>，将一个命令的输出作为另一个命令的输入。例如:</strong> <strong>在 <code>ip addr</code>的输出结果中查找 <code>192.168</code>字符串:</strong> <code>ip addr | grep 192.168</code></p><h2 id="9、系统管理命令"><a href="#9、系统管理命令" class="headerlink" title="9、系统管理命令:"></a>9、系统管理命令:</h2><p><strong>①、查看系统时间</strong> <code>date</code>  查看系统时间 <code>date -s &quot;2018-05-15 22:22:22&quot;</code>将系统时间设置为引号里面的时间</p><p><strong>②、查看磁盘信息</strong> <code>df</code> 查看磁盘信息 <code>df -h</code>  友好地展示磁盘信息</p><p><strong>③、清屏</strong> <code>clear</code>或者按 <code>ctr L</code></p><p><strong>④、进程</strong> <code>ps -ef</code>查看所有进程 <code>ps -ef | grep ssh</code>查找ssh进程</p><p><strong>⑤、杀掉进程</strong> <code>kill 9527</code>杀掉9527号进程 <code>kill -9 9527</code> 强制杀掉9527号进程</p><p><strong>⑥、查看网络端口</strong> <code>netstat -an | grep 3306</code>查看3306端口占用情况</p><p><strong>⑦、ping命令</strong> <code>ping xx.xx.xxx</code>测试网络连通性</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/bg2015120901.png" alt=""></p><h1 id="GIT"><a href="#GIT" class="headerlink" title="GIT"></a>GIT</h1><p>下面是常用 Git 命令清单。几个专用名词的译名如下。</p><blockquote><ul><li>Workspace：工作区</li><li>Index / Stage：暂存区</li><li>Repository：仓库区（或本地仓库）</li><li>Remote：远程仓库</li></ul></blockquote><h2 id="一、新建代码库"><a href="#一、新建代码库" class="headerlink" title="一、新建代码库"></a>一、新建代码库</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在当前目录新建一个Git代码库</span>$ <span class="token function">git</span> init<span class="token comment"># 新建一个目录，将其初始化为Git代码库</span>$ <span class="token function">git</span> init <span class="token punctuation">[</span>project-name<span class="token punctuation">]</span><span class="token comment"># 下载一个项目和它的整个代码历史</span>$ <span class="token function">git</span> clone <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="二、配置"><a href="#二、配置" class="headerlink" title="二、配置"></a>二、配置</h2><p>Git的设置文件为 <code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示当前的Git配置</span>$ <span class="token function">git</span> config --list<span class="token comment"># 编辑Git配置文件</span>$ <span class="token function">git</span> config -e <span class="token punctuation">[</span>--global<span class="token punctuation">]</span><span class="token comment"># 设置提交代码时的用户信息</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.name <span class="token string">"[name]"</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.email <span class="token string">"[email address]"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="三、增加-删除文件"><a href="#三、增加-删除文件" class="headerlink" title="三、增加/删除文件"></a>三、增加/删除文件</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 添加指定文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 添加指定目录到暂存区，包括子目录</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>dir<span class="token punctuation">]</span><span class="token comment"># 添加当前目录的所有文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span><span class="token comment"># 添加每个变化前，都会要求确认</span><span class="token comment"># 对于同一个文件的多处变化，可以实现分次提交</span>$ <span class="token function">git</span> <span class="token function">add</span> -p<span class="token comment"># 删除工作区文件，并且将这次删除放入暂存区</span>$ <span class="token function">git</span> <span class="token function">rm</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 停止追踪指定文件，但该文件会保留在工作区</span>$ <span class="token function">git</span> <span class="token function">rm</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 改名文件，并且将这个改名放入暂存区</span>$ <span class="token function">git</span> <span class="token function">mv</span> <span class="token punctuation">[</span>file-original<span class="token punctuation">]</span> <span class="token punctuation">[</span>file-renamed<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="四、代码提交"><a href="#四、代码提交" class="headerlink" title="四、代码提交"></a>四、代码提交</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 提交暂存区到仓库区</span>$ <span class="token function">git</span> commit -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交暂存区的指定文件到仓库区</span>$ <span class="token function">git</span> commit <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>. -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交工作区自上次commit之后的变化，直接到仓库区</span>$ <span class="token function">git</span> commit -a<span class="token comment"># 提交时显示所有diff信息</span>$ <span class="token function">git</span> commit -v<span class="token comment"># 使用一次新的commit，替代上一次提交</span><span class="token comment"># 如果代码没有任何新变化，则用来改写上一次commit的提交信息</span>$ <span class="token function">git</span> commit --amend -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 重做上一次commit，并包括指定文件的新变化</span>$ <span class="token function">git</span> commit --amend <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="五、分支"><a href="#五、分支" class="headerlink" title="五、分支"></a>五、分支</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有本地分支</span>$ <span class="token function">git</span> branch<span class="token comment"># 列出所有远程分支</span>$ <span class="token function">git</span> branch -r<span class="token comment"># 列出所有本地分支和远程分支</span>$ <span class="token function">git</span> branch -a<span class="token comment"># 新建一个分支，但依然停留在当前分支</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，并切换到该分支</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，指向指定commit</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，与指定的远程分支建立追踪关系</span>$ <span class="token function">git</span> branch --track <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 切换到指定分支，并更新工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 切换到上一个分支</span>$ <span class="token function">git</span> checkout -<span class="token comment"># 建立追踪关系，在现有分支与指定的远程分支之间</span>$ <span class="token function">git</span> branch --set-upstream <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 合并指定分支到当前分支</span>$ <span class="token function">git</span> merge <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 选择一个commit，合并进当前分支</span>$ <span class="token function">git</span> cherry-pick <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除分支</span>$ <span class="token function">git</span> branch -d <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 删除远程分支</span>$ <span class="token function">git</span> push origin --delete <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span>$ <span class="token function">git</span> branch -dr <span class="token punctuation">[</span>remote/branch<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="六、标签"><a href="#六、标签" class="headerlink" title="六、标签"></a>六、标签</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有tag</span>$ <span class="token function">git</span> tag<span class="token comment"># 新建一个tag在当前commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 新建一个tag在指定commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除本地tag</span>$ <span class="token function">git</span> tag -d <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 删除远程tag</span>$ <span class="token function">git</span> push origin :refs/tags/<span class="token punctuation">[</span>tagName<span class="token punctuation">]</span><span class="token comment"># 查看tag信息</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交指定tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交所有tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --tags<span class="token comment"># 新建一个分支，指向某个tag</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="七、查看信息"><a href="#七、查看信息" class="headerlink" title="七、查看信息"></a>七、查看信息</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示有变更的文件</span>$ <span class="token function">git</span> status<span class="token comment"># 显示当前分支的版本历史</span>$ <span class="token function">git</span> log<span class="token comment"># 显示commit历史，以及每次commit发生变更的文件</span>$ <span class="token function">git</span> log --stat<span class="token comment"># 搜索提交历史，根据关键词</span>$ <span class="token function">git</span> log -S <span class="token punctuation">[</span>keyword<span class="token punctuation">]</span><span class="token comment"># 显示某个commit之后的所有变动，每个commit占据一行</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --pretty<span class="token operator">=</span>format:%s<span class="token comment"># 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --grep feature<span class="token comment"># 显示某个文件的版本历史，包括文件改名</span>$ <span class="token function">git</span> log --follow <span class="token punctuation">[</span>file<span class="token punctuation">]</span>$ <span class="token function">git</span> whatchanged <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示指定文件相关的每一次diff</span>$ <span class="token function">git</span> log -p <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示过去5次提交</span>$ <span class="token function">git</span> log -5 --pretty --oneline<span class="token comment"># 显示所有提交过的用户，按提交次数排序</span>$ <span class="token function">git</span> shortlog -sn<span class="token comment"># 显示指定文件是什么人在什么时间修改过</span>$ <span class="token function">git</span> blame <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示暂存区和工作区的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span><span class="token comment"># 显示暂存区和上一个commit的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示工作区与当前分支最新commit之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> HEAD<span class="token comment"># 显示两次提交之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> <span class="token punctuation">[</span>first-branch<span class="token punctuation">]</span><span class="token punctuation">..</span>.<span class="token punctuation">[</span>second-branch<span class="token punctuation">]</span><span class="token comment"># 显示今天你写了多少行代码</span>$ <span class="token function">git</span> <span class="token function">diff</span> --shortstat <span class="token string">"@&#123;0 day ago&#125;"</span><span class="token comment"># 显示某次提交的元数据和内容变化</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交发生变化的文件</span>$ <span class="token function">git</span> show --name-only <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交时，某个文件的内容</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span>:<span class="token punctuation">[</span>filename<span class="token punctuation">]</span><span class="token comment"># 显示当前分支的最近几次提交</span>$ <span class="token function">git</span> reflog<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="八、远程同步"><a href="#八、远程同步" class="headerlink" title="八、远程同步"></a>八、远程同步</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载远程仓库的所有变动</span>$ <span class="token function">git</span> fetch <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 显示所有远程仓库</span>$ <span class="token function">git</span> remote -v<span class="token comment"># 显示某个远程仓库的信息</span>$ <span class="token function">git</span> remote show <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 增加一个新的远程仓库，并命名</span>$ <span class="token function">git</span> remote <span class="token function">add</span> <span class="token punctuation">[</span>shortname<span class="token punctuation">]</span> <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span class="token comment"># 取回远程仓库的变化，并与本地分支合并</span>$ <span class="token function">git</span> pull <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 上传本地指定分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 强行推送当前分支到远程仓库，即使有冲突</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --force<span class="token comment"># 推送所有分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --all<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="九、撤销"><a href="#九、撤销" class="headerlink" title="九、撤销"></a>九、撤销</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 恢复暂存区的指定文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复某个commit的指定文件到暂存区和工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>commit<span class="token punctuation">]</span> <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复暂存区的所有文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token builtin class-name">.</span><span class="token comment"># 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 重置暂存区与工作区，与上一次commit保持一致</span>$ <span class="token function">git</span> reset --hard<span class="token comment"># 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致</span>$ <span class="token function">git</span> reset --hard <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前HEAD为指定commit，但保持暂存区和工作区不变</span>$ <span class="token function">git</span> reset --keep <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个commit，用来撤销指定commit</span><span class="token comment"># 后者的所有变化都将被前者抵消，并且应用到当前分支</span>$ <span class="token function">git</span> revert <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 暂时将未提交的变化移除，稍后再移入</span>$ <span class="token function">git</span> stash$ <span class="token function">git</span> stash pop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></blockquote><h2 id="十、其他"><a href="#十、其他" class="headerlink" title="十、其他"></a>十、其他</h2><blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 生成一个可供发布的压缩包</span>$ <span class="token function">git</span> archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></blockquote><p>一个常用的实例</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">add</span> origin xxx<span class="token punctuation">(</span>复制的SSH链接<span class="token punctuation">)</span><span class="token function">git</span> branch -m master main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span> <span class="token function">git</span> commit -m <span class="token string">"注释"</span> <span class="token function">git</span> pull --rebase origin main<span class="token function">git</span> push origin main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><embed src="./code.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;一些常用的命令，每次忘了都得搜，记录一下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220428094832340.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="笔记" scheme="http://enderfga.cn/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>自动驾驶技术基础之建模与控制</title>
    <link href="http://enderfga.cn/2022/04/25/auto1/"/>
    <id>http://enderfga.cn/2022/04/25/auto1/</id>
    <published>2022-04-25T08:57:56.000Z</published>
    <updated>2022-05-28T16:35:24.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动驾驶技术基础的建模与控制作业</p><span id="more"></span><p>概念题（18分）</p><ol><li>自动驾驶为了出色地完成驾驶任务，可分为哪四大模块？（4分）</li><li>系统建模一般分哪两种建模方式？（2分）</li><li>请写出高速转向车辆模型的简化横向误差模型（即四个状态为误差）（4分）</li><li>二次型性能指标函数一般包含哪三项优化项？（3分）</li><li>线性二次问题三种重要形式分别是？（3分）</li><li>Kalman Filter（LQE）如何通过LQR求得，请写出matlab关键代码，即：xxx=lqr(xxx) （2分）</li></ol><p>编程实践题（12分）</p><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/clip_image002.png" alt=""></p><p>给定一个双质系统:  m~1~ =2, m~2~=1, 弹簧系数 k=5, 阻尼σ=0.1, 质量块与地面的滑动阻尼 δ=0.1 (与速度有成正比)。初始时刻 m~1~ 质量块处于 x=0 的位置, 两质量块距离为 0 。现在 m~2~ 处作用一外力 F 拖动系统使 m~1~ 与 m~2~ 质量块均处于 x=5 的位置。</p><ol><li>对系统建模（系统可以直接测量两个物体的位置）</li><li>判断系统可控性与可观</li><li>结合给定的simulink和脚本文件，设计实现上述系统的LQG控制器并绘制闭环控制性能曲线</li></ol><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/clip_image020.jpg" alt=""></p><embed src="./auto1.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;自动驾驶技术基础的建模与控制作业&lt;/p&gt;</summary>
    
    
    
    
    <category term="自动驾驶" scheme="http://enderfga.cn/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>Cognitive Mapping and Planning for Visual Navigation</title>
    <link href="http://enderfga.cn/2022/04/24/CMP/"/>
    <id>http://enderfga.cn/2022/04/24/CMP/</id>
    <published>2022-04-24T14:56:51.000Z</published>
    <updated>2022-05-28T16:35:25.175Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>认知科学基础课程设计报告</p><span id="more"></span><p>开放性题目，结合视语言、语音识别、机器人平台，采用Webots\ROS等不同开源仿真环境，构建一个单/多智能体的认知导航、认知规划、认知控制仿真算例，里面可以用已有的各种传感器组件、机器人模型，基于前期所讲简单的认知智能知识点做仿真试验，算法可以从github上开源下载使用。鼓励大家选择此题目开展一些小试验，可以提问实现的方式方法。同时提交仿真实现的设计和试验研习报告。突出认知智能应用的关键要点，进行详细阐述说明。</p><embed src="./CMP.pdf" width="100%" height="750" type="application/pdf"><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220424225934056.png" alt=""></p><p>【1】论文地址： <a href="https://arxiv.org/abs/1702.03920">https://arxiv.org/abs/1702.03920</a><br>【2】代码： <a href="https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning">https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning</a><br>【3】论文Slide： <a href="https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1">https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1</a><br>【4】作者主页： <a href="https://people.eecs.berkeley.edu/~sgupta/">https://people.eecs.berkeley.edu/~sgupta/</a><br>【5】作者主页： <a href="https://people.eecs.berkeley.edu/~svlevine/">https://people.eecs.berkeley.edu/~svlevine/</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;认知科学基础课程设计报告&lt;/p&gt;</summary>
    
    
    
    
    <category term="无人系统" scheme="http://enderfga.cn/tags/%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于套接字的网络程序设计</title>
    <link href="http://enderfga.cn/2022/04/19/net2/"/>
    <id>http://enderfga.cn/2022/04/19/net2/</id>
    <published>2022-04-19T11:07:49.000Z</published>
    <updated>2022-05-28T16:35:37.075Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：套接字编程实验</p><span id="more"></span><p><img src="https://blogimg.coding.net/p/img/d/image1/git/raw/master/img/image-20220419191104235.png" alt=""></p><h1 id="套接字编程作业1：Web服务器"><a href="#套接字编程作业1：Web服务器" class="headerlink" title="套接字编程作业1：Web服务器"></a>套接字编程作业1：Web服务器</h1><p>在本实验中，您将学习Python中TCP连接的套接字编程的基础知识：如何创建套接字，将其绑定到特定的地址和端口，以及发送和接收HTTP数据包。您还将学习一些HTTP首部格式的基础知识。</p><p>您将开发一个处理一个HTTP请求的Web服务器。您的Web服务器应该接受并解析HTTP请求，然后从服务器的文件系统获取所请求的文件，创建一个由响应文件组成的HTTP响应消息，前面是首部行，然后将响应直接发送给客户端。如果请求的文件不存在于服务器中，则服务器应该向客户端发送“404 Not Found”差错报文。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>在文件下面你会找到Web服务器的代码框架。您需要填写这个代码。而且需要在标有#Fill in start 和 # Fill in end的地方填写代码。另外，每个地方都可能需要不止一行代码。</p><h3 id="运行服务器"><a href="#运行服务器" class="headerlink" title="运行服务器"></a>运行服务器</h3><p>将HTML文件（例如HelloWorld.html）放在服务器所在的目录中。运行服务器程序。确认运行服务器的主机的IP地址（例如128.238.251.26）。从另一个主机，打开浏览器并提供相应的URL。例如：</p><p><a href="http://128.238.251.26:6789/HelloWorld.html">http://128.238.251.26:6789/HelloWorld.html</a></p><p>“HelloWorld.html”是您放在服务器目录中的文件。还要注意使用冒号后的端口号。您需要使用服务器代码中使用的端口号来替换此端口号。在上面的例子中，我们使用了端口号6789. 浏览器应该显示HelloWorld.html的内容。如果省略“:6789”，浏览器将使用默认端口80，只有当您的服务器正在端口80监听时，才会从服务器获取网页。</p><p>然后用客户端尝试获取服务器上不存在的文件。你应该会得到一个“404 Not Found”消息。</p><h3 id="需要上交的内容"><a href="#需要上交的内容" class="headerlink" title="需要上交的内容"></a>需要上交的内容</h3><p>您需要上交完整的服务器代码，以及客户端浏览器的屏幕截图，用于验证您是否从服务器实际接收到HTML文件内容。</p><h3 id="Web服务器的Python代码框架"><a href="#Web服务器的Python代码框架" class="headerlink" title="Web服务器的Python代码框架"></a>Web服务器的Python代码框架</h3><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#import socket module</span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_STREAM<span class="token punctuation">)</span> <span class="token comment">#Prepare a sever socket </span><span class="token comment">#Fill in start </span><span class="token comment">#Fill in end </span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>       <span class="token comment">#Establish the connection  </span>    <span class="token keyword">print</span> <span class="token string">'Ready to serve...'</span>       connectionSocket<span class="token punctuation">,</span> addr <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>             message <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>        filename <span class="token operator">=</span> message<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                              f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        outputdata <span class="token operator">=</span> <span class="token comment">#Fill in start  #Fill in end</span>        <span class="token comment">#Send one HTTP header line into socket     </span>        <span class="token comment">#Fill in start     </span>        <span class="token comment">#Fill in end  </span>        <span class="token comment">#Send the content of the requested file to the client</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>outputdata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            connectionSocket<span class="token punctuation">.</span>send<span class="token punctuation">(</span>outputdata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        connectionSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> IOError<span class="token punctuation">:</span>        <span class="token comment">#Send response message for file not found</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end</span>        <span class="token comment">#Close client socket</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end         </span>    serverSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="可选练习"><a href="#可选练习" class="headerlink" title="可选练习"></a>可选练习</h3><ol><li>目前，这个Web服务器一次只处理一个HTTP请求。请实现一个能够同时处理多个请求的多线程服务器。使用线程，首先创建一个主线程，在固定端口监听客户端请求。当从客户端收到TCP连接请求时，它将通过另一个端口建立TCP连接，并在另外的单独线程中为客户端请求提供服务。这样在每个请求/响应对的独立线程中将有一个独立的TCP连接。</li><li>不使用浏览器，编写自己的HTTP客户端来测试你的服务器。您的客户端将使用一个TCP连接用于连接到服务器，向服务器发送HTTP请求，并将服务器响应显示出来。您可以假定发送的HTTP请求将使用GET方法。<br>客户端应使用命令行参数指定服务器IP地址或主机名，服务器正在监听的端口，以及被请求对象在服务器上的路径。</li></ol><h1 id="套接字编程作业2：UDPping程序"><a href="#套接字编程作业2：UDPping程序" class="headerlink" title="套接字编程作业2：UDPping程序"></a>套接字编程作业2：UDPping程序</h1><p>在本实验中，您将学习使用Python进行UDP套接字编程的基础知识。您将学习如何使用UDP套接字发送和接收数据报，以及如何设置适当的套接字超时。在实验中，您将熟悉Ping应用程序及其在计算统计信息（如丢包率）中的作用。</p><p>您首先需要研究一个用Python编写的简单的ping服务器程序，并实现对应的客户端程序。这些程序提供的功能类似于现代操作系统中可用的标准ping程序功能。然而，我们的程序使用更简单的UDP协议，而不是标准互联网控制消息协议（ICMP）来进行通信。 ping协议允许客户端机器发送一个数据包到远程机器，并使远程机器将数据包返回到客户（称为回显）的操作。另外，ping协议允许主机计算它到其他机器的往返时间。</p><p>以下是Ping服务器程序的完整代码。你的任务是写出Ping客户端程序。</p><h3 id="服务器代码"><a href="#服务器代码" class="headerlink" title="服务器代码"></a>服务器代码</h3><p>以下代码完整实现了一个ping服务器。您需要在运行客户端程序之前编译并运行此代码。<em>而且您不需要修改此代码。</em></p><p>在这个服务器代码中，30％的客户端的数据包会被模拟丢失。你应该仔细研究这个代码，它将帮助你编写ping客户端。</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># UDPPingerServer.py </span><span class="token comment"># We will need the following module to generate randomized lost packets import random </span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span> <span class="token keyword">import</span> random<span class="token comment"># Create a UDP socket  </span><span class="token comment"># Notice the use of SOCK_DGRAM for UDP packets </span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_DGRAM<span class="token punctuation">)</span> <span class="token comment"># Assign IP address and port number to socket </span>serverSocket<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token number">12000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>   <span class="token comment"># Generate random number in the range of 0 to 10 </span>rand <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>   <span class="token comment"># Receive the client packet along with the address it is coming from  </span>message<span class="token punctuation">,</span> address <span class="token operator">=</span> serverSocket<span class="token punctuation">.</span>recvfrom<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span> <span class="token comment"># Capitalize the message from the client   </span>message <span class="token operator">=</span> message<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If rand is less is than 4, we consider the packet lost and do not respond   </span><span class="token keyword">if</span> rand <span class="token operator">&lt;</span> <span class="token number">4</span><span class="token punctuation">:</span>     <span class="token keyword">continue</span>   <span class="token comment"># Otherwise, the server responds     </span>serverSocket<span class="token punctuation">.</span>sendto<span class="token punctuation">(</span>message<span class="token punctuation">,</span> address<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>服务器程序在一个无限循环中监听到来的UDP数据包。当数据包到达时，如果生成一个随机整数大于或等于4，则服务器将数字转为大写并将其发送回客户端。</p><h3 id="数据包丢失"><a href="#数据包丢失" class="headerlink" title="数据包丢失"></a>数据包丢失</h3><p>UDP为应用程序提供了不可靠的传输服务。消息可能因为路由器队列溢出，硬件错误或其他原因，而在网络中丢失。但由于在内网中很丢包甚至不丢包，所以在本实验室的服务器程序添加人为损失来模拟网络丢包的影响。服务器创建一个随机整数，由它确定传入的数据包是否丢失。</p><h3 id="客户端代码"><a href="#客户端代码" class="headerlink" title="客户端代码"></a>客户端代码</h3><p>您需要实现以下客户端程序。</p><p>客户端向服务器发送10次ping。因为UDP是不可靠的协议，所以从客户端发送到服务器的数据包可能在网络中丢失。因此，客户端不能无限期地等待ping消息的回复。客户等待服务器回答的时间至多为一秒，如果在一秒内没有收到回复，您的客户端程序应该假定数据包在网络传输期间丢失。您需要查找Python文档，以了解如何在数据报套接字上设置超时值。</p><p>具体来说，您的客户端程序应该</p><ol><li>使用UDP发送ping消息（注意：不同于TCP，您不需要首先建立连接，因为UDP是无连接协议。）</li><li>从服务器输出响应消息</li><li>如果从服务器受到响应，则计算并输出每个数据包的往返时延（RTT）（以秒为单位），</li><li>否则输出“请求超时”</li></ol><p>在开发过程中，您应该先在计算机上运行 <code>UDPPingerServer.py</code>，并通过向 <code>localhost</code>（或127.0.0.1）发送数据包来测试客户端。调试完成代码后，您应该能看到ping服务器和ping客户端在不同机器上通过网络进行通信。</p><h3 id="消息格式"><a href="#消息格式" class="headerlink" title="消息格式"></a>消息格式</h3><p>本实验中的ping消息格式使用最简单的方式。客户端消息只有一行，由以下格式的ASCII字符组成：</p><blockquote><p>Ping <em>sequence_number time</em></p></blockquote><p>其中<em>sequence_number</em>从1开始，一直到10，共10条消息，而<em>time</em>则是客户端发送消息时的时间。</p><h3 id="需要上交的内容-1"><a href="#需要上交的内容-1" class="headerlink" title="需要上交的内容"></a>需要上交的内容</h3><p>您需要上交完整的客户端代码和屏幕截图，以验证您的ping程序是否按需求运行。</p><h3 id="可选练习-1"><a href="#可选练习-1" class="headerlink" title="可选练习"></a>可选练习</h3><ol><li>目前，程序计算每个数据包的往返时间（RTT），并单独打印出来。请按照标准ping程序的模式修改。您需要在客户端每次ping后显示最小，最大和平均RTT。另外，还需计算丢包率（百分比）。</li><li>UDP Ping的另一个类似的应用是UDP Heartbeat。心跳可用于检查应用程序是否已启动并运行，并报告单向丢包。客户端在UDP数据包中将一个序列号和当前时间戳发送给正在监听客户端心跳的服务器。服务器收到数据包后，计算时差，报告丢包（若发生）。如果心跳数据包在指定的一段时间内丢失，我们可以假设客户端应用程序已经停止。实现UDP Heartbeat（客户端和服务器端）。您需要修改给定的UDPPingerServer.py和您自己的UDP ping客户端。</li></ol><p><strong>以上内容来自《计算机网络：自顶向下方法》官方文档，与我的作业有部分不同，详见pdf。</strong></p><p><strong>个人实验报告</strong></p><embed src="./Socket.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;计网作业：套接字编程实验&lt;/p&gt;</summary>
    
    
    
    
    <category term="计算机网络" scheme="http://enderfga.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
