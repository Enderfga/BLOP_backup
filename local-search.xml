<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>C2TCP：一个超低延迟的灵活蜂窝式TCP</title>
    <link href="/2022/05/16/net4/"/>
    <url>/2022/05/16/net4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计算机网络前沿论文导读</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/2432716a34cb4571ac86e2b7f56f617.png" /></p><span id="more"></span><embed src="./C2TCP.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智能机器人技术——机器人运动学奇异分析与性能评价</title>
    <link href="/2022/05/15/robot5/"/>
    <url>/2022/05/15/robot5/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><h1id="智能机器人技术机器人运动学奇异分析与性能评价">智能机器人技术——机器人运动学奇异分析与性能评价</h1><p>一、给定平面2R机械臂状态参数，</p><p>状态描述：</p><ul><li>关节状态: <span class="math inline">\(\quad\left[\theta_{1},\theta_{2}\right]^{\mathrm{T}}\)</span></li><li>末端位置: <span class="math inline">\(\quad\left[x_{e},y_{e}\right]^{\mathrm{T}}\)</span></li></ul><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220508155155580.png"alt="image-20220508155155580" /><figcaption aria-hidden="true">image-20220508155155580</figcaption></figure><ol type="1"><li><p>计算逆运动学，求解关节角的表达式（已知末端位置<spanclass="math inline">\(\quad\left[x_{e},y_{e}\right]^{\mathrm{T}}\)</span>，求关节角<spanclass="math inline">\(\quad\left[\theta_{1},\theta_{2}\right]^{\mathrm{T}}\)</span>）</p><p>根据几何关系, 可推导出机械臂末端位置与机械臂关节变量的关系:</p><p><span class="math display">\[\begin{array}{l}p_{\mathrm{ex}}=l_{1} c_{1}+l_{2} c_{12} \\p_{\mathrm{ey}}=l_{1} s_{1}+l_{2} s_{12}\end{array}\]</span></p><p>其中,</p><p><span class="math display">\[\left\{\begin{array}{l}s_{1}=\sin \theta_{1}, c_{1}=\cos \theta_{1} \\s_{12}=\sin \left(\theta_{1}+\theta_{2}\right), c_{12}=\cos\left(\theta_{1}+\theta_{2}\right)\end{array}\right.\]</span></p><p>其向量形式为：</p><p><span class="math display">\[p_{\mathrm{e}}=\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{e} y}\end{array}\right]=\left[\begin{array}{l}l_{1} c_{1}+l_{2} c_{12} \\l_{1} s_{1}+l_{2} s_{12}\end{array}\right]=\left[\begin{array}{l}l_{1} \cos \theta_{1}+l_{2} \cos \left(\theta_{1}+\theta_{2}\right) \\l_{1} \sin \theta_{1}+l_{2} \sin \left(\theta_{1}+\theta_{2}\right)\end{array}\right]\]</span></p><p>将式子两边的平方相加, 有</p><p><span class="math display">\[p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}\left(c_{1}c_{12}+s_{1} s_{12}\right)\]</span></p><p><spanclass="math inline">\(p_{\mathrm{e}}^{2}=p_{\mathrm{ex}}^{2}+p_{\mathrm{ey}}^{2}\)</span>为基坐标系原点到末端坐标系原点的距离。</p><p>根据三角函数的性质, 有</p><p><span class="math display">\[c_{1} c_{12}+s_{1} s_{12}=c_{2}\]</span></p><p>故可化简为</p><p><span class="math display">\[p_{\mathrm{e}}^{2}=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}\]</span></p><p>因此，</p><p><span class="math display">\[\left\{\begin{array}{l}p_{\mathrm{e}}^{2} \leqslant l_{1}^{2}+l_{2}^{2}+2 l_{1}l_{2}=\left(l_{1}+l_{2}\right)^{2} \\p_{\mathrm{e}}^{2} \geqslant l_{1}^{2}+l_{2}^{2}-2 l_{1}l_{2}=\left(l_{1}-l_{2}\right)^{2}\end{array}\right.\\\left|l_{1}-l_{2}\right| \leqslant p_{e} \leqslant l_{1}+l_{2}\]</span></p><p>上式即表示了该 <span class="math inline">\(2 \mathrm{R}\)</span>机械臂的工作空间范围, 其最小边沿和最大边沿分别对应于 <spanclass="math inline">\(\theta_{2}=\pi\)</span> 和 <spanclass="math inline">\(\theta_{2}=0\)</span> 的情况。</p><p>进一步有，</p><p><span class="math display">\[\left|\frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1}l_{2}}\right| \leqslant 1\]</span></p><p>解得：</p><p><span class="math display">\[\theta_{2}=\pm \arccos \frac{p_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2l_{1} l_{2}}=\pm \arccos\frac{x_{\mathrm{e}}^{2}+y_{\mathrm{e}}^{2}-l_{1}^{2}-l_{2}^{2}}{2 l_{1}l_{2}}\]</span></p><p>关节角 <span class="math inline">\(\theta_{2}\)</span> 解出后,将其代入方程组中, 可进一步解出关节角 <spanclass="math inline">\(\theta_{1}\)</span> 。首先根据三角函数的性质:</p><p><span class="math display">\[\begin{aligned}&amp;c_{12}=c_{1} c_{2}-s_{1} s_{2} \\&amp;s_{12}=s_{1} c_{2}+c_{1} s_{2}\end{aligned}\]</span></p><p>有，</p><p><span class="math display">\[\left\{\begin{array}{l}\left(l_{1}+l_{2} c_{2}\right) c_{1}-l_{2} s_{2} s_{1}=p_{\mathrm{ex}}\\l_{2} s_{2} c_{1}+\left(l_{1}+l_{2} c_{2}\right) s_{1}=p_{\mathrm{e} y}\end{array}\right.\]</span></p><p>可写成如下形式:</p><p><span class="math display">\[\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right]\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{l}p_{e x} \\p_{\mathrm{ey}}\end{array}\right]\]</span></p><p>方程组的系数矩阵 <span class="math inline">\(\boldsymbol{A}\)</span>及其行列式分别为</p><p><span class="math display">\[\boldsymbol{A}=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right],\operatorname{det}(\boldsymbol{A})=l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}c_{2}\]</span></p><p>若 <span class="math inline">\(\operatorname{det}(\boldsymbol{A})\neq 0\)</span>, 则矩阵 <spanclass="math inline">\(\boldsymbol{A}\)</span> 满秩, 方程组有解, 即:</p><p><span class="math display">\[\left[\begin{array}{l}c_{1} \\s_{1}\end{array}\right]=\left[\begin{array}{cc}l_{1}+l_{2} c_{2} &amp; -l_{2} s_{2} \\l_{2} s_{2} &amp; l_{1}+l_{2} c_{2}\end{array}\right]^{-1}\left[\begin{array}{l}p_{\mathrm{ex}} \\p_{\mathrm{ey}}\end{array}\right]=\frac{1}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2}c_{2}}\left[\begin{array}{c}\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2}p_{\mathrm{ey}} \\-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ey}}\end{array}\right]\]</span></p><p><span class="math inline">\(\theta_{1}\)</span> 可根据解出的 <spanclass="math inline">\(s_{1}\)</span> 和 <spanclass="math inline">\(c_{1}\)</span> 求出, 即:</p><p><span class="math display">\[\begin{aligned}\theta_{1} &amp;=\arctan 2\left(s_{1}, c_{1}\right)=\arctan2\left(\frac{-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}},\frac{\left(l_{1}+l_{2} c_{2}\right) p_{\mathrm{ex}}+l_{2} s_{2}p_{\mathrm{ey}}}{l_{1}^{2}+l_{2}^{2}+2 l_{1} l_{2} c_{2}}\right) \\&amp;=\arctan 2\left(-l_{2} s_{2} p_{\mathrm{ex}}+\left(l_{1}+l_{2}c_{2}\right) p_{\mathrm{ey}},\left(l_{1}+l_{2} c_{2}\right)p_{\mathrm{ex}}+l_{2} s_{2} p_{\mathrm{ey}}\right)\end{aligned}\]</span></p><p>根据基本不等式及三级函数的性质, 令 <spanclass="math inline">\(\operatorname{det}(\boldsymbol{A})=0\)</span>,则必有 <span class="math inline">\(l_{1}=l_{2}\)</span> 且 <spanclass="math inline">\(\theta_{2}=\pi\)</span>, 即:</p><p><span class="math display">\[\operatorname{det}(\boldsymbol{A})=0 \Rightarrow\left\{\begin{array} { l}{ l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } + 2 l _ { 1 } l _ { 2 } c _ { 2} = 0 } \\{ l _ { 1 } ^ { 2 } + l _ { 2 } ^ { 2 } \geqslant 2 l _ { 1 } l _ { 2 }} \\{ | c _ { 2 } | \leqslant 1 }\end{array} \Rightarrow \left\{\begin{array}{l}l_{1}=l_{2} \\\theta_{2}=\pi\end{array}\right.\right.\]</span></p><p>综上所述, 结果可以求出两组解, 对应于机器人的两种臂型, 分别称为高臂(肘) 和低臂 (肘), 平面 <span class="math inline">\(2 \mathrm{R}\)</span>机械臂逆运动学多解情况分析下图所示。也就是说, 对于前述的 <spanclass="math inline">\(2 \mathrm{R}\)</span> 机械臂,当给定末端点的一个位置 <spanclass="math inline">\(\boldsymbol{p}_{\mathrm{e}}\)</span> 时,有两组关节角与之对应, 即位置级逆运动学有多解。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220515125458389.png"alt="image-20220515125458389" /><figcaption aria-hidden="true">image-20220515125458389</figcaption></figure></li><li><p>计算雅克比矩阵</p></li></ol><p>根据机械臂末端位置与机械臂关节变量的关系求导得：</p><p><span class="math display">\[\left\{\begin{array}{l}\dot{p}_{\mathrm{ex}}=-l_{1} s_{1} \dot{\theta}_{1}-l_{2}s_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=-\left(l_{1}s_{1}+l_{2} s_{12}\right) \dot{\theta}_{1}-l_{2} s_{12} \dot{\theta}_{2}\\\dot{p}_{\mathrm{cy}}=l_{1} c_{1} \dot{\theta}_{1}+l_{2}c_{12}\left(\dot{\theta}_{1}+\dot{\theta}_{2}\right)=\left(l_{1}c_{1}+l_{2} c_{12}\right) \dot{\theta}_{1}+l_{2} c_{12} \dot{\theta}_{2}\\\end{array}\right.\]</span></p><p>即:</p><p><span class="math display">\[\left[\begin{array}{l}\dot{p}_{\mathrm{ex}} \\\dot{p}_{\mathrm{ey}}\end{array}\right]=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} &amp; -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} &amp; l_{2} c_{12}\end{array}\right]\left[\begin{array}{l}\dot{\theta}_{1} \\\dot{\theta}_{2}\end{array}\right]\]</span></p><p>其矩阵形式为：</p><p><span class="math display">\[\dot{\boldsymbol{p}}_{\mathrm{e}}=\boldsymbol{J}_{v}(\boldsymbol{\Theta})\dot{\boldsymbol{\Theta}}\]</span></p><p>此时, <span class="math inline">\(\boldsymbol{J}_{v}\)</span> 为<span class="math inline">\(2 \times 2\)</span> 的方阵:</p><p><span class="math display">\[\boldsymbol{J}_{v}=\left[\begin{array}{cc}-l_{1} s_{1}-l_{2} s_{12} &amp; -l_{2} s_{12} \\l_{1} c_{1}+l_{2} c_{12} &amp; l_{2} c_{12}\end{array}\right]\]</span></p><p>二、给点D-H坐标系，填写D-H参数表。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220515131813671.png"alt="image-20220515131813671" /><figcaption aria-hidden="true">image-20220515131813671</figcaption></figure><p><span class="math display">\[\begin{array}{ccccc}\hline  \text { 连杆i } &amp; \theta_{i} &amp; \alpha_{i} &amp; a_{i}&amp; d_{i} \\\hline1 &amp; 0 &amp; -90^{\circ} &amp; 0 &amp; d_{1} \\2 &amp; 0 &amp; 0 &amp; a_{2} &amp; 0 \\  3 &amp; 0 &amp; 0 &amp; a_{3} &amp; 0\\  \hline\end{array}\]</span></p>]]></content>
    
    
    
    <tags>
      
      <tag>机器人</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch常用代码段合集</title>
    <link href="/2022/05/10/torch/"/>
    <url>/2022/05/10/torch/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>PyTorch最好的资料是官方文档。本文是PyTorch常用代码段，在参考资料的基础上做了一些修补，方便使用时查阅。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220511003116457.png"alt="image-20220511003116457" /><figcaption aria-hidden="true">image-20220511003116457</figcaption></figure><span id="more"></span><h1 id="基本配置"><strong>基本配置</strong></h1><h3 id="导入包和版本查询"><strong>导入包和版本查询</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="可复现性"><strong>可复现性</strong></h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>显卡设置</p><p>如果只需要一张显卡</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Device configuration</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>如果需要指定多张显卡，比如0，1号显卡。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'0,1'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>也可以在命令行运行代码时设置显卡：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> python train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>清除显存</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>也可以使用在命令行重置GPU的指令</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi --gpu-reset -i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h1 id="张量tensor处理"><strong>张量(Tensor)处理</strong></h1><h3 id="张量的数据类型"><strong>张量的数据类型</strong></h3><p>PyTorch有9种CPU张量类型和9种GPU张量类型。</p><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/640"alt="图片" /><figcaption aria-hidden="true">图片</figcaption></figure><h3 id="张量基本信息"><strong>张量基本信息</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 数据类型</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 张量的shape，是个元组</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 维度的数量</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="命名张量"><strong>命名张量</strong></h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在PyTorch 1.3之前，需要使用注释</span><span class="token comment"># Tensor[N, C, H, W]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># PyTorch 1.3之后</span>NCHW <span class="token operator">=</span> <span class="token punctuation">[</span>‘N’<span class="token punctuation">,</span> ‘C’<span class="token punctuation">,</span> ‘H’<span class="token punctuation">,</span> ‘W’<span class="token punctuation">]</span>images <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> names<span class="token operator">=</span>NCHW<span class="token punctuation">)</span>images<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>images<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 也可以这么设置</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 使用align_to可以对维度方便地排序</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>align_to<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'W'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="数据类型转换">数据类型转换</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span>torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token comment"># 类型转换</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="torch.tensor与np.ndarray转换"><strong>torch.Tensor与np.ndarray转换</strong></h3><p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If ndarray has negative stride.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3id="torch.tensor与pil.image转换"><strong>Torch.tensor与PIL.Image转换</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span><span class="token comment"># torch.Tensor -> PIL.Image</span>image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor<span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># Equivalently way</span><span class="token comment"># PIL.Image -> torch.Tensor</span>path <span class="token operator">=</span> <span class="token string">r'./figure.jpg'</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#Equivalently way</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="np.ndarray与pil.image的转换">np.ndarray与PIL.Image的转换</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>ndarray <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h3id="从只包含一个元素的张量中提取值"><strong>从只包含一个元素的张量中提取值</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">value <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="张量形变"><strong>张量形变</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，</span><span class="token comment"># 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="打乱顺序"><strong>打乱顺序</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 打乱第一个维度</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="水平翻转"><strong>水平翻转</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现</span><span class="token comment"># 假设张量的维度为[N, D, H, W].</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3 id="复制张量"><strong>复制张量</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Operation                 |  New/Shared memory | Still in computation graph |</span>tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># |        New         |          Yes               |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># |      Shared        |          No                |</span>tensor<span class="token punctuation">.</span>detach<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># |        New         |          No                | </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="张量拼接"><strong>张量拼接</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，而torch.stack的结果是3x10x5的张量。'''</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="将整数标签转为one-hot编码"><strong>将整数标签转为one-hot编码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pytorch的标记默认从0开始</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">4</span>one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="得到非零元素"><strong>得到非零元素</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>               <span class="token comment"># index of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment"># index of zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>       <span class="token comment"># number of non-zero elements</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># number of zero elements</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="判断两个张量相等"><strong>判断两个张量相等</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>  <span class="token comment"># float tensor</span>torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>     <span class="token comment"># int tensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h3 id="张量扩展"><strong>张量扩展</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><h3 id="矩阵乘法"><strong>矩阵乘法</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Matrix multiplcation: (m*n) * (n*p) * -> (m*p).</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p)</span>result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token comment"># Element-wise multiplication.</span>result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="计算两组数据之间的两两欧式距离"><strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用broadcast机制</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> X2<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h1 id="模型定义和操作"><strong>模型定义和操作</strong></h1><h3 id="一个简单两层卷积网络的示例">一个简单两层卷积网络的示例</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># convolutional neural network (2 convolutional layers)</span><span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> outmodel <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>卷积层的计算和展示可以用这个网站辅助。</p><p>https://ezyang.github.io/convolution-visualizer/index.html</p><h3 id="双线性汇合bilinear-pooling">双线性汇合（bilinear pooling）</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">)</span>                        <span class="token comment"># Assume X has shape N*D*H*W</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W<span class="token punctuation">)</span>  <span class="token comment"># Bilinear pooling</span><span class="token keyword">assert</span> X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> D<span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>   <span class="token comment"># Signed-sqrt normalization</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">)</span>                  <span class="token comment"># L2 normalization</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="多卡同步-bnbatch-normalization"><strong>多卡同步 BN（Batchnormalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batchsize）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>   affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3id="将已有网络的所有bn层改为同步bn层">将已有网络的所有BN层改为同步BN层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">convertBNtoSyncBN</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> process_group<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''Recursively replace all BN layers to SyncBN layer.    Args:        module[torch.nn.Module]. Network    '''</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>batchnorm<span class="token punctuation">.</span>_BatchNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>        sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>module<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> module<span class="token punctuation">.</span>eps<span class="token punctuation">,</span> module<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span>                                          module<span class="token punctuation">.</span>affine<span class="token punctuation">,</span> module<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">,</span> process_group<span class="token punctuation">)</span>        sync_bn<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> module<span class="token punctuation">.</span>running_mean        sync_bn<span class="token punctuation">.</span>running_var <span class="token operator">=</span> module<span class="token punctuation">.</span>running_var        <span class="token keyword">if</span> module<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>            sync_bn<span class="token punctuation">.</span>weight <span class="token operator">=</span> module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>            sync_bn<span class="token punctuation">.</span>bias <span class="token operator">=</span> module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> sync_bn    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> child_module <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token builtin">setattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">=</span> convert_syncbn_model<span class="token punctuation">(</span>child_module<span class="token punctuation">,</span> process_group<span class="token operator">=</span>process_group<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> module<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="类似-bn-滑动平均"><strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward函数中要使用原地（inplace）操作给滑动平均赋值。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        self<span class="token punctuation">.</span>running_mean <span class="token operator">+=</span> momentum <span class="token operator">*</span> <span class="token punctuation">(</span>current <span class="token operator">-</span> self<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="计算模型整体参数量"><strong>计算模型整体参数量</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="查看网络中的参数"><strong>查看网络中的参数</strong></h3><p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name2<span class="token punctuation">,</span> param2<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'----------------------------------------------------'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>name1<span class="token punctuation">,</span> param1<span class="token punctuation">)</span> <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>name1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>param1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="模型可视化使用pytorchviz"><strong>模型可视化（使用pytorchviz）</strong></h3><p>https://github.com/szagoruyko/pytorchviz</p><h3id="类似-keras-的-model.summary-输出模型信息使用pytorch-summary"><strong>类似Keras 的 model.summary() 输出模型信息（使用pytorch-summary）</strong></h3><p>https://github.com/sksq96/pytorch-summary</p><p><strong>模型权重初始化</strong></p><p>注意 model.modules() 和 model.children() 的区别：model.modules()会迭代地遍历模型的所有子层，而 model.children()只会遍历模型下的一层。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Common practise for initialization.</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span>                                      nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token comment"># Initialization with given tensor.</span>layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取模型中的某一层"><strong>提取模型中的某一层</strong></h3><p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 取模型中的前两层</span>new_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>         conv_model<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="部分层使用预训练模型"><strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="将在-gpu-保存的模型加载到-cpu">将在 GPU 保存的模型加载到CPU</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h2id="导入另一个模型的相同部分到新的模型"><strong>导入另一个模型的相同部分到新的模型</strong></h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># model_new代表新的模型</span><span class="token comment"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span>model_new_dict <span class="token operator">=</span> model_new<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>model_common_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> model_saved<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> model_new_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>model_new_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_common_dict<span class="token punctuation">)</span>model_new<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_new_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="数据处理"><strong>数据处理</strong></h1><h3 id="计算数据集的均值和标准差">计算数据集的均值和标准差</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">compute_mean_and_std</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 输入PyTorch的dataset，输出均值和标准差</span>    mean_r <span class="token operator">=</span> <span class="token number">0</span>    mean_g <span class="token operator">=</span> <span class="token number">0</span>    mean_b <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># change PIL Image to numpy array</span>        mean_r <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_g <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        mean_b <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    mean_r <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_g <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    mean_b <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    diff_r <span class="token operator">=</span> <span class="token number">0</span>    diff_g <span class="token operator">=</span> <span class="token number">0</span>    diff_b <span class="token operator">=</span> <span class="token number">0</span>    N <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> _ <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>        img <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        diff_r <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_r<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_g <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_g<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        diff_b <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> mean_b<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        N <span class="token operator">+=</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    std_r <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_r <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_g <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_g <span class="token operator">/</span> N<span class="token punctuation">)</span>    std_b <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>diff_b <span class="token operator">/</span> N<span class="token punctuation">)</span>    mean <span class="token operator">=</span> <span class="token punctuation">(</span>mean_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> mean_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    std <span class="token operator">=</span> <span class="token punctuation">(</span>std_r<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_g<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> std_b<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> mean<span class="token punctuation">,</span> std<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="得到视频数据基本信息">得到视频数据基本信息</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> cv2video <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>mp4_path<span class="token punctuation">)</span>height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_HEIGHT<span class="token punctuation">)</span><span class="token punctuation">)</span>width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_WIDTH<span class="token punctuation">)</span><span class="token punctuation">)</span>num_frames <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FRAME_COUNT<span class="token punctuation">)</span><span class="token punctuation">)</span>fps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>CAP_PROP_FPS<span class="token punctuation">)</span><span class="token punctuation">)</span>video<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="tsn-每段segment采样一帧视频">TSN每段（segment）采样一帧视频</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">K <span class="token operator">=</span> self<span class="token punctuation">.</span>_num_segments<span class="token keyword">if</span> is_train<span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Random index for each segment.</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames <span class="token operator">//</span> K<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>            high<span class="token operator">=</span>num_frames<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> frame_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> num_frames <span class="token operator">></span> K<span class="token punctuation">:</span>        <span class="token comment"># Middle index for each segment.</span>        frame_indices <span class="token operator">=</span> num_frames <span class="token operator">/</span> K <span class="token operator">//</span> <span class="token number">2</span>        frame_indices <span class="token operator">+=</span> num_frames <span class="token operator">//</span> K <span class="token operator">*</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        frame_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>                                        torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_frames<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>K <span class="token operator">-</span> num_frames<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">assert</span> frame_indices<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token punctuation">[</span>frame_indices<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="常用训练和验证数据预处理"><strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255]的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的torch.Tensor。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span>                                             scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span><span class="token punctuation">)</span> val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="模型训练和测试"><strong>模型训练和测试</strong></h1><h3 id="分类模型训练代码"><strong>分类模型训练代码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Loss and optimizer</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># Train the model</span>total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token punctuation">,</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>              <span class="token comment"># Forward pass</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>              <span class="token comment"># Backward and optimizer</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: [&#123;&#125;/&#123;&#125;], Step: [&#123;&#125;/&#123;&#125;], Loss: &#123;&#125;'</span>                  <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="分类模型测试代码"><strong>分类模型测试代码</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Test the model</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># eval mode(batch norm uses moving mean/variance </span>              <span class="token comment">#instead of mini-batch mean/variance)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy of the model on the 10000 test images: &#123;&#125; %'</span>          <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="自定义loss"><strong>自定义loss</strong></h3><p>继承torch.nn.Module类写自己的loss。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLoss</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Moudle<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="标签平滑label-smoothing"><strong>标签平滑（labelsmoothing）</strong></h3><p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log_softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>e <span class="token operator">=</span> e        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction      <span class="token keyword">def</span> <span class="token function">_one_hot</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> classes<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""            Convert labels to one hot vectors              Args:            labels: torch tensor in format [label1, label2, label3, ...]            classes: int, number of classes            value: label value in one hot vector, default to 1              Returns:            return one hot format labels in shape [batchsize, classes]        """</span>        one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span>        <span class="token comment">#labels and value_added  size must match</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        value_added <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>value<span class="token punctuation">)</span>        value_added <span class="token operator">=</span> value_added<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot <span class="token operator">=</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        one_hot<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> value_added<span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot    <span class="token keyword">def</span> <span class="token function">_smooth_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> smooth_factor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""convert targets to one-hot format, and smooth        them.        Args:            target: target in form with [label1, label2, label_batchsize]            length: length of one-hot format(number of classes)            smooth_factor: smooth factor for label smooth              Returns:            smoothed labels in one hot format        """</span>        one_hot <span class="token operator">=</span> self<span class="token punctuation">.</span>_one_hot<span class="token punctuation">(</span>target<span class="token punctuation">,</span> length<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> smooth_factor<span class="token punctuation">)</span>        one_hot <span class="token operator">+=</span> smooth_factor <span class="token operator">/</span> <span class="token punctuation">(</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> one_hot<span class="token punctuation">.</span>to<span class="token punctuation">(</span>target<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">!=</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Expected input tensor to have least 2 dimensions(got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Only 2 dimension tensor are implemented, (got &#123;&#125;)'</span>                    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        smoothed_target <span class="token operator">=</span> self<span class="token punctuation">.</span>_smooth_label<span class="token punctuation">(</span>target<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>e<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span> x <span class="token operator">*</span> smoothed_target<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'none'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> loss              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'sum'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">'mean'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'unrecognized option, expect reduction to be one of none, mean, sum'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>或者直接在训练文件里做label smoothing</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    N <span class="token operator">=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># C is the number of classes.</span>    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="mixup训练"><strong>Mixup训练</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">beta_distribution <span class="token operator">=</span> torch<span class="token punctuation">.</span>distributions<span class="token punctuation">.</span>beta<span class="token punctuation">.</span>Beta<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Mixup images and labels.</span>    lambda_ <span class="token operator">=</span> beta_distribution<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>images<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    mixed_images <span class="token operator">=</span> lambda_ <span class="token operator">*</span> images <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> images<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    label_a<span class="token punctuation">,</span> label_b <span class="token operator">=</span> labels<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token comment"># Mixup loss.</span>    scores <span class="token operator">=</span> model<span class="token punctuation">(</span>mixed_images<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>lambda_ <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_a<span class="token punctuation">)</span>            <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> lambda_<span class="token punctuation">)</span> <span class="token operator">*</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> label_b<span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="l1-正则化">L1 正则化</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">l1_regularization <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment"># Standard cross-entropy loss</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    loss <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="不对偏置项进行权重衰减weight-decay"><strong>不对偏置项进行权重衰减（weightdecay）</strong></h3><p>pytorch里的weight decay相当于l2正则</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">bias_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>others_list <span class="token operator">=</span> <span class="token punctuation">(</span>param <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> name<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> bias_list<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            <span class="token punctuation">&#123;</span><span class="token string">'parameters'</span><span class="token punctuation">:</span> others_list<span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="梯度裁剪gradient-clipping"><strong>梯度裁剪（gradientclipping）</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><h3 id="得到当前学习率"><strong>得到当前学习率</strong></h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># If there is one global learning rate (which is the common case).</span>lr <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token comment"># If there are multiple learning rates for different layers.</span>all_lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>    all_lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>另一种方法，在一个batch训练代码里，当前的lr是optimizer.param_groups[0]['lr']</p><h3 id="学习率衰减">学习率衰减</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Reduce learning rate when validation accuarcy plateau.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span class="token comment"># Cosine annealing learning rate.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token comment"># Reduce learning rate by 10 at given epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># Learning rate warmup by 10 epochs.</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t <span class="token operator">/</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    val<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="优化器链式更新"><strong>优化器链式更新</strong></h3><p>从1.4版本开始，torch.optim.lr_scheduler支持链式更新（chaining），即用户可以定义两个schedulers，并交替在训练中使用。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> ExponentialLR<span class="token punctuation">,</span> StepLRmodel <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> SGD<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>scheduler1 <span class="token operator">=</span> ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>scheduler2 <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> scheduler2<span class="token punctuation">.</span>get_last_lr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler2<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="模型训练可视化"><strong>模型训练可视化</strong></h3><p>PyTorch可以使用tensorboard来可视化训练过程。</p><p>安装和运行TensorBoard。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> tensorboardtensorboard --logdir<span class="token operator">=</span>runs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如'Loss/train'和'Loss/test'。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> n_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Loss/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/train'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Accuracy/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="保存与加载断点"><strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">start_epoch <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># Load checkpoint.</span><span class="token keyword">if</span> resume<span class="token punctuation">:</span> <span class="token comment"># resume为参数，第一次训练时设为0，中断再训练时设为1</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    best_acc <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_acc'</span><span class="token punctuation">]</span>    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load checkpoint at epoch &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best accuracy so far &#123;&#125;.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Train the model</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token comment"># Test the model</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          <span class="token comment"># save checkpoint</span>    is_best <span class="token operator">=</span> current_acc <span class="token operator">></span> best_acc    best_acc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>current_acc<span class="token punctuation">,</span> best_acc<span class="token punctuation">)</span>    checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">'best_acc'</span><span class="token punctuation">:</span> best_acc<span class="token punctuation">,</span>        <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token string">'model'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'checkpoint.pth.tar'</span><span class="token punctuation">)</span>    best_model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'model'</span><span class="token punctuation">,</span> <span class="token string">'best_checkpoint.pth.tar'</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span>    <span class="token keyword">if</span> is_best<span class="token punctuation">:</span>        shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> best_model_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取-imagenet-预训练模型某层的卷积特征">提取 ImageNet预训练模型某层的卷积特征</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># VGG-16 pool5 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token comment"># VGG-16 fc7 feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># ResNet GAP feature.</span>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="提取-imagenet-预训练模型多层的卷积特征">提取 ImageNet预训练模型多层的卷积特征</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Helper class to extract several convolution features from the given    pre-trained model.    Attributes:        _model, torch.nn.Module.        _layers_to_extract, list&lt;str> or set&lt;str>    Example:        >>> model = torchvision.models.resnet152(pretrained=True)        >>> model = torch.nn.Sequential(collections.OrderedDict(                list(model.named_children())[:-1]))        >>> conv_representation = FeatureExtractor(                pretrained_model=model,                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            <span class="token keyword">return</span> conv_representation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="微调全连接层">微调全连接层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># Replace the last fc layer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3id="以较大学习率微调全连接层较小学习率微调卷积层">以较大学习率微调全连接层，较小学习率微调卷积层</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>               <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="其他注意事项"><strong>其他注意事项</strong></h1><ul><li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是O(mn)的内存，线性层太大很容易超出现有显存。</li><li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。</li><li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。</li><li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li><li>model.eval() 和 torch.no_grad() 的区别在于，model.eval()是将网络切换为测试状态，例如 BN和dropout在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行loss.backward()。</li><li>model.zero_grad()会把整个模型的参数的梯度都归零,而optimizer.zero_grad()只会把传入其中的参数的梯度归零.</li><li>torch.nn.CrossEntropyLoss 的输入不需要经过Softmax。torch.nn.CrossEntropyLoss 等价于torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li><li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。</li><li>torch.utils.data.DataLoader 中尽量设置pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False反而更快一些。num_workers 的设置需要在实验中找到最快的取值。</li><li>用 del 及时删除不用的中间变量，节约 GPU 存储。</li><li>使用 inplace 操作可节约 GPU 存储，如</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><ul><li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU的传输更快。</li><li>使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU型号。需要小心数值精度过低带来的稳定性问题。</li><li>时常使用 assert tensor.size() == (N, D, H, W)作为调试手段，确保张量维度和你设想中一致。</li><li>除了标记 y 外，尽量少使用一维张量，使用 n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li><li>统计代码各部分耗时</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>enabled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">as</span> profile<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span><span class="token comment"># 或者在命令行运行</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>bottleneck main<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ul><li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print出来每一行的执行结果的 tensor的形状、数据类型、设备、是否需要梯度的信息。</li></ul><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pip install torchsnooper</span><span class="token keyword">import</span> torchsnooper<span class="token comment"># 对于函数，使用修饰器</span><span class="token decorator annotation punctuation">@torchsnooper<span class="token punctuation">.</span>snoop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。</span><span class="token keyword">with</span> torchsnooper<span class="token punctuation">.</span>snoop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ul><li>原本的代码</li></ul><p>https://github.com/zasdfgbnm/TorchSnooper</p><ul><li>模型可解释性，使用captum库</li></ul><p>https://captum.ai/</p><p><strong>参考资料：</strong></p><p>1.https://zhuanlan.zhihu.com/p/59205847</p><p>2.<ahref="https://pytorch.org/tutorials/">PyTorch官方文档和示例</a></p><p>3.https://pytorch.org/docs/stable/notes/faq.html</p><p>4.https://github.com/szagoruyko/pytorchviz</p><p>5.https://github.com/sksq96/pytorch-summary</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络抓包与协议分析</title>
    <link href="/2022/05/01/net3/"/>
    <url>/2022/05/01/net3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：网络抓包与协议分析实验</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/wall.png"alt="Wireshark — A Walkthrough Of The Best Packet Analyzer In The World" /><figcaption aria-hidden="true">Wireshark — A Walkthrough Of The BestPacket Analyzer In The World</figcaption></figure><embed src="./problem.pdf" width="100%" height="750" type="application/pdf"><embed src="./wireshark.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库原理 Exercises 3&amp;4</title>
    <link href="/2022/04/29/data3/"/>
    <url>/2022/04/29/data3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 5&amp;6</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220429003143556.png"alt="image-20220429003143556" /><figcaption aria-hidden="true">image-20220429003143556</figcaption></figure><h1 id="database-system-concepts-exercises-of-chapter-56">DatabaseSystem Concepts Exercises of Chapter 5&amp;6</h1><p><strong>Exercise 5.8</strong> Consider the bank database of Figure<strong>5.25</strong>. Write an sQL trigger to carryout the followingaction: On <strong>delete</strong> of an account, for each owner oftheaccount, check if the owner has any remaining accounts, and if shedoesnot, delete her from the <em>depositor</em> relation.</p><p>branch(branch_name, branch_city, assets)</p><p>customer ( customer_name, customer_street, customer_city )</p><p>loan( loan_number, branch_name, amount)</p><p>borrower ( customer_name, loan_number )</p><p>account ( account_number, branch_name, balance )</p><p>depositor ( customer_name, account_number )</p><p><strong>Figure 5.25</strong></p><p><strong>My answer:</strong></p><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">trigger</span> <span class="token keyword">check</span><span class="token operator">-</span><span class="token keyword">delete</span><span class="token operator">-</span><span class="token keyword">trigger</span> <span class="token keyword">after</span> <span class="token keyword">delete</span> <span class="token keyword">on</span> account referencing old <span class="token keyword">row</span> <span class="token keyword">as</span> orow<span class="token keyword">for each row</span><span class="token keyword">delete</span> <span class="token keyword">from</span> depositor<span class="token keyword">where</span> depositor<span class="token punctuation">.</span>customer_name <span class="token operator">not</span> <span class="token operator">in</span>   <span class="token punctuation">(</span> <span class="token keyword">select</span> customer_name <span class="token keyword">from</span> depositor     <span class="token keyword">where</span> account_number <span class="token operator">&lt;></span> orow<span class="token punctuation">.</span>account_number <span class="token punctuation">)</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><strong>Exercise</strong> <strong>5.15</strong> Consider an employeedatabase with two relations employee (<spanclass="math inline">\(\underline{employee\_name}\)</span>, street, city)works (<span class="math inline">\(\underline{employee\_name}\)</span>,company_name, salary) where the primary keys are underlined. Write aquery to find companies whose employees earn a higher salary, onaverage, than the average salary at "First Bank Corporation". a. UsingSQL functions as appropriate. b. Without using SQL functions.</p><p><strong>My answer:</strong></p><ol type="a"><li></li></ol><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> avg_salary<span class="token punctuation">(</span>cname <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token keyword">integer</span>     <span class="token keyword">declare</span> result <span class="token keyword">integer</span><span class="token punctuation">;</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token keyword">into</span> result<span class="token keyword">from</span> works<span class="token keyword">where</span> works<span class="token punctuation">.</span>company<span class="token punctuation">.</span>name <span class="token operator">=</span> cname<span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">where</span> avg_salary<span class="token punctuation">(</span>company_name<span class="token punctuation">)</span> <span class="token operator">></span> avg_salary<span class="token punctuation">(</span>“<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ol start="2" type="a"><li></li></ol><div class="code-wrapper"><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> company_name<span class="token keyword">from</span> works<span class="token keyword">group</span> <span class="token keyword">by</span> company_name<span class="token keyword">having</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>salary<span class="token punctuation">)</span><span class="token keyword">from</span> works<span class="token keyword">where</span> company_name<span class="token operator">=</span>”<span class="token keyword">First</span> Bank Corporation”<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><hr /><p><strong>Exercise 6.1</strong> Write the following queries inrelational algebra, using the university schema. <strong>a</strong>.Find the titles of courses in the Comp. Sci. department that have 3credits. <strong>b</strong>. Find the IDs of all students who weretaught by an instructor named Einstein; make sure there are noduplicates in the result. <strong>c</strong>. Find the highest salary ofany instructor. <strong>d</strong>. Find all instructors earning thehighest salary (there may be more than one with the same salary).</p><p><strong>My answer:</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220429003507835.png"alt="image-20220429003507835" /><figcaption aria-hidden="true">image-20220429003507835</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>conda/linux/git常用命令“笔记”</title>
    <link href="/2022/04/28/code/"/>
    <url>/2022/04/28/code/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一些常用的命令，每次忘了都得搜，记录一下</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220428094832340.png"alt="image-20220428094832340" /><figcaption aria-hidden="true">image-20220428094832340</figcaption></figure><span id="more"></span><h1 id="anacondapython">Anaconda&amp;python</h1><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220428093957780.png"alt="image-20220428093957780" /><figcaption aria-hidden="true">image-20220428093957780</figcaption></figure><p><strong>pip安装（tensorflow-gpu为例）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>conda安装</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>pip3安装（指定版本号只需在命令末尾添加==1.12.0版本号）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip3  install tensorflow-gpu&#x3D;&#x3D;1.12.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>使用清华镜像下载</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install tensorflow-gpu&#x3D;&#x3D;1.10 -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>指定目录安装</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install -t D:\ProgramData\Anaconda3\Lib\site-packages torch-1.0.1-cp36-cp36m-win_amd64.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>卸载安装（pip3只需将conda换成pip）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda  uninstall tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>创建虚拟环境（conda为例）</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n py36 python&#x3D;3.6  #py36虚拟环境的名字  python&#x3D;3.6  python版本<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>删除虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda remove -n py36 --all<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>激活虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda activate py36<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>退出虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看所有创建的虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda env list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>用virtualenv创建虚拟环境</strong></p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">VENV_DIR</span><span class="token operator">=</span>venvpip <span class="token function">install</span> virtualenvvirtualenv <span class="token variable">$VENV_DIR</span><span class="token builtin class-name">source</span> <span class="token variable">$VENV_DIR</span>/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><strong>nohup送入后台运行</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">nohup</span> python train.py <span class="token operator">></span>nohup <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>      <span class="token comment">#train.py运行的文件  nohup生成的日志文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>CUDA指定GPU</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token function">nohup</span> python train.py  <span class="token operator">></span> nohup.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>导出requirements.txt</p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python3 -m pip freeze <span class="token operator">></span> requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看GPU使用情况</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>查看进程号</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">ps</span> aux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p><strong>根据进程号杀死进程</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">kill</span> -9 进程号<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/200301122312741.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h1 id="linux">linux</h1><p>linux不像Windows 分了盘，它根目录下有如下常用文件夹:</p><p><em>home</em> ---------- 用户的家</p><p><em>root</em> ---------- 超级管理员root的家</p><p><em>etc</em> ---------- 存放配置文件</p><p><em>usr</em> ---------- 存放共享资源</p><h2 id="cd命令">1、cd命令:</h2><p><strong>①、进入某一个目录</strong> <code>cd 目录名</code></p><p><strong>②、进入多级目录</strong> <code>cd 目录名/目录名</code></p><p><strong>③、返回上一级目录</strong> <code>cd ..</code></p><p><strong>④、返回根目录</strong> <code>cd /</code></p><p><strong>⑤、返回根目录下的某一个目录</strong><code>cd /目录名</code></p><p><strong>⑥、回家</strong> <code>cd ~</code></p><h2 id="创建删除目录">2、创建、删除目录:</h2><p><strong>①、创建目录</strong> <code>mkdir 目录名</code></p><p><strong>②、创建多级目录</strong> <code>mkdir -p a/b/c</code></p><p><strong>③、删除目录(只能删除空目录)</strong><code>rmdir 目录名</code></p><p><strong>④、删除目录(可删除非空目录，带询问)</strong><code>rm -r</code></p><p><strong>⑤、删除目录(不带询问，谨慎使用)</strong><code>rm -rf</code></p><h2 id="对文件的操作">3、对文件的操作:</h2><p><strong>①、创建空白文件</strong> <code>touch 文件名</code></p><p><strong>②、复制文件</strong></p><p><code>cp a.txt b.txt</code> <em>表示复制a文件并重命名为b。</em></p><p><code>cp a.txt dir/b.txt</code><em>表示把a复制到dir文件夹下并重命名为b。</em></p><p><strong>③、移动文件</strong> <code>mv a.txt dir/b.txt</code><em>把a.txt移动到dir目录下并重命名为b.txt。</em></p><p><strong>④、重命名文件</strong> <code>mv a.txt b.txt</code><em>把a.txt重命名为b.txt。</em></p><p><strong>⑤、删除文件</strong></p><p><code>rm 文件名</code> <em>带询问的删除</em></p><p><code>rm -f 文件名</code> <em>不带询问的删除。</em></p><p><strong>⑥、浏览文件</strong></p><p><code>cat 文件名</code> <em>显示文件所有内容</em></p><p><code>more 文件名</code><em>分页显示，空格键下一页，回车键下一行。</em></p><p><code>less 文件名</code><em>分页显示，pgup上一页，pgdn下一页。</em></p><p><code>tail -5 a.txt</code> <em>显示a.txt文件的最后5行。</em></p><p><code>tail -f 文件名</code> <em>动态的查看。</em></p><h2 id="查看目录下的文件">4、查看目录下的文件:</h2><p><strong>①、查看所有文件和目录名称</strong> <code>ls</code></p><p><strong>②、查看所有文件和目录名称(包括隐藏的)</strong><code>ls -a</code></p><p><strong>③、查看文件并显示详细信息(最常用)</strong><code>ll</code></p><p><strong>④、友好的显示</strong> <code>ll -h</code><em>比如显示的文件大小是kb而不是字节。</em></p><h2 id="tar打包命令">5、tar打包命令:</h2><p><strong>①、将当前目录所有文件打包成haha.tar</strong><code>tar -cvf haha.tar ./*</code></p><p><strong>②、将当前目录下所有文件打包并压缩成haha.tar</strong><code>tar -zcvf haha.tar.gz ./*</code></p><p><strong>③、将haha.tar解压到当前目录</strong><code>tar -xvf haha.tar</code></p><p><strong>④、将haha.tar解压到b目录</strong><code>tar -xvf haha.tar -C b</code> <em>注意C是大写的！</em></p><h2 id="其他常用命令">6、其他常用命令:</h2><p><strong>①、grep命令</strong></p><p><code>grep category a.txt</code><em>表示在a.txt中查找category字符串所在的行，前提是打开了a.txt文件。</em></p><p><code>grep category a.txt -A2</code><em>在a.txt中查找category字符串的前两行。</em></p><p><code>grep category a.txt -B2</code><em>在a.txt中查找category字符串的后两行。</em></p><p><strong>②、查看当前目录</strong> <code>pwd</code></p><p><strong>③、wget下载命令</strong> <code>wget www.baidu.com</code><em>下载百度首页</em></p><h2 id="vivim编辑器">7、vi/vim编辑器:</h2><p><strong>①、编辑器有三种模式，分别是:</strong><strong>命令行模式:</strong>此模式无法编辑文件，<code>yy</code>复制行，<code>p</code>粘贴，<code>dd</code>删除行，按如下键都可以进入插入模式:</p><p><code>i</code> 当前位置前插入;</p><p><code>I</code> 当前行行首插入;</p><p><code>a</code> 当前位置后插入;</p><p><code>A</code> 当前行行尾插入;</p><p><code>o</code> 当前行之后插入一行;</p><p><code>O</code> 当前的之前插入一行</p><p><strong>插入模式:</strong>此模式下可以对文件进行编辑。按<code>esc</code>退出插入模式，回到命令行模式。<strong>底行模式:</strong>命令行模式下按<code>:</code>，即可进入底行模式。底行模式有如下常用命令:</p><p><code>q</code> 不保存退出;</p><p><code>q！</code> 不保存强制退出;</p><p><code>wq</code> 保存退出</p><h2 id="管道">8、管道:</h2><p><strong>管道:<code>|</code>，将一个命令的输出作为另一个命令的输入。例如:</strong><strong>在 <code>ip addr</code>的输出结果中查找<code>192.168</code>字符串:</strong><code>ip addr | grep 192.168</code></p><h2 id="系统管理命令">9、系统管理命令:</h2><p><strong>①、查看系统时间</strong> <code>date</code> 查看系统时间<code>date -s "2018-05-15 22:22:22"</code>将系统时间设置为引号里面的时间</p><p><strong>②、查看磁盘信息</strong> <code>df</code> 查看磁盘信息<code>df -h</code> 友好地展示磁盘信息</p><p><strong>③、清屏</strong> <code>clear</code>或者按<code>ctr L</code></p><p><strong>④、进程</strong> <code>ps -ef</code>查看所有进程<code>ps -ef | grep ssh</code>查找ssh进程</p><p><strong>⑤、杀掉进程</strong> <code>kill 9527</code>杀掉9527号进程<code>kill -9 9527</code> 强制杀掉9527号进程</p><p><strong>⑥、查看网络端口</strong><code>netstat -an | grep 3306</code>查看3306端口占用情况</p><p><strong>⑦、ping命令</strong><code>ping xx.xx.xxx</code>测试网络连通性</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/bg2015120901.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h1 id="git">GIT</h1><p>下面是常用 Git 命令清单。几个专用名词的译名如下。</p><blockquote><ul><li>Workspace：工作区</li><li>Index / Stage：暂存区</li><li>Repository：仓库区（或本地仓库）</li><li>Remote：远程仓库</li></ul></blockquote><h2 id="一新建代码库">一、新建代码库</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在当前目录新建一个Git代码库</span>$ <span class="token function">git</span> init<span class="token comment"># 新建一个目录，将其初始化为Git代码库</span>$ <span class="token function">git</span> init <span class="token punctuation">[</span>project-name<span class="token punctuation">]</span><span class="token comment"># 下载一个项目和它的整个代码历史</span>$ <span class="token function">git</span> clone <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="二配置">二、配置</h2><p>Git的设置文件为<code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示当前的Git配置</span>$ <span class="token function">git</span> config --list<span class="token comment"># 编辑Git配置文件</span>$ <span class="token function">git</span> config -e <span class="token punctuation">[</span>--global<span class="token punctuation">]</span><span class="token comment"># 设置提交代码时的用户信息</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.name <span class="token string">"[name]"</span>$ <span class="token function">git</span> config <span class="token punctuation">[</span>--global<span class="token punctuation">]</span> user.email <span class="token string">"[email address]"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="三增加删除文件">三、增加/删除文件</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 添加指定文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 添加指定目录到暂存区，包括子目录</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token punctuation">[</span>dir<span class="token punctuation">]</span><span class="token comment"># 添加当前目录的所有文件到暂存区</span>$ <span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span><span class="token comment"># 添加每个变化前，都会要求确认</span><span class="token comment"># 对于同一个文件的多处变化，可以实现分次提交</span>$ <span class="token function">git</span> <span class="token function">add</span> -p<span class="token comment"># 删除工作区文件，并且将这次删除放入暂存区</span>$ <span class="token function">git</span> <span class="token function">rm</span> <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span class="token comment"># 停止追踪指定文件，但该文件会保留在工作区</span>$ <span class="token function">git</span> <span class="token function">rm</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 改名文件，并且将这个改名放入暂存区</span>$ <span class="token function">git</span> <span class="token function">mv</span> <span class="token punctuation">[</span>file-original<span class="token punctuation">]</span> <span class="token punctuation">[</span>file-renamed<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="四代码提交">四、代码提交</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 提交暂存区到仓库区</span>$ <span class="token function">git</span> commit -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交暂存区的指定文件到仓库区</span>$ <span class="token function">git</span> commit <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>. -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 提交工作区自上次commit之后的变化，直接到仓库区</span>$ <span class="token function">git</span> commit -a<span class="token comment"># 提交时显示所有diff信息</span>$ <span class="token function">git</span> commit -v<span class="token comment"># 使用一次新的commit，替代上一次提交</span><span class="token comment"># 如果代码没有任何新变化，则用来改写上一次commit的提交信息</span>$ <span class="token function">git</span> commit --amend -m <span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token comment"># 重做上一次commit，并包括指定文件的新变化</span>$ <span class="token function">git</span> commit --amend <span class="token punctuation">[</span>file1<span class="token punctuation">]</span> <span class="token punctuation">[</span>file2<span class="token punctuation">]</span> <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="五分支">五、分支</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有本地分支</span>$ <span class="token function">git</span> branch<span class="token comment"># 列出所有远程分支</span>$ <span class="token function">git</span> branch -r<span class="token comment"># 列出所有本地分支和远程分支</span>$ <span class="token function">git</span> branch -a<span class="token comment"># 新建一个分支，但依然停留在当前分支</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，并切换到该分支</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，指向指定commit</span>$ <span class="token function">git</span> branch <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个分支，与指定的远程分支建立追踪关系</span>$ <span class="token function">git</span> branch --track <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 切换到指定分支，并更新工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 切换到上一个分支</span>$ <span class="token function">git</span> checkout -<span class="token comment"># 建立追踪关系，在现有分支与指定的远程分支之间</span>$ <span class="token function">git</span> branch --set-upstream <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>remote-branch<span class="token punctuation">]</span><span class="token comment"># 合并指定分支到当前分支</span>$ <span class="token function">git</span> merge <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 选择一个commit，合并进当前分支</span>$ <span class="token function">git</span> cherry-pick <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除分支</span>$ <span class="token function">git</span> branch -d <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span><span class="token comment"># 删除远程分支</span>$ <span class="token function">git</span> push origin --delete <span class="token punctuation">[</span>branch-name<span class="token punctuation">]</span>$ <span class="token function">git</span> branch -dr <span class="token punctuation">[</span>remote/branch<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="六标签">六、标签</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有tag</span>$ <span class="token function">git</span> tag<span class="token comment"># 新建一个tag在当前commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 新建一个tag在指定commit</span>$ <span class="token function">git</span> tag <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 删除本地tag</span>$ <span class="token function">git</span> tag -d <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 删除远程tag</span>$ <span class="token function">git</span> push origin :refs/tags/<span class="token punctuation">[</span>tagName<span class="token punctuation">]</span><span class="token comment"># 查看tag信息</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交指定tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span class="token comment"># 提交所有tag</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --tags<span class="token comment"># 新建一个分支，指向某个tag</span>$ <span class="token function">git</span> checkout -b <span class="token punctuation">[</span>branch<span class="token punctuation">]</span> <span class="token punctuation">[</span>tag<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="七查看信息">七、查看信息</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示有变更的文件</span>$ <span class="token function">git</span> status<span class="token comment"># 显示当前分支的版本历史</span>$ <span class="token function">git</span> log<span class="token comment"># 显示commit历史，以及每次commit发生变更的文件</span>$ <span class="token function">git</span> log --stat<span class="token comment"># 搜索提交历史，根据关键词</span>$ <span class="token function">git</span> log -S <span class="token punctuation">[</span>keyword<span class="token punctuation">]</span><span class="token comment"># 显示某个commit之后的所有变动，每个commit占据一行</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --pretty<span class="token operator">=</span>format:%s<span class="token comment"># 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件</span>$ <span class="token function">git</span> log <span class="token punctuation">[</span>tag<span class="token punctuation">]</span> HEAD --grep feature<span class="token comment"># 显示某个文件的版本历史，包括文件改名</span>$ <span class="token function">git</span> log --follow <span class="token punctuation">[</span>file<span class="token punctuation">]</span>$ <span class="token function">git</span> whatchanged <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示指定文件相关的每一次diff</span>$ <span class="token function">git</span> log -p <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示过去5次提交</span>$ <span class="token function">git</span> log -5 --pretty --oneline<span class="token comment"># 显示所有提交过的用户，按提交次数排序</span>$ <span class="token function">git</span> shortlog -sn<span class="token comment"># 显示指定文件是什么人在什么时间修改过</span>$ <span class="token function">git</span> blame <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示暂存区和工作区的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span><span class="token comment"># 显示暂存区和上一个commit的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> --cached <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 显示工作区与当前分支最新commit之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> HEAD<span class="token comment"># 显示两次提交之间的差异</span>$ <span class="token function">git</span> <span class="token function">diff</span> <span class="token punctuation">[</span>first-branch<span class="token punctuation">]</span><span class="token punctuation">..</span>.<span class="token punctuation">[</span>second-branch<span class="token punctuation">]</span><span class="token comment"># 显示今天你写了多少行代码</span>$ <span class="token function">git</span> <span class="token function">diff</span> --shortstat <span class="token string">"@&#123;0 day ago&#125;"</span><span class="token comment"># 显示某次提交的元数据和内容变化</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交发生变化的文件</span>$ <span class="token function">git</span> show --name-only <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 显示某次提交时，某个文件的内容</span>$ <span class="token function">git</span> show <span class="token punctuation">[</span>commit<span class="token punctuation">]</span>:<span class="token punctuation">[</span>filename<span class="token punctuation">]</span><span class="token comment"># 显示当前分支的最近几次提交</span>$ <span class="token function">git</span> reflog<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="八远程同步">八、远程同步</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载远程仓库的所有变动</span>$ <span class="token function">git</span> fetch <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 显示所有远程仓库</span>$ <span class="token function">git</span> remote -v<span class="token comment"># 显示某个远程仓库的信息</span>$ <span class="token function">git</span> remote show <span class="token punctuation">[</span>remote<span class="token punctuation">]</span><span class="token comment"># 增加一个新的远程仓库，并命名</span>$ <span class="token function">git</span> remote <span class="token function">add</span> <span class="token punctuation">[</span>shortname<span class="token punctuation">]</span> <span class="token punctuation">[</span>url<span class="token punctuation">]</span><span class="token comment"># 取回远程仓库的变化，并与本地分支合并</span>$ <span class="token function">git</span> pull <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 上传本地指定分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> <span class="token punctuation">[</span>branch<span class="token punctuation">]</span><span class="token comment"># 强行推送当前分支到远程仓库，即使有冲突</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --force<span class="token comment"># 推送所有分支到远程仓库</span>$ <span class="token function">git</span> push <span class="token punctuation">[</span>remote<span class="token punctuation">]</span> --all<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="九撤销">九、撤销</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 恢复暂存区的指定文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复某个commit的指定文件到暂存区和工作区</span>$ <span class="token function">git</span> checkout <span class="token punctuation">[</span>commit<span class="token punctuation">]</span> <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 恢复暂存区的所有文件到工作区</span>$ <span class="token function">git</span> checkout <span class="token builtin class-name">.</span><span class="token comment"># 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>file<span class="token punctuation">]</span><span class="token comment"># 重置暂存区与工作区，与上一次commit保持一致</span>$ <span class="token function">git</span> reset --hard<span class="token comment"># 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变</span>$ <span class="token function">git</span> reset <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致</span>$ <span class="token function">git</span> reset --hard <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 重置当前HEAD为指定commit，但保持暂存区和工作区不变</span>$ <span class="token function">git</span> reset --keep <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 新建一个commit，用来撤销指定commit</span><span class="token comment"># 后者的所有变化都将被前者抵消，并且应用到当前分支</span>$ <span class="token function">git</span> revert <span class="token punctuation">[</span>commit<span class="token punctuation">]</span><span class="token comment"># 暂时将未提交的变化移除，稍后再移入</span>$ <span class="token function">git</span> stash$ <span class="token function">git</span> stash pop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></blockquote><h2 id="十其他">十、其他</h2><blockquote><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 生成一个可供发布的压缩包</span>$ <span class="token function">git</span> archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></blockquote><p>一个常用的实例</p><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">add</span> origin xxx<span class="token punctuation">(</span>复制的SSH链接<span class="token punctuation">)</span><span class="token function">git</span> branch -m master main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span> <span class="token function">git</span> commit -m <span class="token string">"注释"</span> <span class="token function">git</span> pull --rebase origin main<span class="token function">git</span> push origin main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div>]]></content>
    
    
    
    <tags>
      
      <tag>终端</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自动驾驶技术基础之建模与控制</title>
    <link href="/2022/04/25/auto1/"/>
    <url>/2022/04/25/auto1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自动驾驶技术基础的建模与控制作业</p><span id="more"></span><p>概念题（18分）</p><ol type="1"><li>自动驾驶为了出色地完成驾驶任务，可分为哪四大模块？（4分）</li><li>系统建模一般分哪两种建模方式？（2分）</li><li>请写出高速转向车辆模型的简化横向误差模型（即四个状态为误差）（4分）</li><li>二次型性能指标函数一般包含哪三项优化项？（3分）</li><li>线性二次问题三种重要形式分别是？（3分）</li><li>KalmanFilter（LQE）如何通过LQR求得，请写出matlab关键代码，即：xxx=lqr(xxx)（2分）</li></ol><p>编程实践题（12分）</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/clip_image002.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>给定一个双质系统: m<sub>1</sub> =2, m<sub>2</sub>=1, 弹簧系数 k=5,阻尼σ=0.1, 质量块与地面的滑动阻尼 δ=0.1 (与速度有成正比)。初始时刻m<sub>1</sub> 质量块处于 x=0 的位置, 两质量块距离为 0 。现在m<sub>2</sub> 处作用一外力 F 拖动系统使 m<sub>1</sub> 与 m<sub>2</sub>质量块均处于 x=5 的位置。</p><ol type="1"><li>对系统建模（系统可以直接测量两个物体的位置）</li><li>判断系统可控性与可观</li><li>结合给定的simulink和脚本文件，设计实现上述系统的LQG控制器并绘制闭环控制性能曲线</li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/clip_image020.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><embed src="./auto1.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>自动驾驶</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cognitive Mapping and Planning for Visual Navigation</title>
    <link href="/2022/04/24/CMP/"/>
    <url>/2022/04/24/CMP/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>认知科学基础课程设计报告</p><span id="more"></span><p>开放性题目，结合视语言、语音识别、机器人平台，采用Webots，构建一个单/多智能体的认知导航、认知规划、认知控制仿真算例，里面可以用已有的各种传感器组件、机器人模型，基于前期所讲简单的认知智能知识点做仿真试验，算法可以从github上开源下载使用。鼓励大家选择此题目开展一些小试验，可以提问实现的方式方法。同时提交仿真实现的设计和试验研习报告。突出认知智能应用的关键要点，进行详细阐述说明。</p><embed src="./CMP.pdf" width="100%" height="750" type="application/pdf"><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220424225934056.png"alt="image-20220424225934056" /><figcaption aria-hidden="true">image-20220424225934056</figcaption></figure><p>【1】论文地址： https://arxiv.org/abs/1702.03920 【2】代码：https://github.com/tensorflow/models/tree/archive/research/cognitive_mapping_and_planning【3】论文Slide：https://sites.google.com/view/cognitive-mapping-and-planning/?authuser=1【4】作者主页： https://people.eecs.berkeley.edu/~sgupta/【5】作者主页： https://people.eecs.berkeley.edu/~svlevine/</p>]]></content>
    
    
    
    <tags>
      
      <tag>无人系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于套接字的网络程序设计</title>
    <link href="/2022/04/19/net2/"/>
    <url>/2022/04/19/net2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>计网作业：套接字编程实验</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220419191104235.png"alt="image-20220419191104235" /><figcaption aria-hidden="true">image-20220419191104235</figcaption></figure><h1 id="套接字编程作业1web服务器">套接字编程作业1：Web服务器</h1><p>在本实验中，您将学习Python中TCP连接的套接字编程的基础知识：如何创建套接字，将其绑定到特定的地址和端口，以及发送和接收HTTP数据包。您还将学习一些HTTP首部格式的基础知识。</p><p>您将开发一个处理一个HTTP请求的Web服务器。您的Web服务器应该接受并解析HTTP请求，然后从服务器的文件系统获取所请求的文件，创建一个由响应文件组成的HTTP响应消息，前面是首部行，然后将响应直接发送给客户端。如果请求的文件不存在于服务器中，则服务器应该向客户端发送“404Not Found”差错报文。</p><h3 id="代码">代码</h3><p>在文件下面你会找到Web服务器的代码框架。您需要填写这个代码。而且需要在标有#Fillin start 和 # Fill inend的地方填写代码。另外，每个地方都可能需要不止一行代码。</p><h3 id="运行服务器">运行服务器</h3><p>将HTML文件（例如HelloWorld.html）放在服务器所在的目录中。运行服务器程序。确认运行服务器的主机的IP地址（例如128.238.251.26）。从另一个主机，打开浏览器并提供相应的URL。例如：</p><p>http://128.238.251.26:6789/HelloWorld.html</p><p>“HelloWorld.html”是您放在服务器目录中的文件。还要注意使用冒号后的端口号。您需要使用服务器代码中使用的端口号来替换此端口号。在上面的例子中，我们使用了端口号6789.浏览器应该显示HelloWorld.html的内容。如果省略“:6789”，浏览器将使用默认端口80，只有当您的服务器正在端口80监听时，才会从服务器获取网页。</p><p>然后用客户端尝试获取服务器上不存在的文件。你应该会得到一个“404 NotFound”消息。</p><h3 id="需要上交的内容">需要上交的内容</h3><p>您需要上交完整的服务器代码，以及客户端浏览器的屏幕截图，用于验证您是否从服务器实际接收到HTML文件内容。</p><h3 id="web服务器的python代码框架">Web服务器的Python代码框架</h3><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#import socket module</span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_STREAM<span class="token punctuation">)</span> <span class="token comment">#Prepare a sever socket </span><span class="token comment">#Fill in start </span><span class="token comment">#Fill in end </span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>       <span class="token comment">#Establish the connection  </span>    <span class="token keyword">print</span> <span class="token string">'Ready to serve...'</span>       connectionSocket<span class="token punctuation">,</span> addr <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>             message <span class="token operator">=</span>   <span class="token comment">#Fill in start  #Fill in end</span>        filename <span class="token operator">=</span> message<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                              f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        outputdata <span class="token operator">=</span> <span class="token comment">#Fill in start  #Fill in end</span>        <span class="token comment">#Send one HTTP header line into socket     </span>        <span class="token comment">#Fill in start     </span>        <span class="token comment">#Fill in end  </span>        <span class="token comment">#Send the content of the requested file to the client</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>outputdata<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            connectionSocket<span class="token punctuation">.</span>send<span class="token punctuation">(</span>outputdata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        connectionSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> IOError<span class="token punctuation">:</span>        <span class="token comment">#Send response message for file not found</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end</span>        <span class="token comment">#Close client socket</span>        <span class="token comment">#Fill in start</span>        <span class="token comment">#Fill in end         </span>    serverSocket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="可选练习">可选练习</h3><ol type="1"><li>目前，这个Web服务器一次只处理一个HTTP请求。请实现一个能够同时处理多个请求的多线程服务器。使用线程，首先创建一个主线程，在固定端口监听客户端请求。当从客户端收到TCP连接请求时，它将通过另一个端口建立TCP连接，并在另外的单独线程中为客户端请求提供服务。这样在每个请求/响应对的独立线程中将有一个独立的TCP连接。</li><li>不使用浏览器，编写自己的HTTP客户端来测试你的服务器。您的客户端将使用一个TCP连接用于连接到服务器，向服务器发送HTTP请求，并将服务器响应显示出来。您可以假定发送的HTTP请求将使用GET方法。客户端应使用命令行参数指定服务器IP地址或主机名，服务器正在监听的端口，以及被请求对象在服务器上的路径。</li></ol><h1 id="套接字编程作业2udpping程序">套接字编程作业2：UDPping程序</h1><p>在本实验中，您将学习使用Python进行UDP套接字编程的基础知识。您将学习如何使用UDP套接字发送和接收数据报，以及如何设置适当的套接字超时。在实验中，您将熟悉Ping应用程序及其在计算统计信息（如丢包率）中的作用。</p><p>您首先需要研究一个用Python编写的简单的ping服务器程序，并实现对应的客户端程序。这些程序提供的功能类似于现代操作系统中可用的标准ping程序功能。然而，我们的程序使用更简单的UDP协议，而不是标准互联网控制消息协议（ICMP）来进行通信。ping协议允许客户端机器发送一个数据包到远程机器，并使远程机器将数据包返回到客户（称为回显）的操作。另外，ping协议允许主机计算它到其他机器的往返时间。</p><p>以下是Ping服务器程序的完整代码。你的任务是写出Ping客户端程序。</p><h3 id="服务器代码">服务器代码</h3><p>以下代码完整实现了一个ping服务器。您需要在运行客户端程序之前编译并运行此代码。<em>而且您不需要修改此代码。</em></p><p>在这个服务器代码中，30％的客户端的数据包会被模拟丢失。你应该仔细研究这个代码，它将帮助你编写ping客户端。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># UDPPingerServer.py </span><span class="token comment"># We will need the following module to generate randomized lost packets import random </span><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span> <span class="token keyword">import</span> random<span class="token comment"># Create a UDP socket  </span><span class="token comment"># Notice the use of SOCK_DGRAM for UDP packets </span>serverSocket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span> SOCK_DGRAM<span class="token punctuation">)</span> <span class="token comment"># Assign IP address and port number to socket </span>serverSocket<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token number">12000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>   <span class="token comment"># Generate random number in the range of 0 to 10 </span>rand <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>   <span class="token comment"># Receive the client packet along with the address it is coming from  </span>message<span class="token punctuation">,</span> address <span class="token operator">=</span> serverSocket<span class="token punctuation">.</span>recvfrom<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span> <span class="token comment"># Capitalize the message from the client   </span>message <span class="token operator">=</span> message<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If rand is less is than 4, we consider the packet lost and do not respond   </span><span class="token keyword">if</span> rand <span class="token operator">&lt;</span> <span class="token number">4</span><span class="token punctuation">:</span>     <span class="token keyword">continue</span>   <span class="token comment"># Otherwise, the server responds     </span>serverSocket<span class="token punctuation">.</span>sendto<span class="token punctuation">(</span>message<span class="token punctuation">,</span> address<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>服务器程序在一个无限循环中监听到来的UDP数据包。当数据包到达时，如果生成一个随机整数大于或等于4，则服务器将数字转为大写并将其发送回客户端。</p><h3 id="数据包丢失">数据包丢失</h3><p>UDP为应用程序提供了不可靠的传输服务。消息可能因为路由器队列溢出，硬件错误或其他原因，而在网络中丢失。但由于在内网中很丢包甚至不丢包，所以在本实验室的服务器程序添加人为损失来模拟网络丢包的影响。服务器创建一个随机整数，由它确定传入的数据包是否丢失。</p><h3 id="客户端代码">客户端代码</h3><p>您需要实现以下客户端程序。</p><p>客户端向服务器发送10次ping。因为UDP是不可靠的协议，所以从客户端发送到服务器的数据包可能在网络中丢失。因此，客户端不能无限期地等待ping消息的回复。客户等待服务器回答的时间至多为一秒，如果在一秒内没有收到回复，您的客户端程序应该假定数据包在网络传输期间丢失。您需要查找Python文档，以了解如何在数据报套接字上设置超时值。</p><p>具体来说，您的客户端程序应该</p><ol type="1"><li>使用UDP发送ping消息（注意：不同于TCP，您不需要首先建立连接，因为UDP是无连接协议。）</li><li>从服务器输出响应消息</li><li>如果从服务器受到响应，则计算并输出每个数据包的往返时延（RTT）（以秒为单位），</li><li>否则输出“请求超时”</li></ol><p>在开发过程中，您应该先在计算机上运行<code>UDPPingerServer.py</code>，并通过向<code>localhost</code>（或127.0.0.1）发送数据包来测试客户端。调试完成代码后，您应该能看到ping服务器和ping客户端在不同机器上通过网络进行通信。</p><h3 id="消息格式">消息格式</h3><p>本实验中的ping消息格式使用最简单的方式。客户端消息只有一行，由以下格式的ASCII字符组成：</p><blockquote><p>Ping <em>sequence_number time</em></p></blockquote><p>其中<em>sequence_number</em>从1开始，一直到10，共10条消息，而<em>time</em>则是客户端发送消息时的时间。</p><h3 id="需要上交的内容-1">需要上交的内容</h3><p>您需要上交完整的客户端代码和屏幕截图，以验证您的ping程序是否按需求运行。</p><h3 id="可选练习-1">可选练习</h3><ol type="1"><li>目前，程序计算每个数据包的往返时间（RTT），并单独打印出来。请按照标准ping程序的模式修改。您需要在客户端每次ping后显示最小，最大和平均RTT。另外，还需计算丢包率（百分比）。</li><li>UDP Ping的另一个类似的应用是UDPHeartbeat。心跳可用于检查应用程序是否已启动并运行，并报告单向丢包。客户端在UDP数据包中将一个序列号和当前时间戳发送给正在监听客户端心跳的服务器。服务器收到数据包后，计算时差，报告丢包（若发生）。如果心跳数据包在指定的一段时间内丢失，我们可以假设客户端应用程序已经停止。实现UDPHeartbeat（客户端和服务器端）。您需要修改给定的UDPPingerServer.py和您自己的UDPping客户端。</li></ol><p><strong>以上内容来自《计算机网络：自顶向下方法》官方文档，与我的作业有部分不同，详见pdf。</strong></p><p><strong>个人实验报告</strong></p><embed src="./Socket.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智能机器人技术——一阶运动学与静力学</title>
    <link href="/2022/03/30/robot4/"/>
    <url>/2022/03/30/robot4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/gVyodA.jpg"alt="1648571793860.png" /><figcaption aria-hidden="true">1648571793860.png</figcaption></figure><h1id="智能机器人技术一阶运动学与静力学">智能机器人技术——一阶运动学与静力学</h1><p>一、计算/解答题, 请写出解题过程 (30 分)。</p><ol type="1"><li>如下图所示有一处于初始位形的 RRP 机器人 (即讲义例 3 ), 求 (10分):</li></ol><ol type="a"><li><p>写出各关节相对空间坐标系 <spanclass="math inline">\(\{s\}\)</span> 的旋量坐标。求解当 <spanclass="math inline">\(\theta=\left(90^{\circ}, 90^{\circ},1\right)\)</span> 时的正向运动学; 手绘此时的机器人, 标注 <spanclass="math inline">\(\{s\}\)</span> 系和 <spanclass="math inline">\(\{b\}\)</span> 系, 求解此时的空间雅克比 <spanclass="math inline">\(J_{s}\)</span>;</p></li><li><p>写出各关节相对末端坐标系 <spanclass="math inline">\(\{b\}\)</span> 的旋量坐标。求解当 <spanclass="math inline">\(\theta=\left(90^{\circ}, 90^{\circ},1\right)\)</span> 时的正向运动学, 确认与 a) 中结果相同;求解此时的物体雅克比 <span class="math inline">\(J_{b}\)</span>。</p></li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002641939.png"alt="image-20220330002641939" /><figcaption aria-hidden="true">image-20220330002641939</figcaption></figure><ol type="a"><li></li></ol><p>此时的机器人如图所示：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002652483.png"alt="image-20220330002652483" /><figcaption aria-hidden="true">image-20220330002652483</figcaption></figure><p>初始位形<strong>M</strong>：</p><p><span class="math display">\[M=\left[\begin{array}{cccc}-1 &amp; 0 &amp; 0 &amp; 0  \\0 &amp; 0 &amp; 1 &amp; 3  \\0 &amp; 1 &amp; 0 &amp; 2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>相对空间坐标系 <span class="math inline">\(\{s\}\)</span>的旋量坐标为：</p><p><span class="math display">\[\mathcal{S}_{i}：~\begin{array}{|c||c|c|}\hline i &amp; \omega_{i}  &amp; v_{i} \\\hline \hline 1 &amp; (0,0,1) &amp; (0, 0,0) \\\hline 2 &amp; (1,0,0) &amp; (0, 2,0) \\\hline 3 &amp; (0,0,0)  &amp; (0, 1,0) \\\hline\end{array}\\\]</span></p><p>故当<span class="math inline">\(\theta=\left(90^{\circ}, 90^{\circ},1\right)\)</span> 时的正向运动学<strong>PoE</strong>与空间雅克比 <spanclass="math inline">\(J_{s}\)</span>：</p><p>$$ T=\</p><p>J_{s}()=$$</p><p>使用到的函数如下：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">FKinSpace</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> Slist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>T <span class="token operator">=</span> M<span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token function">size</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">1</span>    T <span class="token operator">=</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> T<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> Js <span class="token operator">=</span> <span class="token function">JacobianSpace</span><span class="token punctuation">(</span>Slist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>Js <span class="token operator">=</span> Slist<span class="token punctuation">;</span>T <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">:</span> <span class="token function">length</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span>    T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Js</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">Adjoint</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">Slist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ol start="2" type="a"><li></li></ol><p>初始位形<strong>M</strong>：</p><p><span class="math display">\[M=\left[\begin{array}{cccc}-1 &amp; 0 &amp; 0 &amp; 0  \\0 &amp; 0 &amp; 1 &amp; 3  \\0 &amp; 1 &amp; 0 &amp; 2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>相对空间坐标系 <span class="math inline">\(\{b\}\)</span>的旋量坐标为：</p><p><span class="math display">\[\mathcal{B}_{i}：~\begin{array}{|c||c|c|}\hline i &amp; \omega_{i}  &amp; v_{i} \\\hline \hline 1 &amp; (0,1,0) &amp; (3, 0,0) \\\hline 2 &amp; (-1,0,0) &amp; (0, 3,0) \\\hline 3 &amp; (0,0,0)  &amp; (0, 0,1) \\\hline\end{array}\\\]</span></p><p>故当<span class="math inline">\(\theta=\left(90^{\circ}, 90^{\circ},1\right)\)</span> 时的正向运动学<strong>PoE</strong>与物体雅克比 <spanclass="math inline">\(J_{b}\)</span>：</p><p><span class="math display">\[T=\left[\begin{array}{cccc}0 &amp; 0 &amp; -1 &amp; -3 \\-1 &amp; 0 &amp; 0 &amp; 0\\0 &amp; 1 &amp; 0 &amp; 2\\0 &amp; 0 &amp; 0 &amp; 1\\\end{array}\right]\\(与a中结果相同)\\J_{b}(\theta)=\left[\begin{array}{ccc}0 &amp; -1 &amp; 0 \\0 &amp; 0 &amp; 0 \\1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 \\0 &amp; 4 &amp; 0 \\0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>使用到的函数如下：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">FKinBody</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> Blist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>T <span class="token operator">=</span> M<span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token function">size</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span>    T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> Jb <span class="token operator">=</span> <span class="token function">JacobianBody</span><span class="token punctuation">(</span>Blist<span class="token punctuation">,</span> thetalist<span class="token punctuation">)</span>Jb <span class="token operator">=</span> Blist<span class="token punctuation">;</span>T <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token number">i</span> <span class="token operator">=</span> <span class="token function">length</span><span class="token punctuation">(</span>thetalist<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">1</span>       T <span class="token operator">=</span> T <span class="token operator">*</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span><span class="token function">VecTose3</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> <span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">thetalist</span><span class="token punctuation">(</span><span class="token number">i</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Jb</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">Adjoint</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">Blist</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token number">i</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ol start="2" type="1"><li>如下图所示有一处于初始位形的 RRRP 空间开链机器人, <spanclass="math inline">\(p\)</span> 为<spanclass="math inline">\(\{b\}\)</span> 系原点相对于 <spanclass="math inline">\(\{s\}\)</span> 系的坐标, 求 (10 分):</li></ol><ol type="a"><li>试求当 <span class="math inline">\(\theta=(0,0, \pi / 2, L)\)</span>时的物体雅克比 <span class="math inline">\(J_{b}(\theta)\)</span>;</li><li>试求当 <span class="math inline">\(\theta=(0,0, \pi / 2, L)\)</span>且 <span class="math inline">\(\dot{\theta}=(1,1,1,1)\)</span> 时的<span class="math inline">\(\dot{p}\)</span>。</li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002705450.png"alt="image-20220330002705450" /><figcaption aria-hidden="true">image-20220330002705450</figcaption></figure><ol type="a"><li></li></ol><p>相对空间坐标系 <span class="math inline">\(\{b\}\)</span>的旋量坐标为：</p><p><span class="math display">\[\mathcal{B}_{i}：~\begin{array}{|c||c|c|}\hline i &amp; \omega_{i}  &amp; v_{i} \\\hline \hline 1 &amp; (0,0,1) &amp; (-L, 0,0) \\\hline 2 &amp; (1,0,0) &amp; (0, 0,L) \\\hline 3 &amp; (0,0,1)  &amp; (0, 0,0) \\\hline 4 &amp; (0,0,0)  &amp; (0, 1,0) \\\hline\end{array}\\\]</span></p><p>使用JacobianBody(Blist, thetalist)计算得，当 <spanclass="math inline">\(\theta=(0,0, \pi / 2, L)\)</span> 时的物体雅克比<span class="math inline">\(J_{b}(\theta)\)</span>：</p><p><span class="math display">\[J_{b}(\theta)=\left[\begin{array}{cccC}0 &amp; 0 &amp; 0 &amp;0\\0 &amp; -1 &amp; 0 &amp;0\\1 &amp; 0 &amp; 1 &amp;0\\-L &amp; 0 &amp; -L&amp;0 \\L &amp; 0 &amp; 0 &amp;1\\0 &amp; L &amp; 0&amp;0\end{array}\right]\]</span></p><ol start="2" type="a"><li></li></ol><p>当 <spanclass="math inline">\(\dot{\theta}=(1,1,1,1)\)</span>时：</p><p><span class="math display">\[\mathcal{V}_{b}=J_{b}(\theta) \dot{\theta}=\left[\begin{array}{c}\omega_{b} \\v_{b}\end{array}\right]=\left[\begin{array}{c}0\\-1\\2\\-2L\\L+1\\L\end{array}\right]\\\because R_{s b}=\left[\begin{array}{rrc}0 &amp; -1 &amp; 0 \\1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1\end{array}\right] \\\therefore\dot{p}=R_{s b} v_{b}=\left[\begin{array}{c}-L-1 \\-2 L \\L\end{array}\right]\]</span></p><ol start="3" type="1"><li>如下图所示有一处于初始位形的 PRPRRR 空间开链机器人,此时基坐标系原点与末端坐标系原点之间距离为 <spanclass="math inline">\(L\)</span>, 求 (10 分):</li></ol><ol type="a"><li><p>空间雅克比 <span class="math inline">\(J_{S}\)</span>的前三列;</p></li><li><p>物体雅克比 <span class="math inline">\(J_{b}\)</span>的后两列;</p></li><li><p>初始位形时的 <spanclass="math inline">\(J_{S}(0)\)</span>;</p></li><li><p>初始位形时, 若在末端坐标系的 <spanclass="math inline">\(-\hat{z}_{b}\)</span> 方向产生 <spanclass="math inline">\(100 \mathrm{~N}\)</span> 的力,需要关节提供多少力或力矩? <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330002722057.png"alt="image-20220330002722057" /></p></li><li></li></ol><p>空间雅克比 <span class="math inline">\(J_{S}\)</span> 的前三列：</p><p><span class="math display">\[\begin{aligned}&amp;\mathcal{V}_{s 1}(\theta): \quad \omega_{s1}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 1}=\left[\begin{array}{l}0 \\0 \\1\end{array}\right] \\&amp;\mathcal{V}_{s 2}(\theta): \quad \omega_{s2}=\left[\begin{array}{l}0 \\0 \\1\end{array}\right], q_{2}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 2}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right] \\&amp;\mathcal{V}_{s 3}(\theta): \quad \omega_{s3}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{s 3}=e^{\hat{z} \theta_{2}}\left[\begin{array}{l}0 \\1 \\0\end{array}\right]=\left[\begin{array}{c}-\sin \theta_{2} \\\cos \theta_{2} \\0\end{array}\right]\end{aligned}\]</span></p><ol start="2" type="a"><li></li></ol><p>物体雅克比 <span class="math inline">\(J_{b}\)</span> 的后两列：</p><p><span class="math display">\[\begin{aligned}&amp;\mathcal{V}_{b 6}(\theta): \quad \omega_{b6}=\left[\begin{array}{l}1 \\0 \\0\end{array}\right], q_{6}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{b 6}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right] \\&amp;\mathcal{V}_{b 5}(\theta): \quad \omega_{b5}=e^{\hat{x}\left(-\theta_{6}\right)}\left[\begin{array}{l}0 \\0 \\1\end{array}\right]=\left[\begin{array}{c}0 \\\sin \theta_{6} \\\cos \theta_{6}\end{array}\right], q_{5}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right], v_{b 5}=\left[\begin{array}{l}0 \\0 \\0\end{array}\right]\end{aligned}\]</span></p><ol start="3" type="a"><li></li></ol><p>初始位形时θ=0，故$ J_{S}(0)$：</p><p><span class="math display">\[\because \mathcal{S}_{i}：~\begin{array}{|c||c|c|}\hline i &amp; \omega_{i}  &amp; v_{i} \\\hline \hline 1 &amp; (0,0,0) &amp; (0, 0,1) \\\hline 2 &amp; (0,0,1) &amp; (0,0,0) \\\hline 3 &amp; (0,0,0)  &amp; (0, 1,0) \\\hline 4 &amp; (0,1,0) &amp; (0, 0,0) \\\hline 5 &amp; (0,0,1)  &amp; (L, 0,0) \\\hline 6 &amp; (1,0,0) &amp; (0, 0,-L) \\\hline\end{array}\\\therefore J_{s}(0)=\left[\begin{array}{cccccc}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 0 &amp; L &amp; 0 \\0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -L\end{array}\right]\]</span></p><ol start="4" type="a"><li></li></ol><p><span class="math display">\[\begin{aligned}&amp;\because r_{s b}=\left[\begin{array}{l}0 \\L \\0\end{array}\right], f_{b}=\left[\begin{array}{c}0 \\0 \\-100\end{array}\right]\\&amp;\therefore\mathcal{F}_{s}=\left[\begin{array}{c}m_{s} \\f_{s}\end{array}\right]=\left[\begin{array}{c}r_{s b} \times f_{b} \\f_{b}\end{array}\right]=\left[\begin{array}{c}-100 L \\0 \\0 \\0 \\0 \\-100\end{array}\right]\\&amp;\therefore \tau=J_{s}^{T}(0) \mathcal{F}_{s}\\&amp;=\left[\begin{array}{cccccc}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1 &amp; L &amp; 0 &amp; 0 \\1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -L\end{array}\right]\left[\begin{array}{c}-100 L \\0 \\0 \\0 \\0 \\-100\end{array}\right]=\left[\begin{array}{c}-100 \\0 \\0 \\0 \\0 \\0\end{array}\right]\end{aligned}\]</span></p>]]></content>
    
    
    
    <tags>
      
      <tag>机器人</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于强化学习的无人机自主导航</title>
    <link href="/2022/03/28/UAV/"/>
    <url>/2022/03/28/UAV/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>无人系统导论课程设计报告</p><span id="more"></span><embed src="./UAV.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>无人系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Visual Synthesis Pre-training for NUWA</title>
    <link href="/2022/03/28/NUWA/"/>
    <url>/2022/03/28/NUWA/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>基于深度生成模型的多模态视觉合成</p><span id="more"></span><embed src="./NUWA.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习在新冠肺炎辅助诊断中的应用</title>
    <link href="/2022/03/28/AI/"/>
    <url>/2022/03/28/AI/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>综述论文</p><span id="more"></span><embed src="./COVID-19.pdf" width="100%" height="750" type="application/pdf">]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器&amp;深度学习代码速查表</title>
    <link href="/2022/03/24/graph/"/>
    <url>/2022/03/24/graph/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>搬运自github.com/OUCMachineLearning/OUCML</p><span id="more"></span><h1 id="机器深度学习代码速查表">机器&amp;深度学习代码速查表</h1><h3 id="神经网络">神经网络</h3><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220324225648930.png"alt="image-20220324225648930" /> <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/%E7%BD%91%E7%BB%9C.png"alt="网络" /></p><h3 id="线性代数">线性代数</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/liner.jpg"alt="liner" /><figcaption aria-hidden="true">liner</figcaption></figure><h3 id="python基础">python基础</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sci.jpg"alt="sci" /><figcaption aria-hidden="true">sci</figcaption></figure><h3 id="scipy科学计算">scipy科学计算</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sci.png"alt="sci" /><figcaption aria-hidden="true">sci</figcaption></figure><h3 id="spark">spark</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/spark.jpeg"alt="spark" /><figcaption aria-hidden="true">spark</figcaption></figure><h2 id="数据保存及可视化">数据保存及可视化</h2><h3 id="numpy">numpy</h3><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/np.png"alt="np" /><figcaption aria-hidden="true">np</figcaption></figure><h3 id="pandas">pandas</h3><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/pd.png"alt="pd" /> <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/df.jpeg"alt="df" /> <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/df2.jpeg"alt="df2" /></p><h3 id="bokeh">bokeh</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/bokeh.jpg"alt="bokeh" /><figcaption aria-hidden="true">bokeh</figcaption></figure><h2 id="画图">画图</h2><h3 id="matplotlib">matplotlib</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/matplot.png"alt="matplot" /><figcaption aria-hidden="true">matplot</figcaption></figure><h3 id="ggplot">ggplot</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/data%20vis.jpeg"alt="data vis" /><figcaption aria-hidden="true">data vis</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/gg.jpeg"alt="gg" /><figcaption aria-hidden="true">gg</figcaption></figure><h2 id="机器学习">机器学习</h2><h3 id="sklearn">sklearn</h3><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sk.jpg"alt="sk" /><figcaption aria-hidden="true">sk</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/scikit.png"alt="scikit" /><figcaption aria-hidden="true">scikit</figcaption></figure><h3 id="keras">keras</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/keras.jpeg"alt="keras" /><figcaption aria-hidden="true">keras</figcaption></figure><h3 id="tensorflow">tensorflow</h3><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/TF.png"alt="TF" /><figcaption aria-hidden="true">TF</figcaption></figure><h2 id="算法">算法</h2><h3 id="数据结构">数据结构</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/datastruct.png"alt="datastruct" /><figcaption aria-hidden="true">datastruct</figcaption></figure><h3 id="复杂度">复杂度</h3><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/O.png"alt="O" /><figcaption aria-hidden="true">O</figcaption></figure><h3 id="排序算法">排序算法</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/sort.png"alt="sort" /><figcaption aria-hidden="true">sort</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智能机器人技术——正向运动学</title>
    <link href="/2022/03/24/robot3/"/>
    <url>/2022/03/24/robot3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220324223524468.png"alt="image-20220324223524468" /><figcaption aria-hidden="true">image-20220324223524468</figcaption></figure><h1 id="智能机器人技术正向运动学">智能机器人技术——正向运动学</h1><ol type="1"><li>如下图所示有一处于初始位形的 PRRRRR 空间开链机器人,试确定末端初始位形 <span class="math inline">\(M\)</span> 、在 <spanclass="math inline">\(\{0\}\)</span> 系描述的螺旋轴 Si 、$ 在 ${b}系描述的螺旋轴 Bi （如讲义那样列表即可)。</li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164358687.png"alt="image-20220323164358687" /><figcaption aria-hidden="true">image-20220323164358687</figcaption></figure><p><strong>解得：</strong></p><p>相对基坐标系的<span class="math inline">\(\mathrm{PoE}\)</span> :</p><p><span class="math display">\[T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M\]</span></p><p>相对末端坐标系的<span class="math inline">\(\mathrm{PoE}\)</span>:</p><p><span class="math display">\[T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{B}_{n}\right] \theta_{n}}\]</span></p><p>末端初始位形 <span class="math inline">\(M\)</span>：</p><p><span class="math display">\[\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; L_1+L_2+L_3+L_4 \\0 &amp; 0 &amp; 1 &amp; h \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>在 <span class="math inline">\(\{0\}\)</span> 系描述的螺旋轴 $_{i}$：</p><p><span class="math display">\[[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline\hline 1 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0) \\\hline 2 &amp; (0,0,1) &amp; (0, L_1,0)&amp; (L_1, 0,0) \\\hline 3 &amp; (-1,0,0) &amp; (0, L_1,h)&amp; (0, -h,L_1) \\\hline 4 &amp; (-1,0,0) &amp; (0,L_1+L_2,h)&amp; (0, -h,L_1+L_2) \\\hline 5 &amp; (-1,0,0) &amp; (0,L_1+L_2+L_3,h)&amp; (0, -h,L_1+L_2+L_3)\\\hline 6 &amp; (0,1,0) &amp; (0,0,h) &amp; (-h, 0,1)\\\hline\end{array}\]</span></p><p>在 <span class="math inline">\(\{b\}\)</span> 系描述的螺旋轴 <spanclass="math inline">\(\mathcal{B}_{i}\)</span>：</p><p><span class="math display">\[[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline\hline 1 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0) \\\hline 2 &amp; (0,0,1) &amp; (0, -L_2-L_3-L_4,0)&amp; (-L_2-L_3-L_4,0,0) \\\hline 3 &amp; (-1,0,0) &amp; (0, -L_2-L_3-L_4,0)&amp; (0,0,-L_2-L_3-L_4) \\\hline 4 &amp; (-1,0,0) &amp; (0,-L_3-L_4,0)&amp; (0, 0,-L_3-L_4) \\\hline 5 &amp; (-1,0,0) &amp; (0,-L_4,0)&amp; (0, 0,-L_4) \\\hline 6 &amp; (0,1,0) &amp; (0,0,0) &amp; (0, 0,0)\\\hline\end{array}\]</span></p><ol start="2" type="1"><li>如下图所示有一处于初始位形的 RRRRPR 空间开链机器人,试确定末端初始位形 <span class="math inline">\(M\)</span> 、在 <spanclass="math inline">\(\{0\}\)</span> 系描述的螺旋轴 Si 、$ 在 ${b}系描述的螺旋轴 Bi （如讲义那样列表即可)。 <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164443717.png"alt="image-20220323164443717" /></li></ol><p><strong>解得：</strong></p><p>相对基坐标系的<span class="math inline">\(\mathrm{PoE}\)</span> :</p><p><span class="math display">\[T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M\]</span></p><p>相对末端坐标系的<span class="math inline">\(\mathrm{PoE}\)</span>:</p><p><span class="math display">\[T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{B}_{n}\right] \theta_{n}}\]</span></p><p>末端初始位形 <span class="math inline">\(M\)</span>：</p><p><span class="math display">\[\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; L_1 \\0 &amp; 1 &amp; 0 &amp; L_3+L_4 \\0 &amp; 0 &amp; 1 &amp; -L_5-L_6 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>在 <span class="math inline">\(\{0\}\)</span> 系描述的螺旋轴 $_{i}$：</p><p><span class="math display">\[[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline \hline 1 &amp; (1,0,0) &amp; (0, 0,0)&amp; (0, 0,0) \\\hline 2 &amp; (0,0,-1) &amp; (L_1,0,0)&amp; (0, L_1,0) \\\hline 3 &amp; (0,1,0) &amp; (L_1,0,L_2)&amp; (-L_2, 0,L_1) \\\hline 4 &amp; (1,0,0) &amp; (0,L_3,0)&amp; (0, 0,-L_3) \\\hline 5 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0)\\\hline 6 &amp; (0,1,0) &amp; (L_1,0,-L_5) &amp; (L_5, 0,-L_1) \\\hline\end{array}\]</span></p><p>在 <span class="math inline">\(\{b\}\)</span> 系描述的螺旋轴 <spanclass="math inline">\(\mathcal{B}_{i}\)</span>：</p><p><span class="math display">\[[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline \hline 1 &amp; (1,0,0) &amp; (0, -L_3-L_4,L_5+L_6)&amp; (0,L_5+L_6,L_3+L_4) \\\hline 2 &amp; (0,0,-1) &amp; (0, -L_3-L_4,0)&amp; (L_3+L_4, 0,0) \\\hline 3 &amp; (0,1,0) &amp; (0,0,L_2+L_5+L_6)&amp; (-L_2-L_5-L_6, 0,0)\\\hline 4 &amp; (1,0,0) &amp; (0,-L_4,L_5+L_6)&amp; (0, L_5+L_6,L_4) \\\hline 5 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0)\\\hline 6 &amp; (0,1,0) &amp; (0,0,L_6) &amp; (-L_6, 0,0) \\\hline\end{array}\]</span></p><ol start="3" type="1"><li>如下图所示有一处于初始位形的 RRRPRR 空间开链机器人,试确定末端初始位形 <span class="math inline">\(M\)</span> 、在 <spanclass="math inline">\(\{0\}\)</span> 系描述的螺旋轴 Si 、$ 在 ${b}系描述的螺旋轴 Bi （如讲义那样列表即可)。</li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323164454698.png"alt="image-20220323164454698" /><figcaption aria-hidden="true">image-20220323164454698</figcaption></figure><p><strong>解得：</strong></p><p>相对基坐标系的<span class="math inline">\(\mathrm{PoE}\)</span> :</p><p><span class="math display">\[T(\theta)=e^{\left[\mathcal{S}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{S}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{S}_{n}\right] \theta_{n}} M\]</span></p><p>相对末端坐标系的<span class="math inline">\(\mathrm{PoE}\)</span>:</p><p><span class="math display">\[T(\theta)=M e^{\left[\mathcal{B}_{1}\right] \theta_{1}} \cdotse^{\left[\mathcal{B}_{n-1}\right] \theta_{n-1}}e^{\left[\mathcal{B}_{n}\right] \theta_{n}}\]</span></p><p>末端初始位形 <span class="math inline">\(M\)</span>：</p><p><span class="math display">\[\left[\begin{array}{cccc}-1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; 4 \\0 &amp; 0 &amp; -1 &amp; 1 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>在 <span class="math inline">\(\{0\}\)</span> 系描述的螺旋轴 $_{i}$：</p><p><span class="math display">\[[\mathcal{S}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{S}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline \hline 1 &amp; (0,0,1) &amp; (0, 0,0)&amp; (0, 0,0) \\\hline 2 &amp; (1,0,0) &amp; (0,0,2)&amp; (0, 2,0) \\\hline 3 &amp; (1,0,0) &amp; (0,1,2)&amp; (0, 2,-1) \\\hline 4 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0) \\\hline 5 &amp; (0, \frac{\sqrt{2}}{2} , \frac{\sqrt{2}}{2} ) &amp;(0,3,2) &amp; (\frac{\sqrt{2}}{2}, 0,0)\\\hline 6 &amp; (0,0,-1) &amp; (0,4,0)&amp; (-4, 0,0) \\\hline\end{array}\]</span></p><p>在 <span class="math inline">\(\{b\}\)</span> 系描述的螺旋轴 <spanclass="math inline">\(\mathcal{B}_{i}\)</span>：</p><p><span class="math display">\[[\mathcal{B}]=\left[\begin{array}{cc}{[\omega]} &amp; v \\0 &amp; 0\end{array}\right] \in \operatorname{se}(3) \longrightarrow\mathcal{B}=\left[\begin{array}{c}\omega \\v\end{array}\right] \in \mathbb{R}^{6}\]</span></p><p><span class="math display">\[\because v_i=-\omega_{i} \times q_i \\\begin{array}{|c||c|c|c|}\hline i &amp; \omega_{i} &amp; q_i &amp; v_{i} \\\hline \hline 1 &amp; (0,0,-1) &amp; (0, -4,0)&amp; (4, 0,0) \\\hline 2 &amp; (-1,0,0) &amp; (0,-4,-1)&amp; (0, 1,-4) \\\hline 3 &amp; (-1,0,0) &amp; (0,-3,-1)&amp; (0, 1,-3) \\\hline 4 &amp; (0,0,0) &amp; NULL &amp; (0, 1,0) \\\hline 5 &amp; (0, \frac{\sqrt{2}}{2} , -\frac{\sqrt{2}}{2} ) &amp;(0,-1,-1) &amp; (\sqrt{2}, 0,0)\\\hline 6 &amp; (0,0,1) &amp; (0,0,0)&amp; (0, 0,0) \\\hline\end{array}\]</span></p>]]></content>
    
    
    
    <tags>
      
      <tag>机器人</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库原理 Exercises 2</title>
    <link href="/2022/03/23/data2/"/>
    <url>/2022/03/23/data2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 3</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220323230708879.png"alt="image-20220323230708879" /><figcaption aria-hidden="true">image-20220323230708879</figcaption></figure><h1 id="database-system-concepts-exercises-of-chapter-3">Database SystemConcepts Exercises of Chapter 3</h1><p><strong>Exercises 3.9</strong> Consider the employee database ofFigure <span class="math inline">\(3.20\)</span>, where the primary keysare underlined. Give an expression in SQL for each of the followingqueries.</p><ol type="a"><li><p>Find the names and cities of residence of all employees who workfor "First Bank Corporation".</p></li><li><p>Find the names, street addresses, and cities of residence of allemployees who work for "First Bank Corporation" and earn more than <spanclass="math inline">\(\$ 10,000\)</span>.</p></li><li><p>Find all employees in the database who do not work for "FirstBank Corporation".</p></li><li><p>Find all employees in the database who earn more than eachemployee of "Small Bank Corporation".</p></li><li><p>Assume that the companies may be located in several cities. Findall companies located in every city in which "Small Bank Corporation" islocated.</p></li><li><p>Find the company that has the most employees.</p></li><li><p>Find those companies whose employees earn a higher salary, onaverage, than the average salary at "First Bank Corporation".</p></li></ol><p><span class="math display">\[employee (\underline{employee\_name}, street, city)\\works (\underline{employee\_name}, company\_name, salary)\\company (\underline{company\_name}, city)\\manages ( \underline{ employee\_name, } manager\_name )\\Figure~~3.20~~Employee~~database~~for~~Exercises~~3.9\]</span></p><p><strong>My answer：</strong></p><ol type="a"><li></li></ol><p><strong>select</strong> e.employee_name, city <strong>from</strong>employee <strong>as</strong> e, works <strong>as</strong> w<strong>where</strong> w.company_name <spanclass="math inline">\(=\)</span> 'First Bank Corporation'<strong>and</strong> w.employee_name <spanclass="math inline">\(=\)</span> e.employee_name</p><ol start="2" type="a"><li></li></ol><p><strong>select</strong> * <strong>from</strong> employee<strong>where</strong> employee_name <strong>in</strong>(<strong>select</strong> employee_name <strong>from</strong> works<strong>where</strong> company_name = 'First Bank Corporation'<strong>and</strong> salary <spanclass="math inline">\(&gt;10000\)</span> )</p><ol start="3" type="a"><li></li></ol><p><strong>select</strong> employee_name <strong>from</strong> works<strong>where</strong> company_name <spanclass="math inline">\(\neq\)</span> 'First Bank Corporation'</p><ol start="4" type="a"><li></li></ol><p><strong>select</strong> employee_name <strong>from</strong> works<strong>where</strong> salary <span class="math inline">\(&gt;\)</span><strong>all</strong> (<strong>select</strong> salary<strong>from</strong> works <strong>where</strong> company_name <spanclass="math inline">\(=\)</span> 'Small Bank Corporation')</p><ol start="5" type="a"><li></li></ol><p><strong>select</strong> S.company_name <strong>from</strong> company<strong>as</strong> <span class="math inline">\(S\)</span><strong>where</strong> <strong>not exists</strong>((<strong>select</strong> city <strong>from</strong> company<strong>where</strong> company_name <spanclass="math inline">\(=\)</span> 'Small Bank Corporation')<strong>except</strong> (<strong>select</strong> city<strong>from</strong> company <strong>as</strong> <spanclass="math inline">\(T\)</span> <strong>where</strong> S.company_name<span class="math inline">\(=\)</span> T.company_name ) )</p><ol start="6" type="a"><li></li></ol><p><strong>select</strong> company_name <strong>from</strong> works<strong>group by</strong> company_name <strong>having count</strong>(<strong>distinct</strong> employee_name) <spanclass="math inline">\(&gt;=\)</span> <strong>all</strong>(<strong>select</strong> <strong>count</strong>(<strong>distinct</strong> employee_name) <strong>from</strong> works<strong>group by</strong> company_name)</p><ol start="7" type="a"><li></li></ol><p><strong>select</strong> company_name <strong>from</strong> works<strong>group by</strong> company_name <strong>having</strong><strong>avg</strong> (salary) <span class="math inline">\(&gt;\)</span>(<strong>select</strong> <strong>avg</strong> (salary)<strong>from</strong> works <strong>where</strong> company_name <spanclass="math inline">\(=\)</span> 'First Bank Corporation')</p><p><strong>Exercises 3.8</strong> Consider the bank database of Figure<span class="math inline">\(3.19\)</span>, where the primary keys areunderlined. Construct the following SQL queries for this relationaldatabase.</p><ol type="a"><li><p>Find all customers of the bank who have an account but not aloan.</p></li><li><p>Find the names of all customers who live on the same street andin the same city as "Smith".</p></li><li><p>Find the names of all branches with customers who have an accountin the bank and who live in "Harrison".</p></li></ol><p><span class="math display">\[branch(\underline{branch\_name}, branch\_city, assets)\\customer (\underline{customer\_name}, customer\_street,customer\_city)\\ loan (\underline{loan\_numbe}r, branch\_name,amount)\\borrower (\underline{customer\_name}, \underline{loan\_number})\\account (\underline{account\_number}, branch\_name, balance)\\depositor (\underline{customer\_name}, \underline{account\_number})\\Figure~~3.19~~Banking~~database~~for~~Exercises~~3.8~~and~~3.15\]</span></p><p><strong>My answer:</strong></p><ol type="a"><li></li></ol><p><strong>select</strong> customer_name <strong>from</strong> depositor<strong>except</strong> (<strong>select</strong> customer_name<strong>from</strong> borrower)</p><ol start="2" type="a"><li></li></ol><p><strong>select</strong> F.customer_name <strong>from</strong>customer <strong>as</strong> <span class="math inline">\(F\)</span> joincustomer <strong>as</strong> <span class="math inline">\(S\)</span>using(customer_street, customer_city) <strong>where</strong>S.customer_name <span class="math inline">\(=\)</span> 'Smith'</p><ol start="3" type="a"><li></li></ol><p><strong>select</strong> <strong>distinct</strong> branch_name<strong>from</strong> account <strong>natural join</strong> depositor<strong>natural join</strong> customer <strong>where</strong>customer_city = 'Harrison'</p><p><strong>Exercises 3.15</strong> Consider the bank database of Figure3.19, where the primary keys are underlined. Construct the following SQLqueries for this relational database. a. Find all customers who have anaccount at all the branches located in "Brooklyn". b. Find out the totalsum of all loan amounts in the bank. c. Find the names of all branchesthat have assets greater than those of at least one branch located in"Brooklyn".</p><p><strong>My answer:</strong></p><ol type="a"><li></li></ol><p><strong>select</strong> <strong>distinct</strong> S.customer_name</p><p><strong>from</strong> depositor <strong>as</strong> S</p><p><strong>where</strong> <strong>not exists(</strong></p><p>(<strong>select</strong> branch_name</p><p><strong>from</strong> branch</p><p><strong>where</strong> branch_city = 'Brooklyn')</p><p><strong>except</strong></p><p>(<strong>select</strong> R.branch_name</p><p><strong>from</strong> depositor <strong>as</strong> T, account<strong>as</strong> R</p><p><strong>where</strong> T.account_number = R.account_number</p><p><strong>and</strong> S.customer_name = T.customer_name))</p><ol start="2" type="a"><li></li></ol><p><strong>select</strong> <strong>sum</strong>(amount)<strong>as</strong> sum_loan</p><p><strong>from</strong> loan</p><ol start="3" type="a"><li></li></ol><p><strong>select</strong> branch_name</p><p><strong>from</strong> branch</p><p><strong>where</strong> assets ＞<strong>some</strong></p><p>(<strong>select</strong> assets</p><p><strong>from</strong> branch</p><p><strong>where</strong> branch_city = 'Brooklyn')</p>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智能机器人技术——刚体运动</title>
    <link href="/2022/03/21/robot2/"/>
    <url>/2022/03/21/robot2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><figure><img src="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/A2.jpg"alt="image-20220321151047649" /><figcaption aria-hidden="true">image-20220321151047649</figcaption></figure><h1id="智能机器人技术第三章刚体运动">智能机器人技术第三章——刚体运动</h1><ol type="1"><li><span class="math display">\[已知一固定的空间坐标系 \{s\} 及其 \hat{x}_{s} 、 \hat{y}_{s} 、\hat{z}_{s}轴坐标, 坐标系 \{a\} 的 \hat{x}_{a}轴沿 (0,0,1) 方向,\\\hat{y}_{a} 轴沿 (-1,0,0) 方向; 坐标系 \{b\} 的 \hat{x}_{b} 轴沿 (1,0,0)方向, \hat{y}_{b} 轴沿 (0,0,-1)方向。\]</span></li></ol><p><strong>a)</strong> 手绘 3 个坐标系, 注意画在不同位置以便区分。</p><p><span class="math display">\[由右手定则可知，坐标系 \{a\} 的 \hat{z}_{a} 轴沿 (0,-1,0) 方向，坐标系\{b\} 的 \hat{z}_{b} 轴沿 (0,1,0) 方向。结果如图所示：\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220320155656111.png"alt="image-20220320155656111" /><figcaption aria-hidden="true">image-20220320155656111</figcaption></figure><p><strong>b)</strong></p><p><span class="math display">\[计算旋转矩阵 R_{s a} 和 R_{s b}\]</span></p><p>。</p><p><span class="math display">\[\begin{aligned}R_{sa} &amp;=\left[\begin{array}{lll}0 &amp; -1 &amp; 0 \\0 &amp; 0 &amp; -1 \\1 &amp; 0 &amp; 0\end{array}\right] \\R_{sb} &amp;=\left[\begin{array}{ccc}1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1 \\0 &amp; -1 &amp; 0\end{array}\right]\end{aligned}\]</span></p><p><strong>c)</strong></p><p><span class="math display">\[已知 R_{s b}, 在不使用逆矩阵的情况下计算 R_{s b}^{-1},并验证坐标系画的是否正确。\]</span></p><p>由旋转矩阵的性质得<span class="math inline">\(R^{-1}=R^T\)</span></p><p><span class="math display">\[\begin{aligned}R_{sb}^{-1}=R^T_{sb} &amp;=\left[\begin{array}{ccc}1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -1 \\0 &amp; 1 &amp; 0\end{array}\right]\end{aligned}\]</span></p><p>可知坐标系绘画正确。</p><p><strong>d)</strong></p><p><span class="math display">\[已知 R_{s a} 和 R_{s b}, 计算 R_{a b}, 并验证坐标系画的是否正确。\]</span></p><p><span class="math display">\[\begin{aligned}R_{as}=R_{sa}^{-1}=R^T_{sa} &amp;=\left[\begin{array}{ccc}0 &amp; 0 &amp; 1 \\-1 &amp; 0 &amp; 0 \\0 &amp; -1 &amp; 0\end{array}\right]\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}R_{ab}=R_{as}R_{sb} &amp;=\left[\begin{array}{ccc}0 &amp; -1 &amp; 0 \\-1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -1\end{array}\right]\end{aligned}\]</span></p><p>可知坐标系绘画正确。</p><p><strong>e)</strong></p><p><span class="math display">\[将 R=R_{s b} 作为变换算子, 表示绕 \hat{x} 轴转动 -90^{\circ} 。计算R_{1}=R_{s a} R 与 R_{2}=R R_{s a}, 并回答新姿态 R_{1} 与 R_{2}分别对应的是 R_{s a} 绕哪个坐标系的 \hat{x} 轴转动得到的结果?\]</span></p><p><span class="math display">\[\begin{aligned}R_{1}=R_{sa}R &amp;=\left[\begin{array}{ccc}0 &amp; 0 &amp; -1 \\0 &amp; 1 &amp; 0 \\1 &amp; 0 &amp; 0\end{array}\right]\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}R_{2}=RR_{sa} &amp;=\left[\begin{array}{ccc}0 &amp; -1 &amp; 0 \\1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1\end{array}\right]\end{aligned}\]</span></p><p><span class="math display">\[R_1表示绕坐标系 \{a\} 的 \hat{x}_{a} 轴，R_2表示绕坐标系 \{s\} 的\hat{x}_{s} 轴。\]</span></p><p><strong>f)</strong></p><p><span class="math display">\[利用 R_{s b} 将点 p_{b}=(1,2,3) 从 \{b\} 系变换到 \{s\} 系。\]</span></p><p><span class="math display">\[p_{s}=R_{sb}p_{b}=(1,3,-2)\]</span></p><p><strong>g)</strong></p><p><span class="math display">\[已知 \{s\} 系中一点 p_{s}=(1,2,3), 计算 p^{\prime}=R_{s b} p_{s} 和p^{\prime \prime}=R_{s b}^{T} p_{s} 。每一推导过程均可以解释为坐标变换(无须移动点的位置) 或移动点的位置 (无须改变坐标系)。\]</span></p><p><span class="math display">\[p^{\prime}=R_{s b} p_{s}=(1,3,-2)：其几何意义为移动点的位置，将向量p_s绕\hat{x} 轴转动 -90^{\circ}  (无须改变坐标系)。\]</span></p><p><span class="math display">\[p^{\prime \prime}=R_{s b}^{T} p_{s}=(1,-3,2)：其几何意义为坐标变换，将\{s\} 系中一点 p_{s}变换到 \{b\} 系 (无须移动点的位置) 。\]</span></p><p><strong>h)</strong>已知 <span class="math inline">\(\{s\}\)</span>系中的角速度 <span class="math inline">\(\omega_{s}=(3,2,1)\)</span>,计算其在 <span class="math inline">\(\{a\}\)</span> 系中的表示。</p><p><span class="math display">\[\omega_{a}=R_{as}\omega_s=(1,-3,-2)\]</span></p><p><strong>i)</strong> 计算 <span class="math inline">\(R_{s a}\)</span>的矩阵对数 <span class="math inline">\([\widehat{\omega}]\theta\)</span>, 并提取其中的元素: 单位角速度 <spanclass="math inline">\(\widehat{\omega}\)</span> 和转动量 <spanclass="math inline">\(\theta\)</span> (可以利用编程手段)。</p><p>使用到的函数：</p><p>MatrixLog3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> so3mat <span class="token operator">=</span> <span class="token function">MatrixLog3</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span>acosinput <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">trace</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token keyword">if</span> acosinput <span class="token operator">>=</span> <span class="token number">1</span>    so3mat <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">elseif</span> acosinput <span class="token operator">&lt;=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">if</span> <span class="token operator">~</span><span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">elseif</span> <span class="token operator">~</span><span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">else</span>        omg <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>              <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">R</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">end</span>    so3mat <span class="token operator">=</span> <span class="token function">VecToso3</span><span class="token punctuation">(</span><span class="token keyword">pi</span> <span class="token operator">*</span> omg<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">else</span>theta <span class="token operator">=</span> <span class="token function">acos</span><span class="token punctuation">(</span>acosinput<span class="token punctuation">)</span><span class="token punctuation">;</span>       so3mat <span class="token operator">=</span> theta <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>R <span class="token operator">-</span> R<span class="token operator">'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>so3ToVec：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> omg <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span>omg <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">so3mat</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>AxisAng3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>expc3<span class="token punctuation">)</span>theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span>expc3<span class="token punctuation">)</span><span class="token punctuation">;</span>omghat <span class="token operator">=</span> expc3 <span class="token operator">/</span> theta<span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><p>解得：</p><p><span class="math display">\[[\widehat{\omega}] \theta = \left[\begin{array}{ccc}0 &amp; -1.2092 &amp; -1.2092 \\1.2092 &amp; 0 &amp; -1.2092 \\1.2092 &amp; 1.2092 &amp; 0\end{array}\right]\]</span></p><p>单位角速度 <spanclass="math inline">\(\widehat{\omega}=(0.5774,-0.5774,0.5774)\)</span>和转动量 <span class="math inline">\(\theta=2.0944\)</span></p><p><strong>j)</strong> 计算与转动 <spanclass="math inline">\(\widehat{\omega} \theta=(1,2,0)\)</span>的指数坐标对应的矩阵指数。</p><p>使用到的函数：</p><p>VecToso3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> so3mat <span class="token operator">=</span> <span class="token function">VecToso3</span><span class="token punctuation">(</span>omg<span class="token punctuation">)</span>so3mat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">-</span><span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">omg</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>MatrixExp3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span>  R <span class="token operator">=</span> <span class="token function">MatrixExp3</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span>omgtheta <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span>so3mat<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token function">norm</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">)</span>    R <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">;</span>    omgmat <span class="token operator">=</span> so3mat <span class="token operator">/</span> theta<span class="token punctuation">;</span>    R <span class="token operator">=</span> <span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">cos</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat<span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><span class="math display">\[\begin{aligned}R &amp;=\left[\begin{array}{ccc}-0.2938 &amp; 0.6469 &amp; 0.7037 \\0.6469 &amp; 0.6765 &amp; -0.3518 \\-0.7037 &amp; 0.3518 &amp; -0.6173\end{array}\right]\end{aligned}\]</span></p><p>2.题干如 1 , 并且 <span class="math inline">\(\{a\}\)</span>系原点相对 <span class="math inline">\(\{s\}\)</span> 系的坐标为 <spanclass="math inline">\((3,0,0),\{b\}\)</span> 系原点相对 <spanclass="math inline">\(\{s\}\)</span> 系的坐标为 <spanclass="math inline">\((0,2,0)\)</span>。</p><p><strong>a)</strong> 手绘 3 个坐标系, 注意它们之间的相对位置关系。</p><p>图中<spanclass="math inline">\(\{s\}\)</span>系的三个坐标轴长度均为单位长度，以此绘得结果如下：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220320160304205.png"alt="image-20220320160304205" /><figcaption aria-hidden="true">image-20220320160304205</figcaption></figure><p><strong>b)</strong></p><p><span class="math display">\[计算齐次变换矩阵 T_{s a} 和 T_{s b} 。\]</span></p><p><span class="math display">\[\because T=\left[\begin{array}{cc}R &amp; p \\0 &amp; 1\end{array}\right]\\\therefore T_{sa}=\left[\begin{array}{cccc}0 &amp; -1 &amp; 0 &amp; 3 \\0 &amp; 0 &amp; -1 &amp; 0 \\1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\\T_{sb}=\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1 &amp; 2 \\0 &amp; -1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p><strong>c)</strong></p><p><span class="math display">\[已知 T_{s b}, 在不使用逆矩阵的情况下计算 T_{s b}^{-1},并验证坐标系画的是否正确。\]</span></p><p><span class="math display">\[\because T^{-1}=\left[\begin{array}{cc}R &amp; p \\0 &amp; 1\end{array}\right]^{-1}=\left[\begin{array}{cc}R^{\mathrm{T}} &amp; -R^{\mathrm{T}} p \\0 &amp; 1\end{array}\right]\\\therefore T_{sb}^{-1}=\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -1 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; -2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>可知坐标系绘画正确。</p><p><strong>d)</strong></p><p><span class="math display">\[已知 T_{s a} 和 T_{s b}, 计算 T_{a b}, 并验证坐标系画的是否正确。\]</span></p><p><span class="math display">\[\because T_{as}=T_{sa}^{-1}=\left[\begin{array}{cccc}0 &amp; 0 &amp; 1 &amp; 0 \\-1 &amp; 0 &amp; 0 &amp; 3 \\0 &amp; -1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\\\therefore T_{ab}=T_{as}T_{sb}=\left[\begin{array}{cccc}0 &amp; -1 &amp; 0 &amp; 0 \\-1 &amp; 0 &amp; 0 &amp; 3 \\0 &amp; 0 &amp; -1 &amp; -2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p>可知坐标系绘画正确。</p><p><strong>e)</strong></p><p><span class="math display">\[将 T=T_{s b} 作为变换算子, 表示绕\hat{x}轴转动-90^{\circ} 与沿 \hat{y}移动 2 个单位。计算T_{1}= T_{s a} T 与 T_{2}=T T_{s a}, 并回答新姿态T_{1} 与 T_{2} 分别对应的是 T_{s a} 绕哪个坐标系的变换得到的结果?\]</span></p><p><span class="math display">\[T_{1}=T_{sa}T=\left[\begin{array}{cccc}0 &amp; 0 &amp; -1 &amp; 1 \\0 &amp; 1 &amp; 0 &amp; 0 \\1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]，相对 \{a\}系变换得到的结果，表示绕\hat{x}_{a}轴转动-90^{\circ} 与沿 \hat{x} 移动 2个单位。\]</span></p><p><span class="math display">\[T_{2}=TT_{sa}=\left[\begin{array}{cccc}0 &amp; -1 &amp; 0 &amp; 3 \\1 &amp; 0 &amp; 0 &amp; 2 \\0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]，相对 \{s\}系变换得到的结果，表示绕\hat{x}_{s}轴转动-90^{\circ} 与沿 \hat{x} 移动 3个单位，沿 \hat{y} 移动 2 个单位。\]</span></p><p><strong>f)</strong></p><p><span class="math display">\[利用 T_{s b} 将点 p_{b}=(1,2,3) 从 \{b\} 系变换到 \{s\} 系。\]</span></p><p><span class="math display">\[p_{s}=T_{sb}p_{b}=(1,5,-2)\]</span></p><p><strong>k)</strong></p><p><span class="math display">\[已知 \{s\} 系中一点 p_{s}=(1,2,3), 计算 p^{\prime}=T_{s b} p_{s} 和p^{\prime \prime}=T_{s b}^{-1} p_{s} 。每一推导过程均可以解释为坐标变换(无须移动点的位置) 或移动点的位置 (无须改变坐标系)。\]</span></p><p><span class="math display">\[p^{\prime}=T_{s b} p_{s}=(1,5,-2)：其几何意义为移动点的位置；\]</span></p><p><span class="math display">\[p^{\prime \prime}=T_{s b}^{-1} p_{s}=(1,-3,0)：其几何意义为坐标变换。\]</span></p><p><strong>g)</strong>已知 <span class="math inline">\(\{s\}\)</span>系中的旋量 <spanclass="math inline">\(\mathcal{V}=(3,2,1,-1,-2,-3)\)</span>, 计算其在<span class="math inline">\(\{a\}\)</span> 系中的表示。</p><p><span class="math display">\[\mathcal{V}_{a}=\left[\begin{array}{c}\omega_{a} \\v_{a}\end{array}\right]=\left[\begin{array}{cc}R^{\mathrm{T}} &amp; 0 \\-R^{\mathrm{T}}[p] &amp; R^{\mathrm{T}}\end{array}\right]\left[\begin{array}{c}\omega_{s} \\v_{s}\end{array}\right]=\left[\mathrm{Ad}_{T_{a s}}\right] \mathcal{V}_{s}\\\because \left[\mathrm{Ad}_{T}\right]=\left[\begin{array}{cc}R &amp; 0 \\{[p] R} &amp; R\end{array}\right] \in \mathbb{R}^{6 \times 6} \\\therefore \mathcal{V}_{a}=(1,-3,-2,-9,1,-1)\]</span></p><p><strong>h)</strong> 计算 <span class="math inline">\(T_{s a}\)</span>的矩阵对数 <span class="math inline">\([\delta] \theta\)</span>,并提取其中的元素: 单位螺旋轴 <spanclass="math inline">\(\mathcal{S}\)</span> 和转动量 <spanclass="math inline">\(\theta\)</span> 。</p><p>使用到的函数：</p><p>MatrixLog6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> expmat <span class="token operator">=</span> <span class="token function">MatrixLog6</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">[</span>R<span class="token punctuation">,</span> p<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">TransToRp</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">;</span>omgmat <span class="token operator">=</span> <span class="token function">MatrixLog3</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">isequal</span><span class="token punctuation">(</span>omgmat<span class="token punctuation">,</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    expmat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">T</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">else</span>    theta <span class="token operator">=</span> <span class="token function">acos</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">trace</span><span class="token punctuation">(</span>R<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     expmat <span class="token operator">=</span> <span class="token punctuation">[</span>omgmat<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span> omgmat <span class="token operator">/</span> <span class="token number">2</span> <span class="token punctuation">...</span>                      <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> theta <span class="token operator">-</span> <span class="token function">cot</span><span class="token punctuation">(</span>theta <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">...</span>                        <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat <span class="token operator">/</span> theta<span class="token punctuation">)</span> <span class="token operator">*</span> p<span class="token punctuation">;</span>              <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>se3ToVec：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> V <span class="token operator">=</span> <span class="token function">se3ToVec</span><span class="token punctuation">(</span>se3mat<span class="token punctuation">)</span>V <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>AxisAng6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> <span class="token punctuation">[</span>S<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng6</span><span class="token punctuation">(</span>expc6<span class="token punctuation">)</span>theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span><span class="token function">expc6</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span>    theta <span class="token operator">=</span> <span class="token function">norm</span><span class="token punctuation">(</span><span class="token function">expc6</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">end</span>S <span class="token operator">=</span> expc6 <span class="token operator">/</span> theta<span class="token punctuation">;</span>    <span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>解得：</p><p><span class="math display">\[[\delta] \theta=\left[\begin{array}{cccc}0 &amp; -1.2092 &amp; -1.2092 &amp; 2.2092 \\1.2092 &amp; 0 &amp; -1.2092 &amp; -2.2092 \\1.2092 &amp; 1.2092 &amp; 0 &amp; -1.4184 \\0 &amp; 0 &amp; 0 &amp; 0\end{array}\right]\]</span></p><p>单位螺旋轴 <spanclass="math inline">\(\mathcal{S}=(0.5774,-0.5774,0.5774,1.0548,-1.0548,-0.6772)\)</span>和转动量 <span class="math inline">\(\theta=2.0944\)</span></p><p><strong>i)</strong> 计算与转动 <spanclass="math inline">\(\mathcal{S} \theta=(0,1,2,3,0,0)\)</span>的指数坐标对应的矩阵指数。</p><p>使用到的函数：</p><p>VecTose3：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> se3mat <span class="token operator">=</span> <span class="token function">VecTose3</span><span class="token punctuation">(</span>V<span class="token punctuation">)</span>se3mat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">VecToso3</span><span class="token punctuation">(</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><p>MatrixExp6：</p><div class="code-wrapper"><pre class="line-numbers language-matlab" data-language="matlab"><code class="language-matlab"><span class="token keyword">function</span> T <span class="token operator">=</span> <span class="token function">MatrixExp6</span><span class="token punctuation">(</span>se3mat<span class="token punctuation">)</span>omgtheta <span class="token operator">=</span> <span class="token function">so3ToVec</span><span class="token punctuation">(</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token function">NearZero</span><span class="token punctuation">(</span><span class="token function">norm</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">)</span>    T <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token punctuation">[</span>omghat<span class="token punctuation">,</span> theta<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">AxisAng3</span><span class="token punctuation">(</span>omgtheta<span class="token punctuation">)</span><span class="token punctuation">;</span>    omgmat <span class="token operator">=</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> theta<span class="token punctuation">;</span>     T <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">MatrixExp3</span><span class="token punctuation">(</span><span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">...</span>         <span class="token punctuation">(</span><span class="token function">eye</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">*</span> theta <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">cos</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token punctuation">...</span>          <span class="token operator">+</span> <span class="token punctuation">(</span>theta <span class="token operator">-</span> <span class="token function">sin</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> omgmat <span class="token operator">*</span> omgmat<span class="token punctuation">)</span> <span class="token punctuation">...</span>            <span class="token operator">*</span> <span class="token function">se3mat</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">/</span> theta<span class="token punctuation">;</span>         <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">end</span><span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p><span class="math display">\[\begin{aligned}T &amp;=\left[\begin{array}{cccc}-0.6173 &amp; -0.7037 &amp; 0.3518 &amp; 1.0555 \\0.7037 &amp; -0.2938 &amp; 0.6469 &amp; 1.9407 \\-0.3518 &amp; 0.6469 &amp; 0.6765 &amp; -0.9704 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\end{aligned}\]</span></p><p>3.目前工业机器人领域经常需要定义 4 种坐标系: 参考坐标系 <spanclass="math inline">\(\{a\}\)</span>, 末端或工具坐标系 <spanclass="math inline">\(\{b\}\)</span> 、图像坐标系 <spanclass="math inline">\(\{c\}\)</span> 、件坐标系 <spanclass="math inline">\(\{d\}\)</span>, 如下所示。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314230530164.png"alt="image-20220314230530164" /><figcaption aria-hidden="true">image-20220314230530164</figcaption></figure><p><strong>a)</strong></p><p><span class="math display">\[基于图中所给尺寸, 确定 T_{a d} 和 T_{c d} 。\]</span></p><p><span class="math display">\[T_{ad}=\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; -1 \\0 &amp; 1 &amp; 0 &amp; 1 \\0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p><span class="math display">\[T_{cd}=\left[\begin{array}{cccc}0 &amp; 1 &amp; 0 &amp; 0 \\1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -1 &amp; 2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p><strong>b)</strong></p><p><span class="math display">\[若T_{bc}=[1~~0~~0~~4；0~~1 ~~0~~0；0~~0~~1~~0；0~~0~~0~~1],求T_{ab}。\]</span></p><p><span class="math display">\[T_{ab}=T_{ac}T_{cb}=T_{ad}T_{dc}T_{bc}^{-1}=T_{ad}T_{cd}^{-1}T_{bc}^{-1}\\=\left[\begin{array}{cccc}0 &amp; 1 &amp; 0 &amp; -1 \\1 &amp; 0 &amp; 0 &amp; -3 \\0 &amp; 0 &amp; -1 &amp; 2 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><p><imgsrc="https://cdn.mathpix.com/cropped/2022_03_20_515d600b91de346f2453g-1.jpg?height=1510&amp;width=1069&amp;top_left_y=122&amp;top_left_x=108" /></p><p><imgsrc="https://cdn.mathpix.com/cropped/2022_03_20_515d600b91de346f2453g-2.jpg?height=556&amp;width=999&amp;top_left_y=598&amp;top_left_x=116" /></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220322133139136.png"alt="image-20220322133139136" /><figcaption aria-hidden="true">image-20220322133139136</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220322133103015.png"alt="image-20220322133103015" /><figcaption aria-hidden="true">image-20220322133103015</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>机器人</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库原理 Exercises 1</title>
    <link href="/2022/03/17/data1/"/>
    <url>/2022/03/17/data1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Database System Concepts Exercises of Chapter 2</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/photo-1613068687893-5e85b4638b56"alt="black flat screen computer monitor" /><figcaption aria-hidden="true">black flat screen computermonitor</figcaption></figure><h1 id="database-system-concepts-exercises-of-chapter-2">Database SystemConcepts Exercises of Chapter 2</h1><p><strong>Exercise 2.1</strong> Consider the relational database ofFigure 2.14,</p><p>Employee( person_name, street, city) Works (person_name,company_name, salary) Company(company_name, city) <strong>Figure2.14</strong></p><p>What are the appropriate primary keys?</p><p><strong>My answer:</strong></p><p><span class="math inline">\(employee (\underline{person-name},street, city)\)</span></p><p>$works (, company-name, salary) $</p><p><span class="math inline">\(company (\underline{company-name},city)\)</span></p><p><strong>Exercise</strong> <strong>2.7</strong> Consider therelational database of Figure 2.14. Given an expression in therelational algebra to express each of the following queries:</p><p>a.Find the names of all employees who live in city “Miami”</p><p>b.Find the names of all employees whose salary is greater than$100,000.</p><p>c.Find the names of all employees who live in “Miami” and whosesalary is greater than $100,000.</p><p><strong>My answer:</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220318132151932.png"alt="image-20220318132151932" /><figcaption aria-hidden="true">image-20220318132151932</figcaption></figure><p><strong>Exercise</strong> <strong>2.9</strong> Consider the bankdatabase of Figure 2.15.</p><p>branch(branch_name, branch_city, assets) customer(customer_name,customer_street, customer_city) loan(loan_number, branch_name, amount)borrower(customer_name, loan_number) account(account_number,loan_number) depositor(customer_name, account_number) <strong>Figure2.15</strong></p><ol type="a"><li><p>What are the appropriate primary keys?</p></li><li><p>Given your choice of primary keys, identify appropriate foreignkeys. Assume that branch names and customer names uniquely identifybranches and customers, but loans and accounts can be associated withmore than one customer.</p></li></ol><p><strong>My answer:</strong></p><p>The primary keys are marked with an <spanclass="math inline">\(\underline{underline}\)</span>, and the foreignkeys are marked with a <spanclass="math inline">\(\overline{overline}\)</span>.</p><p><span class="math inline">\(branch(\underline{branch-name},branch-city, assets)\)</span></p><p><span class="math inline">\(customer(\underline{customer-name},customer-street, customer-city)\)</span></p><p><span class="math inline">\(loan(\underline{loan-number},\overline{branch-name}, amount)\)</span></p><p><spanclass="math inline">\(borrower(\overline{\underline{customer-name}},\overline{loan-number})\)</span></p><p><span class="math inline">\(account(\underline{account-number},loan-number)\)</span></p><p><spanclass="math inline">\(depositor(\overline{\underline{customer-name}},\overline{account-number})\)</span></p>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机网络和因特网</title>
    <link href="/2022/03/14/net1/"/>
    <url>/2022/03/14/net1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第一章计算机网络和因特网小结</p><span id="more"></span><h2id="简述面向连接和无连接两种服务的特点">1.<strong>简述面向连接和无连接两种服务的特点。</strong></h2><p>面向连接服务：质量可靠，确保从发送方发出的数据最终按顺序完整地交付给接收方。</p><p>无连接服务：质量不可靠，不能对最终交付作任何保证。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220313164646441.png"alt="image-20220313164646441" /><figcaption aria-hidden="true">image-20220313164646441</figcaption></figure><p><strong>面向连接服务</strong>(connection-oriented)</p><p>面向连接服务具有<strong>可靠的数据传送，流控制，拥塞控制</strong>三个特性。</p><p>特点：</p><p>1、面向连接的数据传输过程必须经过建立连接、连接维护和释放连接的3个过程；</p><p>2、数据传输过程中，各分组不需要携带目的地址。</p><p>面向连接数据传输的收发数据顺序不变，因此传输的可靠性好，但协议复杂，通信效率不高。</p><p><strong>无连接服务</strong>(connectionless)</p><p>两个实体之间的通信<strong>不需要先建立好连接</strong>。是一种不可靠的服务。这种服务常被描述为“尽最大努力交付”(besteffort delivery)或“尽力而为”。</p><p>特点：</p><p>1、数据传输过程中，每个分组都携带完整的目的地址，各分组在系统中是独立传送的。因此，无连接中的数据传输过程不需要经过3个过程；</p><p>2、由于无连接发送的不同的分组，可能经历不同路径到目的主机，所以先发送的不一定先到，因此无连接的数据分组传输过程中，目的主机接收的数据分组可能出现乱序、重复与丢失的现象。</p><p>无连接的可靠性不是很好，但因其省去许多保征机制，因此通信协议相对简单，通信效率较高。</p><h2id="什么是多路复用常分为哪两种类型">2.<strong>什么是多路复用？常分为哪两种类型。</strong></h2><p>多路复用是指在一条传输链路上同时建立多条连接，分别传输数据。</p><p>常分为以下两种类型：</p><p><strong>频分多路复用FDM(frequency-divisionmultiplexing)</strong>：链路的频谱由跨越链路创建的连接所共享，按频率划分若干频段，每个频段专用于一个连接。</p><p><strong>时分多路复用TDM (time-division multiplexing)</strong>：时间划分为固定区间的帧，每帧再划分为固定数量的时隙，每一个时隙专用于一个连接，用于传输数据。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314223649714.png"alt="image-20220314223649714" /><figcaption aria-hidden="true">image-20220314223649714</figcaption></figure><h2id="简述电路交换和分组交换特点及工作过程">3.<strong>简述电路交换和分组交换特点及工作过程。</strong></h2><p><strong>特点：</strong></p><ol type="1"><li><strong>电路交换 (circuit switching)</strong>预留端到端资源：端系统之间通信路径上所需要的资源(缓存，链路带宽)，建立连接； 发送方以恒定速率向接收方传送数据。如，电话网络。</li><li><strong>分组交换(packet switching)</strong> 不需要资源预留；按需使用资源，可能要排队等待，同时有其它分组发送。 如，因特网。</li></ol><p><strong>工作过程：</strong></p><ol type="1"><li><p>电路交换：</p><p>在两台主机A、B之间创建一条专用的端到端连接，分别占用每条链路中的一条电路；</p><p>该连接获得链路带宽的1/n，进行通信。</p></li><li><p>分组交换：</p><p>源端将报文划分为较小的数据块（分组packet）；</p><p>每个分组通过一系列链路和分组交换机传送，直到目的端</p><p>目的端恢复原报文。</p></li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314220812885.png"alt="image-20220314220812885" /><figcaption aria-hidden="true">image-20220314220812885</figcaption></figure><h2id="什么是协议分层的服务模型">4.<strong>什么是协议？分层的服务模型？</strong></h2><p><strong>协议</strong>：控制网络中信息的发送和接收。定义了通信实体之间交换报文的格式和次序，以及在报文传输和/或接收或其他事件所采取的动作。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314223735346.png"alt="image-20220314223735346" /><figcaption aria-hidden="true">image-20220314223735346</figcaption></figure><p><strong>分层的服务模型</strong>：上层调用下层的服务，下层为上层提供服务。</p><p>通过第n层本身执行某些动作，或再使用其相邻下层（第n-1层）的服务，来完成向其上层（第n+1层）提供的服务。</p><h2id="简述分层的特点和分层后数据的传递过程">5.<strong>简述分层的特点和分层后数据的传递过程。</strong></h2><p><strong>分层特点：</strong></p><ul><li>每层功能独立；</li><li>每两个相邻层之间有一逻辑接口，可交换信息；</li><li>上一层建立在下一层基础上，上一层可调用下一层的服务，下一层为上一层提供服务。</li></ul><p><strong>分层后数据的传递过程</strong>：主机（端系统）间数据传送实际上并不是在对等层间直接进行，而是通过相邻层间的传递合作完成。</p><p>发送方：将用户数据由高层向低层逐层传递，每经过一层，加上该层的控制信息，直到最低层（物理层），然后直接通过物理媒体传输到目的方。（逐层封装）</p><p>接收方：将收到的数据由低层向高层逐层传递，每经过一层，去掉该层的控制信息，直到最高层，恢复为用户数据。（逐层解封）</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314222653398.png"alt="image-20220314222653398" /><figcaption aria-hidden="true">image-20220314222653398</figcaption></figure><h2id="因特网分层模型及各层功能">6.<strong>因特网分层模型及各层功能。</strong></h2><p>因特网的协议栈由5个层次组成：物理层、链路层、网络层、运输层和应用层。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220314222941459.png"alt="image-20220314222941459" /><figcaption aria-hidden="true">image-20220314222941459</figcaption></figure><ol type="1"><li>应用层：提供各种网络应用。传输应用报文。 FTP、 SMTP、 HTTP</li><li>运输层：在应用程序的客户机和服务器之间提供传输应用层报文服务。传输报文段。TCP、 UDP</li><li>网络层：主机和主机之间传输网络层分组（数据报）。 IP协议、选路协议</li><li>链路层： 在邻近单元之间传输数据（帧 ）。 PPP、以太网</li><li>物理层：在节点之间传输比特流。 传输媒体</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>智能机器人技术——位形空间</title>
    <link href="/2022/03/02/robot1/"/>
    <url>/2022/03/02/robot1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>智能机器人技术作业记录</p><span id="more"></span><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220302214614790.png"alt="image-20220302214614790" /><figcaption aria-hidden="true">image-20220302214614790</figcaption></figure><h1 id="智能机器人技术位形空间">智能机器人技术——位形空间</h1><p>一、选择/填空题（10 分）。</p><ol type="1"><li>机器人的自由度是 (<strong>D</strong>) ? A. 机器人上点的数量 B.机器人关节数量 C. 组成机器人的刚体的数量 D. 组成机器人的刚体的数量,减去刚体间独立约束的数量</li><li>二维平面刚体的自由度为 (<strong>3</strong>) ；三维空间刚体的自由度为 (<strong>6</strong>) 。</li><li>根据课堂上推算三维空间内刚体自由度的方法,推算出四维空间中刚体的自由度 (<strong>10</strong>)、有关角度的自由度(<strong>6</strong>)、有关平移位置的自由度 (<strong>4</strong>)。(如,三维空间中分别为 <span class="math inline">\(6,3,3\)</span> )</li><li>假设你的手臂（从肩膀到手掌）, 有 7个自由度。你如同一位服务生一样水平端着餐盘,防止洒出酒水。你的手臂此时有几个自由度：<strong>5</strong>，这个任务空间的自由度是：<strong>4</strong>。</li></ol><p>二、简答题, 请写出解题过程 (10 分)。</p><ol type="1"><li><p>考虑两个刚体之间的一个关节。每个刚体有 <spanclass="math inline">\(\mathrm{m}\)</span> 个自由度（二维空间刚体 <spanclass="math inline">\(m=3\)</span>, 三维空间刚体 <spanclass="math inline">\(m=6\)</span> ), 并且没有任何约束。关节有 <spanclass="math inline">\(f\)</span> 个自由度（旋转关节 <spanclass="math inline">\(\mathrm{f}=1\)</span>, 球形关节 <spanclass="math inline">\(\mathrm{f}=3\)</span> 等)。试问,用这个关节关联两个刚体, 那么引入了多少个约束（一个刚体相对于另一个,用字母表示）?</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220302212205280.png"alt="image-20220302212205280" /><figcaption aria-hidden="true">image-20220302212205280</figcaption></figure><p><strong>解：<spanclass="math inline">\(自由度f+平面约束c=平面自由度3，自由度f＋空间约束c=空间自由度6\)</span></strong></p><p><strong>故<spanclass="math inline">\(\pmb{c=-f+m}\)</span></strong></p></li><li><p>考虑一个机构包含了 3 个三维空间刚体 (记住, 包括地面, 所以 <spanclass="math inline">\(\mathrm{N}=4\)</span> ), 和 4 个关节: 1 个转动, 1个平移, 一个万向, 一个球形。使用 Grubler 公式, 计算机构的自由度。</p><p><strong>解：转动副<spanclass="math inline">\(f_1=1\)</span>，移动副<spanclass="math inline">\(f_2=1\)</span>，万向铰<spanclass="math inline">\(f_3=2\)</span>，球形铰<spanclass="math inline">\(f_4=3\)</span></strong></p><p><strong>又<span class="math inline">\(\because N=4\)</span>，<spanclass="math inline">\(J=4\)</span>，<spanclass="math inline">\(m=6\)</span></strong></p><p><strong><span class="math inline">\(\therefore\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(4-1-4\right)+\left(1+1+2+3\right)=1}\)</span></strong></p></li><li><p>如下图的 SRS (球形-转动-球形) 机构, 正在抓取一个物体。试问,当机构紧握物体时 (物体与机构中的机械臂最后一段没有相对运动时),自由度是多少?</p></li></ol><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/2022_02_28_40f28045fe8caa2a438eg-1.jpg" /></p><p><strong>解：Spherical Joint即为球形铰<spanclass="math inline">\(f=3\)</span>，共8个；Revolute Joint即为转动副<spanclass="math inline">\(f=1\)</span>，共4个；</strong></p><p><strong>又<span class="math inline">\(\because N=14\)</span>，<spanclass="math inline">\(J=16\)</span>，<spanclass="math inline">\(m=6\)</span></strong></p><p><span class="math inline">\(\therefore\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(14-1-16\right)+\left(3\times8+1\times4\right)=10}\)</span></p><ol start="4" type="1"><li><p>同上题, 如果现在有 <span class="math inline">\(n\)</span>条这样的机械臂 (题 3 中 <span class="math inline">\(n=4\)</span> ),机构的自由度是?</p><p><strong>同理：<spanclass="math inline">\(\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(3n+2-1-4n\right)+\left(3\times2n+1\timesn\right)=n+6}\)</span></strong></p></li><li><p>同上题, 假设 <span class="math inline">\(n\)</span>条机械臂的转动关节, 被替换成了万向关节, 机构的自由度是?</p><p><strong>同理：<spanclass="math inline">\(\pmb{dof=m(N-1-j)+\sum_{i=1}^Jf_i=6\times\left(3n+2-1-4n\right)+\left(3\times2n+2\timesn\right)=2n+6}\)</span></strong></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>机器人</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022’summary</title>
    <link href="/2021/12/31/2022/"/>
    <url>/2021/12/31/2022/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231192304439.png"alt="image-20211231192304439" /><figcaption aria-hidden="true">image-20211231192304439</figcaption></figure><p>这是2021年发的第一条朋友圈配图，顺手拿来总结吧。</p><span id="more"></span><p>没想到曾经一个因为不怎么使用微信，不怎么看朋友圈而饱受困扰的人会用看朋友圈来回顾自己的一整年。</p><p>毕竟有感而发，这次就不纠结排版美不美观、结构严不严谨了。</p><h1id="天时人事日相催冬至阳生春又来">天时人事日相催，冬至阳生春又来</h1><p>21的一月初我应该有在努力复习吧，因为一整个学期的怠惰，因为对一个优秀女生的追逐。大学跟高中差别真大，没有人逼我写必刷题了，没有人逼我额外补课了，没有所谓火箭班了。大一上虽然大部分都在20年这个区间，但是给我的21年真是奠定了乱七八糟的基础。</p><p>1月6号那天开始听YOASOBI的歌。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231193810905.png"alt="image-20211231193810905" /><figcaption aria-hidden="true">image-20211231193810905</figcaption></figure><p>我的“好友”为我做的图，可惜这位好友不再联系了，倒是图里的内容实现了。</p><p>放假回家了，回了一趟华美，可惜看到华美帝国回忆录的共享文档的时候我还是写不出东西来。</p><h1id="鸿雁长飞光不度鱼龙潜跃水成文">鸿雁长飞光不度，鱼龙潜跃水成文</h1><p>在二月终于和大鸟转转转酒吧的兄弟们会师了，22年的美食王国的勇者传说继续辉煌！可能这是目前我唯一期待的年度团建了吧，一群我可以无条件信任的人。</p><p>这个月里跟了好多人出去玩，多年未见的童年好友，帮我很多的同乡师兄，关系超好的高中同学···（词穷了，就这样吧）</p><p>反正过了个年，又开学了！</p><p>甚至不记得为什么留下这段感慨：</p><p>凡事都有定期。天下万物都有定时，生有时，死有时，哭有时，笑有时，寻找有时，放手有时。</p><p>好消息是1204棋牌中心初具雏形，为后来的金碧辉煌作了铺垫。</p><h1id="空里流霜不觉飞汀上白沙看不见">空里流霜不觉飞，汀上白沙看不见</h1><p>三月里买了我的宝贝surface，那我肯定开始家教了，虽然我天天骂它玩4399都卡，但确实给我带来了极大便利，不管去哪都只带着平板可比背着游戏本的习武之人好多了。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231195659935.png"alt="image-20211231195659935" /><figcaption aria-hidden="true">image-20211231195659935</figcaption></figure><p>在这个时候参加了大创，虽然可能自己完全没有做出什么东西的能力来，但那个星期还是挺震撼的，原来科研离我并不远。毕竟我也梦想成为拉格多科学院的“疯子”。</p><p>这个月里还参加了几次团建，文体组、智协、微软俱乐部（虽然改名了）···大一参加的每一个社团或组织都让我收获了好多好多，知识也好，朋友也好，不禁感慨，还好我参加了。</p><p>三月十号那天还认识了一个special的人，感谢大物，缘分真奇妙。</p><p>虽然我貌似有很多的朋友，但事实上我是一个很害怕交友的人。害怕我的所作所为会对其他人的人生轨迹造成影响（确实怪中二的）。</p><p>不过好在大部分时候都是正面影响，希望我的朋友毕业后，就业后，10年后，50年后还是我的朋友，在我的轨迹留多点痕迹。</p><h1id="江水流春去欲尽江潭落月复西斜">江水流春去欲尽，江潭落月复西斜</h1><p>四月里我开始读诗了！语文老师她看了肯定很惊讶，为什么语文成绩这么差的我居然还会对这些感兴趣，感谢老师的滕王阁序。</p><p>这个月里我应该有好好在写python，matlab，c++和数据结构与算法吧，学基础的编程语言让人充满了成就感。</p><p>这个月最特殊的事应该是认识了another specialpeople，刚好前后差了一个月。</p><p>虽然目前是我生活里最重要的人们，但是真的给我带来了许多的”痛苦“！烦死了！希望来年你们可以不要那么傻，但是请继续傻乐下去。</p><h1id="谁家今夜扁舟子何处相思明月楼">谁家今夜扁舟子，何处相思明月楼</h1><p>五月Enderfga's blog建站了！虽然产生了没几篇高质量内容，但是反正是我的，我说了算！</p><p>看起来这个月里我的朋友圈大部分都是吃吃喝喝，参加了一些小比赛，</p><p>总是会产生一些，我学会了好多东西~然后过了一段时间就发现，原来的自己好傻，连时间复杂度都不知道是什么，连flag都没有听说过。</p><h1id="玉户帘中卷不去捣衣砧上拂还来">玉户帘中卷不去，捣衣砧上拂还来</h1><p>这个月我生日了，收到了好多好多礼物呀，虽然我还是会觉得，某一天不会和它的昨天与明天有所区别，但是被大家重视的一天就另当别论了。</p><p>这个月还停止前面说的追逐，不过即使这样还是要告诉自己：人间一趟，积极向上！</p><p>学弟学妹参加了高考，他们信心满满；而我还在为不挂科努力。</p><h1id="春江潮水连海平海上明月共潮生">春江潮水连海平，海上明月共潮生</h1><p>暑假没有回家，认真打工的七月。</p><p>一天12小时的家教，给我未来的体重激增奠定了经济基础。</p><p>总是会回忆一下人，即使物是人非。</p><p>b站前一段时间是不是火了随机挑战来着？我的七月十七号早知道应该拍成视频，全靠掷骰子随机出发，没想到最后还能到关山月美术馆，莲花山和深圳湾。</p><h1id="斜月沉沉藏海雾碣石潇湘无限路">斜月沉沉藏海雾，碣石潇湘无限路</h1><p>整个八月估计都在为奥运热血沸腾，16年12年08年的我都没有感受到奥运的魅力。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231202939847.png"alt="image-20211231202939847" /><figcaption aria-hidden="true">image-20211231202939847</figcaption></figure><p>当然还有大吃大喝跟兄弟们的沙雕你画我猜。</p><h1id="不知江月待何人但见长江送流水">不知江月待何人，但见长江送流水</h1><p>又开学啦····</p><p>我变成学长了，迎新了好多学弟学妹。</p><p>这个月我估计有点想恋爱了，转了很多有的没的。</p><p>暑假赚钱的心愿：请我的好朋友们吃大餐</p><p>开始在这个月一步步实现了！（钱包肉疼）</p><h1 id="禁街箫鼓寒轻夜永">禁街箫鼓，寒轻夜永</h1><p>国庆爱hanser五周年纪念日！</p><p>第一次跟朋友们出去旅游的国庆假期，有美女美食相伴的日子比在自习室打代码快乐多了。</p><p>越来越胖了，有钱导致我吃的太好，我应该破产的。</p><p>怎么我乐于助人，你们就乐于送我吃蛋糕奶茶呀，这不好！</p><h1id="凝霜夜下拂罗衣浮云中断开明月">凝霜夜下拂罗衣，浮云中断开明月</h1><p>十一月不就是上个月吗？我在干嘛？</p><p>我在陪重要的人吃吃喝喝还有傻乐。</p><p>希望我来年总结的时候我还是在陪重要的人吃喝傻乐，不过得多点努力学习。怎么会有这么懒的人，就知道玩动森···</p><p>十二号那天在大教室里演讲了，感觉自己从小就很有表现欲，奈何没有任何技能，每一次上台前都手抖流汗，</p><p>但是我记得那天我讲的很满意，我自己很满意，有进步就好。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231204209953.png"alt="image-20211231204209953" /><figcaption aria-hidden="true">image-20211231204209953</figcaption></figure><h1id="愿我如星君如月夜夜流光相皎洁">愿我如星君如月，夜夜流光相皎洁</h1><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211231204818624.png"alt="image-20211231204818624" /><figcaption aria-hidden="true">image-20211231204818624</figcaption></figure><p>12月就不单独总结了，总结全年吧！</p><p>本人2021年年度成就总结:</p><ol type="1"><li>学术方面，凭借个人努力，在核酸检测领域产出多份数据真实详尽的报告。</li><li>健康方面，保证膳食纤维摄入，具体表现为每日坚持吃瓜，吃好瓜，吃大瓜。</li><li>商业方面，与各大平台合作，全面参与投资618双11、双12等千亿级重大项目。</li><li>环保方面，股票基金一片绿，绿水青山就是金山银山。在废物利用领域更是成绩斐然:自己作为废物，常常被别人利用。</li><li>运动方面，专注于水上项目，在摸鱼、划水等小项上有突出表现。</li><li>信仰方面，全心全意坚持转发锦鲤不动摇。</li></ol><p>算了不玩梗了。</p><p>这一年有什么值得回顾的吗？</p><p>也许应该是友谊吧，从高中到大学，相识6，7年的朋友们不在了，跳出舒适圈，结识了另外一批可爱的人。</p><p>本来不想花时间写这种东西的，会觉得“你的总结关别人什么事，写出来谁会看呀”。</p><p>后来想了想，真有道理，我应该写给明年31号的自己。</p><p>喂，桂安，你有没有记得刷LeetCode，今天学习强国了吗？和朋友们的关系好不，有没有给他们带来快乐？有给学弟学妹做个好榜样没？</p><p>linux用惯没，c++/python/matlab还记得怎么用吗？绩点到5没？体重下来没？······</p><figure><img src="https://v2.jinrishici.com/one.svg" alt="今日诗词" /><figcaption aria-hidden="true">今日诗词</figcaption></figure><p>2021最大的收获是结识了读到这里的你，谢谢~</p>]]></content>
    
    
    
    <tags>
      
      <tag>闲谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>wsl安装与开发环境搭建</title>
    <link href="/2021/11/26/wsl/"/>
    <url>/2021/11/26/wsl/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>wsl2，vscode，windows terminal，zsh，docker····</p><span id="more"></span><h1 id="windows-subsystem-for-linux">Windows Subsystem for Linux</h1><p>首先贴一个<ahref="https://docs.microsoft.com/zh-cn/windows/wsl/install">官方文档</a></p><h2 id="什么是适用于-linux-的-windows-子系统">什么是适用于 Linux 的Windows 子系统</h2><p>适用于 Linux 的 Windows 子系统可让开发人员按原样运行 GNU/Linux 环境 -包括大多数命令行工具、实用工具和应用程序 -且不会产生传统虚拟机或双启动设置开销。</p><ul><li><a href="https://aka.ms/wslstore">在 Microsoft Store</a>中选择你偏好的 GNU/Linux 分发版。</li><li>运行常用的命令行软件工具（例如<code>grep</code>、<code>sed</code>、<code>awk</code>）或其他 ELF-64二进制文件。</li><li>运行 Bash shell 脚本和 GNU/Linux 命令行应用程序，包括：<ul><li>工具：vim、emacs、tmux</li><li>语言：<ahref="https://docs.microsoft.com/zh-cn/windows/nodejs/setup-on-wsl2">NodeJS</a>、Javascript、<ahref="https://docs.microsoft.com/zh-cn/windows/python/web-frameworks">Python</a>、Ruby、C/C++、C# 与 F#、Rust、Go 等。</li><li>服务：SSHD、<ahref="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">MySQL</a>、Apache、lighttpd、<ahref="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">MongoDB</a>、<ahref="https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-database">PostgreSQL</a>。</li></ul></li><li>使用自己的 GNU/Linux 分发包管理器安装其他软件。</li><li>使用类似于 Unix 的命令行 shell 调用 Windows 应用程序。</li><li>在 Windows 上调用 GNU/Linux 应用程序。</li></ul><h2 id="什么是-wsl-2">什么是 WSL 2？</h2><p>WSL 2 是适用于 Linux 的 Windows子系统体系结构的一个新版本，它支持适用于 Linux 的 Windows 子系统在Windows 上运行 ELF64 Linux 二进制文件。 它的主要目标是<strong>提高文件系统性能</strong>，以及添加<strong>完全的系统调用兼容性</strong>。</p><p>这一新的体系结构改变了这些 Linux 二进制文件与Windows和计算机硬件进行交互的方式，但仍然提供与 WSL1（当前广泛可用的版本）中相同的用户体验。</p><p>单个 Linux 分发版可以在 WSL 1 或 WSL 2 体系结构中运行。每个分发版可随时升级或降级，并且你可以并行运行 WSL 1 和 WSL 2 分发版。WSL 2 使用全新的体系结构，该体系结构受益于运行<strong>真正</strong>的Linux 内核。</p><h2 id="wsl-2安装">WSL 2安装</h2><p>需要CPU开启VT（VirtualizationTechnology），这一步根据CPU不同操作方式不同就不细说了。</p><p>需要先启用“适用于 Linux 的 Windows 子系统”可选功能，然后才能在Windows 上安装 Linux 分发。</p><p>以管理员身份打开 PowerShell 并运行：</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">dism<span class="token punctuation">.</span>exe <span class="token operator">/</span>online <span class="token operator">/</span><span class="token function">enable-feature</span> <span class="token operator">/</span>featurename:Microsoft<span class="token operator">-</span>Windows<span class="token operator">-</span>Subsystem<span class="token operator">-</span>Linux <span class="token operator">/</span>all <span class="token operator">/</span>norestart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>若要更新到 WSL 2，需要运行 Windows 10。</p><ul><li>对于 x64 系统：<strong>版本 1903</strong> 或更高版本，采用<strong>内部版本 18362</strong> 或更高版本。</li><li>对于 ARM64 系统：<strong>版本 2004</strong> 或更高版本，采用<strong>内部版本 19041</strong> 或更高版本。</li><li>低于 18362 的版本不支持 WSL 2。 使用 <ahref="https://www.microsoft.com/software-download/windows10">WindowsUpdate 助手</a>更新 Windows 版本。</li></ul><p>若要检查 Windows 版本及内部版本号，选择 Windows 徽标键 +R，然后键入“winver”，选择“确定”。 更新到“设置”菜单中的<ahref="ms-settings:windowsupdate">最新 Windows 版本</a>。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126110320999.png"alt="image-20211126110320999" /><figcaption aria-hidden="true">image-20211126110320999</figcaption></figure><p>安装 WSL 2 之前，必须启用“虚拟机平台”可选功能。 计算机需要<ahref="https://docs.microsoft.com/zh-cn/windows/wsl/troubleshooting#error-0x80370102-the-virtual-machine-could-not-be-started-because-a-required-feature-is-not-installed">虚拟化功能</a>才能使用此功能。</p><p>以管理员身份打开 PowerShell 并运行：</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">dism<span class="token punctuation">.</span>exe <span class="token operator">/</span>online <span class="token operator">/</span><span class="token function">enable-feature</span> <span class="token operator">/</span>featurename:VirtualMachinePlatform <span class="token operator">/</span>all <span class="token operator">/</span>norestart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126110900611.png"alt="image-20211126110900611" /><figcaption aria-hidden="true">image-20211126110900611</figcaption></figure><p><strong>重新启动</strong> 计算机，以完成 WSL 安装并更新到 WSL 2。</p><p>重启之后<ahref="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">下载安装</a>Linux 内核更新包并将 WSL 2 设置为默认版本。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126111436728.png"alt="image-20211126111436728" /><figcaption aria-hidden="true">image-20211126111436728</figcaption></figure><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">wsl <span class="token operator">--</span><span class="token function">set-default</span><span class="token operator">-</span>version 2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126111557676.png"alt="image-20211126111557676" /><figcaption aria-hidden="true">image-20211126111557676</figcaption></figure><p>最后，打开 <a href="https://aka.ms/wslstore">MicrosoftStore</a>，并选择你偏好的 Linux 分发版。</p><p>单击以下链接会打开每个分发版的 Microsoft Store 页面：</p><ul><li><a href="https://www.microsoft.com/store/apps/9N9TNGVNDL3Q">Ubuntu18.04 LTS</a></li><li><a href="https://www.microsoft.com/store/apps/9n6svws3rx71">Ubuntu20.04 LTS</a></li><li><a href="https://www.microsoft.com/store/apps/9NJFZK00FGKV">openSUSELeap 15.1</a></li><li><a href="https://www.microsoft.com/store/apps/9MZ3D1TRP8T1">SUSELinux Enterprise Server 12 SP5</a></li><li><a href="https://www.microsoft.com/store/apps/9PN498VPMF3Z">SUSELinux Enterprise Server 15 SP1</a></li><li><a href="https://www.microsoft.com/store/apps/9PKR34TNCV07">KaliLinux</a></li><li><a href="https://www.microsoft.com/store/apps/9MSVKQC78PK6">DebianGNU/Linux</a></li><li><a href="https://www.microsoft.com/store/apps/9n6gdm4k2hnc">FedoraRemix for WSL</a></li><li><ahref="https://www.microsoft.com/store/apps/9NV1GV1PXZ6P">Pengwin</a></li><li><a href="https://www.microsoft.com/store/apps/9N8LP0X93VCP">PengwinEnterprise</a></li><li><a href="https://www.microsoft.com/store/apps/9p804crf0395">AlpineWSL</a></li><li><ahref="https://www.microsoft.com/store/apps/9msmjqd017x7">Raft（免费试用版）</a></li></ul><p>首次启动新安装的 Linux分发版时，将打开一个控制台窗口，系统会要求你等待一分钟或两分钟，以便文件解压缩并存储到电脑上。未来的所有启动时间应不到一秒。</p><p>然后，需要为新的 Linux 分发版创建用户帐户和密码。</p><p>另外，以上内容貌似（？）可以使用以下一行命令解决</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wsl --install -d Ubuntu-20.04<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126142919333.png"alt="image-20211126142919333" /><figcaption aria-hidden="true">image-20211126142919333</figcaption></figure><p>另外我发现用户名不能用大写，并且密码是不会显示出来的。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126143140954.png"alt="image-20211126143140954" /><figcaption aria-hidden="true">image-20211126143140954</figcaption></figure><h2 id="换源">换源</h2><p>如果遇到下载速度较慢，或者下载失败等问题，我们还可以把官方源换成国内源。</p><p><strong>备份list文件</strong></p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">cd</span> /etc/apt/<span class="token function">sudo</span> <span class="token function">cp</span> sources.list sources.list.bak<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>备份了，如果下面的哪一步出错了好恢复。</p><p><strong>修改list文件</strong></p><p>管理员权限，使用 vim 进行修改：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">vim</span> sources.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>把想要更换的源复制在剪切板，这里以阿里源为例：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>我们先通过按<strong>ggdG</strong>这几个字母将里面的内容全部删除，</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">通过按下gg后发现光标移动到文件首行了。其中，gg为跳转到文件首行；dG为删除光标所在行以及其下所有行的内容。d为删除，G为跳转到文件末尾行。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>按鼠标右键会进行粘贴，然后输入 :wq! 进行退出与保存。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126135607014.png"alt="image-20211126135607014" /><figcaption aria-hidden="true">image-20211126135607014</figcaption></figure><p>最后复制这两条命令进行更新镜像源列表。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h1 id="windows-terminalvscode">Windows terminal+vscode</h1><p><ahref="https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701?rtc=1&amp;activetab=pivot:overviewtab">WindowsTerminal</a>https://docs.microsoft.com/en-us/windows/terminal/get-started</p><p>VS Code https://code.visualstudio.com</p><p>这两样软件可以大幅提高效率（还很装逼很好看）</p><p>windowsterminal各项设置可以实现许多使用功能，比如我设置了默认启动Ubuntu，添加了gitbash，透明亚克力效果等（本次不介绍，感兴趣自行研究）</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126112846563.png"alt="image-20211126112846563" /><figcaption aria-hidden="true">image-20211126112846563</figcaption></figure><p>可以在工作区文件夹内右键然后在windows终端打开</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126112958904.png"alt="image-20211126112958904" /><figcaption aria-hidden="true">image-20211126112958904</figcaption></figure><p>也可以直接打开window终端，cd到对应文件夹，然后输入</p><div class="code-wrapper"><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">code <span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126113402308.png"alt="image-20211126113402308" /><figcaption aria-hidden="true">image-20211126113402308</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126113507900.png"alt="image-20211126113507900" /><figcaption aria-hidden="true">image-20211126113507900</figcaption></figure><p>至此就可以实现在windows环境下编程，在linux环境下测试。</p><h1 id="docker">Docker</h1><p>使用以下脚本可以实现自动安装。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># install docker</span><span class="token function">curl</span> -fsSL get.docker.com -o get-docker.sh<span class="token function">sh</span> get-docker.sh<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token operator">!</span> <span class="token variable"><span class="token variable">$(</span>getent group docker<span class="token variable">)</span></span> <span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">then</span>     <span class="token function">sudo</span> <span class="token function">groupadd</span> docker<span class="token punctuation">;</span><span class="token keyword">else</span>    <span class="token builtin class-name">echo</span> <span class="token string">"docker user group already exists"</span><span class="token keyword">fi</span><span class="token function">sudo</span> gpasswd -a <span class="token environment constant">$USER</span> docker<span class="token function">sudo</span> <span class="token function">service</span> docker restart<span class="token function">rm</span> -rf get-docker.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126133921891.png"alt="image-20211126133921891" /><figcaption aria-hidden="true">image-20211126133921891</figcaption></figure><p>可以直接复制到txt中，然后修改文件类型跟文件名为install-docker.sh（后缀是sh，名字任意）</p><p>例如我在桌面放置了该脚本，右键打开终端之后输入以下命令即可完成安装。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> install-docker.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126140126640.png"alt="image-20211126140126640" /><figcaption aria-hidden="true">image-20211126140126640</figcaption></figure><p>接下来输入：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">service</span> docker startdocker version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>就可以启动服务，查看版本，证明我们已经安装成功。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126140532065.png"alt="image-20211126140532065" /><figcaption aria-hidden="true">image-20211126140532065</figcaption></figure><p>如果不希望每次都特地启动docker的服务可以使用以下命令设置自启动：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>关于docker的使用就大家自己研究啦。</p><h1 id="on-my-zsh">On-my-zsh</h1><p>一个美观且功能强大的终端</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126145704636.png"alt="image-20211126145704636" /><figcaption aria-hidden="true">image-20211126145704636</figcaption></figure><p>用windows terminal启动Ubuntu，输入以下命令安装：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y <span class="token function">zsh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>oh-my-zsh中整理了常用的zsh<ahref="https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins">扩展</a>和<ahref="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes">主题</a>,所以先安装oh-my-zsh</p><p>使用curl安装 :</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> -c <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token function">curl</span> -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh<span class="token variable">)</span></span>"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>使用wget安装：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sh</span> -c <span class="token string">"<span class="token variable"><span class="token variable">$(</span><span class="token function">wget</span> https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -<span class="token variable">)</span></span>"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>虽然我列出了上面两条命令，但最好还是看看<ahref="https://ohmyz.sh/#install">官网</a>的安装页面，确保命令的最新版本。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126150308574.png"alt="image-20211126150308574" /><figcaption aria-hidden="true">image-20211126150308574</figcaption></figure><p>接下来输入：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">cd</span>code .zshrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><p>就可以cd到根目录文件夹，用vscode的可视化界面编辑配置文件，添加需要的扩展与主题了。</p><p>扩展与主题根据个人需求添加，本文不再赘述。</p><h1 id="python开发">Python开发</h1><p>花里胡哨那么多东西了，讲一点实战（假的）。</p><p>默认Ubuntu已经安装了python，我们只需要安装pip，就可以进行一些简单的编程。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3-pip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126151809809.png"alt="image-20211126151809809" /><figcaption aria-hidden="true">image-20211126151809809</figcaption></figure><p>当然我们不能局限于简单的编程，我们需要<strong>创建虚拟环境</strong>，确保各个环境互相隔离，互不影响。</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3-venv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>创建虚拟环境：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> python3 -m venv <span class="token function">env</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>激活与退出：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">source</span> env/bin/activatedeactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211126181729703.png"alt="image-20211126181729703" /><figcaption aria-hidden="true">image-20211126181729703</figcaption></figure><p>接下来就可以尽情地pipinstall了，在工作环境下新建文件夹，再用vscode打开，即可开始编程。</p>]]></content>
    
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>One-Hot Encoding 独热编码</title>
    <link href="/2021/11/23/onehot/"/>
    <url>/2021/11/23/onehot/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>One-Hot Encoding学习记录</p><span id="more"></span><h1 id="一one-hot-encoding">一、One-Hot Encoding</h1><p>One-Hot编码，又称为一位有效编码，主要是采用位状态寄存器来对个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。在实际的机器学习的应用任务中，特征有时候并不总是连续值，有可能是一些分类值，如性别可分为“male ”和“ female ”。在机器学习任务中，对于这样的特征，</p><p>One-hot在数位电路中被用来表示一种特殊的位元组合，该字节里，仅容许单一位元为1，其他位元都必须为0。之所以称为one-hot就是因为只能有一个1（hot）。若情况相反，只有一个0，其余为1，则称为one-cold。在机器学习里，也有one-hot向量（英语：one-hotvector）的概念。在一任意维度的向量中，仅有一个维度的值是1，其余为0。譬如向量<span class="math inline">\({\displaystyle [0\ 0\ 0\ 0\ 0\ 1\ 0\ 0\ 0\0\ 0\ 0\ 0\ 0\ 0]}{\displaystyle [0\ 0\ 0\ 0\ 0\ 1\ 0\ 0\ 0\ 0\ 0\ 0\ 0\0\0]}\)</span>，即为15维空间中的一组one-hot向量。将类别性资料转换成one-hot向量的过程则称one-hot编码（英语：one-hotencoding）。在统计学中，虚拟变数代表了类似的概念。</p><p>One-hot目前并无公认或被广泛使用的中文译名。目前可见的one-hotencoding译名有独热编码以及一位有效编码。</p><p>通常我们需要对其进行特征数字化，如下面的例子，这些特征值并不是连续的，而是离散的，无序的。</p><p>有如下三个特征属性：</p><ul><li>性别：["male"，"female"]</li><li>地区：["Europe"，"US"，"Asia"]</li><li>浏览器：["Firefox"，"Chrome"，"Safari"，"Internet Explorer"]</li></ul><p>对于某一个样本，如["male"，"US"，"InternetExplorer"]，我们需要将这个分类值的特征数字化，最直接的方法，我们可以采用序列化的方式：[0,1,3]。但是这样的特征处理并不能直接放入机器学习算法中。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20190514150006715.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h1 id="二one-hot-encoding的处理方法">二、One-HotEncoding的处理方法</h1><p>One-Hot 编码是分类变量作为二进制向量的表示。</p><ol type="1"><li>将分类值映射到整数值。</li><li>每个整数值被表示为二进制向量，除了整数的索引之外，它都是零值，它被标记为1。</li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211123195029323.png"alt="image-20211123195029323" /><figcaption aria-hidden="true">image-20211123195029323</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211123195041636.png"alt="image-20211123195041636" /><figcaption aria-hidden="true">image-20211123195041636</figcaption></figure><p>对于上述的问题，性别的属性是二维的，同理，地区是三维的，浏览器则是四维的，这样，我们可以采用One-Hot编码的方式对上述的样本“["male"，"US"，"InternetExplorer"]”编码，“male”则对应着[1，0]，同理“US”对应着[0，1，0]，“InternetExplorer”对应着[0，0，0，1]。</p><p>则完整的特征数字化的结果为：[1,0,0,1,0,0,0,0,1]。这样导致的一个结果就是数据会变得非常的稀疏。</p><h1 id="三python代码举例">三、Python代码举例</h1><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing enc <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>OneHotEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>enc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> array <span class="token operator">=</span> enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>array<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>结果：[[ 1. 0. 0. 1. 0. 0. 0. 0. 1.]]</p><h1 id="四优缺点分析">四、优缺点分析</h1><p><strong>优点：</strong></p><ol type="1"><li><p>解决了分类器不好处理离散数据的问题。</p><ol type="a"><li><p>欧式空间。在回归，分类，聚类等机器学习算法中，特征之间 距离计算或 相似度计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。</p></li><li><p>one-hot 编码。使用 one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用one-hot 编码，确实会让 特征之间的距离计算更加合理。</p></li></ol></li><li><p>在一定程度上也起到了扩充特征的作用。</p></li></ol><p><strong>缺点：</strong></p><ol type="1"><li><p>它是一个词袋模型，不考虑词与词之间的<strong>顺序</strong>（文本中词的顺序信息也是很重要的）；</p></li><li><p>它<strong>假设词与词相互独立</strong>（在大多数情况下，词与词是相互影响的）；</p></li><li><p>它得到的特征是<strong>离散稀疏</strong>的（这个问题最严重）。</p></li></ol><p><strong>与其他编码的差异：</strong></p><ul><li>决定状态机目前状态的时间成本低，因为读取一个正反器的时间成本固定。</li><li>改变机器的状态所需时间成本也是固定，因为每次只需要改变两个正反器的值。</li><li>设计及设计变更容易。</li><li>容易侦测出非法状态。</li><li>可以有效率地使用FPGA的大量正反器。</li><li>相较于其他编码，使用one-hot来实现状态机通常可以达到更高的时脉频率。</li><li>比起其他编码，需要更多的正反器，使得其在PAL装置上不切实际。</li><li>会有很多非法状态存在[7]。这是由于<spanclass="math inline">\({\displaystyleN}\)</span>个正反器构成的计数器总共有<spanclass="math inline">\({\displaystyle2^{N}}\)</span>个状态（每个正反器可以是0或1，所以总共<spanclass="math inline">\({\displaystyle2^{N}}\)</span>种可能状态），但是合法状态却只有<spanclass="math inline">\({\displaystyleN}\)</span>个（即同一时间只允许一个正反器是1,其他必须为0），所以总共会有<spanclass="math inline">\({\displaystyle2^{N}-N}\)</span>个可能的非法状态。</li></ul><h1 id="五应用">五、应用</h1><p><strong>自然语言处理</strong>在自然语言处理中，若有个字典或字库里有<spanclass="math inline">\({\displaystyleN}\)</span>个单字，则每个单字可以被一个<spanclass="math inline">\({\displaystyleN}\)</span>维的one-hot向量代表。譬如若字库里仅有apple（苹果），banana（香蕉），以及pineapple（凤梨）这三个单字，则他们各自的one-hot向量可以为：</p><p><span class="math display">\[{\displaystyle {\begin{array}{ll}apple&amp;=[1\ 0\ 0]\\banana&amp;=[0\1\ 0]\\pineapple&amp;=[0\ 0\ 1]\end{array}}}\]</span></p><p>由于电脑无法理解非数字类的数据，One-hot编码可以将类别性数据转换成统一的数字格式，方便机器学习的算法进行处理及计算。而转换成固定维度的向量则方便机器学习算法进行线性代数上的计算。另外由于一个one-hot向量中，绝大部分的数字都是0，所以若使用稀疏矩阵的数据结构，则可以节省电脑内存的使用量。</p><p><strong>有限状态机</strong>One-hot编码常常被用来表示一个有限状态机的状态。如果使用二进制或格雷码来代表状态，则需要用到解码器才能得知该码代表的状态。使用one-hot来代表状态的话，则不需要解码器，因为若第<spanclass="math inline">\({\displaystylen}\)</span>个位元为1，就代表机器目前在第<spanclass="math inline">\({\displaystyle n}\)</span>个状态。</p><p>一个有限状态机的例子是由15个状态构成的环状计数器。使用one-hot编码来实现此状态机的话，可以将15个正反器串联在一起，每个正反器的Q输出接到下一个正反器的D输入，而第一个正反器的D输入则是接到第15个的Q输出，形成一个环状。第一个正反器代表机器的第一个状态，第二个正反器代表第二个状态，依此类推。当机器被归零重设时，第一个正反器的值为1，其余为0。当一个时脉边缘抵达正反器时，会将1推进到下一个正反器。依照这种方式，1可一步步推进到第15个正反器，亦即第15个状态，再之后则重新回到第一个状态。</p><p>位址解码器可以将二进制或格雷码转换成one-shot表示形式。而优先编码器则是作用相反。</p><h1 id="六资料来源">六、资料来源</h1><ul><li>https://zh.wikipedia.org/wiki/One-hot</li><li>https://blog.csdn.net/google19890102/article/details/44039761</li><li>https://blog.csdn.net/qq_15192373/article/details/89552498</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络回归与分类（波士顿房价与红酒分类）</title>
    <link href="/2021/11/16/middle/"/>
    <url>/2021/11/16/middle/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>机器学习期中大作业，神经网络回归与分类</p><span id="more"></span><h1 id="一描述所使用的神经网络模型">一、描述所使用的神经网络模型</h1><h2 id="神经元模型">1.1 神经元模型</h2><h3 id="神经元模型的定义">1.1.1 神经元模型的定义</h3><p><strong>神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。神经网络中最基本的成分是神经元模型，即上述的“简单单元”。</strong></p><h3 id="m-p神经元模型">1.1.2 M-P神经元模型</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114180429830.png"alt="image-20211114180429830" /><figcaption aria-hidden="true">image-20211114180429830</figcaption></figure><p><strong>输入</strong>：来自其他n个神经元传递过来的输入信号</p><p><strong>处理</strong>：输入信号通过带权重的连接进行传递,神经元接受到总输入值将其与神经元的阈值进行比较</p><p><strong>输出</strong>：通过激活函数的处理以得到输出</p><h3 id="激活函数">1.1.3 激活函数</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114180032126.png"alt="image-20211114180032126" /><figcaption aria-hidden="true">image-20211114180032126</figcaption></figure><h4 id="激活函数的介绍">1.1.3.1 激活函数的介绍</h4><p><strong>如下图所示，神经网络中的每个神经元节点接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入层神经元节点会将输入属性值直接传递给下一层（隐层或输出层）。在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数（又称激励函数）。</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113213541281.png"alt="image-20211113213541281" /><figcaption aria-hidden="true">image-20211113213541281</figcaption></figure><h4 id="激活函数的用途">1.1.3.2 激活函数的用途</h4><p><strong>如果不用激励函数（相当于激励函数是f(x) =x），每一层节点的输入都是上层输出的线性函数，这样无论神经网络有多少层，输出都是输入的线性组合，这种情况就是最原始的感知机，网络的逼近能力就相当有限。当我们引入非线性函数作为激励函数，深层神经网络表达能力就更加强大，不再是输入的线性组合，几乎可以逼近任意函数。</strong></p><h4 id="一些常见的激活函数及其性质">1.1.3.3一些常见的激活函数及其性质</h4><h5 id="relu激活函数">1.1.3.3.1 Relu激活函数</h5><p><strong>Relu函数的解析式：</strong></p><p><span class="math display">\[f_{Relu}(x)=max(0,x)\]</span></p><p><strong>Relu函数及其导数的图像如下图所示：</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113213557078.png"alt="image-20211113213557078" /><figcaption aria-hidden="true">image-20211113213557078</figcaption></figure><p><strong>优点：</strong></p><p><strong>①计算效率较高</strong></p><p><strong>②兼具线性和非线性特性</strong></p><p><strong>缺点：</strong></p><p><strong>梯度消失问题：在x&lt;0时，神经元保持非激活状态，且在反向传导（backwardpass）中梯度为零</strong></p><h5 id="sigmoid激活函数">1.1.3.3.2 Sigmoid激活函数</h5><p><strong>Sigmoid 函数的解析式：</strong></p><p><span class="math display">\[f_{Sigmoid}(x)=\frac{1}{1+e^{-x}}\]</span></p><p><strong>Sigmoid函数及其导数的图像如下图所示：</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114180235544.png"alt="image-20211114180235544" /><figcaption aria-hidden="true">image-20211114180235544</figcaption></figure><p><strong>优点：</strong></p><p><strong>①梯度的“平滑性”</strong></p><p><strong>②输出在“0-1区间”</strong></p><p><strong>缺点：</strong></p><p><strong>①梯度消失问题：神经网络使用 Sigmoid激活函数进行反向传播时，输出接近0或1的神经元其梯度趋近于0 </strong></p><p><strong>②计算成本问题：涉及指数计算</strong></p><p><strong>③不以零为中心：Sigmoid 输出不以零为中心</strong></p><h5 id="tanh-激活函数">1.1.3.3.3 tanh 激活函数</h5><p><strong>tanh函数的解析式：</strong></p><p><span class="math display">\[f_{tanh}(x)=\frac{1-e^{-2x}}{1+e^{-2x}}\]</span></p><p><strong>tanh函数及其导数的图像如下图所示：</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113213650281.png"alt="image-20211113213650281" /><figcaption aria-hidden="true">image-20211113213650281</figcaption></figure><p><strong>优点：</strong></p><p><strong>①梯度的“平滑性”</strong></p><p><strong>②输出以零为中心</strong></p><p><strong>缺点：</strong></p><p><strong>①梯度消失问题：神经网络使用 tanh激活函数进行反向传播时，输出接近-1或1的神经元其梯度趋近于0</strong></p><p><strong>②计算成本问题：涉及指数计算</strong></p><h2 id="神经网络模型">1.2 神经网络模型</h2><h3 id="神经网络模型的定义">1.2.1 神经网络模型的定义</h3><p><strong>将若干神经元按一定的层次结构连接起来就得到了神经网络，可将神经网络视为包含了若干参数的数学模型，这个模型是由若干个函数相互（嵌套）代入而得。</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113213743041.png"alt="image-20211113213743041" /><figcaption aria-hidden="true">image-20211113213743041</figcaption></figure><h3 id="多层前馈神经网络">1.2.2 多层前馈神经网络</h3><h4 id="定义">1.2.2.1 定义</h4><p><strong>每层神经元与下一层神经元全互联，神经元之间不存在同层连接也不存在跨层连接。输入层接受外界输入，隐含层与输出层神经元对信号进行加工，最终结果由输出层神经元输出。根据训练数据来调整神经元之间的“连接权”以及每个功能神经元的“阈值”。</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113213753140.png"alt="image-20211113213753140" /><figcaption aria-hidden="true">image-20211113213753140</figcaption></figure><h4 id="模型训练">1.2.2.2 模型训练</h4><p><strong>数据</strong>：</p><p><span class="math display">\[D=\{(x_1,y_1),(x_2,y_2),……,(x_m,y_m)\},x_i∈R^d,y_i∈R^l\]</span></p><p><strong>模型</strong>：若干神经元按一定的层次结构连接起来，每层神经元与下一层神经元全互联，神经元之间不存在同层连接也不存在跨层连接，所形成的神经网络模型。</p><p><strong>策略</strong>：</p><p><strong>①平方损失（回归问题）</strong></p><p><span class="math display">\[L(y_i,f(x_i))=(y_i-f(x_i)^2),ERM\]</span></p><p>** ②交叉熵损失（二分类问题）**</p><hr /><p><span class="math display">\[L(y_i,f(x_i))=-y_ilog(p(y_i=1|x_i))-(1-y_i)log(p(y_i=0|x_i))\]</span></p><p><strong>算法</strong>：误差逆传播算法（error Back Propagation）</p><h1 id="二描述训练模型所使用的算法">二、描述训练模型所使用的算法</h1><h1 id="误差逆传播算法">2.1 误差逆传播算法</h1><h3 id="应用领域">2.1.1 应用领域</h3><p><strong>反向传播算法应用较为广泛，从字面意思理解，与前向传播相互对应。在简单的神经网络中，反向传播算法，可以理解为最优化损失函数过程，求解每个参与运算的参数的梯度的方法。在前馈神经网中，反向传播从求解损失函数偏导过程中，步步向前求解每一层的参数梯度。在卷积神经网络中，反向传播可以求解全连接层的参数梯度。在循环神经网络中，反向传播算法可以求解每一个时刻t或者状态t的参数梯度（在RNN，反向传播更多是BPTT）。如今对于BP的理解，认为是在优化损失函数或者目标函数过程中，求解参与运算的参数的梯度方法，是一种比较普遍的说法。</strong></p><h3 id="网络结构">2.1.2 网络结构</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113192037294.png"alt="image-20211113192037294" /><figcaption aria-hidden="true">image-20211113192037294</figcaption></figure><ol type="1"><li><strong>正向传播求损失，反向传播回传误差</strong></li><li><strong>根据误差信号修正每层的权重</strong></li><li><strong>f是激活函数；f(netj)是隐层的输出； f(netk）是输出层的输出O;d是target。</strong></li></ol><h3 id="基本参数结构">2.1.2 基本参数结构</h3><p><strong>为了方便讨论，我们以一个隐层的神经网络结构进行推导。多隐层的神经网络推导思想与此类似，可推广。如下图为一个神经网络结构。</strong></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211113192136112.png"alt="image-20211113192136112" /><figcaption aria-hidden="true">image-20211113192136112</figcaption></figure><h4 id="参数简述">2.1.2.1参数简述</h4><p><span class="math display">\[\begin{align}&amp;输入参数：x_1^k,\dots ,x_i^k,\dots,x_d^k\\&amp;输入层到第一隐层第h个神经元的权重：v_{1h},\dots,v_{ih},\dots,v_{dh}\\&amp;第一层第h个神经元输入：\alpha _{h}= \sum_{i=1}^{d}v_{ih}x_i^k\\&amp;第一隐层阙值：\gamma _{1},\dots,\gamma _{h},\dots,\gamma _{q}\\&amp;第一隐层第h个输出：b_h=f_{sigmoid}(\alpha _h-\gamma _h) \\&amp;第一隐层到第j个输出神经元的权重：w_{1j},\dots,w_{hj},\dots,w_{qj}\\&amp;第j个输出神经元的输入：\beta _j=\sum_{h=1}^{q}w_{hj}b_h\\&amp;输出层阙值：\theta _{1},\dots,\theta _{j},\dots,\theta_{l}\\&amp;输出值：y_j^k=f_{sigmoid}(\alpha _h-\gamma _h)\end{align}\]</span></p><p><strong>所以前向传播计算误差为：</strong></p><p><span class="math display">\[E_{k}=\frac{1}{2}\sum_{j=1}^{l}\left(y_{j}^{k}-\hat{y}_{j}^{k}\right)^{2}\]</span></p><h3 id="参数调整策略">2.1.3 参数调整策略</h3><p><strong>BP算法的核心思想：使用梯度下降来搜索可能的权向量的假设空间，以找到最佳的拟合样例的权向量。具体而言，即利用损失函数，每次向损失函数负梯度方向移动，直到损失函数取得最小值。或者说，反向传播算法，是根据损失函数，求出损失函数关于每一层的权值及偏置项的偏导数，也称为梯度，用该值更新初始的权值和偏置项，一直更新到损失函数取得最小值或是设置的迭代次数完成为止。以此来计算神经网络中的最佳的参数。</strong></p><p><span class="math display">\[损失函数：E_{k}=\frac{1}{2}\sum_{j=1}^{l}\left(y_{j}^{k}-\hat{y}_{j}^{k}\right)^{2}\]</span></p><h4 id="计算准备">2.1.3.1 计算准备</h4><p><span class="math display">\[\frac{\partial E_k}{\partial \hat{y_j^k} }=(y_j^k-\hat{y_j^k})(-1)\\f_{sigmoid}(x)^{(1)}=f_{sigmoid}(x)(1-f_{sigmoid}(x))\\\eta:学习率\]</span></p><p><strong>下面，我们讲分别讨论每个参数的更新：</strong></p><h4 id="w更新">2.1.3.2 <strong>w</strong>更新</h4><p><span class="math display">\[更新公式：w_{hj}=w_{hj}+\bigtriangleup w_{hj}\]</span></p><p>下面对<strong>w</strong>进行讨论:</p><p><span class="math display">\[\begin{align}\bigtriangleup w_{hj}=&amp;-\eta  \frac{\partial E_k}{\partial w_{hj}}\\=&amp;-\eta (\frac{\partial E_k}{\partial \hat{y_j^k}}\cdot\frac{\partial \hat{y_j^k}}{\partial \beta _j}  \cdot\frac{\partial \beta _j}{\partial w_{hj}}  )\\=&amp;-\eta (y_j^k-\hat{y_j^k})(-1)\cdot \hat{y_j^k}(1-\hat{y_j^k})\cdot b_h\\令g_j&amp;=(y_j^k-\hat{y_j^k})\cdot \hat{y_j^k} (1-\hat{y_j^k})\\\\最终可得&amp;\bigtriangleup w_{hj}=\eta g_jb_h\end{align}\]</span></p><h4 id="θ更新">2.1.3.3 <strong>θ</strong>更新</h4><p><span class="math display">\[更新公式：\theta_{j}=\theta_{j}+\bigtriangleup \theta_{j}\]</span></p><p><strong>下面对</strong>θ<strong>进行讨论：</strong></p><p><span class="math display">\[\begin{align}\bigtriangleup \theta_j=&amp;-\eta  \frac{\partial E_k}{\partial\theta_{j}}\\=&amp;-\eta  (\frac{\partial E_k}{\partial \hat{y_j^k}}\cdot\frac{\partial \hat{y_j^k}}{\partial \theta _j}    )\\=&amp;-\eta (y_j^k-\hat{y_j^k})(-1)\cdot \hat{y_j^k}(1-\hat{y_j^k})\cdot(-1)\\=&amp;-\eta g_j\end{align}\]</span></p><h4 id="v更新">2.1.3.4 <strong>v</strong>更新</h4><p><span class="math display">\[更新公式：v_{ih}=v_{ih}+\bigtriangleup v_{ih}\]</span></p><p><strong>下面对</strong>v<strong>进行讨论：</strong></p><p><span class="math display">\[\begin{align}\bigtriangleup v_{ih}=&amp;-\eta \frac{\partial E_k}{\partial v_{ih}}\\=&amp;-\eta\frac{\partial E_k}{\partial b_h}\cdot  \frac{\partialb_h}{\partial \alpha _h}\cdot  \frac{\partial \alpha _h}{\partialv_{ih}} \\=&amp;-\eta(\sum_{j=1}^{l}\frac{\partial E_k}{\partial \hat{y_j^k}}\cdot\frac{\partial \hat{y_j^k}}{\partial \beta _j}  \cdot\frac{\partial \beta _j}{\partial b_{h}})\cdot b_h(1-b_h)\cdot x_i^k\\=&amp;\eta \sum_{j=1}^{l}g_jw_{hj}b_h(1-b_h)x_i^k\end{align}\]</span></p><h4 id="γ更新">2.1.3.5γ更新</h4><p><span class="math display">\[更新公式：\gamma_{h}=\gamma_{h}+\bigtriangleup \gamma_{h}\]</span></p><p><strong>下面对</strong>γ<strong>进行讨论：</strong></p><p><span class="math display">\[\begin{align}\bigtriangleup \gamma_{h}=&amp;-\eta \frac{\partial E_k}{\partial\gamma_{h}}\\=&amp;-\eta\frac{\partial E_k}{\partial b_h}\cdot  \frac{\partialb_h}{\partial \gamma _h} \\=&amp;-\eta(\sum_{j=1}^{l}\frac{\partial E_k}{\partial \hat{y_j^k}}\cdot\frac{\partial \hat{y_j^k}}{\partial \beta _j}  \cdot\frac{\partial \beta _j}{\partial b_{h}})\cdot b_h(1-b_h)\cdot (-1)\\=&amp;\eta \sum_{j=1}^{l}g_jw_{hj}b_h(1-b_h)(-1)\end{align}\]</span></p><h3 id="算法伪代码">2.1.3 算法伪代码</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114180628211.png"alt="image-20211114180628211" /><figcaption aria-hidden="true">image-20211114180628211</figcaption></figure><h1id="三描述模型超参数确定的过程分析模型训练结果">三、描述模型超参数确定的过程，分析模型训练结果</h1><h2 id="超参数的概念">3.1 超参数的概念</h2><p>大部分机器学习算法都需要花费大量时间去训练，而在训练之前需要提前配置一些变量。这些变量对训练结果影响很大，但没有对任何数据集都适用的一组变量，需要根据具体应用具体配置，这些需要配置的变量称之为超参数（hyperparameters）。区分超参数和模型参数最大的一点就是是否通过数据来进行调整，模型参数通常是有数据来驱动调整，超参数则不需要数据来驱动，而是在训练前或者训练中人为的进行调整的参数。例如卷积核的具体核参数就是指模型参数，这是由数据驱动的。而学习率则是人为来进行调整的超参数。这里需要注意的是，通常情况下卷积核数量、卷积核尺寸这些也是超参数，注意与卷积核的核参数区分。</p><h2 id="神经网络包含的超参数">3.2 神经网络包含的超参数</h2><h3 id="超参数种类">3.2.1 超参数种类</h3><p>通常可以将超参数分为三类：网络参数、优化参数、正则化参数。</p><p>网络参数：可指网络层与层之间的交互方式（相加、相乘或者串接等）、卷积核数量和卷积核尺寸、网络层数（也称深度）和激活函数等。</p><p>优化参数：一般指学习率（learning rate）、批样本数量（batchsize）、不同优化器的参数以及部分损失函数的可调参数。</p><p>正则化：权重衰减系数，丢弃法比率（dropout）</p><p><strong>神经网络包含的超参数具体为以下十一个：</strong></p><ol type="1"><li><strong>学习率 η</strong></li><li><strong>正则化参数 λ</strong></li><li><strong>神经网络的层数 L</strong></li><li><strong>每一个隐层中神经元的个数 j</strong></li><li><strong>学习的回合数Epoch</strong></li><li><strong>小批量数据 minibatch 的大小</strong></li><li><strong>输出神经元的编码方式</strong></li><li><strong>代价函数的选择</strong></li><li><strong>权重初始化的方法</strong></li><li><strong>神经元激活函数的种类</strong></li><li><strong>参加训练模型数据的规模</strong></li></ol><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211112080119294.png"alt="image-20211112080119294" /><figcaption aria-hidden="true">image-20211112080119294</figcaption></figure><p>在上图中可以看到超参数 2，3，4， 7主要影响的时神经网络的分类正确率；9主要影响代价函数曲线下降速度，同时有时也会影响正确率；1，8，10主要影响学习速度，这点主要体现在训练数据代价函数曲线的下降速度上；5，6，11主要影响模型分类正确率和训练用总体时间。这上面所提到的时某个超参数对于神经网络想到的首要影响，并不代表着该超参数只影响学习速度或者正确率。</p><h3 id="超参数重要性顺序">3.2.2 超参数重要性顺序</h3><ul><li>首先，学习率，损失函数上的可调参数。在网络参数、优化参数、正则化参数中最重要的超参数可能就是学习率了。学习率直接控制着训练中网络梯度更新的量级，直接影响着模型的有效容限能力；损失函数上的可调参数，这些参数通常情况下需要结合实际的损失函数来调整，大部分情况下这些参数也能很直接的影响到模型的的有效容限能力。这些损失一般可分成三类，第一类辅助损失结合常见的损失函数，起到辅助优化特征表达的作用。例如度量学习中的Centerloss，通常结合交叉熵损失伴随一个权重完成一些特定的任务。这种情况下一般建议辅助损失值不高于或者不低于交叉熵损失值的两个数量级；第二类，多任务模型的多个损失函数，每个损失函数之间或独立或相关，用于各自任务，这种情况取决于任务之间本身的相关性，目前笔者并没有一个普适的经验由于提供参考；第三类，独立损失函数，这类损失通常会在特定的任务有显著性的效果。例如RetinaNet中的focalloss，其中的参数γ，α，对最终的效果会产生较大的影响。这类损失通常论文中会给出特定的建议值。</li><li>其次，批样本数量，动量优化器（Gradient Descent withMomentum）的动量参数β。批样本决定了数量梯度下降的方向。过小的批数量，极端情况下，例如batchsize为1，即每个样本都去修正一次梯度方向，样本之间的差异越大越难以收敛。若网络中存在批归一化（batchnorm），batchsize过小则更难以收敛，甚至垮掉。这是因为数据样本越少，统计量越不具有代表性，噪声也相应的增加。而过大的batchsize，会使得梯度方向基本稳定，容易陷入局部最优解，降低精度。一般参考范围会取在[1:1024]之间，当然这个不是绝对的，需要结合具体场景和样本情况；动量衰减参数β是计算梯度的指数加权平均数，并利用该值来更新参数，设置为0.9 是一个常见且效果不错的选择；</li><li>最后，Adam优化器的超参数、权重衰减系数、丢弃法比率（dropout）和网络参数。在这里说明下，这些参数重要性放在最后并不等价于这些参数不重要。而是表示这些参数在大部分实践中不建议过多尝试，例如Adam优化器中的β1，β2，ϵ，常设为0.9、0.999、10−8就会有不错的表现。权重衰减系数通常会有个建议值，例如0.0005，使用建议值即可，不必过多尝试。dropout通常会在全连接层之间使用防止过拟合，建议比率控制在[0.2,0.5]之间。使用dropout时需要特别注意两点：一、在RNN中，如果直接放在memorycell中,循环会放大噪声，扰乱学习。一般会建议放在输入和输出层；二、不建议dropout后直接跟上batchnorm，dropout很可能影响batchnorm计算统计量，导致方差偏移，这种情况下会使得推理阶段出现模型完全垮掉的极端情况；网络参数通常也属于超参数的范围内，通常情况下增加网络层数能增加模型的容限能力，但模型真正有效的容限能力还和样本数量和质量、层之间的关系等有关，所以一般情况下会选择先固定网络层数，调优到一定阶段或者有大量的硬件资源支持可以在网络深度上进行进一步调整。</li></ul><h2 id="模型超参数确定">3.3 模型超参数确定</h2><h3 id="超参数调优的原因">3.3.1 超参数调优的原因</h3><p>本质上，这是模型优化寻找最优解和正则项之间的关系。网络模型优化调整的目的是为了寻找到全局最优解（或者相比更好的局部最优解），而正则项又希望模型尽量拟合到最优。两者通常情况下，存在一定的对立，但两者的目标是一致的，即最小化期望风险。模型优化希望最小化经验风险，而容易陷入过拟合，正则项用来约束模型复杂度。所以如何平衡两者之间的关系，得到最优或者较优的解就是超参数调整优化的目的。</p><h3 id="模型超参数的确定">3.3.2 模型超参数的确定</h3><p><strong>四种主流超参数调优技术：</strong></p><ol type="1"><li><strong>传统或手动调参</strong></li><li><strong>网格搜索</strong></li><li><strong>随机搜索</strong></li><li><strong>贝叶斯搜索</strong></li></ol><p>在传统的调优中，我们通过手动检查随机超参数集来训练算法，并选择最适合我们目标的参数集。但这种方法不能保证得到最佳的参数组合，反复试验会消耗更多的时间。</p><h4 id="网格搜索">3.3.2.1 网格搜索</h4><ul><li>网格搜索是一种基本的超参数调整技术。它类似于手动调优，为网格中指定的所有给定超参数值的每个排列建立模型，并评估和选择最佳模型。由于它尝试每一种超参数组合，并根据交叉验证分数选择最佳组合，这使得GridsearchCV 极其缓慢。</li><li>这种启发式的搜索算法对超参数搜索算法，被称之为网格搜索。(如果人工处理所有可能的超参数组合，通常的办法是，根据超参数的维度，列成相应的表格，比如说k的取值有[2，3，4，5，6，7，8]，另一个系数比如λ取值有[0.01,0.03,0.1,0.3]等，这样就可以列出一个二维表格，组合出7*4种可能性的超参数组合，再对每一个格子中具体的超参数组合，通过交叉验证的方式进行模型性能的评估，然后通过验证性能的比较，最终筛选出最佳的超参数数据组合)</li><li>网格搜索采用交叉验证的方法，来寻找更好的超参数组合的过程非常耗时，由于各个新模型在执行交叉验证的过程中是相互独立的，那么我们可以充分利用多核处理器甚至是分布式的计算资源来从事并行搜索，从而成倍的节省运算时间。<imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/482493cc74974f85ba09b50697801c27.jpeg"alt="img" /></li></ul><h4 id="随机搜索">3.3.2.2 随机搜索</h4><p>使用随机搜索代替网格搜索的动机是，在许多情况下，所有的超参数可能并非同等重要。随机搜索从超参数空间中随机选择参数组合，参数按n_iter给定的迭代次数进行选择。随机搜索已经被实践证明比网格搜索得到的结果更好，但随机搜索的问题是它不能保证给出最佳的参数组合。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114180715729.png"alt="image-20211114180715729" /><figcaption aria-hidden="true">image-20211114180715729</figcaption></figure><h4 id="贝叶斯优化">3.3.2.3 贝叶斯优化</h4><p>贝叶斯优化属于一类被称为<strong><em>sequential model-basedoptimization</em>(SMBO)</strong>的优化算法。这些算法使用先前对损失 f的观测，来确定下一个(最佳)点来取样 f。该算法大致可以概括如下：</p><ol type="1"><li><strong>使用先前计算过的点 X1: n，计算损失 f的后验期望值。</strong></li><li><strong>在一个新的点 Xnew取样损失 f ，它最大化了 f的期望的某些效用函数。该函数指定 f域的哪些区域是最适合采样的。</strong></li></ol><p>重复这些步骤，直到达到某种收敛准则。</p><h5 id="高斯过程">3.3.2.3.1 高斯过程</h5><p>在贝叶斯调参过程中，假设一组超参数组合是X=x1,x2,...,xn(xn表示某一个超参数的值)，而这组超参数与最后我们需要优化的损失函数存在一个函数关系，最终的评估结果为Y，通过什么样的X可以取得最优的Y，我们假设是f(X)，Y=F(X)</p><p>而目前机器学习其实是一个黑盒子(blackbox),即我们只知道input和output，所以上面的函数f(x)很难确定。所以我们需要将注意力转移到一个我们可以解决的函数上去。</p><p>于是可以假设这个寻找最优化参数的过程是一个高斯过程。高斯过程有个特点，就是当随机遍历一定的数据点并拿到结果之后，可以大致绘制出整个数据的分布曲线。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/998084-20180726204924171-1721363009.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h5 id="贝叶斯优化理论">3.3.2.3.2 贝叶斯优化理论</h5><p>还是这张图，把横轴看作是参数组合X，纵轴看作是这个参数的结果Y。可以通过已经构建的曲线，找到曲线上升的方向，从而在这个方向上继续探索，这样就可以大概率拿到更好的结果。在生活的轨迹上，如果找到一条明确通往幸福的路，可以继续向前探索，因为大概率可以成功，但也许也有会错过更好的机会，陷入局部最优解。请看上图中的五角星，如果我们处于它的位置，继续向上走会迎来一个高峰，但是如果后退，在下降一段时间之后可能会迎来更高的波峰，你该如何选择。</p><p>于是，在参数的探索中要掌握一个平衡：</p><p>开发：在明确的曲线上扬方向继续走，大概率获得更好的结果，但是容易陷入局部最优。</p><p>探索：除了在曲线上扬的方向，在其它的区域也不忘寻找</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114102651780.png"alt="image-20211114102651780" /><figcaption aria-hidden="true">image-20211114102651780</figcaption></figure><h2 id="结果分析">3.4 结果分析</h2><h3 id="mape">3.4.1 MAPE</h3><p><strong>平均绝对百分比误差（Mean Absolute PercentageError）</strong></p><p><span class="math display">\[M A P E=\frac{100 \%}{n}\sum_{i=1}^{n}\left|\frac{\hat{y}_{i}-y_{i}}{y_{i}}\right|\]</span></p><p>范围[0,+∞)，MAPE 为0%表示完美模型，MAPE 大于 100%则表示劣质模型。</p><p>注意：当真实值有数据等于0时，存在分母0除问题，该公式不可用！</p><h3 id="调参前结果及分析">3.4.2 调参前结果及分析</h3><h4 id="代码">3.4.2.1 代码</h4><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">mlp &#x3D; MLPRegressor(hidden_layer_sizes&#x3D;(100), activation&#x3D;&#39;relu&#39;, solver&#x3D;&#39;adam&#39;, alpha&#x3D;0.0001, batch_size&#x3D;&#39;auto&#39;, learning_rate&#x3D;&#39;constant&#39;, learning_rate_init&#x3D;0.001, power_t&#x3D;0.5, max_iter&#x3D;200, shuffle&#x3D;True, random_state&#x3D;None, tol&#x3D;0.0001, verbose&#x3D;False, warm_start&#x3D;False, momentum&#x3D;0.9, nesterovs_momentum&#x3D;True, early_stopping&#x3D;False, validation_fraction&#x3D;0.1, beta_1&#x3D;0.9, beta_2&#x3D;0.999, epsilon&#x3D;1e-08, n_iter_no_change&#x3D;10, max_fun&#x3D;15000) #所有参数默认mlp.fit(X_std, Y)MAPE &#x3D; -1*cross_val_score(mlp, X_std, Y, cv&#x3D;rkf,scoring&#x3D;&#39;neg_mean_absolute_percentage_error&#39;).mean()print(&#39;MAPE:&#39;,MAPE)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><h4 id="结果及分析">3.4.2.2 结果及分析</h4><p>首先我们使用<ahref="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neural_network"><code>sklearn.neural_network</code></a>.<ahref="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html?highlight=mlp#sklearn.neural_network.MLPRegressor">MLPRegressor</a>中的所有默认参数设置来训练模型，五次五折交叉验证的平均MAPE为：0.2036462204885882</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114171851292.png"alt="image-20211114171851292" /><figcaption aria-hidden="true">image-20211114171851292</figcaption></figure><p>Fig.1 调参前残差图</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114171902074.png"alt="image-20211114171902074" /><figcaption aria-hidden="true">image-20211114171902074</figcaption></figure><p>Fig.2 调参前预测误差图</p><p>残差是因变量未被自变量解释的部分，线性模型要求残差服从独立同分布，且分布类型为正态分布。通过一系列方法判断残差是否符合这一要求，可以达到检验模型是否符合相应假设的目的。从上图可以看出，我们的训练集和测试集的R<sup>2</sup>在0.75左右，说明我们的模型训练结果具有一定的可信度，但并不理想。下面我们进行调参，尝试提高准确率。</p><h3 id="网格搜索调参">3.4.3 网格搜索调参</h3><p>接下来我们手动调试模型，将各个超参数逐一修改并查看MAPE的变化结果，最终得出'<strong>hidden_layer_sizes</strong>'，'<strong>activation</strong>'，'<strong>solver</strong>'，'<strong>alpha</strong>'，'<strong>learning_rate</strong>'</p><p>这五个对结果影响较大的参数。</p><p>最后我们利用GridSearchCV结合一些“经验结论”来搜索出最优的超参数。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114222524771.png"alt="image-20211114222524771" /><figcaption aria-hidden="true">image-20211114222524771</figcaption></figure><h4 id="代码-1">3.4.3.1 代码</h4><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none"># 超参数调优from sklearn.model_selection import GridSearchCVparameters &#x3D; &#123;&#39;hidden_layer_sizes&#39;: [(10,10,10,10,10),(20,20,20,20,20),(30,30,30,30,30),(40,40,40,40,40),(50,50,50,50,50),(60,60,60,60,60),(70,70,70,70,70),(80,80,80,80,80),(90,90,90,90,90),(100,100,100,100,100)],                &#39;activation&#39;: [&#39;identity&#39;, &#39;logistic&#39;,&#39;tanh&#39;, &#39;relu&#39;],                &#39;solver&#39;: [&#39;adam&#39;,&#39;lbgfs&#39;,&#39;sgd&#39;],                &#39;alpha&#39;: [0.0001, 0.001, 0.01, 0.1, 1,10,100],                &#39;learning_rate&#39;: [&#39;constant&#39;, &#39;invscaling&#39;, &#39;adaptive&#39;]&#125;grid &#x3D; GridSearchCV(mlp, parameters, cv&#x3D;rkf, scoring&#x3D;&#39;neg_mean_absolute_percentage_error&#39;,n_jobs&#x3D;-1)grid.fit(X_std, Y)print(&#39;最优参数：&#39;,grid.best_params_)print(&#39;最优模型得分：&#39;,grid.best_score_)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h4 id="结果及分析-1">3.4.3.2 结果及分析</h4><ul><li><strong>最优参数： {'activation': 'relu', 'alpha': 1,'hidden_layer_sizes': (100, 100, 100, 100, 100), 'learning_rate':'adaptive', 'solver': 'sgd'} </strong></li><li><strong>最优模型得分： 0.10669120458358475</strong></li></ul><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114221915446.png"alt="image-20211114221915446" /><figcaption aria-hidden="true">image-20211114221915446</figcaption></figure><p>Fig.3 调参后残差图</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211114221934910.png"alt="image-20211114221934910" /><figcaption aria-hidden="true">image-20211114221934910</figcaption></figure><p>Fig.4 调参后预测误差图</p><p>经过网格搜索最优参数后，我们的模型得到大幅度提升。从上可见，我们的训练和测试的R<sup>2</sup>均在0.98以上，说明模型对训练集的拟合效果和泛化能力都很强。</p><h1 id="四总结模型训练过程中的收获">四、总结模型训练过程中的收获</h1><h2 id="神经网络的训练过程">4.1 神经网络的训练过程</h2><p>简单的神经网络的训练过程包括以下几个步骤：</p><ol type="1"><li><strong>定义一个包含多个可学习参数（权重）的神经网络；</strong></li><li><strong>对输入的数据集进行迭代计算；</strong></li><li><strong>通过多层网络结构来处理输入数据；</strong></li><li><strong>计算损失值（输出值与目标值的差值）；</strong></li><li><strong>反向传播梯度到神经网络的参数中；</strong></li><li><strong>根据更新规则来更新网络中的权重值。</strong></li></ol><h2 id="确定超参数">4.2 确定超参数</h2><p>其中，如何定义一个包含多个可学习参数的神经网络（即如何确定模型的超参数）是重点，会影响神经网络学习速度和最后结果。我们确定超参数的步骤如下：</p><p>①我们根据经验结论手动调试模型，将各个超参数逐一修改并查看MAPE的变化结果，最终得出'<strong>hidden_layer_sizes</strong>'，'<strong>activation</strong>'，'<strong>solver</strong>'，'<strong>alpha</strong>'，</p><p>'<strong>learning_rate</strong>'这五个对结果影响较大的参数。</p><p>②搜集“经验总结”的资料后，我们用网格搜索法对下列超参数进行排列组合，得到10*****4*****3*****7*****3=2520种超参数的排列组合方式。</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">parameters &#x3D; &#123;&#39;hidden_layer_sizes&#39;: [(10,10,10,10,10),(20,20,20,20,20),(30,30,30,30,30),(40,40,40,40,40),(50,50,50,50,50),(60,60,60,60,60),(70,70,70,70,70),(80,80,80,80,80),(90,90,90,90,90),(100,100,100,100,100)],                &#39;activation&#39;: [&#39;identity&#39;, &#39;logistic&#39;,&#39;tanh&#39;, &#39;relu&#39;],                &#39;solver&#39;: [&#39;adam&#39;,&#39;lbgfs&#39;,&#39;sgd&#39;],                &#39;alpha&#39;: [0.0001, 0.001, 0.01, 0.1, 1,10,100],                &#39;learning_rate&#39;: [&#39;constant&#39;, &#39;invscaling&#39;, &#39;adaptive&#39;]&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>③使用五次五折将数据划分为25份，把上述2520种超参数的组合都跑一遍数据（计算神经网络中的最佳的参数用的是误差逆传播算法），每一个组合都会得到25个MAPE值，取平均；之后2520份MAPE中的最小值对应的超参数组合即为我们选定的最优超参数组合。</p><h2 id="防止过拟合的方法">4.3 防止过拟合的方法</h2><p>在机器学习模型（特别是深度学习模型）的训练过程中，模型是非常容易过拟合的。深度学习模型在不断的训练过程中训练误差会逐渐降低，但测试误差的走势则不一定。</p><p>①正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则。</p><p>②数据增强（Dataaugmentation），增大数据的训练量；还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。</p><p>③重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。</p><p>④提前终止法（Earlystopping），对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradientdescent）学习算法。提前终止法便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。</p><p>⑤丢弃法（Dropout）。这个方法在神经网络里面很常用。丢弃法是ImageNet中提出的一种方法，通俗一点讲就是丢弃法在训练的时候让神经元以一定的概率不工作。</p><p>以下内容出自<strong>复旦大学邱锡鹏教授著作</strong>《神经网络与深度学习》</p><h1 id="一描述所使用的神经网络模型-1">一、描述所使用的神经网络模型</h1><h2 id="人脑神经网络">1.1 人脑神经网络</h2><p>人类大脑是人体最复杂的器官，由神经元、神经胶质细胞、神经干细胞和血管组成．其中，神经元（Neuron），也叫神经细胞（NerveCell），是携带和传输信息的细胞，是人脑神经系统中最基本的单元．人脑神经系统是一个非常复杂的组织，包含近860亿个神经元，每个神经元有上千个突触和其他神经元相连接．这些神经元和它们之间的连接形成巨大的复杂网络，其中神经连接的总长度可达数千公里．我们人造的复杂网络，比如全球的计算机网络，和大脑神经网络相比要“简单”得多．</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119093130413.png"alt="image-20211119093130413" /><figcaption aria-hidden="true">image-20211119093130413</figcaption></figure><h2 id="人工神经网络">1.2 人工神经网络</h2><p>人工神经网络是为模拟人脑神经网络而设计的一种计算模型，它从结构、实现机理和功能上模拟人脑神经网络．人工神经网络与生物神经元类似， 由多个节点（ 人工神经元） 互相连接而成，可以用来对数据之间的复杂关系进行建模．不同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小．每个节点代表一种特定函数， 来自其他节点的信息经过其相应的权重综合计算，输入到一个激活函数中并得到一个新的活性值（ 兴奋或抑制）．从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统．虽然我们可以比较容易地构造一个人工神经网络，但是如何让人工神经网络具有学习能力并不是一件容易的事情．早期的神经网络模型并不具备学习能力．首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督学习方法．感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上． 直到 1980 年左右，反向传播算法才有效地解决了多层神 经网络的学习问题，并成为最为流行的神经网络学习算法．</p><p>人工神经网络诞生之初并不是用来解决机器学习问题．由于人工神经网络可以用作一个通用的函数逼近器（一个两层的神经网络可以逼近任意的函数），因此我们可以将人工神经网络看作一个可学习的函数，并将其应用到机器学习中． 理论上， 只要有足够的训练数据和神经元数量，人工神经网络就可以学到很多复杂的函数．我们可以把一个人工神经网络塑造复杂函数的能力称为网络容量（ NetworkCapacity）， 这与可以被储存在网络中的信息的复杂度以及数量相关．</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119094549829.png"alt="image-20211119094549829" /><figcaption aria-hidden="true">image-20211119094549829</figcaption></figure><h2 id="前馈神经网络">1.3 前馈神经网络</h2><p>在本次作业中， 我们主要采用误差反向传播来进行学习的神经网络，即作为一种机器学习模型的神经网络．从机器学习的角度来看，神经网络一般可以看作一个非线性模型，其基本组成单元为具有非线性激活函数的神经元， 通过大量神经元之间的连接，使得神经网络成为一种高度非线性的模型．神经元之间的连接权重就是需要学习的参数，可以在机器学习的框架下通过梯度下降方法来进行学习．</p><h3 id="神经元">1.3.1 神经元</h3><p>1943 年， 心理学家 McCulloch 和数学家 Pitts 根据生物神经元的结构，提出了一种非常简单的神经元模型， MP神经元． 现代神经网络中的神经元和 MP神经元的结构并无太多变化． 不同的是， MP 神经元中的激活函数𝑓为0或1的阶跃函数，而现代神经元中的激活函数通常要求是连续可导的函数．</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119205516708.png"alt="image-20211119205516708" /><figcaption aria-hidden="true">image-20211119205516708</figcaption></figure><p>净输入 <strong>z</strong> 在经过一个非线性函数 $f() $ 后,得到神经元的活性值 ( Activation ) <strong>a</strong> ,</p><p><span class="math display">\[a=f(z)\]</span></p><p>其中非线性函数 $f() $ 称为激活函数 ( Activation Function ).</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119100021496.png"alt="image-20211119100021496" /><figcaption aria-hidden="true">image-20211119100021496</figcaption></figure><h3 id="激活函数-1">1.3.2 激活函数</h3><ol type="1"><li>激活函数在神经元中非常重要的。为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质:连续并可导(允许少数点上不可导)的非线性函数.可导的激活函数可以直接利用数值优化的方法来学习网络参数.</li><li>激活函数及其导函数要尽可能的简单,有利于提高网络计算效率.</li><li>激活函数的导函数的值域要在一个合适的区间内,不能太大也不能太小,否则会影响训练的效率和稳定性.</li></ol><p>下面介绍几种在神经网络中常用的激活函数.</p><h4 id="sigmoid型函数">1.3.2.1 Sigmoid型函数</h4><p>Sigmoid型函数是指一类S型曲线函数,为两端饱和函数.常用的Sigmoid型函数有Logistic函数和Tanh 函数.</p><h5 id="logistic">1.3.2.1.1 Logistic</h5><p>Logistic 函数定义为</p><p><span class="math display">\[\sigma(x)=\frac{1}{1+\exp (-x)}\]</span></p><p>Logistic 函数可以看成是一个“挤压” 函数， 把一个实数域的输入“挤压”到(0, 1)． 当输入值在0附近时， Sigmoid型函数近似为线性函数；当输入值靠近两端时， 对输入进行抑制． 输入越小， 越接近于 0； 输入越大，越接近于 1． 这样的特点也和生物神经元类似， 对一些输入会产生兴奋（输出为1）， 对另一些输入产生抑制（ 输出为0）．和感知器使用的阶跃激活函数相比，Logistic函数是连续可导的，其数学性质更好．因为Logistic函数的性质，使得装备了Logistic激活函数的神经元具有以下两点性质：</p><ol type="1"><li>其输出直接可以看作概率分布，使得神经网络可以更好地和统计学习模型进行结合．</li><li>其可以看作一个软性门（ Soft Gate），用来控制其他神经元输出信息的数量.</li></ol><h5 id="tanh">1.3.2.1.2 Tanh</h5><p>Tanh 函数也是一种 Sigmoid 型函数. 其定义为</p><p><span class="math display">\[\tanh (x)=\frac{\exp (x)-\exp (-x)}{\exp (x)+\exp (-x)}\]</span></p><p>Tanh 函数可以看作放大并平移的 Logistic 函数, 其值域是 (-1,1) .</p><p><span class="math display">\[\tanh (x)=2 \sigma(2 x)-1\]</span></p><p>下图给出了 Logistic 函数和 Tanh 函数的形状． Tanh函数的输出是零中心化的（ Zero-Centered）， 而 Logistic 函数的输出恒大于0． 非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（ BiasShift）， 并进一步使得梯度下降的收敛速度变慢 .</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119100752525.png"alt="image-20211119100752525" /><figcaption aria-hidden="true">image-20211119100752525</figcaption></figure><p>Logistic函数和Tanh函数都是Sigmoid型函数， 具有饱和性，但是计算开销较大． 因为这两个函数都是在中间（ 0附近） 近似线性，两端饱和． 因此， 这两个函数可以通过分段函数来近似．</p><p>以 Logistic 函数 $ (x) $ 为例, 其导数为 $^{}(x)=(x)(1-(x)) $.Logistic 函数 在 0 附近的一阶泰勒展开 ( Taylor expansion ) 为</p><p><span class="math display">\[\begin{aligned}g_{l}(x) &amp; \approx \sigma(0)+x \times \sigma^{\prime}(0) \\&amp;=0.25 x+0.5\end{aligned}\]</span></p><p>这样 Logistic 函数可以用分段函数 hard-logistic (x) 来近似.</p><p><span class="math display">\[\begin{aligned}\operatorname{hard}-\operatorname{logistic}(x)&amp;=\left\{\begin{array}{ll}1 &amp; g_{l}(x) \geq 1 \\g_{l} &amp; 0&lt;g_{l}(x)&lt;1 \\0 &amp; g_{l}(x) \leq 0\end{array}\right.\\&amp;=\max \left(\min \left(g_{l}(x), 1\right), 0\right) \\&amp;=\max (\min (0.25 x+0.5,1), 0)\end{aligned}\]</span></p><p>同样, Tanh 函数在 0 附近的一阶泰勒展开为</p><p><span class="math display">\[\begin{aligned}g_{t}(x) &amp; \approx \tanh (0)+x \times \tanh ^{\prime}(0) \\&amp;=x\end{aligned}\]</span></p><p>这样 $ $ 函数也可以用分段函数$ -(x) $来近似.</p><p><span class="math display">\[\begin{aligned}\operatorname{hard}-\tanh (x) &amp;=\max \left(\min \left(g_{t}(x),1\right),-1\right) \\&amp;=\max (\min (x, 1),-1)\end{aligned}\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119101318245.png"alt="image-20211119101318245" /><figcaption aria-hidden="true">image-20211119101318245</figcaption></figure><h4 id="relu函数">1.3.2.2 ReLU函数</h4><p>ReLU（ Rectified Linear Unit， 修正线性单元） [Nair et al., 2010]，也叫Rectifier函数[Glorot et al., 2011]，是目前深度神经网络中经常使用的激活函数．ReLU实际上是一个斜坡（ ramp）函数， 定义为</p><p><span class="math display">\[\begin{aligned}\operatorname{ReLU}(x) &amp;=\left\{\begin{array}{ll}x &amp; x \geq 0 \\0 &amp; x&lt;0\end{array}\right.\\&amp;=\max (0, x)\end{aligned}\]</span></p><p><strong>优点</strong> 采用 ReLU 的神经元只需要进行加、乘和比较的操作， 计算上更加高效．ReLU 函数也被认为具有生物学合理性（Biological Plausibility）， 比如单侧抑制、宽兴奋边界（即兴奋程度可以非常高）． 在生物神经网络中，同时处于兴奋状态的神经元非常稀疏． 人脑中在同一时刻大概只有 1% ∼ 4%的神经元处于活跃状态． Sigmoid 型激活函数会导致一个非稀疏的神经网络， 而ReLU 却具有很好的稀疏性， 大约50%的神经元会处于激活状态． 在优化方面，相比于Sigmoid型函数的两端饱和， ReLU函数为左饱和函数，且在 𝑥 &gt; 0时导数为 1， 在一定程度上缓解了神经网络的梯度消失问题，加速梯度下降的收敛速度．</p><p><strong>缺点</strong> ReLU 函数的输出是非零中心化的，给后一层的神经网络引入偏置偏移，会影响梯度下降的效率．此外， ReLU神经元在训练时比较容易“死亡”． 在训练时， 如果参数在一次不恰当的更新后，第一个隐藏层中的某个 ReLU 神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是0，在以后的训练过程中永远不能被激活． 这种现象称为死亡 ReLU 问题（ DyingReLU Problem ),并且也有可能会发生在其他隐藏层.</p><p>在实际使用中,为了避免上述情况,有几种 ReLU的变种也会被广泛使用.</p><h5 id="带泄露的relu">1.3.2.2.1 带泄露的ReLU</h5><p>带泄露的ReLU（ Leaky ReLU） 在输入 𝑥 &lt; 0时， 保持一个很小的梯度𝛾．这样当神经元非激活时也能有一个非零的梯度可以更新参数，避免永远不能被激活[Maas et al., 2013]． 带泄露的ReLU的定义如下：</p><p><span class="math display">\[\begin{aligned}\operatorname{LeakyReLU}(x) &amp;=\left\{\begin{array}{ll}x &amp; \text { if } x&gt;0 \\\gamma x &amp; \text { if } x \leq 0\end{array}\right.\\&amp;=\max (0, x)+\gamma \min (0, x)\end{aligned}\]</span></p><p>其中 𝛾是一个很小的常数， 比如0.01． 当𝛾 &lt; 1时，带泄露的ReLU也可以写为</p><p><span class="math display">\[\operatorname{LeakyReLU}(x)=\max (x, \gamma x)\]</span></p><p>相当于是一个比较简单的maxout单元 .</p><h5 id="带参数的relu">1.3.2.2.2 带参数的ReLU</h5><p>带参数的 ReLU（ Parametric ReLU， PReLU） 引入一个可学习的参数，不同神经元可以有不同的参数． 对于第 𝑖 个神经元， 其 PReLU 的定义为</p><p><span class="math display">\[\begin{aligned}\operatorname{PReLU}_{i}(x) &amp;=\left\{\begin{array}{ll}x &amp; \text { if } x&gt;0 \\\gamma_{i} x &amp; \text { if } x \leq 0\end{array}\right.\\&amp;=\max (0, x)+\gamma_{i} \min (0, x)\end{aligned}\]</span></p><p>其中 𝛾𝑖 为 𝑥 ≤ 0 时函数的斜率． 因此， PReLU 是非饱和函数． 如果 𝛾𝑖 =0， 那么PReLU就退化为ReLU． 如果𝛾𝑖 为一个很小的常数，则PReLU可以看作带泄露的ReLU． PReLU 可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数．</p><h5 id="elu函数">1.3.2.2.3 ELU函数</h5><p>ELU（ Exponential Linear Unit，指数线性单元）是一个近似的零中心化的非线性函数， 其定义为</p><p><span class="math display">\[\begin{aligned}\operatorname{ELU}(x) &amp;=\left\{\begin{array}{ll}x &amp; \text { if } x&gt;0 \\\gamma(\exp (x)-1) &amp; \text { if } x \leq 0\end{array}\right.\\&amp;=\max (0, x)+\min (0, \gamma(\exp (x)-1))\end{aligned}\]</span></p><p>其中 𝛾 ≥ 0是一个超参数， 决定𝑥 ≤ 0时的饱和曲线，并调整输出均值在0附近．</p><h5 id="softplus函数">1.3.2.2.4 Softplus函数</h5><p>Softplus 函数 可以看作 Rectifier 函数的平滑版本， 其定义为</p><p><span class="math display">\[\operatorname{Softplus}(x)=\log (1+\exp (x))\]</span></p><p>Softplus函数其导数刚好是Logistic函数．Softplus函数虽然也具有单侧抑制、宽兴奋边界的特性， 却没有稀疏激活性.</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119103024771.png"alt="image-20211119103024771" /><figcaption aria-hidden="true">image-20211119103024771</figcaption></figure><h3 id="多层前馈神经网络模型">1.3.3 多层前馈神经网络模型</h3><p>给定一组神经元， 我们可以将神经元作为节点来构建一个网络．不同的神经网络模型有着不同网络连接的拓扑结构．一种比较直接的拓扑结构是前馈网络． 前馈神经网络（ Feedforward NeuralNetwork， FNN） 是最早发明的简单人工神经网络．前馈神经网络也经常称为多层感知器（ Multi-Layer PerceptronMLP）．但多层感知器的叫法并不是十分合理， 因为前馈神经网络其实是由多层的Logistic 回归模型（ 连续的非线性函数） 组成， 而不是由多层的感知器（不连续的非线性函数） 组成 .</p><p>前馈神经网络中， 各神经元分别属于不同的层．每一层的神经元可以接收前一层神经元的信号， 并产生信号输出到下一层．第0层称为输入层， 最后一层称为输出层， 其他中间层称为隐藏层．整个网络中无反馈， 信号从输入层向输出层单向传播， 可用一个有向无环图表示.</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119103824459.png"alt="image-20211119103824459" /><figcaption aria-hidden="true">image-20211119103824459</figcaption></figure><p>对于本次作业中的多分类问题 $ y {1, , C} $, 使用 Softmax 回归分类器,相当于网络 最后一层设置 C 个神经元, 其激活函数为 Softmax 函数.网络最后一层 (第 L 层) 的输出可以作为每个类的条件概率, 即</p><p><span class="math display">\[\hat{\boldsymbol{y}}=\operatorname{softmax}\left(\boldsymbol{z}^{(L)}\right)\]</span></p><p>其中 $^{(L)} ^{C} $为第 L 层神经元的净输入; $ ^{C} $为第 L层神经元的活性值, 每 一维分别表示不同类别标签的预测条件概率.</p><p>故采用交叉熵损失函数, 对于样本 $ (, y) $, 其损失函数为</p><p><span class="math display">\[\mathcal{L}(\boldsymbol{y}, \hat{\boldsymbol{y}})=-\boldsymbol{y}^{\top}\log \hat{\boldsymbol{y}},\]</span></p><p>其中 $ {0,1}^{C} $为标签 y 对应的 one-hot 向量表示. <imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119205657015.png"alt="image-20211119205657015" /></p><p><span class="math display">\[\|\boldsymbol{W}\|_{F}^{2}=\sum_{l=1}^{L} \sum_{i=1}^{M_{l}}\sum_{j=1}^{M_{l-1}}\left(w_{i j}^{(l)}\right)^{2}\]</span></p><p>有了学习准则和训练样本, 网络参数可以通过梯度下降法来进行学习.在梯度下降方法的每次迭代中,第 l 层的参数 $^{(l)} $ 和 $^{(l)}$参数更新方式为</p><p><span class="math display">\[\begin{aligned}\boldsymbol{W}^{(l)} &amp; \leftarrow \boldsymbol{W}^{(l)}-\alpha\frac{\partial \mathcal{R}(\boldsymbol{W}, \boldsymbol{b})}{\partial\boldsymbol{W}^{(l)}} \\&amp;=\boldsymbol{W}^{(l)}-\alpha\left(\frac{1}{N}\sum_{n=1}^{N}\left(\frac{\partial\mathcal{L}\left(\boldsymbol{y}^{(n)},\hat{\boldsymbol{y}}^{(n)}\right)}{\partial\boldsymbol{W}^{(l)}}\right)+\lambda \boldsymbol{W}^{(l)}\right) \\\boldsymbol{b}^{(l)} &amp; \leftarrow \boldsymbol{b}^{(l)}-\alpha\frac{\partial \mathcal{R}(\boldsymbol{W}, \boldsymbol{b})}{\partial\boldsymbol{b}^{(l)}} \\&amp;=\boldsymbol{b}^{(l)}-\alpha\left(\frac{1}{N} \sum_{n=1}^{N}\frac{\partial \mathcal{L}\left(\boldsymbol{y}^{(n)},\hat{\boldsymbol{y}}^{(n)}\right)}{\partial \boldsymbol{b}^{(l)}}\right)\end{aligned}\]</span></p><p>其中 $$ 为学习率.</p><p>梯度下降法需要计算损失函数对参数的偏导数,如果通过链式法则逐一对每个参数进行求偏导比较低效.在神经网络的训练中经常使用<strong>反向传播算法</strong>来高效地计算梯度.</p><h1 id="二描述训练模型所使用的算法-1">二、描述训练模型所使用的算法</h1><p>假设采用随机梯度下降进行神经网络参数学习, 给定一个样本$ (, )$ ,将其输入到神经网络模型中, 得到网络输出为 $ <span class="math inline">\(.假设损失函数为\)</span> (, ) $,要进行参数学习就需要计算损失函数关于每个参数的导数.</p><p>不失一般性, 对第 l 层中的参数$ ^{(l)} $和 $ ^{(l)} <spanclass="math inline">\(计算偏导数. 因为\)</span> <spanclass="math inline">\(的计算 涉及向量对矩阵的微分, 十分繁琐,因此我们先计算\)</span> (, ) $关于参数矩阵中每个元素的偏导数 $ $.根据链式法则,</p><p><span class="math display">\[\begin{array}{l}\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial w_{i j}^{(l)}}=\frac{\partial\boldsymbol{z}^{(l)}}{\partial w_{i j}^{(l)}} \frac{\partial\mathcal{L}(\boldsymbol{y}, \hat{\boldsymbol{y}})}{\partial\boldsymbol{z}^{(l)}} \\\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial \boldsymbol{b}^{(l)}}=\frac{\partial\boldsymbol{z}^{(l)}}{\partial \boldsymbol{b}^{(l)}} \frac{\partial\mathcal{L}(\boldsymbol{y}, \hat{\boldsymbol{y}})}{\partial\boldsymbol{z}^{(l)}}\end{array}\]</span></p><p>以上两个公式中的第二项都是目标函数关于第 l 层的神经元 $^{(l)}$的偏导数,称为误差项, 可以一次计算得到. 这样我们只需要计算三个偏导数,分别为 <span class="math inline">\(\frac{\partial\boldsymbol{z}^{(l)}}{\partial w_{i j}^{(l)}}, \frac{\partial\boldsymbol{z}^{(l)}}{\partial \boldsymbol{b}^{(l)}} 和 \frac{\partial\mathcal{L}(\boldsymbol{y}, \hat{\boldsymbol{y}})}{\partial\boldsymbol{z}^{(l)}} .\)</span></p><h2 id="偏导数计算">2.1 偏导数计算</h2><p>下面分别来计算这三个偏导数：</p><ol type="1"><li>计算偏导数 $ $因 <spanclass="math inline">\(z^{(l)}=\boldsymbol{W}^{(l)}\boldsymbol{a}^{(l-1)}+\boldsymbol{b}^{(l)} ,\)</span> 偏导数</li></ol><p><span class="math display">\[\begin{aligned}\frac{\partial z^{(l)}}{\partial w_{i j}^{(l)}} &amp;=[\frac{\partialz_{1}^{(l)}}{\partial w_{i j}^{(l)}}, \cdots,\frac{\partial z_{i}^{(l)}}{\partial w_{i j}^{(l)}}\cdots,\frac{\partial z_{M_{l}}^{(l)}}{\partial w_{i j}^{(l)}}]\\&amp;=[0, \cdots, {\frac{\partial\left(\boldsymbol{w}_{i:}^{(l)}\boldsymbol{a}^{(l-1)}+b_{i}^{(l)}\right)}{\partial w_{i j}^{(l)}}},\cdots, 0] \\&amp;=\left[0, \cdots, a_{j}^{(l-1)}, \cdots, 0\right] \\&amp; \triangleq \mathbb{l}_{i}\left(a_{j}^{(l-1)}\right) \quad \in\mathbb{R}^{1 \times M_{l}}\end{aligned}\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119205757205.png"alt="image-20211119205757205" /><figcaption aria-hidden="true">image-20211119205757205</figcaption></figure><h2 id="误差项">2.2 误差项</h2><p>误差项 $^{(l)} $也间接反映了不同神经元对网络能力的贡献程度,从而比较好地解决 了贡献度分配问题 ( Credit Assignment Problem,CAP ).根据 $ <sup>{(l+1)}=</sup>{(l+1)} <sup>{(l)}+</sup>{(l+1)} $, 有</p><p><span class="math display">\[\frac{\partial \boldsymbol{z}^{(l+1)}}{\partial\boldsymbol{\alpha}^{(l)}}=\left(\boldsymbol{W}^{(l+1)}\right)^{\top}\quad \in \mathbb{R}^{M_{l} \times M_{l+1}}\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119205825727.png"alt="image-20211119205825727" /><figcaption aria-hidden="true">image-20211119205825727</figcaption></figure><p><span class="math display">\[\begin{aligned}\frac{\partial \boldsymbol{\alpha}^{(l)}}{\partial \boldsymbol{z}^{(l)}}&amp;=\frac{\partial f_{l}\left(\boldsymbol{z}^{(l)}\right)}{\partial\boldsymbol{z}^{(l)}} \\&amp;=\operatorname{diag}\left(f_{l}^{\prime}\left(\boldsymbol{z}^{(l)}\right)\right)\quad \in \mathbb{R}^{M_{l} \times M_{l}}\end{aligned}\]</span></p><p>因此,根据链式法则,第 l 层的误差项为</p><p><span class="math display">\[\begin{aligned}\delta^{(l)} &amp; \triangleq \frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial \boldsymbol{z}^{(l)}} \\&amp;=\frac{\partial \boldsymbol{a}^{(l)}}{\partial\boldsymbol{z}^{(l)}}  \cdot \frac{\partial\boldsymbol{z}^{(l+1)}}{\partial \boldsymbol{a}^{(l)}} \cdot\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial \boldsymbol{z}^{(l+1)}} \\&amp;={\operatorname{diag}\left(f_{l}^{\prime}\left(\boldsymbol{z}^{(l)}\right)\right)}\cdot\left(\boldsymbol{W}^{(l+1)}\right)^{\top}  \cdot{\delta^{(l+1)}}\\&amp;=f_{l}^{\prime}\left(\boldsymbol{z}^{(l)}\right)\odot\left(\left(\boldsymbol{W}^{(l+1)}\right)^{\top}\delta^{(l+1)}\right) \quad \in \mathbb{R}^{M_{l}},\end{aligned}\]</span></p><p>其中 $ $是向量的 Hadamard 积运算符, 表示每个元素相乘.从上面的公式可以看出,第 l 层的误差项可以通过第 l+1 层的误差项计算得到,这就是误差的反向传播 ( BackPropagation, BP ). 反向传播算法的含义是: 第 l层的一个神经元的误差项 ( 或敏感性 ) 是所有与该神经元相连的第 l+1 层的神经元的误差项的权重和. 然后, 再乘上该神经元激活函数的梯度.在计算出上面三个偏导数之后,</p><p><span class="math display">\[\begin{aligned}\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial w_{i j}^{(l)}}&amp;={l}_{i}\left(a_{j}^{(l-1)}\right) \delta^{(l)} \\&amp;=\left[0, \cdots, a_{j}^{(l-1)}, \cdots,0\right]\left[\delta_{1}^{(l)}, \cdots, \delta_{i}^{(l)}, \cdots,\delta_{M_{l}}^{(l)}\right]^{\top} \\&amp;=\delta_{i}^{(l)} a_{j}^{(l-1)}\end{aligned}\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119205855415.png"alt="image-20211119205855415" /><figcaption aria-hidden="true">image-20211119205855415</figcaption></figure><p><span class="math display">\[\left[\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial \boldsymbol{W}^{(l)}}\right]_{ij}=\left[\delta^{(l)}\left(\boldsymbol{a}^{(l-1)}\right)^{\top}\right]_{ij}\]</span></p><p>因此, $ (, ) $关于第 l 层权重 $ ^{(l)} $的梯度为</p><p><span class="math display">\[\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial\boldsymbol{W}^{(l)}}=\delta^{(l)}\left(\boldsymbol{a}^{(l-1)}\right)^{\top}\quad \in \mathbb{R}^{M_{l} \times M_{l-1}}\]</span></p><p>同理, $(, ) $关于第 l 层偏置 $ ^{(l)} $的梯度为</p><p><span class="math display">\[\frac{\partial \mathcal{L}(\boldsymbol{y},\hat{\boldsymbol{y}})}{\partial \boldsymbol{b}^{(l)}}=\delta^{(l)} \quad\in \mathbb{R}^{M_{l}}\]</span></p><h2 id="实现步骤与伪代码">2.3 实现步骤与伪代码</h2><p>在计算出每一层的误差项之后, 我们就可以得到每一层参数的梯度. 因此,使用误差反向传播算法的前馈神经网络训练过程可以分为以下三步:</p><ol type="1"><li>前馈计算每一层的净输入 $^{(l)} $和激活值 $ ^{(l)} $,直到最后一层;</li><li>反向传播计算每一层的误差项 <spanclass="math inline">\(\delta^{(l)}\)</span> ;</li><li>计算每一层参数的偏导数, 并更新参数.</li></ol><p>使用反向传播算法的随机梯度下降训练过程：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119113727799.png"alt="image-20211119113727799" /><figcaption aria-hidden="true">image-20211119113727799</figcaption></figure><h1id="三描述模型超参数确定的过程分析模型训练结果-1">三、描述模型超参数确定的过程，分析模型训练结果</h1><p>在神经网络中， 除了可学习的参数之外， 还存在很多超参数．这些超参数对网络性能的影响也很大．不同的机器学习任务往往需要不同的超参数． 常见的超参数有以下三类：</p><ol type="1"><li>网络结构,包括神经元之间的连接关系、层数、每层的神经元数量、激活函数的类型等.</li><li>优化参数,包括优化方法、学习率、小批量的样本数量等.</li><li>正则化系数.</li></ol><p>超参数优化（ Hyperparameter Optimization） 主要存在两方面的困难：</p><ul><li>超参数优化是一个组合优化问题，无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法；</li><li>评估一组超参数配置（ Configuration）的时间代价非常高，从而导致一些优化方法（ 比如演化算法（ Evolution Algorithm））在超参数优化中难以应用</li></ul><p>对于超参数的配置，比较简单的方法有网格搜索、随机搜索、贝叶斯优化、动态资源分配和神经架构搜索，这次我们介绍最后两种。</p><h2 id="动态资源分配">3.1 动态资源分配</h2><p>在超参数优化中， 每组超参数配置的评估代价比较高．如果我们可以在较早的阶段就估计出一组配置的效果会比较差，那么我们就可以中止这组配置的评估，将更多的资源留给其他配置．这个问题可以归结为多臂赌博机问题的一个泛化问题：<strong>最优臂问题（ Best-Arm Problem）</strong>，即在给定有限的机会次数下， 如何玩这些赌博机并找到收益最大的臂．和多臂赌博机问题类似，最优臂问题也是在利用和探索之间找到最佳的平衡．</p><p>由于目前神经网络的优化方法一般都采取随机梯度下降，因此我们可以通过一组超参数的学习曲线来预估这组超参数配置是否有希望得到比较好的结果．如果一组超参数配置的学习曲线不收敛或者收敛比较差，我们可以应用<strong>早期停止（ Early-Stopping）</strong>策略来中止当前的训练．</p><p>动态资源分配的关键是将有限的资源分配给更有可能带来收益的超参数组合．一种有效方法是<strong>逐次减半（ Successive Halving）</strong> 方法，将超参数优化看作一种非随机的最优臂问题． 假设要尝试 𝑁 组超参数配置，总共可利用的资源预算（ 摇臂的次数） 为𝐵， 我们可以通过𝑇 = ⌈log2(𝑁)⌉ -1轮逐次减半的方法来选取最优的配置．</p><h3 id="实现步骤与伪代码-1">3.1.1 实现步骤与伪代码</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119165313867.png"alt="image-20211119165313867" /><figcaption aria-hidden="true">image-20211119165313867</figcaption></figure><p>在逐次减半方法中， 尝试的超参数配置数量 𝑁 十分关键． 如果𝑁 越大，得到最佳配置的机会也越大， 但每组配置分到的资源就越少，这样早期的评估结果可能不准确． 反之， 如果 𝑁 越小，每组超参数配置的评估会越准确， 但有可能无法得到最优的配置． 因此，如何设置 𝑁 是平衡“利用-探索” 的一个关键因素．一种改进的方法是<strong>HyperBand方法</strong>， 通过尝试不同的𝑁来选取最优参数．</p><h2 id="神经架构搜索">3.2 神经架构搜索</h2><p>上面介绍的超参数优化方法都是在固定（ 或变化比较小） 的超参数空间𝒳中进行最优配置搜索，而最重要的神经网络架构一般还是需要由有经验的专家来进行设计 .神经架构搜索（ Neural Architecture Search， NAS）是一个新的比较有前景的研究方向， 通过神经网络来自动实现网络架构的设计．一个神经网络的架构可以用一个变长的字符串来描述． 利用元学习的思想，神经架构搜索利用一个控制器来生成另一个子网络的架构描述．控制器可以由一个循环神经网络来实现．控制器的训练可以通过强化学习来完成，其奖励信号为生成的子网络在开发集上的准确率 .</p><h2 id="结果分析-1">3.3 结果分析</h2><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119191016077.png"alt="image-20211119191016077" /><figcaption aria-hidden="true">image-20211119191016077</figcaption></figure><p>在两次报告中我们一共介绍了5种超参数调优方式，也都尝试过应用到实验中，但并没有获得很大的提升。且结合数据量较小，网络结构较简单的实际，我们依旧选择了根据一些“经验结论”来进行网格搜索。</p><p>默认参数下，五次五折交叉验证结果：</p><p>Accuracy: 0.95</p><p>使用代码如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neural_network <span class="token keyword">import</span> MLPClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>mlp <span class="token operator">=</span> MLPClassifier<span class="token punctuation">(</span>hidden_layer_sizes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> solver<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token string">'constant'</span><span class="token punctuation">,</span> learning_rate_init<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> power_t<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> warm_start<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> nesterovs_momentum<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> early_stopping<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> validation_fraction<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span> n_iter_no_change<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> max_fun<span class="token operator">=</span><span class="token number">15000</span><span class="token punctuation">)</span> <span class="token comment">#均以官网默认参数设置</span>mlp<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>ACC <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>mlp<span class="token punctuation">,</span> X_std<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cv<span class="token operator">=</span>rkf<span class="token punctuation">,</span>scoring<span class="token operator">=</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy:'</span><span class="token punctuation">,</span>ACC<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>网格搜索最优参数的结果为：</p><p>Accuracy: 0.96125</p><p>混淆矩阵如图：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119193317068.png"alt="image-20211119193317068" /><figcaption aria-hidden="true">image-20211119193317068</figcaption></figure><p>ROC曲线如图：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119193347579.png"alt="image-20211119193347579" /><figcaption aria-hidden="true">image-20211119193347579</figcaption></figure><p>评价指标（精确率，召回率和F1值）：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119193422505.png"alt="image-20211119193422505" /><figcaption aria-hidden="true">image-20211119193422505</figcaption></figure><p>从上面可以看出，我们的模型分类结果完全正确，甚至有可能出现了过拟合。为了避免这种情况，我们继续修改参数，发现即使不设置任何超参数也可以达到这样的准确率，也从另一方面证明了神经网络拟合能力的强悍。</p><p>网格搜索代码如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 超参数调优</span><span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCVparameters <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'hidden_layer_sizes'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">70</span><span class="token punctuation">,</span><span class="token number">70</span><span class="token punctuation">,</span><span class="token number">70</span><span class="token punctuation">,</span><span class="token number">70</span><span class="token punctuation">,</span><span class="token number">70</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token string">'activation'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'identity'</span><span class="token punctuation">,</span> <span class="token string">'logistic'</span><span class="token punctuation">,</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> <span class="token string">'relu'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token string">'solver'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'adam'</span><span class="token punctuation">,</span><span class="token string">'lbgfs'</span><span class="token punctuation">,</span><span class="token string">'sgd'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token string">'alpha'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.0001</span><span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'constant'</span><span class="token punctuation">,</span> <span class="token string">'invscaling'</span><span class="token punctuation">,</span> <span class="token string">'adaptive'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>grid <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>mlp<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> cv<span class="token operator">=</span>rkf<span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_absolute_percentage_error'</span><span class="token punctuation">,</span>n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>grid<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最优参数：'</span><span class="token punctuation">,</span>grid<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最优模型得分：'</span><span class="token punctuation">,</span>grid<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="四总结模型训练过程中的收获-1">四、总结模型训练过程中的收获</h1><h2 id="优化与正则化">4.1 优化与正则化</h2><p>神经网络的优化和正则化是既对立又统一的关系．一方面我们希望优化算法能找到一个全局最优解（ 或较好的局部最优解），另一方面我们又不希望模型优化到最优解， 这可能陷入过拟合．优化和正则化的统一目标是期望风险最小化．</p><h3 id="优化">4.1.1 优化</h3><p>在优化方面， 训练神经网络时的主要难点是非凸优化以及梯度消失问题．在深度学习技术发展的初期， 我们通常需要利用预训练和逐层训练等比较低效的方法来辅助优化．随着深度学习技术的发展， 我们目前通常可以高效地、端到端地训练一个深度神经网络． 这些提高训练效率的方法通常分为以下 3个方面：</p><ol type="1"><li>修改网络模型来得到更好的优化地形， 比如使用逐层归一化、残差连接以及ReLU激活函数等；</li><li>使用更有效的优化算法， 比如动态学习率以及梯度估计修正等；</li><li>使用更好的参数初始化方法</li></ol><h3 id="泛化">4.1.2 泛化</h3><p>在泛化方面，传统的机器学习中有一些很好的理论可以帮助我们在模型的表示能力、复杂度和泛化能力之间找到比较好的平衡，但是这些理论无法解释深度神经网络在实际应用中的泛化能力表现．根据通用近似定理，神经网络的表示能力十分强大． 从直觉上，一个过度参数化的神经网络很容易产生过拟合现象，因为它的容量足够记住所有训练数据． 但是实验表明，神经网络在训练过程中依然优先记住训练数据中的一般模式（ Pattern），即具有高泛化能力的模式 ． 但目前，神经网络的泛化能力还没有很好的理论支持．在传统机器学习模型上比较有效的ℓ1 或ℓ2正则化在深度神经网络中作用也比较有限， 而一些经验的做法（比如小的批量大小、大的学习率、提前停止、丢弃法、数据增强） 会更有效。</p><h2 id="与回归的差异">4.2 与回归的差异</h2><p>和回归问题不同， 分类问题中的目标标签 𝑦 是离散的类别标签，因此分类问题中的决策函数需要输出离散值或是标签的后验概率．线性分类模型一般是一个广义线性函数，即一个或多个线性判别函数加上一个非线性激活函数．所谓“线性”是指决策边界由一个或多个超平面组成．</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119171348116.png"alt="image-20211119171348116" /><figcaption aria-hidden="true">image-20211119171348116</figcaption></figure><h2 id="对深度学习框架的初步了解">4.3 对深度学习框架的初步了解</h2><p>在深度学习中， 一般通过误差反向传播算法来进行参数学习．采用手工方式来计算梯度再写代码实现的方式会非常低效， 并且容易出错．此外， 深度学习模型需要的计算机资源比较多， 一般需要在 CPU 和 GPU之间不断进行切换， 开发难度也比较大． 因此，一些支持自动梯度计算、无缝CPU和GPU切换等功能的深度学习框架就应运而生．比较有代表性的框架包括：Theano、Caffe、TensorFlow、Pytorch、飞桨（PaddlePaddle）、Chainer和MXNet等。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211119185714226.png"alt="image-20211119185714226" /><figcaption aria-hidden="true">image-20211119185714226</figcaption></figure><p>因此本次作业我们没有局限在scikit-learn中，我们了解并学习了TensorFlow，pytorch等框架的使用，搭建了简易的神经网络对本次作业的数据进行分析。虽然最终得到的效果不及sklearn，但是在体验的过程加深了对神经网络的理解。</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>岭回归，特征工程分析advertising.csv</title>
    <link href="/2021/10/28/ridge/"/>
    <url>/2021/10/28/ridge/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>机器学习第二次作业记录。小组成员：方桂安，刘玥，周敏。</p><span id="more"></span><h1 id="一数据分析">一、数据分析</h1><h2 id="数据缺失检查">1.1 数据缺失检查</h2><p>首先，为了我们能正常进行数据分析，我们进行了数据缺失分布情况检查。代码及结果如下：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026214742931.png"alt="image-20211026214742931" /><figcaption aria-hidden="true">image-20211026214742931</figcaption></figure><p>缺失值总数：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026214800042.png"alt="image-20211026214800042" /><figcaption aria-hidden="true">image-20211026214800042</figcaption></figure><p>由上可知，我们的数据中没有缺失值，不需要进行插值处理。</p><h2 id="销售量与各媒体投入关系分析">1.2 销售量与各媒体投入关系分析</h2><h3 id="散点图">1.2.1 散点图</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026214824135.png"alt="image-20211026214824135" /><figcaption aria-hidden="true">image-20211026214824135</figcaption></figure><p>以上是销售量与各项媒体投入量的散点图。从上图我们可以看出，sales和TV投入量有明显的正相关关系，随着TV投入增多，sales大体上呈上升趋势。sales和radio投入量也有较弱的正相关趋势，但sales分布在以radio投入量为指标时，分布较零散，相关关系弱于sales与TV投入量。而sales和newspaper的相关性最弱，sales集中分布在newspaper低投入区域内。</p><h3 id="各项数据分析">1.2.2 各项数据分析</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026215012236.png"alt="image-20211026215012236" /><figcaption aria-hidden="true">image-20211026215012236</figcaption></figure><p>由上图可知，TV类广告的平均投入量最大，其投入量的最小值，二分位数，中位数和四分位数，最大值均大于其他类型的广告，说明企业偏向于在TV类广告投入更多资金。</p><h3 id="相关系数">1.2.3 相关系数</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026215047222.png"alt="image-20211026215047222" /><figcaption aria-hidden="true">image-20211026215047222</figcaption></figure><p>上图为四个变量的相关系数热力图，由此可以看出，销售量和TV，radio，newspaper的相关性依次减弱。</p><h3 id="散点图矩阵多变量之间的关系可视化">1.2.4散点图矩阵，多变量之间的关系可视化</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026215104208.png"alt="image-20211026215104208" /><figcaption aria-hidden="true">image-20211026215104208</figcaption></figure><h2 id="得出结论">1.3 得出结论</h2><p>由上面的分析可知，销售量和TV投入量相关性最大，其次是radio，newspaper，这也符合我们目前的社会情况，人们更多的是在电视等电子产品上获取信息。所以，加大上述三种广告方式的投入会对销售量有依次递减的增幅影响。</p><h1id="二描述10折交叉验证对数据集的处理">二、描述10折交叉验证对数据集的处理</h1><h2 id="引入10折交叉验证的原因">2.1 引入10折交叉验证的原因</h2><p>泛化能力是指模型在训练集上训练后,对新数据进行准确预测的能力。在机器学习的模型选择中，我们要对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。而实际应用中，我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，所以我们随机将数据集切为三部分：</p><ul><li>训练集：用来训练模型，对应训练误差。</li><li>验证集：用来选择模型，对应测试误差。</li><li>测试集：用来最终对学习方法进行评估，对应泛化误差的近似。</li></ul><p>但是在实际应用中数据往往是不充足的，为了选择泛化能力更好的模型，我们可以对数据集D进行适当的处理，从中产生出训练集S和测试集T。几种常见的做法有：简单交叉验证(holdoutcross-validation)、留一交叉验证(leave-one-outcross-validation,LOOCV)、<em>k</em>折交叉验证(<em>k</em>-foldcross-validation)、多重<em>k</em>折交叉验证、分层法(stratification-splitcross-validation)、自助法(bootstraps)等。而综合考虑几种方法的特点后，本次我们选择的处理方法是10折交叉验证法。</p><h2 id="折交叉验证的基本原理">2.2 10折交叉验证的基本原理</h2><p>10折交叉验证是指将原始数据集随机划分为样本数量近乎相等的10个子集，轮流将其中的9个合并作为训练集，其余1个作为测试集。在每次试验中计算正确率等评价指标，最终通过k次试验后取评价指标的平均值来评估该模型的泛化能力。</p><p>10折交叉验证的基本步骤如下:</p><ol type="1"><li>原始数据集划分为10个样本量尽可能均衡的子集；</li><li>使用第1个子集作为测试集，第2～9个子集合并作为训练集；</li><li>使用训练集对模型进行训练,计算多种评价指标在测试集下的结果；</li><li>重复2-3步骤,轮流将第2-10个子集作为测试集；</li><li>计算各评价指标的平均值作为最终结果，最终选出10次测评中平均测试误差最小的模型。</li></ol><p>10折交叉验证的原理示意见下图。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211026214227086.png"alt="image-20211026214227086" /><figcaption aria-hidden="true">image-20211026214227086</figcaption></figure><p>由于将数据集D划分为k个子集同样存在多种划分方式，为了减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次。故我们可以采用“10次10折交叉验证”。</p><h2 id="折交叉验证函数python代码">2.3 10折交叉验证函数python代码</h2><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> KFold  <span class="token comment"># 从sklearn导入KFold包</span><span class="token keyword">def</span> <span class="token function">Ten_Flod_spilt</span><span class="token punctuation">(</span>fold<span class="token punctuation">,</span>data<span class="token punctuation">,</span>label<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''    param fold: 要取第几折的数据。    param data: 需要分块的数据    param label: 对应的需要分块标签    return: 对应折的训练集、测试集和对应的标签    '''</span>    split_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    kf <span class="token operator">=</span> KFold<span class="token punctuation">(</span>n_splits<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> train<span class="token punctuation">,</span> test <span class="token keyword">in</span> kf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>        split_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        split_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train<span class="token punctuation">,</span>test<span class="token operator">=</span>split_list<span class="token punctuation">[</span><span class="token number">2</span> <span class="token operator">*</span> fold<span class="token punctuation">]</span><span class="token punctuation">,</span>split_list<span class="token punctuation">[</span><span class="token number">2</span> <span class="token operator">*</span> fold <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">return</span>  data<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span>test<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token punctuation">[</span>test<span class="token punctuation">]</span>  <span class="token comment">#已经分好块的数据集</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>在后续使用中只需循环调用该函数即可达到10折交叉验证的目的：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> Ten_Flod_spilt<span class="token punctuation">(</span>i<span class="token punctuation">,</span>X_s<span class="token punctuation">,</span>y_s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div><h1 id="三描述所使用的线性模型">三、描述所使用的线性模型</h1><h2 id="基本形式">3.1 基本形式</h2><p>给定由d个属性描述的示例<strong>x</strong>=(x<sub>1</sub>;x<sub>2</sub>;...;x<sub>d</sub>)，其中x<sub>i</sub>是<strong>x</strong>在第i个属性上的取值，线性回归(linearregression)试图学得一个通过属性的线性组合来进行预测的函数，即</p><p><span class="math display">\[f(\boldsymbol{x})=w_{1} x_{1}+w_{2} x_{2}+\ldots+w_{d} x_{d}+b\]</span></p><p>一般用向量形式写成</p><p><span class="math display">\[f(\boldsymbol{x})=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\]</span></p><p>其中<strong>w</strong>=(w<sub>1</sub>;w<sub>2</sub>;... ;w<sub>d</sub>)。<strong>w</strong>和b学得之后，模型就得以确定。</p><p>故本题中的模型应该为</p><p><span class="math display">\[\widehat{Sales}=w_{1} ·TV+w_{2} ·radio+w_{3}·newspaper+b，使得\widehat{Sales}\cong Sales\]</span></p><p>此处有三个属性描述样本，故又称为多元线性回归(multivariate linearregression)。</p><p>其基本形式为</p><p><span class="math display">\[\hat{f}\left(\hat{x}_{N+1}\right)=\hat{x}_{N+1}^{T}\widehat{\omega}^{*}\\其中  \hat{x}_{N+1}=\left(x_{N+1} ; 1\right) \in \mathbb{R}^{n+1},\widehat{\omega}^{*}=\left(\omega^{*} ; b^{*}\right) \in\mathbb{R}^{n+1}\]</span></p><h2 id="岭回归">3.2 岭回归</h2><p>吉洪诺夫正则化以安德烈·尼古拉耶维奇·吉洪诺夫命名，为非适定性问题的正则化中最常见的方法。在统计学中，本方法被称为脊回归或岭回归（ridgeregression）；在机器学习领域则称为权重衰减或权值衰减（weightdecay）。因为有不同的数学家独立发现此方法，此方法又称做吉洪诺夫－米勒法（Tikhonov–Millermethod）、菲利浦斯－图米法（Phillips–Twomeymethod）、受限线性反演（constrained linear inversionmethod），或线性正规化（linear regularization）。</p><p><span class="math display">\[min\ L(W)=\frac{1}{2}(XW-y)^T(XW-y)+\frac{1}{2}\alpha||W||^2_2\]</span></p><p><span class="math display">\[W=(X^TX+\alpha I)^{-1}X^Ty\]</span></p><p>根据4.2、4.3的分析，我们最终决定在最小二乘法的基础上采取L2正则化，即岭回归。相应地，为了使用岭回归和缩减技术，首先需要对特征做标准化处理。因为，我们需要使每个维度特征具有相同的重要性，故采用了z-score标准化。随着模型复杂度的提升，在训练集上的效果就越好，即模型的偏差就越小；但是同时模型的方差就越大。对于岭回归的α而言，随着α的增大，<spanclass="math inline">\(|X^TX+\alpha I|\)</span>就越大，<spanclass="math inline">\((X^TX+\alpha I)^{-1}\)</span>就越小，模型的方差就越小；而α越大使得<strong>W</strong>的估计值更加偏离真实值，模型的偏差就越大。所以岭回归的关键是找到一个合理的α值来平衡模型的方差和偏差。</p><p>本次使用10折交叉验证法来确定α值，每一种训练集和测试集下都会有对应的一个模型及模型评分（如均方误差），进而可以得到一个平均评分。对于α值则选择平均评分最优的α值。</p><h2 id="特征工程">3.3 特征工程</h2><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211027233323219.png"alt="image-20211027233323219" /><figcaption aria-hidden="true">image-20211027233323219</figcaption></figure><p>如图所示为梯度下降法，最小二乘法和sklearn调用所得结果与真实值的对比折线图。从中可以看出，三种折线都已经接近重合，但又与真实值存在差异。查阅资料后，我们了解了特征工程的相关知识。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/967090-20170116151505067-1134887580.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>“数据决定了机器学习的上限，而算法只是尽可能逼近这个上限”，这里的数据指的就是经过特征工程得到的数据。特征工程指的是把原始数据转变为模型的训练数据的过程，它的目的就是获取更好的训练数据特征，使得机器学习模型逼近这个上限。特征工程能使得模型的性能得到提升，有时甚至在简单的模型上也能取得不错的效果。特征工程在机器学习中占有非常重要的作用，一般认为括特征构建、特征提取、特征选择三个部分。特征构建比较麻烦，需要一定的经验。特征提取与特征选择都是为了从原始特征中找出最有效的特征。它们之间的区别是特征提取强调通过特征转换的方式得到一组具有明显物理或统计意义的特征；而特征选择是从特征集合中挑选一组具有明显物理或统计意义的特征子集。两者都能帮助减少特征的维度、数据冗余，特征提取有时能发现更有意义的特征属性，特征选择的过程经常能表示出每个特征的重要性对于模型构建的重要性。</p><p>本次作业中主要使用了特征构建、特征选择、特征缩放，具体结果将在第五部分讨论。</p><h1 id="四描述训练模型所使用的算法">四、描述训练模型所使用的算法</h1><h2 id="数据预处理">4.1 数据预处理</h2><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211027090542621.png"alt="image-20211027090542621" /><figcaption aria-hidden="true">image-20211027090542621</figcaption></figure><p>本次数据处理使用的是z-score标准化，转换公式为：</p><p><span class="math display">\[z=\frac{x-\mu}{\sigma}\]</span></p><p>使用python具体实现如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fit_transform</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    std_ <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 标准差</span>    mean_ <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 均值</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean_<span class="token punctuation">)</span> <span class="token operator">/</span> std_<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="策略">4.2 策略</h2><h3 id="经验风险最小化">4.2.1 经验风险最小化</h3><p>均方误差是回归任务中最常用的性能度量，因此我们可试图让均方误差最小化，即</p><p><span class="math display">\[\begin{aligned}\left(w^{*}, b^{*}\right) &amp;=\underset{(w, b)}{\arg \min }\sum_{i=1}^{m}\left(f\left(x_{i}\right)-y_{i}\right)^{2} \\&amp;=\underset{(w, b)}{\arg \min } \sum_{i=1}^{m}\left(y_{i}-wx_{i}-b\right)^{2}\end{aligned}\]</span></p><p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”(Euclideandistance)。基于均方误差最小化来进行模型求解的方法称为“最小二乘法”(leastsquare method)。具体求解过程在4.3中进行介绍。</p><h3 id="结构风险最小化">4.2.2 结构风险最小化</h3><h4 id="正则化">4.2.2.1 正则化</h4><p>当模型的复杂度增大时，训练误差会逐渐减小并趋于0；而测试误差会先减小，达到最大值后又增大。当选择的模型复杂度过大时，就会发生过拟合，如下图所示。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211027095448459.png"alt="image-20211027095448459" /><figcaption aria-hidden="true">image-20211027095448459</figcaption></figure><p>为了避免因为过拟合问题而导致拟合效果不佳，我们在经验风险上加一个正则化项或罚项，使结构风险最小，这种方法叫做正则化，一般具有如下形式：</p><p><span class="math display">\[\min _{f \in \mathcal{F}} \sum_{i=1}^{N} L\left(y_{i},f\left(x_{i}\right)\right)+\lambda J(f)\]</span></p><h4 id="l1与l2正则化">4.2.2.2 L1与L2正则化</h4><p>使用L1范数（也称曼哈顿距离或Taxicab范数，只允许在与空间轴平行行径的距离）又叫<strong>lasso</strong>回归，损失函数变为：</p><p><span class="math display">\[J(\mathbf{W})=\frac{1}{2 n}(\mathbf{X}\mathbf{W}-\mathbf{Y})^{T}(\mathbf{X}\mathbf{W}-\mathbf{Y})+\alpha\|W\|_{1}\]</span></p><p>使用L2范数（也称欧几里德距离，是向量到原点的最短距离）又叫<strong>ridge</strong>回归，损失函数变为：</p><p><span class="math display">\[J(\mathbf{W})=\frac{1}{2}(\mathbf{X}\mathbf{W}-\mathbf{Y})^{T}(\mathbf{X} \mathbf{W}-\mathbf{Y})+\frac{1}{2}\alpha\|W\|_{2}^{2}\]</span></p><p>L1能使得一些特征的系数变小，甚至还使一些绝对值较小的系数直接变为0，产生稀疏解，起到特征选择的作用，增强模型的泛化能力。</p><p>L2的优点是可以限制|w|的大小，从而使模型更简单，更稳定，即使加入一些干扰样本也不会对模型产生较大的影响，而且还能解决非正定的问题，强制使XTX可逆有解。</p><p><span class="math display">\[\theta=\left(X X^{T}+\alpha I\right)^{-1} X Y\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/1335117-20180708193526314-357302334.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/1335117-20180708194712773-1094778410.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在上图中，两个坐标分别是要学习到的两个参数ω1和ω2；彩色线是损失函数J的等高线即损失值相等线；方形和圆形就分别是L1和L2所产生的额外误差（约束空间）；最后的目标要是两者最小，即要得到能使两者相加最小的点，也就是图中的黑色交点。在画等差图时，L1的效果就很容易与坐标轴相交了，这就是会产生很多0，即造成参数稀疏的原因。而且同时如果给一个微小的偏移，L2移动不会很大，而L1可能会移动到方形边上产生很多的交点，所以L1比较不稳定。</p><p>L2倾向于使ω的分量取值更均衡，即非零分量个数更稠密，而L1倾向ω的分量取值更稀疏，即非零分量个数更少。所以从图可以看出L1的边缘比较尖锐，与目标函数的等高线相交时，交点会常在那些尖锐的地方，所以很多的参数就是0，即L1能产生稀疏解。所以在调参时如果我们主要的目的只是为了解决过拟合，一般选择L2正则化就够了。但是如果选择L2正则化发现还是过拟合，即预测效果差的时候，就可以考虑L1正则化。另外，如果模型的特征非常多，我们希望一些不重要的特征系数归零，从而让模型系数稀疏化的话，也可以使用L1正则化。</p><p>综合考虑，我们在本次的损失函数中引入的是L2正则化。</p><h2 id="算法">4.3 算法</h2><h3 id="最小二乘法">4.3.1 最小二乘法</h3><h4 id="问题分析">4.3.1.1 问题分析</h4><p>我们的策略是</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028184420327.png"alt="image-20211028184420327" /><figcaption aria-hidden="true">image-20211028184420327</figcaption></figure><p>我们进行展开</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028184438472.png"alt="image-20211028184438472" /><figcaption aria-hidden="true">image-20211028184438472</figcaption></figure><p>下面，我们进行梯度推导</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028184450724.png"alt="image-20211028184450724" /><figcaption aria-hidden="true">image-20211028184450724</figcaption></figure><p>由于<span class="math inline">\(L(W)\)</span>是关于<spanclass="math inline">\(W\)</span>的凸函数，所以我们在梯度为零的点，即是我们要求的最优解。</p><p><span class="math display">\[令\frac{\partial L}{\partial W}=0\\得(X^TX+\alpha I)W=X^Ty\]</span></p><p>我们要通过此方法求得<spanclass="math inline">\(W\)</span>，需要的条件是<spanclass="math inline">\(X^TX+\alpha I\)</span>可逆，若其可逆，则<spanclass="math inline">\(W\)</span>的解是</p><p><span class="math display">\[W=(X^TX+\alpha I)^{-1}X^Ty\]</span></p><p>因为最小二乘法要求<span class="math inline">\(X^TX+\alphaI\)</span>必须存在可逆矩阵，在实际问题中可能不满足，于是我们下面采用梯度下降法进行迭代求解。</p><h4 id="代码实现">4.3.1.2 代码实现</h4><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">lms</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">:</span>    x_train_<span class="token operator">=</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x_train<span class="token punctuation">]</span>    x_test_<span class="token operator">=</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x_test<span class="token punctuation">]</span>    theta_n <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_train_<span class="token punctuation">.</span>T<span class="token punctuation">,</span> x_train_<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">0.1</span><span class="token operator">*</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>x_train_<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x_train_<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>  <span class="token comment"># theta = (X`X)^(-1)X`Y，其中X`表示X的转置，使用L2范数正则化</span>    y_pre <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_test_<span class="token punctuation">,</span> theta_n<span class="token punctuation">)</span>    mse <span class="token operator">=</span> np<span class="token punctuation">.</span>average<span class="token punctuation">(</span><span class="token punctuation">(</span>y_test <span class="token operator">-</span> y_pre<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> theta_n<span class="token punctuation">,</span> y_pre<span class="token punctuation">,</span> mse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="梯度下降法">4.3.2 梯度下降法</h3><h4 id="问题分析-1">4.3.2.1 问题分析</h4><p>首先，我们的目标是下式</p><p><span class="math display">\[令\hat{\omega}=W\\E(\hat{\omega})=\frac{1}{2}(X\hat{\omega}-y)^T(X\hat{\omega}-y)+\frac{1}{2}\alpha||\hat{\omega}||^2_2\quad,\hat{\omega}=\mathop{argmin}_\hat{\omega}\E(\hat{\omega})\]</span></p><p>梯度下降法是一种迭代算法：我们选取适当的初始值<spanclass="math inline">\(\hat{\omega}^{(0)}\)</span>，不断迭代，更新<spanclass="math inline">\(\hat{\omega}\)</span>的值，进行目标函数的极小化，直到收敛。由于负梯度方向是使得函数值下降最快的方向，在迭代的每一步，以负梯度方向更新<spanclass="math inline">\(\hat{\omega}\)</span>的值，从而达到减小函数值的目的。如下图形象化表示：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211027100605390.png"alt="image-20211027100605390" /><figcaption aria-hidden="true">image-20211027100605390</figcaption></figure><h4 id="核心思想">4.3.2.2 核心思想</h4><ol type="1"><li><spanclass="math inline">\(E(\hat{\omega})\)</span>是具有一阶连续偏导数的凸函数，其极值点在一阶导数为零的地方取得</li><li>一阶泰勒展开：<spanclass="math inline">\(E(\hat{\omega})\thickapproxE(\hat{\omega}^{(k)})+\nablaE(\hat{\omega}^{(k)})(\hat{\omega}-\hat{\omega}^{(k)})\)</span>，其中，<spanclass="math inline">\(\nabla E(\hat{\omega}^{(k)})\)</span>是<spanclass="math inline">\(E(\hat{\omega})\)</span>在<spanclass="math inline">\(\hat{\omega}^{(k)}\)</span>的梯度：</li></ol><p><span class="math display">\[\nabla E(\hat{\omega}^{(k)})=\frac{\partial E(\hat{\omega})}{\partial\hat{\omega}}|_{\hat{\omega}=\hat{\omega}^{(k)}}\]</span></p><ol start="3" type="1"><li>求取第k+1次迭代值：<spanclass="math inline">\(\hat{\omega}^{k+1}=\hat{\omega}^{(k)}+\eta_k*(-\nablaE(\hat{\omega}^{(k)}))\)</span>，其中<spanclass="math inline">\(\eta_k\)</span>是步长，有我们最初指定。梯度如下（推导在上面部分）：<span class="math display">\[\frac{\partial E}{\partial \hat{\omega}}=X^TX\hat{\omega}-X^Ty+\alphaI\hat{\omega}\quad(I是n\times n的单位矩阵)\]</span></li></ol><h4 id="求解步骤">4.3.2.3 求解步骤</h4><p>输入：目标函数<spanclass="math inline">\(E(\hat{\omega})\)</span>，梯度函数<spanclass="math inline">\(\nablaE(\hat{\omega})\)</span>，计算精度ε，步长<spanclass="math inline">\(\eta_k\)</span>；</p><p>输出： <spanclass="math inline">\(E(\hat{\omega})\)</span>的极小点<spanclass="math inline">\(\hat{\omega}^*\)</span>。</p><p>（1）取初始值<span class="math inline">\(\hat{\omega}^{(0)}\in\mathbb{R}^{d+1}\)</span>，置k=0；</p><p>（2）计算<spanclass="math inline">\(E(\hat{\omega}^{(k)})\)</span>；</p><p>（3）计算梯度<span class="math inline">\(\nablaE(\hat{\omega}^{(k)})\)</span>，当<span class="math inline">\(||\nablaE(\hat{\omega}^{(k)})||&lt;\varepsilon\)</span>时，令<spanclass="math inline">\(\hat{\omega}^*=\hat{\omega}^{(k)}\)</span>，</p><p>停止迭代；</p><p>（4）置<spanclass="math inline">\(\hat{\omega}^{(k+1)}=\hat{\omega}^{(k)}+\eta_k(-\nablaE(\hat{\omega}^{(k)}))\)</span>，计算<spanclass="math inline">\(E(\hat{\omega}^{(k+1)})\)</span>，</p><p>当<spanclass="math inline">\(||E(\hat{\omega}^{(k+1)})-E(\hat{\omega}^{(k)})||&lt;\varepsilon\)</span>或<spanclass="math inline">\(||\hat{\omega}^{(k+1)}-\hat{\omega}^{(k)}||&lt;\varepsilon\)</span>时，</p><p>令<spanclass="math inline">\(\hat{\omega}^*=\hat{\omega}^{(k)}\)</span>，停止迭代；</p><p>（5）否则，置k=k+1，转步骤（3）。</p><h4 id="代码实现-1">4.3.2.4 代码实现</h4><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GradientDescent_MultiLine</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr  <span class="token comment"># 学习率，用来控制步长（权重调整幅度）</span>        self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> epochs  <span class="token comment"># 循环迭代的次数</span>        self<span class="token punctuation">.</span>lose <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 损失值计算（损失函数）：均方误差</span>    <span class="token triple-quoted-string string">'''根据提供的训练数据对模型进行训练'''</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        y <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># 去掉冗余的维度</span>        self<span class="token punctuation">.</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 初始权重，权重向量初始值为0（或任何其他值），长度比X的特征数量多1（多出来的为截距）</span>        <span class="token comment"># 开始训练</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>            y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 计算预测值</span>            error <span class="token operator">=</span> y <span class="token operator">-</span> y_hat  <span class="token comment"># 计算真实值与预测值之间的差距</span>            self<span class="token punctuation">.</span>lose<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>error <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>T<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 将损失加入到损失列表中，使用L2范数正则化</span>            <span class="token comment">#print("迭代次数:&#123;0&#125;,进度：&#123;1&#125;%".format(i + 1, 100.0 * (i + 1) / self.epochs), "  loss:", np.sum(error ** 2) / 2)</span>            <span class="token comment"># j &lt;- j + α * sum((y - y_hat) * x(j))</span>            x_<span class="token operator">=</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">]</span>            <span class="token comment">#self.w[0] += self.lr * np.sum(error)</span>            <span class="token comment">#self.w[1:] += self.lr * np.dot(x.T, error)</span>            I<span class="token operator">=</span>np<span class="token punctuation">.</span>identity<span class="token punctuation">(</span>x_<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>w<span class="token operator">=</span>self<span class="token punctuation">.</span>w<span class="token operator">-</span>self<span class="token punctuation">.</span>lr<span class="token operator">*</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_<span class="token punctuation">.</span>T<span class="token punctuation">,</span> x_<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">0.2</span><span class="token operator">*</span>I<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_<span class="token punctuation">.</span>T<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1id="五分析模型训练结果包括训练误差和测试误差">五、分析模型训练结果，包括训练误差和测试误差</h1><h2 id="评估指标计算公式">5.1 评估指标计算公式</h2><p>训练误差是模型关于训练数据集的平均损失；测试误差是模型关于测试数据集的平均损失。计算公式如下：</p><p><span class="math display">\[R_{e m p}(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y,\hat{f}\left(x_{i}\right)\right)\]</span></p><p><span class="math display">\[e_{t e s t}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} L\left(y_{i},\hat{f}\left(x_{i}\right)\right)\]</span></p><p>其中N为训练样本容量，<em>N</em>′为测试样本容量。由于我们在线性回归中使用的是平方损失函数，故上述计算结果又叫均方误差MSE（Mean Squared Error）：</p><p><span class="math display">\[M S E=\frac{1}{m} \sum_{i=1}^{m}\left(y_{\text {test}}^{(i)}-\hat{y}_{\text {test }}^{(i)}\right)^{2}\]</span></p><p>但是，MSE公式有一个问题是会改变量纲。因为公式平方了，我们可以对这个MSE开方，得到第二个评价指标：均方根误差RMSE（Root Mean Squared Error）：</p><p><span class="math display">\[R M S E = \sqrt{M S E}=\sqrt{\frac{1}{m} \sum_{i=1}^{m}\left(y_{\text{test }}^{(i)}-\hat{y}_{\text {test }}^{(i)}\right)^{2}}\]</span></p><p>但是MSE不甚全面，某些情况下决定系数 R2（coefficient ofdetermination）显得尤为有用，它可以看作是MSE的标准化版本，用于更好地解释模型的性能。R2值的定义如下：</p><p><span class="math display">\[R^{2}=1-\frac{\left(\sum_{i=1}^{m}\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}\right)/ m}{\left(\sum_{i=1}^{m}\left(y^{(i)}-\bar{y}\right)^{2}\right) /m}=1-\frac{M S E(\hat{y}, y)}{\operatorname{Var}(y)}\]</span></p><h2 id="误差分析思路">5.2 误差分析思路</h2><p>结合前文的推导分析，我们最终采用的是线性最小二乘法与L2正则化，即alpha取值为1.0的<strong>Ridge回归</strong>，并结合特征工程中特征构建（将<strong>TV<em>radio<strong>，</strong>radio</em>newspaper</strong>作为新的特征），特征选择（加入新的特征，舍弃相关系数较小的newspaper），特征缩放（将TV，radio，newspaper进行开方、平方、三次方等）的思路进行了14种情况的实验，并得出了每一种情况的MSE，RMSE，R<sup>2</sup>。</p><p>所使用的代码为：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data_s<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'TV'</span><span class="token punctuation">,</span><span class="token string">'radio'</span><span class="token punctuation">,</span><span class="token string">'newspaper'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data_s<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'sales'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'MSE=%f'</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token operator">*</span>cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RMSE=%f'</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token operator">*</span>cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_root_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'R2=%f'</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">*</span>cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'r2'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'%'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>clf<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>clf<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="训练结果">5.3 训练结果</h2><p>14种情况的训练误差及测试误差记录在jupyternotebook的ipynb文件中，此处展示其中三种。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028143446583.png"alt="image-20211028143446583" /><figcaption aria-hidden="true">image-20211028143446583</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028143509634.png"alt="image-20211028143509634" /><figcaption aria-hidden="true">image-20211028143509634</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211028144137987.png"alt="image-20211028144137987" /><figcaption aria-hidden="true">image-20211028144137987</figcaption></figure><p>上图所示的第13种情况训练所得模型的各项评估指标最优，故将其model文件保存，助教老师可以使用test.ipynb自动载入模型，并计算出测试误差MSE。</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> joblib<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error model <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pickle'</span><span class="token punctuation">)</span> <span class="token comment">#载入模型</span>data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'5_test.csv'</span><span class="token punctuation">)</span> <span class="token comment">#读入数据</span>data_s <span class="token operator">=</span> <span class="token punctuation">(</span>data<span class="token operator">-</span>data<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>data<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#归一化</span>data_s<span class="token punctuation">[</span><span class="token string">'TV_min'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data_s<span class="token punctuation">[</span><span class="token string">'TV'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token operator">**</span><span class="token number">0.2</span><span class="token punctuation">)</span>data_s<span class="token punctuation">[</span><span class="token string">'TV_radio'</span><span class="token punctuation">]</span><span class="token operator">=</span>data_s<span class="token punctuation">[</span><span class="token string">'TV'</span><span class="token punctuation">]</span><span class="token operator">*</span>data_s<span class="token punctuation">[</span><span class="token string">'radio'</span><span class="token punctuation">]</span>X <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data_s<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'TV_radio'</span><span class="token punctuation">,</span><span class="token string">'TV_min'</span><span class="token punctuation">,</span><span class="token string">'radio'</span><span class="token punctuation">,</span><span class="token string">'newspaper'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data_s<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'sales'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试误差MSE=%f'</span><span class="token operator">%</span>mean_squared_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h1 id="六总结模型训练过程中的收获">六、总结模型训练过程中的收获</h1><h2 id="学习数据分析处理">6.1 学习数据分析处理</h2><p>在进行计算之前，我们首先对数据进行了预处理和分析。首先，我们检查了数据是否缺失。然后，我们画出了散点图，散点图矩阵，相关系数热力图等，分析了销售量和各项广告投入量之间的数据关系，以便于对数据的进一步处理。在对数据的处理中，我们首先进行了数据标准化，将不同量级的数据统一转化为同一量级，以保证数据之间的可比性。而后，我们查阅资料，为了获取更好的训练数据特征，了解了特征工程相关内容，再根据之前对数据的分析，我们对数据进行了特征构建、特征选择等，具体结果上面已经展示。</p><h2 id="加深对十折交叉验证的理解">6.2 加深对十折交叉验证的理解</h2><p>在机器学习的模型选择中，我们要对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。而实际应用中，我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，所以我们随机将数据集切为三部分：训练集，验证集和测试集。在十折交叉验证中，我们通过某种特定的划分，将所有数据划分为十个，并依次选取作为测试集，剩下的作为训练集。在这个过程中，我们加深了对十折交叉验证的理解。</p><h2 id="对于正则化的理解加深">6.3 对于正则化的理解加深</h2><p>正则化的目的：防止过拟合。过拟合指的是给定一堆数据，这堆数据带有噪声，利用模型去拟合这堆数据，可能会把噪声数据也给拟合了，这一方面会造成模型比较复杂，比如，原本一次函数能够拟合的数据，由于数据带有噪声，导致需要用五次函数来拟合；另一方面，同时会导致模型的泛化性能很差，在测试集上的结果准确率非常高，但测试新数据时，因为得到的是过拟合的模型，正确率会很低。</p><p>正则化的本质：约束（限制）要优化的参数。本来<strong>解空间</strong>是全部区域，但通过正则化添加了一些约束，使得解空间变小了，甚至在个别正则化方式下，解变得稀疏了。正如下图所示：</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/1335117-20180708193526314-357302334.png"alt="img" /><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/1335117-20180708194712773-1094778410.png"alt="img" /></p><p>彩色线就是优化过程中遇到的等高线，一圈代表一个目标函数值，圆心就是样本观测值（假设一个样本），半径就是误差值，受限条件就是黑色边界（就是正则化的部分），二者相交处，才是最优参数。</p><p>可以看到，L1 与L2的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性，例如图中的相交点就有w1=0，而更高维的时候除了角点以外，还有很多边的轮廓也是既有很大的概率成为第一次相交的地方，又会产生稀疏性。相比之下，L2就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了。这就从直观上来解释了为什么L1-regularization能产生稀疏性，而L2-regularization 不行的原因了。</p><h2 id="关于算法的择优">6.4 关于算法的择优</h2><p>最开始我们分析结构风险最小化的策略，最小二乘法可能不可逆，同时为了增加模型的泛化能力，我们在损失函数中加入了惩罚项，由于对L1，L2正则化的分析，我们选择L2正则化，经过推导，发现最小二乘法可以直接得到解析解，解决了W系数矩阵非正定问题。由于梯度下降法是通过迭代逼近结果，所以只能得到近似解，所以我们选择最小二乘法来进行计算。</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>逻辑回归模型及lbfgs算法公式推导</title>
    <link href="/2021/10/23/logistic/"/>
    <url>/2021/10/23/logistic/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>机器学习第一次作业记录。小组成员：方桂安，刘玥，周敏。</p><span id="more"></span><h2 id="一描述逻辑回归模型">一、描述逻辑回归模型</h2><h3 id="数据">1.1数据</h3><p><span class="math display">\[D=\{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\},x_i\in\mathbb{R}^n,y_i\in\{0,1\}\]</span></p><h3 id="模型">1.2模型</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235517425.png"alt="image-20211023235517425" /><figcaption aria-hidden="true">image-20211023235517425</figcaption></figure><p>最初模型：</p><p><span class="math display">\[f(x_i)=\omega^Tx_i+b,使得f(x_i)\simeq g(y_i)\]</span></p><p>我们的标记变量y的范围是0或1，所以我们需要一个函数能够将上述x的线性组合转化为0或1，最理想的是阶跃函数。</p><p><span class="math display">\[阶跃函数：y=g^{-1}(\omega^Tx+b)= \begin{cases}0, &amp; \omega^Tx+b&lt;0\\0.5, &amp; \omega^Tx+b=0\\1, &amp; \omega^Tx+b&gt;0\end{cases}\]</span></p><p>但由于阶跃函数不连续，不满足单调可微的条件。所以我们希望通过一个一定程度上近似阶跃函数的“替代函数”，并且希望它单调可微。由此，我们想到了逻辑斯蒂函数。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235558559.png"alt="image-20211023235558559" /><figcaption aria-hidden="true">image-20211023235558559</figcaption></figure><p>它的图像如下：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/1990595-20200922165029694-1712738583.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>因为Logistic回归主要用于分类问题，以二分类为例，对于所给数据集假设存在这样的一条直线可以将数据完成线性可分。<imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/tW5koNMJrG193KEtuAH7cQ.png"alt="img" /></p><p>当我们要找到分类概率 P(Y=1) 与输入向量 x的直接关系时，我们引入Sigmoid函数，然后通过比较概率值来判断类别。</p><p>引入sigmoid函数具体实现如下：</p><p>但因为逻辑斯蒂函数的值域在[0,1]之间，无法直接输出0或1。在此基础上，考虑到<spanclass="math inline">\(\omega^Tx+b\)</span>取值是连续的，因此它不能拟合离散变量。可以考虑用它来拟合条件概率<spanclass="math inline">\(p(y=1|x)\)</span>，因为概率的取值也是连续的,我们将逻辑斯蒂函数的输出作为输入x能预测到y为1的概率，并利用对数几率函数，得到下面三个式子。通过此方法，我们将线性模型转换为概率模型。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235625407.png"alt="image-20211023235625407" /><figcaption aria-hidden="true">image-20211023235625407</figcaption></figure><h3 id="策略">1.3策略</h3><p>在策略上，我们采用极大似然法。即选择最优的w，b使得我们输入x得到的正确的y的概率最大，即下式：</p><p><span class="math display">\[(w^*,b^*)=\mathop{argmax}\limits_{(w,b)}\prod_{i=1}^Np(y_i|x_i;\omega,b)\]</span></p><p>我们这里做一点变换：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235646944.png"alt="image-20211023235646944" /><figcaption aria-hidden="true">image-20211023235646944</figcaption></figure><p>因为上式是连乘的函数，我们通过对数似然函数将之转化为求和，即下式：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235715659.png"alt="image-20211023235715659" /><figcaption aria-hidden="true">image-20211023235715659</figcaption></figure><p>为了方便计算，我们做以下处理</p><p><span class="math display">\[assume \ that\  \hat{\omega}=(\omega;b),\hat{x}=(x;1)\]</span></p><p>则上式可化为</p><p><span class="math display">\[\hat{\omega^*}=\mathop{argmin}\limits_{\hat{\omega}}\sum_{i=1}^N(-y_i\hat{\omega}x_i+ln(1+e^{\hat{\omega}^T\hat{x}_i}))\]</span></p><p>这是一个凸函数，可用经典的数值优化算法，如梯度下降法、牛顿法求解。</p><p>最终，我们学得的逻辑斯蒂回归模型为</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235742051.png"alt="image-20211023235742051" /><figcaption aria-hidden="true">image-20211023235742051</figcaption></figure><h2 id="二描述训练模型所使用的算法">二、描述训练模型所使用的算法</h2><h3 id="梯度下降法">2.1梯度下降法</h3><h4 id="问题分析">2.1.1问题分析</h4><p>首先，我们的目标是下式</p><p><span class="math display">\[E(\hat{\omega})=\sum_{i=1}^N(-y_i\hat{\omega}^T\hat{x}_i+ln(1+e^{\hat{\omega}^T\hat{x}_i})),\hat{\omega}^*=\mathop{argmin}_{\hat{\omega}}E(\hat{\omega})\]</span></p><p>梯度下降法是一种迭代算法：我们选取适当的初始值<spanclass="math inline">\(\hat{\omega}^{(0)}\)</span>，不断迭代，更新<spanclass="math inline">\(\hat{\omega}\)</span>的值，进行目标函数的极小化，直到收敛。由于负梯度方向是使得函数值下降最快的方向，在迭代的每一步，以负梯度方向更新<spanclass="math inline">\(\hat{\omega}\)</span>的值，从而达到减小函数值的目的。如下图形象化表示：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023152139696.png"alt="image-20211023152139696" /><figcaption aria-hidden="true">image-20211023152139696</figcaption></figure><h4 id="核心思想">2.1.2核心思想：</h4><ol type="1"><li><spanclass="math inline">\(E(\hat{\omega})\)</span>是具有一阶连续偏导数的凸函数，其极值点在一阶导数为零的地方取得</li><li>一阶泰勒展开：<spanclass="math inline">\(E(\hat{\omega})\thickapproxE(\hat{\omega}^{(k)})+\nablaE(\hat{\omega}^{(k)})(\hat{\omega}-\hat{\omega}^{(k)})\)</span>，其中，<spanclass="math inline">\(\nabla E(\hat{\omega}^{(k)})\)</span>是<spanclass="math inline">\(E(\hat{\omega})\)</span>在<spanclass="math inline">\(\hat{\omega}^{(k)}\)</span>的梯度：</li></ol><p><span class="math display">\[\nabla E(\hat{\omega}^{(k)})=\frac{\partial E(\hat{\omega})}{\partial\hat{\omega}}|_{\hat{\omega}=\hat{\omega}^{(k)}}\]</span></p><ol start="3" type="1"><li>求取第k+1次迭代值：<spanclass="math inline">\(\hat{\omega}^{k+1}=\hat{\omega}^{(k)}+\eta_k*(-\nablaE(\hat{\omega}^{(k)}))\)</span>，其中<spanclass="math inline">\(\eta_k\)</span>是步长，由我们最初指定。梯度推导：</li></ol><p><span class="math display">\[E(\hat{\omega})=\sum_{i=1}^N(-y_i\hat{\omega}^T\hat{x}_i+ln(1+e^{\hat{\omega}^T\hat{x}_i}))\\\nablaE(\hat{\omega}^{(k)})=\sum_{i=1}^N-y_i\hat{x}_i+\frac{1}{1+e^{\hat{\omega}^T\hat{x}_i}}*e^{\hat{\omega}^T\hat{x}_i}*\hat{x}_i\\=-\sum_{i=1}^Nx_i(y_i-\frac{e^{\hat{\omega}^T\hat{x}_i}}{1+e^{\hat{\omega}^T\hat{x}_i}})\]</span></p><h4 id="伪代码">2.1.3伪代码：</h4><p>输入：目标函数<spanclass="math inline">\(E(\hat{\omega})\)</span>，梯度函数<spanclass="math inline">\(\nablaE(\hat{\omega})\)</span>，计算精度ε，步长<spanclass="math inline">\(\eta_k\)</span>；</p><p>输出： <spanclass="math inline">\(E(\hat{\omega})\)</span>的极小点<spanclass="math inline">\(\hat{\omega}^*\)</span>。</p><p>（1）取初始值<span class="math inline">\(\hat{\omega}^{(0)}\in\mathbb{R}^{d+1}\)</span>，置k=0；</p><p>（2）计算<spanclass="math inline">\(E(\hat{\omega}^{(k)})\)</span>；</p><p>（3）计算梯度<span class="math inline">\(\nablaE(\hat{\omega}^{(k)})\)</span>，当<span class="math inline">\(||\nablaE(\hat{\omega}^{(k)})||&lt;\varepsilon\)</span>时，令<spanclass="math inline">\(\hat{\omega}^*=\hat{\omega}^{(k)}\)</span>，</p><p>停止迭代；</p><p>（4）置<spanclass="math inline">\(\hat{\omega}^{(k+1)}=\hat{\omega}^{(k)}+\eta_k(-\nablaE(\hat{\omega}^{(k)}))\)</span>，计算<spanclass="math inline">\(E(\hat{\omega}^{(k+1)})\)</span>，</p><p>当<spanclass="math inline">\(||E(\hat{\omega}^{(k+1)})-E(\hat{\omega}^{(k)})||&lt;\varepsilon\)</span>或<spanclass="math inline">\(||\hat{\omega}^{(k+1)}-\hat{\omega}^{(k)}||&lt;\varepsilon\)</span>时，</p><p>令<spanclass="math inline">\(\hat{\omega}^*=\hat{\omega}^{(k)}\)</span>，停止迭代；</p><p>（5）否则，置k=k+1，转步骤（3）。</p><h4 id="分析">2.1.4分析</h4><p>优点：方法简单，易理解</p><p>缺点：迭代次数多，下降速度慢，如下图，我们采用梯度下降法，迭代近50000次才收敛</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023152205584.png"alt="image-20211023152205584" /><figcaption aria-hidden="true">image-20211023152205584</figcaption></figure><p>且准确率如下，可以看出准确率不高。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023152217061.png"alt="image-20211023152217061" /><figcaption aria-hidden="true">image-20211023152217061</figcaption></figure><h3 id="牛顿法">2.2牛顿法</h3><h4 id="核心思想-1">2.2.1核心思想：</h4><p><spanclass="math inline">\(E(\hat{\omega})\)</span>是具有二阶连续偏导数的函数</p><p>二阶泰勒展开：<span class="math inline">\(E(\hat{\omega})\thickapproxE(\hat{\omega}^{(k)})+\nablaE(\hat{\omega}^{(k)})(\hat{\omega}-\hat{\omega}^{(k)})+\frac{1}{2}(\hat{\omega}-\hat{\omega}^{(k)})^TH(\hat{\omega}^{(k)})(\hat{\omega}-\hat{\omega}^{(k)})\)</span></p><p><span class="math display">\[\nabla E(\hat{\omega})=\frac{\partial E(\hat{\omega})}{\partial\hat{\omega}}|_{(d+1)\times 1},H(\hat{\omega})=\frac{\partial^2E(\hat{\omega})}{\partial \hat{\omega}_i \partial\hat{\omega}_j}|_{(d+1)\times 1}\]</span></p><p>利用二阶泰勒展开<spanclass="math inline">\(E(\hat{\omega})\)</span>取极小点的必要条件<spanclass="math inline">\(\nablaE(\hat{\omega})=0\)</span>，在第k次迭代<spanclass="math inline">\(\hat{\omega}^{(k)}\)</span>，求<spanclass="math inline">\(\nablaE(\hat{\omega}^{(k)})+H(\hat{\omega}^{(k)})(\hat{\omega}-\hat{\omega}^{(k)})=0\)</span>的点，作为第k+1次迭代值<spanclass="math inline">\(\hat{\omega}^{(k+1)}\)</span></p><h4 id="伪代码-1">2.2.2伪代码</h4><p>输入：目标函数<spanclass="math inline">\(E(\hat{\omega})\)</span>，梯度函数<spanclass="math inline">\(\nabla E(\hat{\omega})\)</span>，海森矩阵<spanclass="math inline">\(H(\hat{\omega})\)</span>，精度ε；</p><p>输出：<spanclass="math inline">\(E(\hat{\omega})\)</span>的极小点<spanclass="math inline">\(\hat{\omega}^*\)</span>。</p><p>（1）取初始值<span class="math inline">\(\hat{\omega}^{(0)}\in\mathbb{R}^{n+1}\)</span>，置k=0；</p><p>（2）计算梯度<span class="math inline">\(\nablaE(\hat{\omega}^{(k)})\)</span>；</p><p>（3）当<spanclass="math inline">\(||E(\hat{\omega}^{(k)})||&lt;\varepsilon\)</span>时，令<spanclass="math inline">\(\hat{\omega}^*=\hat{\omega}^{(k)}\)</span>，停止迭代；</p><p>否则，计算海森矩阵<spanclass="math inline">\(H(\hat{\omega}^{(k)})\)</span> ；</p><p>（4）置<spanclass="math inline">\(\hat{\omega}^{(k+1)}=\hat{\omega}^{(k)}-(H(\hat{\omega}))^{(-1)}\nablaE(\hat{\omega}^{(k)})\)</span>；</p><p>（5）置k=k+1，转步骤（2）。</p><h4 id="分析-1">2.2.3分析</h4><p>牛顿法优点：下降速度快，属于二次收敛</p><p>缺点：海森矩阵计算复杂度高，且要求可逆才能计算，所以我们查阅资料，将采用拟牛顿法。</p><h3 id="bfgs算法">2.3 BFGS算法:</h3><p>由于上述牛顿公式中可以看出，我们的海森矩阵不易得到，因此我们有以下迭代公式来逼近海森矩阵：</p><p><span class="math display">\[H_{k+1}=H_k+\frac{y_ky_k^T}{y_k^Ts_k}-\frac{H_ks_ks_k^TH_k^T}{s_k^TH_k^Ts_k}\]</span></p><p>但计算量还是很大，矩阵相乘太多。所以我们最终采取<spanclass="math inline">\(Sherman-Morrison\)</span>公式进行变换可得：</p><p><span class="math display">\[H_{k+1}=\left(I-\frac{s_{k} y_{k}^{T}}{y_{k}^{T} s_{k}}\right)H_{k}\left(I-\frac{y_{k} s_{k}^{T}}{y_{k}^{T} s_{k}}\right)+\frac{s_{k}s_{k}^{T}}{y_{k}^{T}s_{k}} \quad(1)\]</span></p><p>公式推导如下：</p><p><span class="math display">\[\begin{array}{l}\text { Sherman Morrison 公式: }\\\left(\mathrm{A}+\frac{u u^{T}}{t}\right)^{-1}=A^{-1}-\frac{A^{-1} uu^{T} A^{-1}}{t+u^{T} A^{-1} u}\\\left(\mathrm{H}+\frac{y y^{T}}{y^{T} \mathrm{~s}}-\frac{H s s^{T}\mathrm{H}}{s^{T} H s}\right)^{-1}\\=\left(\mathrm{H}+\frac{y y^{T}}{y^{T}\mathrm{~s}}\right)^{-1}+\left(\mathrm{H}+\frac{y y^{T}}{y^{T}\mathrm{~s}}\right)^{-1} \frac{H s s^{T} H}{s^{T} H^{T} s-s^{T}H\left(\mathrm{H}+\frac{y y^{T}}{y^{T} \mathrm{~S}}\right)^{-1}\mathrm{Hs}}\left(\mathrm{H}+\frac{y y^{T}}{y^{T}\mathrm{~S}}\right)^{-1}\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} S+y^{T} H^{-1}y}\right)+\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} S+y^{T} H^{-1}y}\right) \frac{H s s^{T} H}{s^{T} H S-s^{T} H\left(H^{-1}-\frac{H^{-1}y y^{T}-1}{y^{T} s+y^{T} H^{-1} y}\right) H s}\left(H^{-1}-\frac{H^{-1}y y^{T} H^{-1}}{y^{T} S+y^{T} H^{-1} y}\right)\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T}H^{-1} y}\right)+\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T}\mathrm{~s}+y^{T} H^{-1} y}\right) \frac{H s s^{T} H}{\frac{s^{T} yy^{T} s}{y^{T} \mathrm{~s}+y^{T} H^{-1} y}}\left(H^{-1}-\frac{H^{-1} yy^{T} H^{-1}}{y^{T} \mathrm{~S}+y^{T} H^{-1} y}\right)\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T}H^{-1} y}\right)+\frac{H^{-1} H s s^{T} H H^{-1}}{\frac{s^{T} y y^{T}S}{y^{T} s+y^{T} H^{-1} y}}-\frac{H^{-1} H s s^{T} H}{\frac{s^{T} yy^{T} s}{}}{y^{T} \mathrm{~s}+y^{T} H^{-1} y} H^{-1} \frac{yy^{T}}{y^{T} \mathrm{~s}+y^{T} H^{-1} y} H^{-1}\\-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T} H^{-1} y} \frac{Hs s^{T} H}{\frac{s^{T} y y^{T} S}{y^{T} \mathrm{~s}+y^{T} H^{-1} y}}H^{-1}\\+H^{-1} \frac{y y^{T}}{y^{T} \mathrm{~s}+y^{T} H^{-1} y} H^{-1} \frac{Hs s^{T} H}{\frac{s^{T} y y^{T} S}{y^{T} \mathrm{~s}+y^{T} H^{-1} y}}H^{-1} \frac{y y^{T}}{y^{T} \mathrm{~s}+y^{T} H^{-1} y} H^{-1}\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T}H^{-1} y}\right)+\frac{s s^{T}\left(y^{T} \mathrm{~s}+y^{T} H^{-1}y\right)}{s^{T} y y^{T} s}-\frac{s s^{T} y y^{T} H^{-1}}{s^{T} y y^{T}S}-\frac{H^{-1} y y^{T} S S^{T}}{s^{T} y y^{T} S}\\+\frac{H^{-1} y y^{T} S s^{T} y y^{T} H^{-1}}{\left(y^{T}\mathrm{~s}+y^{T} H^{-1} y\right) s^{T} y y^{T} S}\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T}H^{-1} y}\right)+\frac{s s^{T}\left(y^{T} \mathrm{~s}+y^{T} H^{-1}y\right)}{\left(s^{T} y\right)^{2}}-\frac{s\left(s^{T} y\right) y^{T}H^{-1}}{\left(s^{T} y\right)^{2}}-\frac{H^{-1} y\left(y^{T} s\right)s^{T}}{\left(s^{T} y\right)^{2}}\\+\frac{H^{-1} y\left(y^{T} S s^{T} y\right) y^{T} H^{-1}}{\left(y^{T}\mathrm{~s}+y^{T} H^{-1} y\right) s^{T} y y^{T} S}\\=\left(H^{-1}-\frac{H^{-1} y y^{T} H^{-1}}{y^{T} \mathrm{~s}+y^{T}H^{-1} y}\right)+\frac{s s^{T}\left(y^{T} \mathrm{~s}+y^{T} H^{-1}y\right)}{\left(s^{T} y\right)^{2}}-\frac{s y^{T} H^{-1}}{s^{T}y}-\frac{H^{-1} y s^{T}}{s^{T} y}+\frac{H^{-1} y y^{T}H^{-1}}{\left(y^{T} \mathrm{~s}+y^{T} H^{-1} y\right)}\\=H^{-1}+\frac{s s^{T}\left(y^{T} \mathrm{~s}+y^{T} H^{-1}y\right)}{\left(s^{T} y\right)^{2}}-\frac{s y^{T} H^{-1}}{s^{T}y}-\frac{H^{-1} y s^{T}}{s^{T} y}\\=H^{-1}+\frac{s s^{T} y^{T} \mathrm{~s}}{\left(s^{T}y\right)^{2}}+\frac{s s^{T} y^{T} H^{-1} y}{\left(s^{T}y\right)^{2}}-\frac{s y^{T} H^{-1}}{s^{T} y}-\frac{H^{-1} y s^{T}}{s^{T}y}\\=H^{-1}\left(I-\frac{y s^{T}}{s^{T} y}\right)-\frac{s y^{T}H^{-1}}{s^{T} y}\left(I-\frac{y s^{T}}{s^{T} y}\right)+\frac{ss^{T}}{s^{T} y}\\=\left(I-\frac{s y^{T}}{s^{T} y}\right) H^{-1}\left(I-\frac{ys^{T}}{s^{T} y}\right)+\frac{s s^{T}}{s^{T} y}\end{array}\]</span></p><h3 id="l-bfgs算法">2.4 L-BFGS算法</h3><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235811630.png"alt="image-20211023235811630" /><figcaption aria-hidden="true">image-20211023235811630</figcaption></figure>$$<span class="math display">\[\begin{array}{c}H_{k+1}=V_{k}^{T} H_{k} V_{k}+\rho_{k} s_{k} s_{k}^{T} \\\end{array}\]</span><p>$$</p><p>给定初始矩阵<spanclass="math inline">\(H_0=I\)</span>，利用上式，可得：</p><p><span class="math display">\[\begin{aligned}H_{1}&amp;=V_{0}^{T} H_{0} V_{0}+\rho_{0} s_{0} s_{0}^{T}\\H_{2} &amp;=V_{1}^{T} H_{1} V_{1}+\rho_{1} s_{1} s_{1}^{T} \\&amp;=V_{1}^{T}\left(V_{0}^{T} H_{0} V_{0}+\rho_{0} s_{0}s_{0}^{T}\right) V_{1}+\rho_{1} s_{1} s_{1}^{T} \\&amp;\left.=V_{1}^{T} V_{0}^{T} H_{0} V_{0} V_{1}+V_{1}^{T} \rho_{0}s_{0} s_{0}^{T}\right) V_{1}+\rho_{1} s_{1} s_{1}^{T} \\&amp; \\\quad H_{k+1} &amp;=\left(V_{k}^{T} V_{k-1}^{T} \ldots V_{1}^{T}V_{0}^{T}\right) H_{0}\left(V_{0} V_{1} \ldots V_{k-1} V_{k}\right) \\&amp;+\left(V_{k}^{T} V_{k-1}^{T} \ldots V_{1}^{T}\right) \rho_{1} s_{1}s_{1}^{T}\left(V_{1} \ldots V_{k-1} V_{k}\right) \\&amp;+\ldots \\&amp;+\left(V_{k}^{T}\right) \rho_{k-1} s_{k-1}s_{k-1}^{T}\left(V_{k}\right) \\&amp;+\rho_{k} s_{k} s_{k}^{T}\end{aligned}\]</span></p><p>只保留最近的m步后，上式的迭代公式变为：</p><p><span class="math display">\[\begin{aligned}H_{k+1} &amp;=\left(V_{k}^{T} V_{k-1}^{T} \ldots V_{k-m}^{T}\right)H_{0}\left(V_{k-m} \ldots V_{k-1} V_{k}\right) \\&amp;+\left(V_{k}^{T} V_{k-1}^{T} \ldots V_{k-m+1}^{T}\right) \rho_{k-m}s_{k-m} s_{k-m}^{T}\left(V_{k-m+1} \ldots V_{k-1} V_{k}\right) \\+&amp; \ldots \\&amp;+\left(V_{k}^{T}\right) \rho_{k-1} s_{k-1}s_{k-1}^{T}\left(V_{k}\right) \\&amp;+\rho_{k} s_{k} s_{k}^{T}\end{aligned}\]</span></p><p>所求方向为：</p><p><span class="math display">\[\begin{aligned}H_{k} \nabla f &amp;=\left(V_{K-1}^{T} V_{K-2}^{T} \ldotsV_{K-m}^{T}\right) H_{0}\left(V_{K-m} V_{K-m+1} \ldots V_{K-1}\right)\nabla f \\&amp;+\left(V_{K-1}^{T} \ldots V_{K-m+1}^{T}\right)\rho_{k-m} s_{k-m}s_{k-m}^T(V_{k-m+1}\dots V_{k-1}V_{k}) \nabla f\\&amp;+\ldots \\&amp;+V_{k-1} \rho_{k-1} s_{k-1}s_{k-1}^TV_k\nabla f \\&amp;+\rho_{k} s_{k}s_{k}^T\nabla f\end{aligned}\]</span></p><p>Two-Loop 算法：</p><p><span class="math display">\[\begin{array}{l}q_{k} \leftarrow \nabla f_{k} \\\text { for } i=k-1 \text { to } k-m \text { do } \\\quad \alpha_{i}=\rho_{i} s_{i}^{T} q_{i+1} \\q_{i}=q_{i+1}-\alpha_{i} y_{i} \\\text { end for } \\r_{k-m-1}=H_{0} q_{k-m} \\\text { for } i=k-m, k-m+1 \text { to } k-1 \text { do } \\\quad \beta_{i}=\rho_{i} y_{i}^{T} r_{i-1} \\r_{i}=r_{i-1}+s_{i} \alpha_{i}-\beta_{i} \\\text { end for } \\\text { End, The result is } H_{k+1} \nabla f=r\end{array}\]</span></p><p>Two-Loop算法解析---第一个循环：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235846434.png"alt="image-20211023235846434" /><figcaption aria-hidden="true">image-20211023235846434</figcaption></figure><p>重写公式：</p><p><span class="math display">\[\begin{aligned}H_{k} \nabla f &amp;=\left(V_{K-1}^{T} V_{K-2}^{T} \ldotsV_{K-m}^{T}\right) H_{0}\left(V_{K-m} V_{K-m+1} \ldots V_{K-1}\right)\nabla f \\&amp;+\left(V_{K-1}^{T} \ldots V_{K-m+1}^{T}\right) s_{k-m} \alpha_{k-m}\\&amp;+\ldots \\&amp;+V_{k-1} s_{k-1} \alpha_{k-2} \\&amp;+s_{k-1} \alpha_{k-1}\end{aligned}\]</span></p><p>Two-Loop算法解析---第二个循环：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023235910775.png"alt="image-20211023235910775" /><figcaption aria-hidden="true">image-20211023235910775</figcaption></figure><p>初始:</p><p><span class="math display">\[r_{k-\mathrm{m}}=V_{k-\mathrm{m}} H_{0} V_{k-\mathrm{m}}V_{k-\mathrm{m}+1} \ldots V_{k-1} \nabla\mathrm{f}+\mathrm{s}_{k-\mathrm{m}} \alpha_{k-m}\]</span></p><p>得：</p><p><span class="math display">\[\begin{aligned}r_{k-\mathrm{m}+\mathrm{i}} &amp;=V_{k-\mathrm{m}+\mathrm{i}} \ldotsV_{k-\mathrm{m}} H_{0} V_{k-\mathrm{m}} \ldotsV_{k-\mathrm{m}+\mathrm{i}} \nabla \mathrm{f} \\&amp;+\left(V_{k-\mathrm{m}+\mathrm{i}} \ldots V_{k-\mathrm{m}+1}\right)\mathrm{s}_{k-\mathrm{m}} \alpha_{k-m} \\&amp;+\left(V_{k-\mathrm{m}+\mathrm{i}} \ldots V_{k-\mathrm{m}+2}\right)\mathrm{s}_{k-\mathrm{m}+1} \alpha_{k-m+1}\\&amp;+\dots\\&amp;s_{k-m+1}\alpha_{k-m+i}\end{aligned}\]</span></p><p><span class="math inline">\(r_{k-1}\)</span>即是所求的搜索方向d。</p><p>使用LBFGS求解逻辑回归模型代码如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment"># 进一步处理数据集和测试集，将输入和输出分割</span>train<span class="token punctuation">.</span>columns<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">,</span><span class="token string">'x2'</span><span class="token punctuation">,</span><span class="token string">'y'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>test<span class="token punctuation">.</span>columns<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">,</span><span class="token string">'x2'</span><span class="token punctuation">,</span><span class="token string">'y'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>train<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">,</span> <span class="token string">'x2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>train<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>test<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">,</span> <span class="token string">'x2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>test<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 使用 sklearn 的 LogisticRegression 作为模型</span><span class="token comment"># 其中有 penalty，solver，multi_class 几个比较重要的参数，不同的参数有不同的准确率</span>model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>solver<span class="token operator">=</span><span class="token string">'newton-cg'</span><span class="token punctuation">)</span><span class="token comment"># newton-cg sag lbfgs liblinear</span><span class="token comment"># 对数据进行标准化</span>ss <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train <span class="token operator">=</span> ss<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span> X_test <span class="token operator">=</span> ss<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token comment"># 拟合</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token comment"># 预测测试集</span>predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token comment"># 打印准确率</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集准确率：'</span><span class="token punctuation">,</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">)</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>column_stack<span class="token punctuation">(</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>intercept_<span class="token punctuation">,</span> model<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#print(weights)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="三绘制roc曲线和pr曲线">三、绘制ROC曲线和PR曲线</h2><div class="code-wrapper"><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown">该部分出现的英语缩写：TP: True PositiveFP: False PositiveFN: False NegativeTN: True NegativeP: PrecisionR: RecallTPR: True Positive RateFPR: False Positive Rate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="roc曲线">3.1 ROC曲线</h3><h4 id="介绍">3.1.1介绍</h4><p>ROC全称是“受试者工作特征”(Receiver OperatingCharacteristic)曲线，它源于“二战”中用于敌机检测的雷达信号分析技术，二十世纪六七十年代开始被用于一些心理学、医学检测应用中，此后被引入机器学习领域，用来评判分类、检测结果的好坏。因此，ROC曲线是非常重要和常见的统计分析方法。</p><p>为了绘制ROC曲线，我们需要计算出两个重要量的值（</p><p><strong>TPR</strong>、<strong>FPR</strong>），分别以它们为横、纵坐标作图。其中的TP、FP、TN、FN来自于<strong>混淆矩阵</strong>，且TP+FP+TN+FN=样本总数。</p><p><span class="math display">\[TPR=\frac{TP}{TP+FN}\]</span></p><p><span class="math display">\[FPR=\frac{FP}{FP + TN}\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023004557339.png"alt="image-20211023004557339" /><figcaption aria-hidden="true">image-20211023004557339</figcaption></figure><h4 id="画图流程">3.1.2画图流程</h4><ol type="1"><li>给定m+个正例和m-个负例，根据学习器预测结果对样例进行排序</li><li>然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为0，在坐标(0,0)处标记一个点</li><li>将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例，设前一个标记点坐标为(x,y)，当前若为真正例，则对应标记点的坐标为<spanclass="math inline">\(\left ( x,y+\frac{1}{m^{+}} \right)\)</span>；当前若为假正例，则对应标记点的坐标为<spanclass="math inline">\(\left ( x+\frac{1}{m^{-}},y \right )\)</span></li><li>最后用线段连接相邻点</li></ol><h4 id="auc分析">3.1.3 AUC分析</h4><p>ROC曲线下方的面积也有着重要意义（英语：Area under the Curve of ROC(AUC ROC)），其意义是：</p><ul><li>因为是在1x1的方格里求面积，AUC必在0~1之间。</li><li>假设阈值以上是正例，以下是反例；</li><li>简单说：<strong>AUC值越大的分类器，正确率越高。</strong></li></ul><p>从AUC判断分类器（预测模型）优劣的标准：</p><ul><li>AUC =1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。</li><li>0.5 &lt; AUC &lt;1，优于随机猜测。这个分类器（模型）妥善设置阈值的话，能有预测价值。</li><li>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</li><li>AUC &lt;0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</li></ul><p>假设ROC曲线由为{ ( x1,y1 ),⋯,( xN′,yN′ )}的点按需连接而成且有x<sub>1</sub>=0,x<sub>N'</sub>=1，则AUC可估算为：</p><p><span class="math display">\[AUC=\frac{1}{2} \sum_{j=1}^{N{}&#39;-1} \left ( x_{j+1}-x_{j}  \right )\left ( y_{j+1}+y_{j}  \right )\]</span></p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023143342594.png"alt="image-20211023143342594" /><figcaption aria-hidden="true">image-20211023143342594</figcaption></figure><p>如图即为使用本次作业所提供数据绘制的ROC曲线。由于测试样例有限，所以仅能获得有限个（真正例率，假正例率）坐标对，无法产生光滑的ROC曲线；由此计算得到的AUC的值为0.9648，可以得知该模型的性能较优。</p><p>完整代码如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_roc</span><span class="token punctuation">(</span>confidence_scores<span class="token punctuation">,</span> data_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#真正率，假正率</span>    fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>data_labels<span class="token punctuation">,</span> confidence_scores<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'ROC Curve'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'FPR'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'TPR'</span><span class="token punctuation">)</span>     <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> auc    auc<span class="token operator">=</span>auc<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">)</span> <span class="token comment">#AUC计算</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span>tpr<span class="token punctuation">,</span><span class="token string">'k--'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'roc_curve(AUC=%0.4f)'</span> <span class="token operator">%</span> auc<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="pr曲线">3.2 PR曲线</h3><h4 id="介绍-1">3.2.1介绍</h4><p>PR曲线全称为查准率-查全率曲线，查准率P与查全率R分别定义为：</p><p><span class="math display">\[P=\frac{TP}{TP+FP}，R=\frac{TP}{TP+FN}\]</span></p><p>查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。</p><h4 id="画图流程-1">3.2.2画图流程</h4><p>绘制PR曲线的流程与ROC曲线类似，我们需要根据学习器的预测结果按正例可能性大小对样例进行排序，再逐个样本的选择阈值，在该样本之前的都属于正例，该样本之后的都属于负例。每一个样本作为划分阈值时，都可以计算对应的precision和recall，那么就可以以此绘制曲线。</p><h4 id="ap分析">3.2.3 AP分析</h4><p>其中平衡点是曲线上“查准率=查全率”时的取值，可用于度量PR曲线有交叉的分类器性能高低。与AUC类似，PR曲线下方面积也有重要意义。PR曲线下的面积称之为AP(AveragePrecision)，通常来说一个越好的分类器，AP值越高。</p><p>对于连续的PR曲线，有：</p><p><span class="math display">\[AP=\int_{0}^{1} p\left ( r \right ) \mathrm{d}r\]</span></p><p>但由于曲线可能出现不可导的部分，故我们常常求其近似值：</p><p><span class="math display">\[p_{\text {interp }}(r)=\max _{\tilde{r} \geq r} p(\tilde{r})\]</span></p><p>对于离散的PR曲线，有：</p><p><span class="math display">\[\mathrm{AP}=\sum_{k=1}^{n} p(k) \Delta r(k)\]</span></p><p>另外PR曲线平衡点更用常用的是F1度量：</p><p><span class="math display">\[F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { 样例总数}+T P-T N}\]</span></p><p>比F1度量更一般的形式是F<sub>β</sub>：</p><p><span class="math display">\[F_{\beta}=\frac{\left(1+\beta^{2}\right) \times P \timesR}{\left(\beta^{2} \times P\right)+R}\]</span></p><ul><li>β=1：标准F1</li><li>β&gt;1：偏重查全率（逃犯信息检索）</li><li>β&lt;1：偏重查准率（商品推荐系统）</li></ul><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211023150341520.png"alt="image-20211023150341520" /><figcaption aria-hidden="true">image-20211023150341520</figcaption></figure><p>如图即为使用本次作业所提供数据绘制的PR曲线。在现实任务中，PR曲线是非单调、不平滑的，在很多局部有上下波动；由此计算得到的AP的值为0.9751，可以得知该模型的性能较优。</p><p>完整代码如下：</p><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_pr</span><span class="token punctuation">(</span>confidence_scores<span class="token punctuation">,</span> data_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'PR Curve'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Recall'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Precision'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">#精确率，召回率，阈值</span>    precision<span class="token punctuation">,</span>recall<span class="token punctuation">,</span>thresholds <span class="token operator">=</span> precision_recall_curve<span class="token punctuation">(</span>data_labels<span class="token punctuation">,</span>confidence_scores<span class="token punctuation">)</span>     <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> average_precision_score    AP <span class="token operator">=</span> average_precision_score<span class="token punctuation">(</span>data_labels<span class="token punctuation">,</span> confidence_scores<span class="token punctuation">)</span> <span class="token comment"># 计算AP</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>recall<span class="token punctuation">,</span> precision<span class="token punctuation">,</span><span class="token string">'k--'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'pr_curve(AP=%0.4f)'</span> <span class="token operator">%</span> AP<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h2 id="四总结模型训练过程中的收获">四、总结模型训练过程中的收获</h2><h3 id="加深了对逻辑斯蒂回归的理解">4.1加深了对逻辑斯蒂回归的理解</h3><h4 id="简述对模型的理解">4.1.1简述对模型的理解：</h4><p>因为线性回归模型产生的预测值是一系列实值。为了使得输出的预测结果变成分类所需的0和1，我们需要在线性回归的基础式子外再套一个函数将其输出变成0和1，又要求该函数单调可微，所以我们引入logistic函数，将输出的预测结果成功转为概率值。这样，逻辑斯蒂回归模型被成功应用于解决分类模型。</p><h4 id="关于算法的择优">4.1.2关于算法的择优：</h4><p>在代码实现过程中，我们最开始使用的是梯度下降法，但是迭代速度较慢，拟合效果不是很好；之后我们选择了牛顿法，但是因为计算海森矩阵的复杂度太高，我们选择用一种拟牛顿法——‘L-BFGS’来逼近海森矩阵，最终达到了我们理想的效果。</p><p>梯度下降法和牛顿法/拟牛顿法相比，两者都是迭代求解，不过梯度下降法是梯度求解，而牛顿法/拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快。</p><h3 id="实现了代码技能的提升">4.2实现了代码技能的提升</h3><p>在代码实现过程中，我们调用了机器学习工具包sklearn中的重要函数——LogisticRegression函数，熟悉了它的常用参数及意义，下面以表格形式列出我们在此次模型训练中使用到的参数。</p><table><colgroup><col style="width: 2%" /><col style="width: 50%" /><col style="width: 46%" /></colgroup><thead><tr class="header"><th>参数</th><th>意义</th><th>备注</th></tr></thead><tbody><tr class="odd"><td>penalty</td><td>str类型，可选项有{‘L1’,‘L2’}，用来确定惩罚项的规范。‘newton-cg’，‘sag’和‘lbfgs’仅支持‘L2’惩罚项。</td><td>该参数是为了添加惩罚项，避免过拟合，用以提高函数的泛化能力。我们在本次模型训练中使用的是‘L2’。</td></tr><tr class="even"><td>solver</td><td>可选的优化算法有{‘newton-cg’，‘lbfgs’,‘liblinear’,‘sag’}</td><td>小数据集中，liblinear是一个好选择，sag和saga对大数据更快；多分类问题中，除了liblinear其它四种算法都可以使用；newton-cg，lbfgs和sag仅能使用L2惩罚项；我们经过对比，选择的算法是lbfgs。</td></tr><tr class="odd"><td>multi_class</td><td>str类型，可选参数有{‘ovr’，‘multinomial’}如果是二元分类问题则两个选项一样，如果是多元分类则ovr将进行多次二分类，分别为一类别和剩余其它所有类别;multinomial则分别进行两两分类，需要T(T-1)/2次分类。</td><td>在多分类中，ovr快，精度低; multinomial慢，精度高。</td></tr></tbody></table><h3id="提高了公式推导和文章排版能力">4.3提高了公式推导和文章排版能力</h3><p>报告中的所有公式，我们都脚踏实地，一步步手动推导，并学习使用latex将其手动输入并排版。在这个过程中，我们对算法中公式的来源更加清楚，对其原理理解更加深透。这提高了我们的公式推导能力和文章排版能力。</p><h3id="锻炼了小组合作精神提高了小组合作能力">4.4锻炼了小组合作精神，提高了小组合作能力</h3><p>在正式写报告之前，我们对本次作业任务以及对逻辑斯蒂回归模型的理解进行了讨论；然后为了加深彼此对知识的掌握程度，每个人都对代码进行了独立编写，在实现的过程中探讨互助；最后，我们根据彼此的优势项对任务进行了分工合作，齐心协力创作出了这份尽可能完善的报告。</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>typora+picgo+github(cdn)高效写作[gitee达咩]</title>
    <link href="/2021/10/20/picgo/"/>
    <url>/2021/10/20/picgo/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>解决hexo博客图片上传问题</p><span id="more"></span><p>Markdown是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。</p><p>Markdown 语言在 2004 由约翰·格鲁伯（英语：John Gruber）创建。</p><p>Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub等多种格式的文档。</p><p>Markdown 编写的文档后缀为 <strong>.md</strong>,<strong>.markdown</strong>。</p><hr /><p><a href="https://typora.io/">Typora</a> gives you a seamlessexperience as both a reader and a writer.</p><p>It removes the preview window, mode switcher, syntax symbols of</p><p>markdown source code, and all other unnecessary distractions.Instead,</p><p>it provides a real live preview feature to help you concentrate onthe content itself.</p><hr /><p>懒得解释了，总之markdown真好用，typorayyds！（正式版开始收费了，但还是很良心）</p><p>但是一直以来我都觉得写blog是个很痛苦的过程，除了因为我懒，就是每次都得一张一张上传图片，所以迟迟未更新。</p><p>直到我使用了typora+picgo+gitee这一组合。</p><hr /><p><a href="https://github.com/PicGo/">Picgo</a>的GitHub页面上包含了<ahref="https://github.com/PicGo/PicGo-Core">core</a>，<ahref="https://github.com/PicGo/vs-picgo">vscode的扩展版</a>和各种各样<ahref="https://github.com/PicGo/Awesome-PicGo">awesome的插件</a>。</p><p>不过我选择的是编译好的<ahref="https://github.com/Molunerfinn/PicGo/releases">发行版程序</a>。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020213735806.png"alt="image-20211020213735806" /><figcaption aria-hidden="true">image-20211020213735806</figcaption></figure><p>安装过程中没什么需要注意的，总之就是一路点下去。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020213944319.png"alt="image-20211020213944319" /><figcaption aria-hidden="true">image-20211020213944319</figcaption></figure><p>打开后应该是一个这样的界面，我首先排除GitHub和Imgur了，毕竟不能保证每一位用户都科学上网。</p><p>接下来我根据网上的教程按顺序尝试了SMMS，七牛云，又拍云···</p><p>第一个配置好上传不了，后面俩配置得也很完美，什么域名绑定，cdn加速···结果本地图片显示，上传到博客上就显示不了了，原因不得而知。</p><p>最后我选择了免费，访问速度还快的Gitee。</p><p>首先在插件设置中搜索并下载：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020215002022.png"alt="image-20211020215002022" /><figcaption aria-hidden="true">image-20211020215002022</figcaption></figure><p>如果没有Gitee账户，先进行<a href="https://gitee.com/">注册</a>。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020220550100.png"alt="image-20211020220550100" /><figcaption aria-hidden="true">image-20211020220550100</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020220758789.png"alt="image-20211020220758789" /><figcaption aria-hidden="true">image-20211020220758789</figcaption></figure><p>记好我红框出来的内容，然后到个人设置里生成私人令牌。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020221019061.png"alt="image-20211020221019061" /><figcaption aria-hidden="true">image-20211020221019061</figcaption></figure><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020221038756.png"alt="image-20211020221038756" /><figcaption aria-hidden="true">image-20211020221038756</figcaption></figure><p>描述由你决定，只需要选择图中两项，然后把令牌<strong>复制</strong>好备用。（关闭之后就不再明文显示了！）</p><p>最后在picgo中填好各项参数：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020221334908.png"alt="image-20211020221334908" /><figcaption aria-hidden="true">image-20211020221334908</figcaption></figure><p>把gitee设置为默认图床之后至此已经可以使用Ctrl+C复制图片，Ctrl＋Shift＋P上传至图床，Ctrl+V粘贴到typora中。</p><p>为了简化操作，可以在typora的偏好设置中进行如下修改：</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211020222002514.png"alt="image-20211020222002514" /><figcaption aria-hidden="true">image-20211020222002514</figcaption></figure><p>（顺便验证一下成功与否）</p><p>大功告成，从此写作可以完全抛弃图片的苦恼，一键上传，so easy~</p><p>另外推荐两个我常常使用的图片<ahref="https://bigjpg.com/">无损放大</a>和<ahref="https://www.picdiet.com/zh-cn">无损压缩</a>的网站。</p><p>虽然自动化上传之后我就不会去调整图片的大小了······</p><hr /><h1 id="更新">2022.3.30更新</h1><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330110138852.png"alt="image-20220330110138852" /><figcaption aria-hidden="true">image-20220330110138852</figcaption></figure><p>图片不能显示几天了，还以为是我网络环境不好。上了知乎才知道，原来gitee直接把外链屏蔽了，甚至把所有图片替换成他们的logo，气抖冷！</p><p>只能连夜把我200多张图片下载然后上传到GitHub，重新配置好picgo，再把以往所有文章的图片链接前缀替换了。</p><p>GitHub在picgo里自带，不需要插件，配置方法跟上面大同小异，我就不重新写一遍了。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20220330110738648.png"alt="image-20220330110738648" /><figcaption aria-hidden="true">image-20220330110738648</figcaption></figure><p>设定仓库名：用户名/新建的仓库名</p><p>设定分支名：master或者main均可</p><p>设定Token：类似于gitee</p><p>存储路径：仓库里的文件夹名，可任取，上传后会自动生成目录</p><p><strong>设定自定义域名</strong>：虽然可以用GitHub的前缀，但由于考虑到访问速度问题，故采取国内cdn加速的方法解决，格式如下：</p><p>https://cdn.jsdelivr.net/gh/用户名/新建的仓库名@分支名</p>]]></content>
    
    
    
    <tags>
      
      <tag>写作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用搜索算法解决八数码问题</title>
    <link href="/2021/10/19/8puzzle/"/>
    <url>/2021/10/19/8puzzle/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>人工智能导论作业记录。</p><span id="more"></span><h2 id="一问题描述与分析">一、问题描述与分析</h2><p>八数码问题就是在一个大小为3×3的九宫格上,放置8块编号为1-8的木块，九宫格中有一个空格，周围(上下左右)的木块可以和空格交换位置。对于问题，给定一个初始状态，目标状态是期望达到1-8顺序排列的序列，并且空格在右下角，问题的实质就是寻找一个合法的移动序列。</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204607.png" /></p><p>不是每一个给定的初始状态都存在解，在分析之前，引入线性代数中的几个概念：</p><ul><li><p>逆序数：在一个排列中，如果一对数字的前后位置与大小顺序相反，即前面的数大于后面的数，那么它们就称为一个逆序。一个排列中序的总数就称为这个排列的逆序数。</p></li><li><p>奇排列：逆序数为奇数的排列称为奇排列</p></li><li><p>偶排列：逆序数为偶数的排列称为偶排列</p><p>使用线性代数理论可以得知，对于任意目标状态，只有初始状态的逆序数和目标状态的逆序数的奇偶性相同才有解(逆序数计算不包括0的逆序数)。</p><p>证明：</p><p>∵八数码问题每一个步骤都可以视作 0 的移动， 0的移动至多有四个可能的方向 又∵ 0 是序列中最小的数，序列的奇偶性不会跟随0 的移动而改变 且对于其余数字而言，要么与 0 互换，要么跨过两个数字和 0互换 ∴逆序数的改变只有变化为 0、 -2、 +2 这三种情况又∵奇数±偶数=奇数，偶数±偶数=偶数∴序列在变换过程中，它的奇偶性不会发生改变∴如果初始序列和目标序列不是同为奇排列或者偶排列，那么这个八数码问题就是无解的。</p></li></ul><p>以图中所给状态为例，初始状态的逆序数t=0+6+5+1+2+1+1=16，目标状态的逆序数t'=0，故有解。</p><h2 id="二深度优先遍历搜索dfs">二、深度优先遍历搜索(DFS)</h2><h3 id="算法介绍">2.1算法介绍</h3><p><strong>深度优先搜索算法</strong>（英语：Depth-First-Search，DFS）是一种用于遍历或搜索树或图的算法。这个算法会尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止，属于盲目搜索。以下图为例，DFS方法首先从根节点1开始，其最终得到的遍历顺序是“1-2-3-4-5-6-7-8-9-10-11-12”。（假定左分枝和右分枝中优先选择左分枝）</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204640.png" /></p><p>我们将其应用于八数码问题的解决。解八数码问题实际上就是找出从初始状态到达目标状态所经过的一系列中间过渡状态。前文提到DFS遍历的树是已经存在的，我们只需要按照规定的遍历方法就能完成遍历，而对于八数码问题，没有已经存在的路径供我们遍历，需要我们从初始状态向下延伸（也就是上下左右移动）才能构造出类似的树。</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204711.png" /></p><p>以上图为例。在使用DFS进行搜索时，每个状态都会按照一定的顺序进行上下左右移动（在上图中是下、左、右、上的顺序），一次移动后会产生一个新的状态，然后以新状态为起点继续按约定的顺序（例如先向下）移动。终止的条件是找到解或者达到深度界限。那么如果按照图中下、左、右、上的顺序搜索后的结果将会是最左边的一条路一直是优先向下移动，如果不能向下则依次会是左、右、上的一种。</p><h3 id="实验代码">2.2实验代码</h3><div class="code-wrapper"><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;初始状态压入队列    D_open.push(new borad(NULL, start, 0, INT_MAX - 1));    printf(&quot;DFS：\n&quot;);    while (!D_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad *cur &#x3D; D_open.top();           D_open.pop();        &#x2F;&#x2F;if (cur-&gt;depth &#x3D;&#x3D; 5) &#123;        &#x2F;&#x2F;    break;        &#x2F;&#x2F;&#125;        &#x2F;&#x2F;与目标状态的距离，为0即到达目标状态        if (hn(cur-&gt;status, target) &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%d\n目标状态深度为%d\n\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad *temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, INT_MAX - 1);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                D_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="实验结果">2.3实验结果</h3><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204805.png" /></p><p>如图所示，深度优先算法在解决八数码问题时有一个致命缺点，就是必须设置一个深度界限，否则，搜索会一直沿着纵深方向发展，会一直无法搜索到解路径。即使加了限制条件，搜索到了解路径，解路径也不一定是最优解路径。</p><h3 id="实验总结">2.4实验总结</h3><ul><li>缺点：如果目标节点不在搜索进入的分支上，而该分支又是一个无穷分支,就得不到解,因此该算法是不完备的。</li><li>优点：如果目标节点在搜索进入的分支上，则可以较快得到解。</li></ul><h2 id="三广度优先遍历搜索bfs">三、广度优先遍历搜索(BFS)</h2><h3 id="算法介绍-1">3.1算法介绍</h3><p><strong>广度优先搜索算法</strong>（英语：Breadth-First-Search，缩写为BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。BFS是一种盲目搜索法，目的是系统地展开并检查图中的所有节点，以找寻结果。</p><p>BFS会先访问根节点的所有邻居节点，然后再依次访问邻居节点的邻居节点，直到所有节点都访问完毕。在具体的实现中，使用open和closed两个表，open是一个队列，每次对open进行一次出队操作（并放入closed中），并将其邻居节点进行入队操作。直到队列为空时即完成了所有节点的遍历。closed表在遍历树时其实没有用，因为子节点只能从父节点到达。但在进行图的遍历时，一个节点可能会由多个节点到达，所以此时为了防止重复遍历应该每次都检查下一个节点是否已经在closed中了。依旧以下图为例，BFS方法首先从根节点1开始，其最终得到的遍历顺序是“1-2-7-8-3-6-9-12-4-5-10-11”。可以看出来BFS进行遍历时是一层一层的搜索的。</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204640.png" /></p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204722.png" /></p><p>在应用BFS算法进行八数码问题搜索时需要open和closed两个表。首先将初始状态加入open队列，然后进行出队操作并放入closed中，对出队的状态进行扩展（所谓扩展也就是找出其上下左右移动后的状态），将扩展出的状态加入队列，然后继续循环出队-扩展-入队的操作，直到找到解为止。在上图这个例子中，红圈里的数字是遍历顺序。当找到解时一直往前找父节点即可找出求解的移动路线。</p><h3 id="实验代码-1">3.2实验代码</h3><div class="code-wrapper"><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;初始状态压入队列    B_open.push(new borad(NULL, start, 0, INT_MAX - 1));    printf(&quot;BFS：\n&quot;);    while (!B_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad* cur &#x3D; B_open.front();        B_open.pop();        &#x2F;&#x2F;与目标状态的距离，为0即到达目标状态        if (hn(cur-&gt;status, target) &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%d\n目标状态深度为%d\n\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad* temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, INT_MAX - 1);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                B_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;    &#x2F;&#x2F;清空close表    close.clear();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="实验结果-1">3.3实验结果</h3><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204754.png" /></p><p>如图所示，广度优先算法成功找到了深度为22的最优解，但是close表是DFS中深度46312产生的大小为47788的close表的两倍多，由于𝐵𝐹𝑆算法进行的是盲目的搜索，没有考虑代价，而且利用了空间换取时间的策略，故空间也相对会有更大的复杂度。</p><h3 id="实验总结-1">3.4实验总结</h3><ul><li>缺点：当目标节点距离初始节点较远时会产生许多无用的节点，搜索效率低，只能适用于到达目标结点步数较少的情况。</li><li>优点：只要问题有解，则总可以得到解，而且是最短路径的解。</li></ul><h2 id="四a算法实现八数码问题">四、A*算法实现八数码问题</h2><h3 id="算法介绍-2">4.1算法介绍</h3><p>**A*搜索算法**（A* searchalgorithm）是一种在图形平面上，有多个节点的路径，求出最低通过成本的算法，也是许多其他问题的常用启发式算法。该算法综合了最良优先搜索和Dijkstra算法的优点：在进行启发式搜索提高算法效率的同时，可以保证找到一条最优路径（基于评估函数）。</p><p>在A*算法中，一个结点位置的好坏用估价函数来对它进行评估：</p><p><span class="math display">\[f{}&#39;\left ( n \right )=g{}&#39;\left ( n \right )+h{}&#39;\left ( n\right )\]</span></p><p>这里，f'(n)是估价函数，g'(n)是起点到终点的最短路径值(也称为最小耗费或最小代价)，h'(n)是n到目标的最短路经的启发值。由于这个f'(n)其实是无法预先知道的，因而实际上使用的是如下估价函数：</p><p><span class="math display">\[f\left ( n \right )=g\left ( n \right )+h\left ( n \right )\]</span></p><p>这个公式遵循以下特性：</p><ul><li>如果g(n)为0，即只计算任意顶点n到目标的评估函数h(n)，而不计算起点到顶点n的距离，则算法转化为使用贪心策略的最良优先搜索，速度最快，但可能得不出最优解；</li><li>如果h(n)不大于顶点n到目标顶点的实际距离，则一定可以求出最优解，而且h(n)越小，需要计算的节点越多，算法效率越低，常见的评估函数有——欧几里得距离、曼哈顿距离、切比雪夫距离；</li><li>如果h(n)为0，即只需求出起点到任意顶点n的最短路径g(n)，而不计算任何评估函数h(n)，则转化为单源最短路径问题，即Dijkstra算法，此时需要计算最多的顶点；</li></ul><p>其中，g(n)是从初始结点到节点n的实际代价，h(n)是从结点n到目标结点的最佳路径的估计代价。在这里主要是h(n)体现了搜索的启发信息，因为g(n)是已知的。用f(n)作为f'(n)的近似，也即用g(n)代替g'(n)，h(n)代替h'(n)。这样必须满足两个条件：</p><ol type="1"><li>g(n)≥g'(n)(大多数情况下都是满足的，可以不用考虑)，且f必须保持单调递增；</li><li>h必须小于等于实际的从当前节点到达目标节点的最小耗费h(n)≤h'(n)。（可以证明应用这样的估价函数可以找到最短路径）</li></ol><h3 id="实验代码-2">4.2实验代码</h3><div class="code-wrapper"><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;初始状态压入队列    printf(&quot;A* Fn&#x3D;Gn+Hn：\n&quot;);    while (!A_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad* cur &#x3D; A_open.top();        A_open.pop();        &#x2F;&#x2F;hn&#x3D;Fn-depth为与目标状态的曼哈顿距离，为0即到达目标状态        if (cur-&gt;Fn - cur-&gt;depth &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%d\n目标状态深度为%d\n\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad* temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, 0);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                &#x2F;&#x2F;计算启发函数值，并更新节点                temp-&gt;Fn &#x3D; temp-&gt;depth + hn(temp-&gt;status, target);                &#x2F;&#x2F;加入A_open表                A_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;    &#x2F;&#x2F;清空close表    close.clear();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><h3 id="实验结果-2">4.3实验结果</h3><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204738.png" /></p><p>如图所示，A*搜索算法在解决八数码问题时取得了最优的结果，无论是时间复杂度还是空间复杂度都得到了极大的优化。但是𝐴∗算法作为一种预测算法，不能保证解为最优解。</p><h3 id="实验总结-2">4.4实验总结</h3><ul><li>优点：A*算法在绝大多数的情况下，在性能方面都远远优与DFS和BFS。算法的主要运行性能，取决于估价函数f的选取。</li><li>缺点：由于算法本身的特点，因此根据估价函数找到的解路径不一定是最优解路径。</li></ul><h2 id="五效率比较及优缺点">五、效率比较及优缺点</h2><h3 id="概念">5.1概念</h3><p>首先给出几个用来进行效率比价的变量：</p><ol type="1"><li><p>深度(D)：从初始节点到达目标的路径深度；</p></li><li><p>时间(T)：搜索程序运行的时间,单位毫秒(ms)；</p></li><li><p>状态数(N)：整个过程中生成的状态总数；</p></li><li><p>外显率(P)：搜索工程中,从初始节点向目标节点进行搜索的区域的宽度。</p><p>其中时间使用C标准库函数 clock_t clock(void)计算获得，返回三个算法程序执行起，处理器时钟所使用的时间。为了获取 CPU所使用的秒数，必须除以CLOCKS_PER_SEC。而外显率定义为以下公式计算获得：</p><p><span class="math display">\[P=\frac{D}{N},P\in \left( 0,1\right]\]</span></p></li></ol><h3 id="实验数据分析">5.2 实验数据分析</h3><p>数据说明：</p><ol type="1"><li>环境为Windows系统，语言为C++，使用clock()函数输出算法时间；</li><li>目标状态1 2 3 4 5 6 7 8 0；</li><li>由于运行时间受电脑影响很大，具有一定的随机性，因而每个状态执行3次,取平均数作为最终结果时间。</li></ol><p>以下为题目所给初始状态产生的数据：</p><table><thead><tr class="header"><th></th><th>深度D</th><th>时间T</th><th>状态数N</th><th>外显率P</th></tr></thead><tbody><tr class="odd"><td>DFS</td><td>46312</td><td>0.295000</td><td>47788</td><td>0.969113</td></tr><tr class="even"><td>BFS</td><td>22</td><td>0.793000</td><td>102868</td><td>0.000213</td></tr><tr class="odd"><td>A*</td><td>22</td><td>0.005000</td><td>503</td><td>0.043737</td></tr></tbody></table><p>以下为随机初始状态产生的数据：</p><table><thead><tr class="header"><th>状态数N</th><th>DFS</th><th>BFS</th><th>A*</th></tr></thead><tbody><tr class="odd"><td>1</td><td>37809</td><td>60897</td><td>1114</td></tr><tr class="even"><td>2</td><td>13571</td><td>129921</td><td>1289</td></tr><tr class="odd"><td>3</td><td>39006</td><td>36948</td><td>926</td></tr><tr class="even"><td>4</td><td>56982</td><td>38459</td><td>182</td></tr><tr class="odd"><td>5</td><td>101524</td><td>23754</td><td>610</td></tr><tr class="even"><td>6</td><td>62529</td><td>85828</td><td>1175</td></tr><tr class="odd"><td>7</td><td>119230</td><td>43684</td><td>750</td></tr><tr class="even"><td>8</td><td>72091</td><td>129811</td><td>2492</td></tr><tr class="odd"><td>9</td><td>68716</td><td>40819</td><td>393</td></tr><tr class="even"><td>10</td><td>128887</td><td>159858</td><td>6852</td></tr></tbody></table><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204834.png" /></p><table><thead><tr class="header"><th>深度D</th><th>DFS</th><th>BFS</th><th>A*</th></tr></thead><tbody><tr class="odd"><td>1</td><td>36756</td><td>20</td><td>20</td></tr><tr class="even"><td>2</td><td>13268</td><td>24</td><td>24</td></tr><tr class="odd"><td>3</td><td>37943</td><td>19</td><td>19</td></tr><tr class="even"><td>4</td><td>55007</td><td>19</td><td>19</td></tr><tr class="odd"><td>5</td><td>95102</td><td>18</td><td>20</td></tr><tr class="even"><td>6</td><td>60172</td><td>22</td><td>22</td></tr><tr class="odd"><td>7</td><td>108378</td><td>20</td><td>20</td></tr><tr class="even"><td>8</td><td>69118</td><td>24</td><td>24</td></tr><tr class="odd"><td>9</td><td>66096</td><td>20</td><td>20</td></tr><tr class="even"><td>10</td><td>113307</td><td>25</td><td>27</td></tr></tbody></table><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204843.png" /></p><table><thead><tr class="header"><th>时间T</th><th>DFS</th><th>BFS</th><th>A*</th></tr></thead><tbody><tr class="odd"><td>1</td><td>0.226</td><td>0.444</td><td>0.011</td></tr><tr class="even"><td>2</td><td>0.079</td><td>1.026</td><td>0.012</td></tr><tr class="odd"><td>3</td><td>0.231</td><td>0.277</td><td>0.01</td></tr><tr class="even"><td>4</td><td>0.347</td><td>0.291</td><td>0.002</td></tr><tr class="odd"><td>5</td><td>0.675</td><td>0.176</td><td>0.006</td></tr><tr class="even"><td>6</td><td>0.372</td><td>0.665</td><td>0.011</td></tr><tr class="odd"><td>7</td><td>0.749</td><td>0.321</td><td>0.007</td></tr><tr class="even"><td>8</td><td>0.429</td><td>0.997</td><td>0.024</td></tr><tr class="odd"><td>9</td><td>0.439</td><td>0.302</td><td>0.003</td></tr><tr class="even"><td>10</td><td>0.796</td><td>1.367</td><td>0.068</td></tr></tbody></table><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204853.png" /></p><table><thead><tr class="header"><th>外显率P</th><th>DFS</th><th>BFS</th><th>A*</th></tr></thead><tbody><tr class="odd"><td>1</td><td>0.000972</td><td>0.000328</td><td>0.017953</td></tr><tr class="even"><td>2</td><td>0.000978</td><td>0.000185</td><td>0.018619</td></tr><tr class="odd"><td>3</td><td>0.000973</td><td>0.000514</td><td>0.020518</td></tr><tr class="even"><td>4</td><td>0.000965</td><td>0.000494</td><td>0.104396</td></tr><tr class="odd"><td>5</td><td>0.000937</td><td>0.000758</td><td>0.032787</td></tr><tr class="even"><td>6</td><td>0.000962</td><td>0.000256</td><td>0.018723</td></tr><tr class="odd"><td>7</td><td>0.000909</td><td>0.000458</td><td>0.026667</td></tr><tr class="even"><td>8</td><td>0.000959</td><td>0.000185</td><td>0.009631</td></tr><tr class="odd"><td>9</td><td>0.000962</td><td>0.00049</td><td>0.050891</td></tr><tr class="even"><td>10</td><td>0.000879</td><td>0.000156</td><td>0.00394</td></tr></tbody></table><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20211020204901.png" /></p><h3 id="研究结论">5.3研究结论</h3><p>通过研究，可得结论如下：</p><ol type="1"><li>DFS搜索效率受深度影响很大，由于深度界限设置得很大，故搜索结点冗余多、速度慢；</li><li>BFS找到的一定是最优解，但是在算法效率上，不一定比DFS好，且远远不如A*算法，同时BFS在搜索深度较深时，产生的冗余结点较多；</li><li>A*算法在效率上相对最优，时间和空间上都比DFS和BFS更优，但缺点是，找到的解不一定是最优解。</li></ol><h2 id="六参考文献">六、参考文献</h2><p>[1]付宏杰,王雪莹,周健,周孙静,朱珠,张俊余.八数码问题解法效率比较及改进研究[J].软件导刊,2016,15(09):41-45.</p><p>[2]StuartJ.Russell,PeterNorvig. 人工智能:一种现代的方法(第3版)[J].计算机教育, 2011(15):68-68.</p><p>[3]Thomas,H.Cormen,Charles,E.Leiserson,Ronald,L.Rivest,Clifford,Stein,殷建平,徐云,王刚,刘晓光,苏明,邹恒明,王宏志.算法导论(原书第3版)[J]. 计算机教育(10期):51-51.</p><h2 id="七完整代码">七、完整代码</h2><div class="code-wrapper"><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;queue&gt;#include &lt;stack&gt;#include &lt;unordered_set&gt;#include &lt;unordered_map&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;#include &lt;time.h&gt;#include &lt;math.h&gt;#include &lt;climits&gt;using namespace std;struct borad &#123;    int status[9];&#x2F;&#x2F;status[0]到status[8]表示3X3的矩阵，0表示空格    int depth;&#x2F;&#x2F;深度    int Fn;&#x2F;&#x2F;启发函数值，Fn &#x3D; depth + hn即深度加曼哈顿距离    borad* pre;&#x2F;&#x2F;父指针，指向移动前的棋盘状态    borad() : pre(0), status(), depth(0), Fn(INT_MAX - 1) &#123;        for (int j &#x3D; 0; j &lt; 9; j++) &#123;            status[j] &#x3D; j;        &#125;    &#125;    borad(borad* x, int i[9], int y, int z) : pre(x), depth(y), Fn(z) &#123;        for (int j &#x3D; 0; j &lt; 9; j++) &#123;            status[j] &#x3D; i[j];        &#125;    &#125;&#125;;&#x2F;&#x2F;优先队列自定义排序规则，升序struct cmp &#123;    bool operator() (const borad* a, const borad* b) &#123;        return a-&gt;Fn &gt; b-&gt;Fn;    &#125;&#125;;bool swapnum(int a, int b, int* status);&#x2F;&#x2F;交换元素int getindex(int* status, int num);&#x2F;&#x2F;获得元素在棋盘上的一维坐标void print(int* status);&#x2F;&#x2F;打印棋盘int hn(int* status, int* target);&#x2F;&#x2F;当前状态与目标状态的曼哈顿距离void printans(borad* cur);&#x2F;&#x2F;打印解法，回溯int status2int(int* status);&#x2F;&#x2F;棋盘状态转为int格式int reversesum(int* status);&#x2F;&#x2F;计算逆序数之和int* randstatus(int* target);&#x2F;&#x2F;获得随机初始状态int main() &#123;    clock_t start_t, end_t;    double total_t;    int go[4] &#x3D; &#123; -1,1,-3,3 &#125;;&#x2F;&#x2F;四个移动方向    int start[9] &#x3D; &#123; 1,8,7,3,0,5,4,6,2 &#125;;&#x2F;&#x2F;初始状态    int target[9] &#x3D; &#123; 1,2,3,4,5,6,7,8,0 &#125;;&#x2F;&#x2F;目标状态    &#x2F;&#x2F;int* start;&#x2F;&#x2F;随机初始状态    &#x2F;&#x2F;生成随机初始状态    &#x2F;&#x2F;start &#x3D; randstatus(target);    stack&lt;borad*&gt; D_open;&#x2F;&#x2F;DFS的open表，使用栈，深度大的在表头    queue&lt;borad*&gt; B_open;&#x2F;&#x2F;BFS的open表，使用队列，深度小的在表头    priority_queue&lt;borad*, vector&lt;borad*&gt;, cmp&gt; A_open;&#x2F;&#x2F;A*的open表，使用优先队列，启发函数值小的元素在表头    unordered_set&lt;int&gt; close;&#x2F;&#x2F;close表，存放已访问过的状态，元素为状态的int格式    &#x2F;&#x2F;例：&#123; 1,2,3,8,0,4,7,6,5 &#125;&#x3D;&#x3D;》123804765(int)    &#x2F;&#x2F;&#123; 0,1,3,8,2,4,7,6,5 &#125;&#x3D;&#x3D;》13824765(int)    A_open.push(new borad(NULL, start, 0, INT_MAX - 1));    borad* temp &#x3D; A_open.top();    printf(&quot;初始状态：&quot;);    print(temp-&gt;status);    printf(&quot;目标状态：&quot;);    print(target);    start_t &#x3D; clock();    &#x2F;&#x2F;--------------------------------------------start-A*-------- Fn&#x3D;Gn+Hn -----------------------------&#x2F;&#x2F;    &#x2F;&#x2F;初始状态压入队列    printf(&quot;A* Fn&#x3D;Gn+Hn：\n&quot;);    while (!A_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad* cur &#x3D; A_open.top();        A_open.pop();        &#x2F;&#x2F;hn&#x3D;Fn-depth为与目标状态的曼哈顿距离，为0即到达目标状态        if (cur-&gt;Fn - cur-&gt;depth &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%ld\n目标状态深度为%d\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad* temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, 0);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                &#x2F;&#x2F;计算启发函数值，并更新节点                temp-&gt;Fn &#x3D; temp-&gt;depth + hn(temp-&gt;status, target);                &#x2F;&#x2F;加入A_open表                A_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;    &#x2F;&#x2F;清空close表    close.clear();    &#x2F;&#x2F;--------------------------------------------end-A*--------- Fn&#x3D;Gn+Hn -------------------------&#x2F;&#x2F;    end_t &#x3D; clock();    &#x2F;&#x2F;清空A_open    while (!A_open.empty()) &#123;        A_open.pop();    &#125;    total_t &#x3D; ((double)end_t - (double)start_t) &#x2F; CLOCKS_PER_SEC;    printf(&quot;总时间：%f\n\n\n&quot;, total_t);    start_t &#x3D; clock();    &#x2F;&#x2F;--------------------------------------------start-BFS------------------------------------------&#x2F;&#x2F;    &#x2F;&#x2F;初始状态压入队列    B_open.push(new borad(NULL, start, 0, INT_MAX - 1));    printf(&quot;BFS：\n&quot;);    while (!B_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad* cur &#x3D; B_open.front();        B_open.pop();        &#x2F;&#x2F;与目标状态的距离，为0即到达目标状态        if (hn(cur-&gt;status, target) &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%ld\n目标状态深度为%d\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad* temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, INT_MAX - 1);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                B_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;    &#x2F;&#x2F;清空close表    close.clear();    &#x2F;&#x2F;--------------------------------------------end-BFS------------------------------------------&#x2F;&#x2F;    end_t &#x3D; clock();    total_t &#x3D; ((double)end_t - (double)start_t) &#x2F; CLOCKS_PER_SEC;    printf(&quot;总时间：%f\n\n\n&quot;, total_t);    start_t &#x3D; clock();    &#x2F;&#x2F;--------------------------------------------start-DFS------------------------------------------&#x2F;&#x2F;    &#x2F;&#x2F;初始状态压入队列    D_open.push(new borad(NULL, start, 0, INT_MAX - 1));    printf(&quot;DFS：\n&quot;);    while (!D_open.empty()) &#123;        &#x2F;&#x2F;弹出一个状态        borad* cur &#x3D; D_open.top();        D_open.pop();        &#x2F;&#x2F;if (cur-&gt;depth &#x3D;&#x3D; 5) &#123;        &#x2F;&#x2F;    break;        &#x2F;&#x2F;&#125;        &#x2F;&#x2F;与目标状态的距离，为0即到达目标状态        if (hn(cur-&gt;status, target) &#x3D;&#x3D; 0) &#123;            printf(&quot;到达目标状态\nclose表大小为%ld\n目标状态深度为%d\n&quot;, close.size(), cur-&gt;depth);            &#x2F;&#x2F;printans(cur);            break;        &#125;        &#x2F;&#x2F;存放int格式的状态        int intstatus &#x3D; status2int(cur-&gt;status);        &#x2F;&#x2F;出现重复状态        if (close.count(intstatus)) &#123;            continue;        &#125;        &#x2F;&#x2F;加入close表，表示已访问过        close.insert(intstatus);        &#x2F;&#x2F;获得0的坐标        int zeroindex &#x3D; getindex(cur-&gt;status, 0);        for (int i &#x3D; 0; i &lt; 4; i++) &#123;            &#x2F;&#x2F;新建节点，复制当前棋盘状态，深度+1            borad* temp &#x3D; new borad(cur, cur-&gt;status, cur-&gt;depth + 1, INT_MAX - 1);            &#x2F;&#x2F;0向四个方向移动            if (swapnum(zeroindex, zeroindex + go[i], temp-&gt;status)) &#123;                &#x2F;&#x2F;移动成功                D_open.push(temp);            &#125;            else &#123;                &#x2F;&#x2F;移动失败                delete(temp);            &#125;        &#125;    &#125;    &#x2F;&#x2F;--------------------------------------------end-DFS------------------------------------------&#x2F;&#x2F;    end_t &#x3D; clock();    total_t &#x3D; ((double)end_t - (double)start_t) &#x2F; CLOCKS_PER_SEC;    printf(&quot;总时间：%f\n&quot;, total_t);    &#x2F;&#x2F;delete(start);    return 0;&#125;&#x2F;&#x2F;打印棋盘void print(int* status) &#123;    for (int i &#x3D; 0; i &lt; 9; i++) &#123;        if (i % 3 &#x3D;&#x3D; 0) &#123;            printf(&quot;\n&quot;);        &#125;        printf(&quot;%d &quot;, status[i]);    &#125;    printf(&quot;\n\n&quot;);&#125;&#x2F;&#x2F;获得元素在棋盘上的一维坐标int getindex(int* status, int num) &#123;    for (int i &#x3D; 0; i &lt; 9; i++) &#123;        if (status[i] &#x3D;&#x3D; num) &#123;            return i;        &#125;    &#125;    return -1;&#125;&#x2F;&#x2F;交换元素bool swapnum(int a, int b, int* status) &#123;    if (b &gt;&#x3D; 0 &amp;&amp; b &lt;&#x3D; 8 &amp;&amp; (a &#x2F; 3 &#x3D;&#x3D; b &#x2F; 3 || a % 3 &#x3D;&#x3D; b % 3)) &#123;        swap(status[a], status[b]);        return true;    &#125;    else &#123;        return false;    &#125;&#125;&#x2F;&#x2F;当前状态与目标状态的曼哈顿距离int hn(int* status, int* target) &#123;    &#x2F;&#x2F;获得当前状态与目标状态的二维x，y坐标    int x, y, xt, yt, it, h &#x3D; 0;    for (int i &#x3D; 0; i &lt; 9; i++) &#123;        x &#x3D; i % 3;        y &#x3D; i &#x2F; 3;        it &#x3D; getindex(target, status[i]);        xt &#x3D; it % 3;        yt &#x3D; it &#x2F; 3;        h +&#x3D; abs(x - xt) + abs(y - yt);    &#125;    return h;&#125;&#x2F;&#x2F;打印解法，回溯void printans(borad* cur) &#123;    vector&lt;string&gt; ans;    while (cur) &#123;        ans.push_back(to_string(cur-&gt;status[0]) + to_string(cur-&gt;status[1]) + to_string(cur-&gt;status[2]) + &quot;\n&quot;            + to_string(cur-&gt;status[3]) + to_string(cur-&gt;status[4]) + to_string(cur-&gt;status[5]) + &quot;\n&quot;            + to_string(cur-&gt;status[6]) + to_string(cur-&gt;status[7]) + to_string(cur-&gt;status[8]));        cur &#x3D; cur-&gt;pre;    &#125;    for (int i &#x3D; ans.size() - 1; i &gt;&#x3D; 0; i--) &#123;        printf(&quot;%s\n ↓\n&quot;, ans[i].c_str());    &#125;    printf(&quot;END\n\n&quot;);&#125;&#x2F;&#x2F;棋盘状态转为int格式int status2int(int* status) &#123;    int res &#x3D; 0;    for (int i &#x3D; 0, j &#x3D; 8; i &lt; 9; i++, j--) &#123;        res +&#x3D; status[i] * pow(10, j);    &#125;    return res;&#125;&#x2F;&#x2F;计算逆序数之和int reversesum(int* status) &#123;    int sum &#x3D; 0;    for (int i &#x3D; 0; i &lt; 9; i++) &#123;        if (status[i] !&#x3D; 0) &#123;            for (int j &#x3D; 0; j &lt; i; j++) &#123;                if (status[j] &gt; status[i]) &#123;                    sum++;                &#125;            &#125;        &#125;    &#125;    return sum;&#125;&#x2F;&#x2F;获得随机初始状态int* randstatus(int* target) &#123;    int* start &#x3D; new int[9]();    unordered_map&lt;int, int&gt; nums;&#x2F;&#x2F;记录已添加的数    srand((int)time(0));    int element, sum1, sum2;    sum2 &#x3D; reversesum(target);    &#x2F;&#x2F;根据初始状态与目标状态的逆序数之和（sum1、sum2）是否相等，判断初始状态是否有解，不相等（即无解）则重新生成初始状态    do &#123;        for (int i &#x3D; 0; i &lt; 9; i++) &#123;            element &#x3D; rand() % 9;            while (nums[element]) &#123;                element &#x3D; rand() % 9;            &#125;            nums[element]++;            start[i] &#x3D; element;        &#125;        &#x2F;&#x2F;清空记录        nums.clear();        &#x2F;&#x2F;计算逆序数之和        sum1 &#x3D; reversesum(start);    &#125; while (sum1 % 2 !&#x3D; sum2 % 2);    return start;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Texlive+VScode</title>
    <link href="/2021/10/18/latex/"/>
    <url>/2021/10/18/latex/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>搭建Latex环境：Texlive+VScode 相关记录</p><span id="more"></span><h2 id="安装-texlive">1.安装 Texlive</h2><p>鉴于我校没有（我知道的）可用开源软件镜像站，所以在到清华大学开源软件镜像站的<ahref="https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/">texlive</a>页下载。</p><p><a href="https://imgtu.com/i/5UYncq"><imgsrc="https://z3.ax1x.com/2021/10/18/5UYncq.png"alt="5UYncq.png" /></a></p><p>可能由于更新导致你打开之后的页面与上面的内容不一致，总之下载最新的texlive***.iso，虽然很大但各种宏包齐全，用起来能省去各种麻烦。</p><p>在带宽扩容之后的校园网加持下，不用几年就能下载完这个iso文件了。</p><p>如果你是windows7甚至xp用户，我建议你把iso文件解压然后进行后续操作。</p><p>如果是windows 10/11，系统自带虚拟光驱，直接双击进入即可。</p><p>（ linux/macOS 我不了解，省略）效果如图：</p><p><a href="https://imgtu.com/i/5UUe9H"><imgsrc="https://z3.ax1x.com/2021/10/18/5UUe9H.png"alt="5UUe9H.png" /></a></p><p>双击或者右键以管理员身份运行install-tl-advanced.bat，可以点进<strong>Advanced</strong>进入高级安装，点击<strong>Customize</strong>来取消你不需要安装的宏包，比如非中英的语言包，这里我只修改了安装目录，最后开始漫长的等待。</p><p><a href="https://imgtu.com/i/5UaCGQ"><imgsrc="https://z3.ax1x.com/2021/10/18/5UaCGQ.png"alt="5UaCGQ.png" /></a></p><p>（安装TeXworks前端也可以取消掉，毕竟都打算用vscode了，加上前面说的语言包之类的，可以省个1G左右，我想着留条后路就啥都没改，也不缺这点空间）</p><p>（在我的电脑上一共安装了57 min 56 s，教程都快写完了，还没有装好）</p><h2 id="安装-vscode">2. 安装 VSCode</h2><p>到<ahref="https://code.visualstudio.com/Download">官网</a>根据你的系统选择下载安装即可，这部分应该大多数人都安装过了，没什么需要注意的。</p><p><a href="https://imgtu.com/i/5Ud4hD"><imgsrc="https://z3.ax1x.com/2021/10/18/5Ud4hD.png"alt="5Ud4hD.png" /></a></p><p>安装完成之后可以在应用商店挑选各种提高使用体验的扩展，跟本文相关的主要是<strong>LatexWorkshop</strong>。</p><p><a href="https://imgtu.com/i/5U0KJS"><imgsrc="https://z3.ax1x.com/2021/10/18/5U0KJS.png"alt="5U0KJS.png" /></a></p><p>安装完成之后，可以创建或者打开一个tex文件，此时代码已经被高亮显示了。</p><p><a href="https://imgtu.com/i/5U560K"><imgsrc="https://z3.ax1x.com/2021/10/18/5U560K.png"alt="5U560K.png" /></a></p><p>按下快捷键Ctrl+Alt+B（build latex project），顺利生成，效果不错。</p><p><a href="https://imgtu.com/i/5U5xcn"><imgsrc="https://z3.ax1x.com/2021/10/18/5U5xcn.png"alt="5U5xcn.png" /></a></p><h2 id="配置-vscode-的-插件">3. 配置 VSCode 的 插件</h2><p>按下F1或者Ctrl＋shift＋P，输入setjson，选择第三个（如图所示）。</p><p><a href="https://imgtu.com/i/5Uo9xA"><imgsrc="https://z3.ax1x.com/2021/10/18/5Uo9xA.png"alt="5Uo9xA.png" /></a></p><div class="code-wrapper"><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"latex-workshop.latex.tools"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">&#123;</span>   <span class="token comment">// 编译工具和命令</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"xelatex"</span><span class="token punctuation">,</span>   <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"xelatex"</span><span class="token punctuation">,</span>   <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"-synctex=1"</span><span class="token punctuation">,</span>   <span class="token string">"-interaction=nonstopmode"</span><span class="token punctuation">,</span>   <span class="token string">"-file-line-error"</span><span class="token punctuation">,</span>   <span class="token string">"-pdf"</span><span class="token punctuation">,</span>   <span class="token string">"%DOCFILE%"</span>            <span class="token punctuation">]</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>        <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"pdflatex"</span><span class="token punctuation">,</span>   <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"pdflatex"</span><span class="token punctuation">,</span>   <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"-synctex=1"</span><span class="token punctuation">,</span>   <span class="token string">"-interaction=nonstopmode"</span><span class="token punctuation">,</span>   <span class="token string">"-file-line-error"</span><span class="token punctuation">,</span>   <span class="token string">"%DOCFILE%"</span>            <span class="token punctuation">]</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>        <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"bibtex"</span><span class="token punctuation">,</span>   <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"bibtex"</span><span class="token punctuation">,</span>   <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"%DOCFILE%"</span>            <span class="token punctuation">]</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token property">"latex-workshop.latex.recipes"</span><span class="token operator">:</span> <span class="token punctuation">[</span>      <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"xelatex"</span><span class="token punctuation">,</span>   <span class="token property">"tools"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"xelatex"</span>          <span class="token punctuation">]</span><span class="token punctuation">,</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>      <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"pdflatex"</span><span class="token punctuation">,</span>   <span class="token property">"tools"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"pdflatex"</span>          <span class="token punctuation">]</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>      <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"xelatex->bibtex->xelatex->xelatex"</span><span class="token punctuation">,</span>   <span class="token property">"tools"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"xelatex"</span><span class="token punctuation">,</span>   <span class="token string">"bibtex"</span><span class="token punctuation">,</span>   <span class="token string">"xelatex"</span><span class="token punctuation">,</span>   <span class="token string">"xelatex"</span>          <span class="token punctuation">]</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>      <span class="token punctuation">&#123;</span>   <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"pdflatex->bibtex->pdflatex->pdflatex"</span><span class="token punctuation">,</span>   <span class="token property">"tools"</span><span class="token operator">:</span> <span class="token punctuation">[</span>   <span class="token string">"pdflatex"</span><span class="token punctuation">,</span>   <span class="token string">"bibtex"</span><span class="token punctuation">,</span>   <span class="token string">"pdflatex"</span><span class="token punctuation">,</span>   <span class="token string">"pdflatex"</span>          <span class="token punctuation">]</span>      <span class="token punctuation">&#125;</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"latex-workshop.view.pdf.viewer"</span><span class="token operator">:</span> <span class="token string">"tab"</span><span class="token punctuation">,</span><span class="token property">"editor.inlineSuggest.enabled"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span><span class="token property">"latex-workshop.latex.autoClean.run"</span><span class="token operator">:</span> <span class="token string">"onBuilt"</span><span class="token punctuation">,</span><span class="token property">"latex-workshop.latex.autoBuild.run"</span><span class="token operator">:</span> <span class="token string">"never"</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><ul><li>Ctrl+Alt+B 是编译</li><li>Ctrl+Alt+V是编译+预览pdf</li></ul><p>我最开始写这些其实是想要把中大的foxitpdf设置成默认的pdf预览软件，不过最终效果并不好，所以作罢。</p><p>（咨询了foxit的技术客服，他们说目前是实现不了的）</p><p>上面这些设置主要是因为默认的编译工具是 latexmk，由于不需要用到latexmk，因此把其修改为中文环境常用的 xelatex；将 tools 中的%DOC%替换成%DOCFILE%就可以支持编译中文路径下的文件了。</p><p>还可以研究的设置有很多，什么正向搜索反向搜索之类的，有兴趣的朋友可以自行了解。</p><p><a href="https://ericp.cn/cmd">公式指导手册</a></p><p>如果中文无法显示就加上这一句：</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">\usepackage[UTF8]&#123;ctex&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div><p>Latex的相关公式及使用就不再赘述了。</p><p>由于vscode不一定能成功实现4次编译，故我编写了以下bat文件，可以一次性生成pdf并清除所有过程文件：</p><div class="code-wrapper"><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>:: 四次编译：xe-bib-xe-xe::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>xelatex reportbibtex reportxelatex reportxelatex report::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>:: 清除文件以及清除更多文件::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>:clean<span class="token builtin class-name">echo</span> 删除编译临时文件del /f /q /s *.log *.glo *.ilg *.lof *.ind *.out *.thm *.toc *.lot *.loe *.out.bak *.blg *.synctex.gz *.aux *.bbl *.xdvdel /f /q *.idxdel /f /s *.dvi *.psgoto end::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>:: 结束符，无任何具体意义::<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>:end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>]]></content>
    
    
    
    <tags>
      
      <tag>写作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello world!</title>
    <link href="/2021/04/25/Helloworld/"/>
    <url>/2021/04/25/Helloworld/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>My First blog:Something about Enderfga</p><span id="more"></span><h1 id="think-twice-code-once.">Think twice, code once.</h1>        <div id="aplayer-XPAfDUOr" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;">            <div class="code-wrapper"><pre class="aplayer-lrc-content"></pre></div>        </div>        <script>          var ap = new APlayer({            element: document.getElementById("aplayer-XPAfDUOr"),            narrow: false,            autoplay: true,            showlrc: false,            music: {              title: "Never Coming Back",              author: "Evan Call",              url: "https://cdn.jsdelivr.net/gh/Enderfga/Enderfga/Backup/music.mp3",              pic: "https://z3.ax1x.com/2021/04/24/cvhTxI.jpg",              lrc: ""            }          });          window.aplayers || (window.aplayers = []);          window.aplayers.push(ap);        </script><p><a href="https://imgtu.com/i/gAAR54"><imgsrc="https://z3.ax1x.com/2021/04/30/gAAR54.jpg"alt="gAAR54.jpg" /></a></p><p>自打成为一个程序猿开始，翻阅博客文章学习就成了我的日常（质量确实有够参差不齐···），CSDN、博客园、简书、知乎、GitHub等我都经常光顾，于是萌生了自己写blog的想法，苦于技术力不足一直搁置至今（现在也不怎么样哈哈哈）。在GZTime的协助下，我自己的小破站终于建成啦~希望我早日产出点技术性文章，现在只能拿来记流水账了······</p><h1 id="enderfga">Enderfga？</h1><p>关于我的id来源其实挺傻的，在成为程序猿之前我是一名资深游戏玩家，我还清楚地记得我接触的第一款网络游戏叫植物大战僵尸OL，然后是洛克王国，卡布西游，奥奇传说···直到六年级那年，我玩了第一款我愿将其称之为“游戏”或者说是“第九艺术”的作品——Minecraft。</p><p><a href="https://imgtu.com/i/gAAhG9"><imgsrc="https://z3.ax1x.com/2021/04/30/gAAhG9.jpg"alt="gAAhG9.jpg" /></a></p><p>MC一直陪我走到今天，我对编程的兴趣基本也是萌芽于此。虽然课程里没有涉及Java，但有机会我还是会争取好好自学Java和C#的。至于MC，不管怎么更新换代，mod/红石/命令方块/欺负末影龙/种田养猪都挺吸引我的。</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">EnderDragon—Enderman-Enderfga,Doesn&#39;t that sound cool?&quot;This is not the end,this is not even the beginning of the end,but,perhaps,the end of the beginning.&quot;                   ——Winston Leonard Spencer Churchill<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div><p>这个id不知不觉间居然用了七年了，从个别网站到所有账户统一，我也不舍得换新的了（在互联网上统一貌似不是什么好习惯，还容易查到我年轻的时候留下的黑历史···）只希望外国友人看到这么沙雕的英语名不要笑我哈哈哈。（谷歌娘念的好可爱！）</p><p><a href="https://imgtu.com/i/gAm5Bq"><imgsrc="https://z3.ax1x.com/2021/04/30/gAm5Bq.jpg"alt="gAm5Bq.jpg" /></a></p><h1 id="acgn-引きこもり">ACGN-引きこもり</h1><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/treasure.jpg" /></p><div style="text-align:center">宿舍一角</div><h2 id="animation">Animation</h2><p>二次元浓度++；</p><p>很庆幸自己的童年有虹猫蓝兔七侠传，洛洛历险记，蓝猫淘气三千问，秦时明月，东方神娃······等等优秀国产作品陪伴（甚至顺便在里面学会了普通话），后来在星空卫视的《动漫先锋》栏目里入坑了日漫：犬夜叉，海贼王，钢之炼金术师，七龙珠，<strong>火影忍者</strong>，<strong>银魂</strong>······没有这几部番，肯定也没有现在时而中二热血，时而沙雕废柴的我。至于B站的入站时间是2015-07-1017:20:10（这是通过答题的时间，终于不是游客了！）（用时间戳查的，我怎么可能记得这种东西）</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/gZkFVf.jpg"alt="General 2560x1440 Aerith Gainsborough Final Fantasy video games women ponytail flowers jacket dress" /><figcaption aria-hidden="true">General 2560x1440 Aerith GainsboroughFinal Fantasy video games women ponytail flowers jacketdress</figcaption></figure><p>那个时候特地去看了某科学的超电磁炮，lovelive什么的，四舍五入也算是二刺猿入门了（吧？）</p><p>从零开始的异世界生活，一拳超人，灵能百分百，小林家的龙女仆，干物妹小埋，刺客伍六七，<strong>紫罗兰永恒花园</strong>······这些年看番的频率虽然少了，但那种每周等更新看番的热情已经刻进DNA了。每顿饭的时候刷刷B站的剪辑还能感慨一下“爷青回”，泪目一会。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211208140846878.png"alt="image-20211208140846878" /><figcaption aria-hidden="true">image-20211208140846878</figcaption></figure><p>另外我的头像其实是桂小太郎，不过因为版权意识的加深，可能有机会还是得重画一个。</p><p><a href="https://imgtu.com/i/fgyay4"><imgsrc="https://z3.ax1x.com/2021/08/15/fgyay4.jpg"alt="fgyay4.jpg" /></a></p><p>更新：桂先生成功升级了，参考了尼尔机械纪元中9S的装扮，现在科技感满满！</p><p><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/%E7%8C%AB%E7%8C%ABw.jpg" /></p><p>更新的更新：另外一个版本诞生啦！是煤气罐猫猫的拟人版！</p><h2 id="comic">Comic</h2><p>回忆了一下，我好像不怎么看漫画。起初看漫画是因为死火海更新太慢了，后来在快看上看了几部，记得名字的有阎王不高兴，哑舍，快把我哥带走，<strong>蝉女</strong>。好看是好看，感觉有点像折中选择，不如动画灵动也不如小说全面。</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/20180718145340_ZKfkz.thumb.1000_0.jpeg"alt="蝉女" /><figcaption aria-hidden="true">蝉女</figcaption></figure><p>已经完全想不起来蝉女讲什么了，但画风针不戳。最近听了《<ahref="https://bilibili.com/video/BV1WX4y1G7ok">鉴情师</a>》这首歌才想起来的。</p><h2 id="game">Game</h2><p>说到这个我可就不困了（zzzzz....）</p><p><a href="https://imgtu.com/i/gV9KCn"><imgsrc="https://z3.ax1x.com/2021/05/01/gV9KCn.jpg"alt="gV9KCn.jpg" /></a></p><div style="text-align:center"><iframe width="100%" height="500" src="https://player.bilibili.com/player.html?aid=5868975&amp;bvid=BV1Ts411k73E&amp;cid=9531080&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></iframe></div><p><a href="https://imgtu.com/i/gV9eEQ"><imgsrc="https://z3.ax1x.com/2021/05/01/gV9eEQ.jpg"alt="gV9eEQ.jpg" /></a></p><div style="text-align:center"><iframe width="100%" height="500" src="https://player.bilibili.com/player.html?aid=460307938&amp;bvid=BV1t5411w723&amp;cid=331362469&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></iframe></div><figure><imgsrc="https://cdn.jsdelivr.net/gh/Enderfga/image1@master/img/image-20211208141258648.png"alt="image-20211208141258648" /><figcaption aria-hidden="true">image-20211208141258648</figcaption></figure><div style="text-align:center"><iframe width="100%" height="500" src="https://player.bilibili.com/player.html?aid=12069119&amp;bvid=BV1Wx411q7zb&amp;cid=19911067&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></div><p>我记得当年进b站答题的时候有一道题让我选出“老头滚动条”的原名，百度的过程中我了解到“上古卷轴5”(老滚)mod的丰富程度堪比MC，中世纪剑与魔法的世界也让我着迷，于是我毅然决然地成为了一名抓根宝（龙裔），但通关的过程中我饱受迷路的困扰：黑灯瞎火的洞窟、乱七八糟的陷阱、不可名状的地图···于是我决定找一款我想怎么走就怎么走的游戏——《Assassin‘sCreed》。一入坑就是10年，我愿时间永远停留在佛罗伦萨塔顶的月圆之夜。库里的全套刺客信条通关了，我又想念剑与魔法的故事了，因为久仰其大名我下载了——《TheWitcher3》。这是一部我最喜欢的游戏，没有之一，这也许就是“第九艺术”吧。三言两语不能表达出其中的波澜壮阔，每一个支线，每一部DLC都值得我一遍又一遍地游玩。</p><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">我吻过凯尔莫罕忽然冷冽而至的白雪，我听过史凯利杰伴着海妖清啸的海风。我仰头饮尽诺威格瑞陈年的矮人烈酒，我策马走遍全威伦最艰险的万水千山。对我而言，家是什么地方。是那抹黑白裙摆的倩影，还是那丁香与醋栗的芬芳。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div><p>给我留下深刻印象的游戏有很多，尼尔里的“世界竟然如此美丽”，2077里的"以我残躯化烈火"，死亡搁浅里的“我在冥滩等你”······希望我的程序猿之路最终可以走到像小岛秀夫那样，拥有自己的工作室，书写自己的艺术。</p><p>（另外上面2B那张图的作者是Wlop，我最喜欢的画师）</p><h2 id="novel">Novel</h2><p>我还年轻的时候会看一些天蚕土豆，唐家三少，耳根写的小说······对我的文学水平真是没有半点提升。</p><p>在高二语文老师的耳濡目染下，我一个理工男对文学兴趣盎然。即使很忙，也想抽点时间陶冶情操。</p><div style="text-align:center">落霞与孤鹜齐飞，秋水共长天一色</div><p><a href="https://imgtu.com/i/gV41qf"><imgsrc="https://z3.ax1x.com/2021/05/01/gV41qf.jpg"alt="gV41qf.jpg" /></a></p><p>除了诗与词，还记得名字的书只剩下《巨人的陨落》、《三体》、《外婆的道歉信》、《自由在高处》······</p><p>剩下的各种悬疑侦探小说就不列举了（不过强推一手《神探夏洛克》《POI疑犯追踪》）。</p><h2 id="music">Music</h2><p>我这个人听的歌有亿点点杂，基本歌单里什么都沾一点（二次元&amp;欧美占比较大）</p><p>特地开了一个Music版块都是因为——hanser！</p><div style="text-align:center"><iframe width="100%" height="500" src="https://player.bilibili.com/player.html?aid=4848309&amp;bvid=BV1Cs411i7B1&amp;cid=7870718&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></div><p>2016-10-01至今，永远单推憨憨！</p><p><a href="https://imgtu.com/i/4jdP0g"><imgsrc="https://z3.ax1x.com/2021/10/05/4jdP0g.jpg"alt="4jdP0g.jpg" /></a></p><h1 id="enderfga-1">Enderfga。</h1><p>不知不觉写了好多废话了······</p><p>总之，大学生活开始了，希望我能当好一个神奇海螺/哆啦安梦。</p><div data-align="right">----Nothing is true，everything is permitted.</div>]]></content>
    
    
    
    <tags>
      
      <tag>闲谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
